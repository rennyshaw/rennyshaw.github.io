<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2013年7月flash游戏推荐</title>
    <url>/post/aecb2428.html</url>
    <content><![CDATA[<p><img src="/../images/2013%E5%B9%B47%E6%9C%88flash%E6%B8%B8%E6%88%8F%E6%8E%A8%E8%8D%90/clip_image001.jpg" alt="http://cdn.aixifan.com/dotnet/artemis/u/cms/www/201307/301624317w88.jpg"></p>
<p><strong>[**</strong>相关游戏请点击右上角传送门按钮]**</p>
]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>-游戏</tag>
      </tags>
  </entry>
  <entry>
    <title>EFI系统分区设定盘符 取消盘符</title>
    <url>/post/7f94f96a.html</url>
    <content><![CDATA[<p>给EFI系统分区设定盘符Win7 64bit安装后的出现EFI分区，在磁盘管理中右键点击无法指定盘符，可以进行下面的操作。</p>
<h2 id="工具-原料"><a href="#工具-原料" class="headerlink" title="工具/原料"></a>工具/原料</h2><ul>
<li>efi分区格式硬盘</li>
<li>64位系统</li>
</ul>
<h2 id="方法-步骤"><a href="#方法-步骤" class="headerlink" title="方法/步骤"></a>方法/步骤</h2><ol>
<li>—-以管理员身份运行cmd，输入： diskpart sel disk M(M为你的efi分区所在磁盘号，一般为数字0) list part sel part x (x为EFI分区分区号，我的是分区1，类型为“主要”) set id=ebd0a0a2-b9e5-4433-87c0-68b6b72699c7 assign letter=y (y为分配的盘符，任意)</li>
<li>返回EFI系统分区隐藏 —-以管理员身份运行cmd，输入： diskpart sel disk M(M为你的efi分区所在磁盘号，一般为数字0) list part sel part x (x为EFI分区分区号，我的是分区1，类型为“主要”) set id=c12a7328-f81f-11d2-ba4b-00a0c93ec93b （EFI系统分区ID）</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>FreeNas发布共享存储的三种方法</title>
    <url>/post/cde4f897.html</url>
    <content><![CDATA[<p>使用多块磁盘建立raid</p>
<p>Freenas的raid级别定义</p>
<p>raid 0 ———————— stripe</p>
<p>raid 1 ————————mirror</p>
<p>raid 5 ———————– RAID-Z</p>
<p>raid 10 \ raid 6 ————RAID-Z2</p>
<p>\1. 使用多块磁盘建立raid</p>
<p>Freenas的raid级别定义</p>
<p>raid 0 ———————— stripe raid 1 ————————mirror raid 5 ———————– RAID-Z raid 10 \ raid 6 ————RAID-Z2</p>
<p>UFS Volume manager（UFS卷管理）模式下，只能建立raid 0,1,3</p>
<p>ZFS Volume manager（动态文件系统卷管理）模式下，可以建立raid 0,1,5,6,1+0，还可以将磁盘设为备份模式</p>
<p>现在使用ZFS模式，利用4块硬盘建立一个raid 5</p>
<p>这个raid5建好了，少了30G的空间，也就是1.5块磁盘空间（理论上是只少一块盘的空间）</p>
<p>\2. 在新建的raid磁盘上建立2个目录，其中nfs目录等下做NFS共享，cifs目录等下做CIFS共享给windows</p>
<p>\3. 发布NFS共享</p>
<p>选择NFS共享的目录路径 /mnt/raid-5/nfs，然后点击确定</p>
<p>发布出去的NFS共享如下图</p>
<p>由于nfs目录没有给other用户增加写入权限，所以客户端连接过来后是不能写入数据的，需要更改目录权限</p>
<p>\4. 使用esxi进行挂载</p>
<p>成功挂载，如下图</p>
<p>进行写入测试</p>
<p>\5. 发布CIFS共享给windows客户端</p>
<p>发布出去的CIFS共享如下图</p>
<p>由于cifs目录没有给other用户增加写入权限，所以客户端连接过来后是不能写入数据的，需要更改目录权限</p>
<p>\6. 在win 7上进行访问测试</p>
<p>写入测试</p>
<p>\7. 发布iscsi共享存储</p>
<p>小知识：</p>
<p>iSCSI的主要功能是在 TCP/IP 网络上的主机系统（启动器 initiator）和存储设备（目标器 target）之间进行大量数据封装和可靠传输。此外，iSCSI在IP网络封装 SCSI 命令，且运行在TCP上。</p>
<ol>
<li>划分LUN</li>
</ol>
<ol start="2">
<li>启动ISCISI服务，并进入ISCSI配置模式</li>
</ol>
<ol start="3">
<li>配置入口（Portals）</li>
</ol>
<p>4)配置哪些iscsi发起端（Initiator；或者这样；5)配置iscsitarget；6)配置要发布共享的存储资源的范围（也就是第一步；7)将iscsitarget与存储资源的范围进行；8)使用win7自带的iscsi发起程序进行测试；先手动启动iscsiInitiator服务；打开iscsi发起程序，使用快速连接；连接成功后，“磁盘管理”下多了一块2</p>
<hr>
<ol start="4">
<li>配置哪些iscsi发起端（Initiator）可以连接存储服务器</li>
</ol>
<p>或者这样</p>
<ol start="5">
<li>配置iscsi target</li>
</ol>
<ol start="6">
<li>配置要发布共享的存储资源的范围（也就是第一步划分的LUN）</li>
</ol>
<ol start="7">
<li>将iscsi target 与存储资源的范围进行关联，即完成了iscsi的发布</li>
</ol>
<ol start="8">
<li>使用win 7自带的iscsi发起程序进行测试</li>
</ol>
<p>先手动启动iscsi Initiator服务</p>
<p>打开iscsi发起程序，使用快速连接</p>
<p>连接成功后，“磁盘管理”下多了一块20G的硬盘</p>
<p>将硬盘联机 — 初始化（MBR） — 格式化</p>
<p>正在格式化</p>
<p>资源管理里出现了一块20G的新硬盘</p>
<ol start="9">
<li>在ESXI上挂载iscsi资源（需要把刚才已经格式化的硬盘先做“删除卷”操作，然后再把iscsi连接断开。</li>
</ol>
<p>因为ESXI和win 7使用的文件系统不一样，esxi无法识别NTFS的分区，win 7也无法操作ESXI使用的VMFS文件系统，所以这两个无法互操作的主机最好不要同时连接相同的LUN，即使连接上了也无法做任何操作！但是相同的主机类型是可以同时连接的，比如多台esxi主机可以同时连接相同的LUN，这就是虚拟化中所说的共享存储。）</p>
<p>首先配置vswitch，在现有的物理网卡下增加一个端口（port），专门用于esxi和存储服务器通信</p>
<p>给这个端口配置IP地址，最后完成port的创建</p>
<p>配置存储适配器</p>
<p>添加vmkernel端口绑定</p>
<p>选择要与iscsi适配器绑定的vmkernel适配器</p>
<p>绑定成功</p>
<p>使用动态发现搜索iscsi资源（当然也可以使用静；点关闭后提示是否重新扫描适配器，点“是”；再到“存储器”选项卡中去“添加存储器”；最后无脑下一步，填入数据存储名称，再无脑下一步即；浏览数据并进行写入测试，全部OK！；到这里，使用FreeNas发布三种共享（NFS,；</p>
<hr>
<p>使用动态发现搜索iscsi资源（当然也可以使用静态发现输入IP和目标名称来连接存储服务器）</p>
<p>点关闭后提示是否重新扫描适配器，点“是”</p>
<p>再到“存储器”选项卡中去“添加存储器”</p>
<p>最后无脑下一步，填入数据存储名称，再无脑下一步即完成了和iscsi target的连接</p>
<p>浏览数据并进行写入测试，全部OK！</p>
<p>到这里，使用FreeNas发布三种共享（NFS,CIFS,ISCSI）的方法全部over！</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>-linux</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN的数学推导和案例应用</title>
    <url>/post/2379.html</url>
    <content><![CDATA[<blockquote>
<p>本章涉及到的知识点清单：</p>
<p><strong>1、数学期望的定义</strong></p>
<p><strong>2、KL散度的定义</strong></p>
<p><strong>3、零和博弈</strong></p>
<p><strong>4、GAN的工作原理</strong></p>
<p><strong>5、GAN的目标函数</strong></p>
<p><strong>6、求解D的最优解</strong></p>
<p><strong>7、反求解G使得G和D的概率分布差异最小</strong></p>
<p><strong>8、案例之GAN实现拟合二次函数</strong></p>
</blockquote>
<p>在推导GAN公式之前，需要预备一些数学期望和KL散度的知识点</p>
<p>一、数学期望的定义</p>
<p>期望：在概率论中，将实验中<strong>每次可能产生的结果的概率乘以其结果的总和，反映随机变量平均取值的大小</strong>。根据其随机变量的取值范围不同，分为离散型和连续型</p>
<p>对于连续型随机变量x，其概率密度函数为f(x)，则X的数学期望E(x)可以表示成微积分的形式</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194302590.png" alt="img"></p>
<p>二、KL散度的定义</p>
<p>KL散度：在信息论中，<strong>用生成的概率分布Q来拟合逼近真实的概率分布P时，所产生的信息损耗</strong>，即描述两个概率分布的差异，其本身是非对称的</p>
<p>设x是连续型随机变量，其真实概率分布为P(x)，拟合分布概率为Q(x)，则P对Q的KL散度为</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194324640.png" alt="img"></p>
<p>三、零和博弈</p>
<p><strong>GAN被称为对抗式神经网络，启发自博弈论中的二人零和博弈</strong></p>
<p>零和博弈：<strong>指参与博弈的双方，在严格的竞争下，一方的收益必然意味着另一方的损失，博弈过程中，双方的各自收益和损失的相加总和永远为零，双方完全不存在合作的可能</strong>。就好比下棋一样，你和对手的每一步棋都是向着自己最有利的方向走，最终只有一方赢一方输，而下棋的总成绩永远为零</p>
<p>显然，GAN也是由博弈双方组成，分别为<strong>生成网络G（Generator）和判别网络D（Discriminator）</strong></p>
<p>四、GAN的工作原理</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194349495.jpg" alt="img"></p>
<p>GAN的工作过程</p>
<p>上图中，x是真实数据，Pdata(x)是x的概率分布，z是噪点数据，P(z)是z的概率分布，其工作过程为：</p>
<blockquote>
<p><strong>(1)：从噪声z进行随机抽样，传入G网络，生成新数据G(z)和其概率分布Pg(G(z))</strong></p>
<p><strong>(2)：将真实数据和G生成的新数据一起传入D网络进行真假判别，通过sigmoid函数来输出判定类别</strong></p>
<p><strong>(3)：迭代优化D和G损失函数，根据D来调整G</strong></p>
<p><strong>(4)：直到D和G达到收敛，即D无法判断G产生数据的真假性，即Pg(G(z))已经非常逼近Pdata(x)</strong></p>
</blockquote>
<p>至此，我们可以抽象看出GAN的目的，<strong>将随机噪声z通过G网络得到一个和真实数据分布Pdata(x)差不多的生成分布Pg(G(z))，这个过程就是G和D相互博弈的过程</strong></p>
<p>五、GAN的目标函数</p>
<p>定义GAN的目标函数为V(G，D)，在博弈过程中，G希望减少V的值让自己生成的分布无法识别，而D希望增大V的值让自己可以高效的判别出数据的真假类别，则V(G，D)的表达式为</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194407390.png" alt="img"></p>
<p>目标函数</p>
<p>其中E表示真实数据x和噪点数据z的数学期望</p>
<p>G网络是一个生成器，可以是全连接神经网络、卷积神经网络等等，通过噪点分布P(z)，一般是高斯分布，得到一个生成数据的分布Pg(x)，我们希望Pg(x)非常靠近Pdata(x)，来拟合逼近真实分布</p>
<p>D网络是一个判别函数，需要解决传统的二分类问题，其职责就是有效的区分真实分布和生成分布，即衡量Pg(x)和Pdata(x)之间的差距，并通过反复的迭代训练</p>
<p>六、求解D的最优解</p>
<p>从目标函数出发，由于V是连续的，我们将V写成微积分的形式来表示期望</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/2018122619450691.png" alt="img"></p>
<p>目标函数的积分形式1</p>
<p>设G(z)生成的数据是x，分别求出噪点z和噪点的微分dz表达式</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194521503.png" alt="img"></p>
<p>z和dz关于x的表达式</p>
<p>带入z和dz，可以得到</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194659286.png" alt="img"></p>
<p>目标函数的积分形式2</p>
<p>我们定义Pg(x)表示z的生成分布，则</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/2018122619474799.png" alt="img"></p>
<p>生成分布Pg(x)</p>
<p>带入目标函数可得</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194811812.png" alt="img"></p>
<p>目标函数的积分形式3</p>
<p>现在要求V(D，G)关于D的最大值，则固定G来求D的偏导数</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194831825.png" alt="img"></p>
<p>求解D的最大值</p>
<p>七、反求解G使得G和D的概率分布差异最小</p>
<p>从D(x)的最优解D*(X)的表达式可以看到，我们期望当G产生出来的拟合分布和真实分布一致时，即</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/2018122619485130.png" alt="img"></p>
<p>拟合分布和真实分布一致</p>
<p>在这个条件下，D*(x)=1/2，<strong>即此时D网络已经无法直接分辨出G产生出来的数据的真假性了</strong></p>
<p>那么当D满足最优解后，此时的G的解是什么呢？我们只需要带入D*(x)反过来求解G即可</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194914915.png" alt="img"></p>
<p>带入D*(x)求出C(G)积分式</p>
<p>我们对上述积分表达式进行等效处理，在log里面的分式上，分子分母同时除以2（分式不变原理），然后保持分母不变，将分子的1/2利用对数的乘法原理提到外面，则上式可以等效变形为</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226195008106.png" alt="img"></p>
<p>等效变化C(G)积分式</p>
<p>我们引入连续函数的KL散度将上式积分式整理成散度表达式</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226195102873.png" alt="img"></p>
<p>C(G)散度表达式</p>
<p>根据KL散度的定义，当拟合分布Pg(x)完全等于真实分布Pdata(x)时，KL=0，所以G网络的最小值是-log4</p>
<p>由此证明了当D网络逼近其最优解的同时，G网络也无限逼近其最小值</p>
<p>八、案例之GAN实现拟合二次函数</p>
<p>有G网络和D网络的意义，我们编写如下代码来拟合二次函数，其中G网络只是一个全连接网络，利用梯度下降来反向传播更新其权重</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194020811.png" alt="img"></p>
<p>G网络和D网络</p>
<p>迭代5000次后的博弈结果为</p>
<p>训练开始的生成分布</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/20181226194108608.png" alt="img"></p>
<p>训练结束的生成分布</p>
<p><img src="/../images/GAN%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E5%92%8C%E6%A1%88%E4%BE%8B%E5%BA%94%E7%94%A8/2018122619412674.png" alt="img"></p>
<p>从结果上可以看到，G网络生成的分布(绿色)已经非常逼近真实分布(蓝色)，且D网络的判别能力逼近50%，G网络的最优值逼近-log4=1.38629达到了很好的收敛效果</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>A Song of Ice and Fire冰与火之歌Game of Thrones权力的游戏</title>
    <url>/post/bec41196.html</url>
    <content><![CDATA[<p><img src="/../images/%E6%9D%83%E5%8A%9B%E7%9A%84%E6%B8%B8%E6%88%8F/ac6eddc451da81cb97a797275866d01608243192.jpg" alt="img"> </p>
<p>《权力的游戏第六季》</p>
<p><a href="http://www.zxba.cc/ju/oumeiju/14138/">http://www.zxba.cc/ju/oumeiju/14138/</a></p>
<p>《权力的游戏第六季》</p>
<p><a href="http://ftgherys3.top/dsj/oumei/quanlideyouxidiliuji/index.html">http://ftgherys3.top/dsj/oumei/quanlideyouxidiliuji/index.html</a></p>
<p>权力的游戏第六季1-7集下载_权力的游戏无删减版下载_权力的游戏第六季未删减版下载_追剧_游魂岛</p>
<p><a href="http://www.youhundao.com/zhuiju/quanli/">http://www.youhundao.com/zhuiju/quanli/</a></p>
<p>《权力的游戏》</p>
<p><a href="http://www.ttmeiju.com/meiju/Game.of.Thrones.html">http://www.ttmeiju.com/meiju/Game.of.Thrones.html</a></p>
]]></content>
      <categories>
        <category>电影</category>
      </categories>
      <tags>
        <tag>-电影</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN生成对抗式神经网络实际操作</title>
    <url>/post/22f26062.html</url>
    <content><![CDATA[<p><a href="https://aichn.cn/post/5b91f628.html">上一篇文章</a>我们强力推导了GAN的数学公式，它就是：<br>$$<br>V = E _ { x \sim P _ { \text {data} } } [ \log D ( x ) ] + E _ { x \sim P _ { G } } [ \log ( 1 - D ( x ) ) ]<br>$$<br>在我们训练D网络的时候，我们要让V最大化，当我们训练G网络的时候我们要让V最小化，就是这么简单。因此哪怕数学推导那篇五六千字的博客不想看，实做也可以做。</p>
<p>实做上比较大的一个问题是我们实际上不能获取到全部真实图像样本和全部拟合图像样本。因此上面这道公式在实做上是搞不成的。</p>
<p>我们采取的方法是抽样。也就是从<br>$$<br>P _ { \text {data} }(x)<br>$$<br>中抽出m个样本，写作<br>$$<br>{ x ^ { 1 } , x ^ { 2 } , \ldots , x ^ { m } }，<br>$$<br>再从<br>$$<br>P _ { \text {G} }(x)<br>$$<br>中抽出m个样本，写作<br>$$<br>{ \tilde { x } ^ { 1 } , \tilde { x } ^ { 2 } , \ldots , \tilde { x } ^ { m } }，<br>$$<br>然后我们认为这m个样本的分布和总体的分布就差不多了。那么上面的公式就变成下面这个样子：<br>$$<br>\tilde { V } = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \log D \left( x ^ { i } \right) + \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \log \left( 1 - D \left( \tilde { x } ^ { i } \right) \right)<br>$$<br>当然可能有人会说，这样不就存在着误差吗？</p>
<p>是的，但这个误差会随着样本的增多和样本分布的合理化而减小，因此我们在选样本的时候还是要注意样本的数量和分布的合理性。不要搞10张样本就拿来训练，起码是“万”级别的，且如果你想生成的是猫的图像，不要选几万张“白”猫，因为那样生成网络和判别网络均会认为猫就是白色的，没有别的颜色。</p>
<p>OK，分析完误差之后我们假定样本是十分给力的，那么我们就能根据面这道公式来做计算。</p>
<p>首先看到D网络，我们要做的是最大化上面这个<br>$$<br>\tilde { V }<br>$$<br>，先来看看logx长什么样。<br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C/20181228105228842.png" alt="在这里插入图片描述"><br>可以看出它是一个单调递增的函数，因此要<br>$$<br>\tilde { V }<br>$$<br>取得最大值，其实就是要<br>$$<br>\frac { 1 } { m } \sum _ { i = 1 } ^ { m } \log D \left( x ^ { i } \right)和\frac { 1 } { m } \sum _ { i = 1 } ^ { m } \log \left( 1 - D \left( \tilde { x } ^ { i } \right) \right)<br>$$<br>分别取得最大值。也就是要<br>$$<br>D \left( x ^ { i } \right)<br>$$<br>取得最大值，<br>$$<br>1 - D \left( \tilde { x } ^ { i } \right)<br>$$<br>取得最大值。因此，我们只需要在输入真实样本的时候尽量让D网络输出1，而输入拟合样本的时候让网络尽量输出0就搞定了。</p>
<p>这里有个非常神奇的地方，就是我们要求的这道式子跟二分类问题的交叉熵损失函数居然长的是一样的。我们先看看二分类问题的交叉熵损失函数长什么样：<br>$$<br>-\sum _ { i = 1 } ^ { m }p \left( x _ { i } \right)\log q \left( x _ { i } \right)-\sum _ { i = 1 } ^ { m }(1-p \left( x _ { i } \right))\log (1-q \left( \tilde { x } _ { i } \right))<br>$$<br>这里因为是二分问题，因此<br>$$<br>p \left( x _ { i } \right)<br>$$<br>在正样本中等于1，在负样本中等于0，这个时候上面的式子变成：<br>$$<br>-\sum _ { i = 1 } ^ { m }\log q \left( x _ { i } \right)-\sum _ { i = 1 } ^ { m }\log (1-q \left( \tilde { x } _ { i } \right))<br>$$<br>这道式子忽略掉常数项刚刚好是V取反。而我们本来求D网络就是求V取最大值的情况，一旦给V取反，则变成求最小值，直接等于损失函数的目标！真是不要太方便！</p>
<p>那么具体流程是什么呢？</p>
<p>1.从<br>$$<br>P _ { \text {data} }(x)<br>$$<br>中抽出m个样本，写作<br>$$<br>{ x ^ { 1 } , x ^ { 2 } , \ldots , x ^ { m } }，<br>$$<br>再从<br>$$<br>P _ { \text {G} }(x)<br>$$<br>中抽出m个样本（也就是让G网络生成m个样本），写作<br>$$<br>{ \tilde { x } ^ { 1 } , \tilde { x } ^ { 2 } , \ldots , \tilde { x } ^ { m } }<br>$$<br>2.用二分问题的交叉熵损失函数作为损失函数，然后用样本对网络进行训练，完事，就是这么简单。</p>
<p>再来看看G网络，我们从前面已经知道G网络的目标是最小化：<br>$$<br>\tilde { V } = \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \log D \left( x ^ { i } \right) + \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \log \left( 1 - D \left( \tilde { x } ^ { i } \right) \right)<br>$$<br>因为在训练G网络的时候，D网络是不变的，因此上面式子左边的一项是不变的，相当于一个常数。而对于最小化问题来说，常数是不影响结果的，因此我们其实是在最小化：<br>$$<br>\tilde { V }_G= \frac { 1 } { m } \sum _ { i = 1 } ^ { m } \log \left( 1 - D \left( \tilde { x } ^ { i } \right) \right)<br>$$<br>按理说按照上面所述已经可以开始写代码了。但实际上还有个操作上的问题，这个问题出在log(1−x)这个函数上，它长这样：<br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C/20181228105242348.png" alt="在这里插入图片描述"><br>可以看到当x接近1的时候该函数相当的陡峭，而在0附近它却不是很陡（其实对log(1−x)求下导就可以知道它的导数的绝对值是逐步增大的，也就是它渐渐变陡）。这有什么问题呢？</p>
<p>问题就在于一开始的时候因为G网络的参数是接近随机的，基本上骗不过D网络，因此<br>$$<br>D \left( \tilde { x } ^ { i } \right)<br>$$<br>这个东西在一开始的时候总会输出接近0的数。而从上面我们知道，如果越接近0，那么log(1−x)这个损失函数就越平。而在训练后期，<br>$$<br>D \left( \tilde { x } ^ { i } \right)<br>$$<br>会慢慢增加（最理想是0.5），这个时候log(1−x)损失函数却越变越陡。这跟我们需要的是完全相反的！我们希望的是一开始训练快速收缩到最优解附近，然后慢慢调整找到最优解，而它反过来。因此虽然理论上那么列式是完全合理的，但实际上用这么一个损失函数会使得训练比较崩溃，十分的反直觉。因此为了解决这个问题，GAN用的损失函数并不是log(1−x)，而是−log(x)：<br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C/20181228112241677.png" alt="在这里插入图片描述"><br>这个损失函数就牛逼了，单调性和log(1−x)一样，且陡峭程度变化完全符合我们的要求。因此我们真正训练G网络的时候用的是它。但这么改有个问题，就是我们本来G网络训练的是一个JS距离，现在训练的却不知道是个啥，只知道它大致等价于JS距离。不过这个问题好像也不是很要紧，总之我们训练的是这个式子：<br>$$<br>\tilde { V }_G= -\frac { 1 } { m } \sum _ { i = 1 } ^ { m } \log \left(D \left( \tilde { x } ^ { i } \right) \right)<br>$$<br>看到这个式子再联系上面的D网络，聪明的你可能发现它长得和二分类问题的交叉熵损失函数输入正样本的情况又是一模一样的（除了个没多大所谓的常数项）。这在我们实际操作中简直不要太方便！具体流程是：</p>
<p>1.从z中抽出m个样本，写作<br>$$<br>{ \tilde { z } ^ { 1 } , \tilde { z } ^ { 2 } , \ldots , \tilde { z } ^ { m } }<br>$$<br>2.用二分问题的交叉熵损失函数作为损失函数，然后用样本对网络进行训练，大功告成！</p>
<p>那么具体的训练过程大概总结下是这个样子的，先定住G网络训练几次D网络，再定住D网络训练一次G网络，循环往复就行了。为什么是几次和一次呢？</p>
<p>首先，因为我们希望D网络这把尺子准一点，最好每次都找到全局最优解，这样能更好的指导G网络。</p>
<p>其次，我们希望G网络每次不要更新太多，具体可见下图：<br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C/20181228105313523.png" alt="在这里插入图片描述"><br>如果更新太多，G网络的形状可能会从左边变到右边，这样D网络的最大值点会到处飘，比较难训练。</p>
<p>下面放上实现代码，非常简单。主要参考的《深度学习框架PyTorch：入门与实践》这本书的代码，本人把其他复杂的东西删掉了，就剩下最简单的实现部分，这样看起来清楚点。</p>
<p><a href="http://model.py/">model.py</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding:utf-8</span><br><span class="line">from torch import nn</span><br><span class="line"></span><br><span class="line">class NetG(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    生成器定义</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, opt):</span><br><span class="line">        super(NetG, self).__init__()</span><br><span class="line">        ngf &#x3D; opt.ngf  # 生成器feature map数</span><br><span class="line"></span><br><span class="line">        self.main &#x3D; nn.Sequential(</span><br><span class="line">            # 输入是一个nz维度的噪声，我们可以认为它是一个1*1*nz的feature map</span><br><span class="line">            nn.ConvTranspose2d(opt.nz, ngf * 8, 4, 1, 0, bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(ngf * 8),</span><br><span class="line">            nn.ReLU(True),</span><br><span class="line">            # 上一步的输出形状：(ngf*8) x 4 x 4</span><br><span class="line"></span><br><span class="line">            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(ngf * 4),</span><br><span class="line">            nn.ReLU(True),</span><br><span class="line">            # 上一步的输出形状： (ngf*4) x 8 x 8</span><br><span class="line"></span><br><span class="line">            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(ngf * 2),</span><br><span class="line">            nn.ReLU(True),</span><br><span class="line">            # 上一步的输出形状： (ngf*2) x 16 x 16</span><br><span class="line"></span><br><span class="line">            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(ngf),</span><br><span class="line">            nn.ReLU(True),</span><br><span class="line">            # 上一步的输出形状：(ngf) x 32 x 32</span><br><span class="line"></span><br><span class="line">            nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias&#x3D;False),</span><br><span class="line">            nn.Tanh()  # 输出范围 -1~1 故而采用Tanh</span><br><span class="line">            # 输出形状：3 x 96 x 96</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        return self.main(input)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class NetD(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    判别器定义</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, opt):</span><br><span class="line">        super(NetD, self).__init__()</span><br><span class="line">        ndf &#x3D; opt.ndf</span><br><span class="line">        self.main &#x3D; nn.Sequential(</span><br><span class="line">            # 输入 3 x 96 x 96</span><br><span class="line">            nn.Conv2d(3, ndf, 5, 3, 1, bias&#x3D;False),</span><br><span class="line">            nn.LeakyReLU(0.2, inplace&#x3D;True),</span><br><span class="line">            # 输出 (ndf) x 32 x 32</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(ndf * 2),</span><br><span class="line">            nn.LeakyReLU(0.2, inplace&#x3D;True),</span><br><span class="line">            # 输出 (ndf*2) x 16 x 16</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(ndf * 4),</span><br><span class="line">            nn.LeakyReLU(0.2, inplace&#x3D;True),</span><br><span class="line">            # 输出 (ndf*4) x 8 x 8</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias&#x3D;False),</span><br><span class="line">            nn.BatchNorm2d(ndf * 8),</span><br><span class="line">            nn.LeakyReLU(0.2, inplace&#x3D;True),</span><br><span class="line">            # 输出 (ndf*8) x 4 x 4</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias&#x3D;False),</span><br><span class="line">            nn.Sigmoid()  # 输出一个数(概率)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        return self.main(input).view(-1)</span><br></pre></td></tr></table></figure>
<p><a href="http://main.py/">main.py</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding:utf-8</span><br><span class="line">import os</span><br><span class="line">import torch as t</span><br><span class="line">import torchvision as tv</span><br><span class="line">import tqdm</span><br><span class="line">from model import NetG, NetD</span><br><span class="line"></span><br><span class="line">class Config(object):</span><br><span class="line">    data_path &#x3D; &#39;data&#x2F;&#39;  # 数据集存放路径</span><br><span class="line">    num_workers &#x3D; 4  # 多进程加载数据所用的进程数</span><br><span class="line">    image_size &#x3D; 96  # 图片尺寸</span><br><span class="line">    batch_size &#x3D; 256  #一次训练样本数</span><br><span class="line">    max_epoch &#x3D; 200  #最大训练次数</span><br><span class="line">    lr1 &#x3D; 2e-4  # 生成器的学习率</span><br><span class="line">    lr2 &#x3D; 2e-4  # 判别器的学习率</span><br><span class="line">    beta1 &#x3D; 0.5  # Adam优化器的beta1参数</span><br><span class="line">    gpu &#x3D; True  # 是否使用GPU</span><br><span class="line">    nz &#x3D; 100  # 噪声维度</span><br><span class="line">    ngf &#x3D; 64  # 生成器feature map数</span><br><span class="line">    ndf &#x3D; 64  # 判别器feature map数</span><br><span class="line"></span><br><span class="line">    save_path &#x3D; &#39;imgs&#x2F;&#39;  # 生成图片保存路径</span><br><span class="line">    d_every &#x3D; 1  # 每1个batch训练一次判别器</span><br><span class="line">    g_every &#x3D; 5  # 每5个batch训练一次生成器</span><br><span class="line">    save_every &#x3D; 1  # 每1个epoch保存一次模型</span><br><span class="line">    #netd_path &#x3D; &#39;checkpoints&#x2F;netd.pth&#39;</span><br><span class="line">    #netg_path &#x3D; &#39;checkpoints&#x2F;netg.pth&#39;</span><br><span class="line">    netd_path &#x3D; None</span><br><span class="line">    netg_path &#x3D; None</span><br><span class="line"></span><br><span class="line">opt &#x3D; Config()</span><br><span class="line"></span><br><span class="line">def train():</span><br><span class="line">    device&#x3D;t.device(&#39;cuda&#39;) if opt.gpu else t.device(&#39;cpu&#39;)</span><br><span class="line"></span><br><span class="line">    # 读入数据格式转换</span><br><span class="line">    transforms &#x3D; tv.transforms.Compose([</span><br><span class="line">        tv.transforms.Resize(opt.image_size),#图像尺寸缩放</span><br><span class="line">        tv.transforms.ToTensor(),</span><br><span class="line">        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))#先将数据归一化到（0,1），再用公式(x-mean)&#x2F;std将每个元素分布到（-1,1）</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    dataset &#x3D; tv.datasets.ImageFolder(opt.data_path, transform&#x3D;transforms)</span><br><span class="line">    dataloader &#x3D; t.utils.data.DataLoader(dataset,</span><br><span class="line">                                         batch_size&#x3D;opt.batch_size,</span><br><span class="line">                                         shuffle&#x3D;True,</span><br><span class="line">                                         num_workers&#x3D;opt.num_workers,</span><br><span class="line">                                         drop_last&#x3D;True</span><br><span class="line">                                         )</span><br><span class="line"></span><br><span class="line">    # 网络初始化，如有预训练模型则读入</span><br><span class="line">    netg, netd &#x3D; NetG(opt), NetD(opt)</span><br><span class="line">    map_location &#x3D; lambda storage, loc: storage</span><br><span class="line">    if opt.netd_path:</span><br><span class="line">        netd.load_state_dict(t.load(opt.netd_path, map_location&#x3D;map_location))</span><br><span class="line">    if opt.netg_path:</span><br><span class="line">        netg.load_state_dict(t.load(opt.netg_path, map_location&#x3D;map_location))</span><br><span class="line">    netd.to(device)</span><br><span class="line">    netg.to(device)</span><br><span class="line"></span><br><span class="line">    # 定义优化器和损失函数</span><br><span class="line">    optimizer_g &#x3D; t.optim.Adam(netg.parameters(), opt.lr1, betas&#x3D;(opt.beta1, 0.999))</span><br><span class="line">    optimizer_d &#x3D; t.optim.Adam(netd.parameters(), opt.lr2, betas&#x3D;(opt.beta1, 0.999))</span><br><span class="line">    criterion &#x3D; t.nn.BCELoss().to(device)</span><br><span class="line"></span><br><span class="line">    # 真图片label为1，假图片label为0</span><br><span class="line">    # noises为生成网络的输入</span><br><span class="line">    true_labels &#x3D; t.ones(opt.batch_size).to(device)</span><br><span class="line">    fake_labels &#x3D; t.zeros(opt.batch_size).to(device)</span><br><span class="line">    fix_noises &#x3D; t.randn(opt.batch_size, opt.nz, 1, 1).to(device)#产生正态分布的随机数，也就是G网络的z</span><br><span class="line">    noises &#x3D; t.randn(opt.batch_size, opt.nz, 1, 1).to(device)</span><br><span class="line"></span><br><span class="line">    epochs &#x3D; range(opt.max_epoch)</span><br><span class="line">    for epoch in iter(epochs):</span><br><span class="line">        for ii, (img, _) in tqdm.tqdm(enumerate(dataloader)):</span><br><span class="line">            real_img &#x3D; img.to(device)</span><br><span class="line"></span><br><span class="line">            if ii % opt.d_every &#x3D;&#x3D; 0:</span><br><span class="line">                # 训练判别器</span><br><span class="line">                optimizer_d.zero_grad()#清空节点值</span><br><span class="line">                ## 尽可能的把真图片判别为正确</span><br><span class="line">                output &#x3D; netd(real_img)</span><br><span class="line">                error_d_real &#x3D; criterion(output, true_labels)</span><br><span class="line">                error_d_real.backward()</span><br><span class="line"></span><br><span class="line">                ## 尽可能把假图片判别为错误</span><br><span class="line">                noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))</span><br><span class="line">                fake_img &#x3D; netg(noises).detach()  # 根据噪声生成假图</span><br><span class="line">                output &#x3D; netd(fake_img)</span><br><span class="line">                error_d_fake &#x3D; criterion(output, fake_labels)</span><br><span class="line">                error_d_fake.backward()</span><br><span class="line">                optimizer_d.step()</span><br><span class="line"></span><br><span class="line">            if ii % opt.g_every &#x3D;&#x3D; 0:</span><br><span class="line">                # 训练生成器</span><br><span class="line">                optimizer_g.zero_grad()</span><br><span class="line">                noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))</span><br><span class="line">                fake_img &#x3D; netg(noises)</span><br><span class="line">                output &#x3D; netd(fake_img)</span><br><span class="line">                error_g &#x3D; criterion(output, true_labels)</span><br><span class="line">                error_g.backward()</span><br><span class="line">                optimizer_g.step()</span><br><span class="line"></span><br><span class="line">        if (epoch+1) % opt.save_every &#x3D;&#x3D; 0:</span><br><span class="line">            # 保存模型、图片</span><br><span class="line">            fix_fake_imgs &#x3D; netg(fix_noises)</span><br><span class="line">            tv.utils.save_image(fix_fake_imgs.data[:64], &#39;%s&#x2F;%s.png&#39; % (opt.save_path, epoch), normalize&#x3D;True,range&#x3D;(-1, 1))</span><br><span class="line">            t.save(netd.state_dict(), &#39;checkpoints&#x2F;netd.pth&#39;)</span><br><span class="line">            t.save(netg.state_dict(), &#39;checkpoints&#x2F;netg.pth&#39;)</span><br><span class="line">            t.save(netd.state_dict(), &#39;checkpoints&#x2F;netd_%s.pth&#39; % epoch)</span><br><span class="line">            t.save(netg.state_dict(), &#39;checkpoints&#x2F;netg_%s.pth&#39; % epoch)</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    train()</span><br></pre></td></tr></table></figure>
<p>一开始训练得到的图如下的一坨：<br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C/20181228105416232.png" alt="在这里插入图片描述"><br>后面训练了一百多个轮次之后渐渐好了起来：<br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C/20181228105426838.png" alt="在这里插入图片描述"><br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C/20190210180619325.png" alt="在这里插入图片描述"><br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E9%99%85%E6%93%8D%E4%BD%9C/20190210180625909.png" alt="在这里插入图片描述"><br>可以看到有些图片已经有模有样了，但有些还蛮崩坏的。这跟原生GAN的一些缺陷有关系，比如说DD网络容易过拟合，或者GG网络分布远远不足以覆盖目标子集，距离一直很大等等。这个在后面的改进版本逐步得到解决，会在以后研究到的时候跟大家分享。当然也可以直接去Bilibili看看李宏毅教授的视频，讲得非常给力！</p>
<p>另外如果希望用可视化工具visdom，可以将main.py的代码修改如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding:utf-8</span><br><span class="line">import os</span><br><span class="line">import torch as t</span><br><span class="line">import torchvision as tv</span><br><span class="line">import tqdm</span><br><span class="line">from model import NetG, NetD</span><br><span class="line">import visdom</span><br><span class="line"></span><br><span class="line">class Config(object):</span><br><span class="line">    data_path &#x3D; &#39;data&#x2F;&#39;  # 数据集存放路径</span><br><span class="line">    num_workers &#x3D; 4  # 多进程加载数据所用的进程数</span><br><span class="line">    image_size &#x3D; 96  # 图片尺寸</span><br><span class="line">    batch_size &#x3D; 256  #一次训练样本数</span><br><span class="line">    max_epoch &#x3D; 200  #最大训练次数</span><br><span class="line">    lr1 &#x3D; 2e-4  # 生成器的学习率</span><br><span class="line">    lr2 &#x3D; 2e-4  # 判别器的学习率</span><br><span class="line">    beta1 &#x3D; 0.5  # Adam优化器的beta1参数</span><br><span class="line">    gpu &#x3D; True  # 是否使用GPU</span><br><span class="line">    nz &#x3D; 100  # 噪声维度</span><br><span class="line">    ngf &#x3D; 64  # 生成器feature map数</span><br><span class="line">    ndf &#x3D; 64  # 判别器feature map数</span><br><span class="line"></span><br><span class="line">    save_path &#x3D; &#39;imgs&#x2F;&#39;  # 生成图片保存路径</span><br><span class="line">    d_every &#x3D; 1  # 每1个batch训练一次判别器</span><br><span class="line">    g_every &#x3D; 5  # 每5个batch训练一次生成器</span><br><span class="line">    save_every &#x3D; 1  # 每1个epoch保存一次模型</span><br><span class="line">    #netd_path &#x3D; &#39;checkpoints&#x2F;netd.pth&#39;</span><br><span class="line">    #netg_path &#x3D; &#39;checkpoints&#x2F;netg.pth&#39;</span><br><span class="line">    netd_path &#x3D; None</span><br><span class="line">    netg_path &#x3D; None</span><br><span class="line"></span><br><span class="line">opt &#x3D; Config()</span><br><span class="line"></span><br><span class="line">def train():</span><br><span class="line">    device&#x3D;t.device(&#39;cuda&#39;) if opt.gpu else t.device(&#39;cpu&#39;)</span><br><span class="line"></span><br><span class="line">    # 读入数据格式转换</span><br><span class="line">    transforms &#x3D; tv.transforms.Compose([</span><br><span class="line">        tv.transforms.Resize(opt.image_size),#图像尺寸缩放</span><br><span class="line">        tv.transforms.ToTensor(),</span><br><span class="line">        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))#先将数据归一化到（0,1），再用公式(x-mean)&#x2F;std将每个元素分布到（-1,1）</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    dataset &#x3D; tv.datasets.ImageFolder(opt.data_path, transform&#x3D;transforms)</span><br><span class="line">    dataloader &#x3D; t.utils.data.DataLoader(dataset,</span><br><span class="line">                                         batch_size&#x3D;opt.batch_size,</span><br><span class="line">                                         shuffle&#x3D;True,</span><br><span class="line">                                         num_workers&#x3D;opt.num_workers,</span><br><span class="line">                                         drop_last&#x3D;True</span><br><span class="line">                                         )</span><br><span class="line"></span><br><span class="line">    # 网络初始化，如有预训练模型则读入</span><br><span class="line">    netg, netd &#x3D; NetG(opt), NetD(opt)</span><br><span class="line">    map_location &#x3D; lambda storage, loc: storage</span><br><span class="line">    if opt.netd_path:</span><br><span class="line">        netd.load_state_dict(t.load(opt.netd_path, map_location&#x3D;map_location))</span><br><span class="line">    if opt.netg_path:</span><br><span class="line">        netg.load_state_dict(t.load(opt.netg_path, map_location&#x3D;map_location))</span><br><span class="line">    netd.to(device)</span><br><span class="line">    netg.to(device)</span><br><span class="line"></span><br><span class="line">    # 定义优化器和损失函数</span><br><span class="line">    optimizer_g &#x3D; t.optim.Adam(netg.parameters(), opt.lr1, betas&#x3D;(opt.beta1, 0.999))</span><br><span class="line">    optimizer_d &#x3D; t.optim.Adam(netd.parameters(), opt.lr2, betas&#x3D;(opt.beta1, 0.999))</span><br><span class="line">    criterion &#x3D; t.nn.BCELoss().to(device)</span><br><span class="line"></span><br><span class="line">    # 真图片label为1，假图片label为0</span><br><span class="line">    # noises为生成网络的输入</span><br><span class="line">    true_labels &#x3D; t.ones(opt.batch_size).to(device)</span><br><span class="line">    fake_labels &#x3D; t.zeros(opt.batch_size).to(device)</span><br><span class="line">    fix_noises &#x3D; t.randn(opt.batch_size, opt.nz, 1, 1).to(device)#产生正态分布的随机数，也就是G网络的z</span><br><span class="line">    noises &#x3D; t.randn(opt.batch_size, opt.nz, 1, 1).to(device)</span><br><span class="line"></span><br><span class="line">    #可视化</span><br><span class="line">    vis &#x3D; visdom.Visdom()</span><br><span class="line"></span><br><span class="line">    epochs &#x3D; range(opt.max_epoch)</span><br><span class="line">    for epoch in iter(epochs):</span><br><span class="line">        for ii, (img, _) in tqdm.tqdm(enumerate(dataloader)):</span><br><span class="line">            real_img &#x3D; img.to(device)</span><br><span class="line"></span><br><span class="line">            if ii % opt.d_every &#x3D;&#x3D; 0:</span><br><span class="line">                # 训练判别器</span><br><span class="line">                optimizer_d.zero_grad()#清空节点值</span><br><span class="line">                ## 尽可能的把真图片判别为正确</span><br><span class="line">                output &#x3D; netd(real_img)</span><br><span class="line">                error_d_real &#x3D; criterion(output, true_labels)</span><br><span class="line">                error_d_real.backward()</span><br><span class="line"></span><br><span class="line">                ## 尽可能把假图片判别为错误</span><br><span class="line">                noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))</span><br><span class="line">                fake_img &#x3D; netg(noises).detach()  # 根据噪声生成假图</span><br><span class="line">                output &#x3D; netd(fake_img)</span><br><span class="line">                error_d_fake &#x3D; criterion(output, fake_labels)</span><br><span class="line">                error_d_fake.backward()</span><br><span class="line">                optimizer_d.step()</span><br><span class="line"></span><br><span class="line">            if ii % opt.g_every &#x3D;&#x3D; 0:</span><br><span class="line">                # 训练生成器</span><br><span class="line">                optimizer_g.zero_grad()</span><br><span class="line">                noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))</span><br><span class="line">                fake_img &#x3D; netg(noises)</span><br><span class="line">                output &#x3D; netd(fake_img)</span><br><span class="line">                error_g &#x3D; criterion(output, true_labels)</span><br><span class="line">                error_g.backward()</span><br><span class="line">                optimizer_g.step()</span><br><span class="line"></span><br><span class="line">        if (epoch+1) % opt.save_every &#x3D;&#x3D; 0:</span><br><span class="line">            # 保存模型、图片</span><br><span class="line">            fix_fake_imgs &#x3D; netg(fix_noises)</span><br><span class="line">            tv.utils.save_image(fix_fake_imgs.data[:64], &#39;%s&#x2F;%s.png&#39; % (opt.save_path, epoch), normalize&#x3D;True,range&#x3D;(-1, 1))</span><br><span class="line">            vis.images(fix_fake_imgs.detach().cpu().numpy()[:64] * 0.5 + 0.5, win&#x3D;&#39;fixfake&#39;)</span><br><span class="line">            t.save(netd.state_dict(), &#39;checkpoints&#x2F;netd.pth&#39;)</span><br><span class="line">            t.save(netg.state_dict(), &#39;checkpoints&#x2F;netg.pth&#39;)</span><br><span class="line">            t.save(netd.state_dict(), &#39;checkpoints&#x2F;netd_%s.pth&#39; % epoch)</span><br><span class="line">            t.save(netg.state_dict(), &#39;checkpoints&#x2F;netg_%s.pth&#39; % epoch)</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    train()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN生成对抗式神经网络数学推导</title>
    <url>/post/5b91f628.html</url>
    <content><![CDATA[<p>由<a href="https://aichn.cn/post/fbf175a6.html">上面一篇文章</a>我们已经知道了，如果我们从真实数据分布里面取n个样本，根据给定样本我们可以列出其出现概率的表达式，那么生成这N个样本数据的似然(likelihood)就是<br>$$<br>l ( \theta )= \prod _ { i = 1 } ^ { N } p \left( x _ { i } | \theta \right)<br>$$<br>我们要找到\thetaθ来最大化这个函数，便是极大似然估计，公式如下：<br>$$<br>\hat { \theta } = \arg \max _ { \theta } H ( \theta ) = \arg \max _ { \theta } \ln l ( \theta ) = \arg \max _ { \theta } \sum _ { i = 1 } ^ { N } \ln p \left( x _ { i } | \theta \right)<br>$$<br>那么下面我们来看看GAN的推导。</p>
<p>在极大似然估计中，我们假定要求的事物有一个固定的模型，写作<br>$$<br>P_{data}(x)Pdata(x)<br>$$<br>，但这个模型十分复杂，我们无法完全彻底的去刻画它，只能列一个带有参数的式子，然后用模型抽样出来的样本去估计出这个参数到底最有可能是什么。</p>
<p>打个比方，有一个箱子，里面有一百多亿个球，球的颜色分别是红橙黄绿蓝靛紫七种，那么问从里面拿一个球出来是红色的概率。</p>
<p>面对这样一个问题。如果“一百多”后面没有跟着个“亿”，我们可以直接把不同颜色的球数出来，这样概率就有了。但有个”亿”要去数就比较要命了。因此我们知道这个系统肯定是存在着一个固定分布的参数，但不知道这个参数是个什么鬼，就只能把分布模型写成<br>$$<br>P_{data}(x)<br>$$<br>，然后用别的方式来想办法逼近这个模型。</p>
<p>我们从模型中抽出m个样本，记为<br>$$<br>{ x _{ 1 } , x _ { 2 } , \ldots , x _ { m }}<br>$$<br>然后用这些样本来估计我们模型的参数，列式如下（这里式子用李宏毅教授视频写法，和之前的有些许差异，但所表述东西是一样的）：<br>$$<br>\theta ^ { * } = \arg \max _ { \theta } \prod _ { i = 1 } ^ { m } P _ { G } \left( x ^ { i } ; \theta \right) = \arg \max _ { \theta } \log \prod _ { i = 1 } ^ { m } P _ { G } \left( x ^ { i } ; \theta \right)<br>$$</p>
<p>$$<br>= \arg \max _ { \theta } \sum _ { i = 1 } ^ { m } \log P _ { G } \left( x ^ { i } ; \theta \right)  \quad\left{ x <em>{ 1 } , x _ { 2 } , \ldots , x _ { m } \right} , from ,P</em>{data}(x)<br>$$</p>
<p>$$<br>\approx \arg \max _ { \theta } E _ { x \sim P _ { \text {data} } } \left[ \log P _ { G } ( x ; \theta ) \right]<br>$$</p>
<p>这里的≈可能需要稍微看看，中间一道式子的意思是我们利用抽样得到的样本列出极大似然估计式子，在这个之间会对所有样本概率做处理之后进行累加。假设我们取的样本就是全部样本空间（也就是我们完整取了一百多亿个球），那么它将等于<br>$$<br>\arg \max _ { \theta } m\times E _ { x \sim P _ { \text {data} } } \left[ \log P _ { G } ( x ; \theta ) \right]<br>$$<br>这里的m是样本个数，也就是一个正整数，而我们式子求的是最大值点，因此上面的式子m写不写是一样的，式子变成<br>$$<br>\arg \max _ { \theta } E _ { x \sim P _ { \text {data} } } \left[ \log P _ { G } ( x ; \theta ) \right]<br>$$<br>但因为我们取的样本并不是整个样本空间（如果我们能取整个样本空间那还聊个屁啊），我们只能尽可能的让样本分布与整个样本空间近似，因此才有了这个约定于号。</p>
<p>如果<br>$$<br>P_{data}(x)<br>$$<br>这东西是连续型的，那么上面的式子可以写成积分的形式，如下：<br>$$<br>\arg \max _ { \theta } \int _ { x } P _ { d a t a } ( x ) \log P _ { G } ( x ; \theta )\ dx<br>$$<br>又因为对于求最大值而言，对式子加上一个固定常数和减掉一个固定常数都不会影响最后的结果，因此我们可以再给上面的式子凑一个常数进去。变成如下形式：<br>$$<br>\arg \max _ { \theta } \int _ { x } P _ { d a t a } ( x ) \log P _ { G } ( x ; \theta ) d x - \int _ { x } P _ { d a t a } ( x ) \log P _ { d a t a } ( x ) d x<br>$$<br>这里这样凑是很巧妙的！！！因为要把公式凑成KLKL散度的样子。至于是怎么想到的这件事情。。。我也不知道，依稀记得初中参加奥数班的时候，老师在空间中取一个点，然后做了快十条辅助线来求解几何问题，那个时候我就觉得智商不够用了。。。</p>
<p>将上面式子整理如下：<br>$$<br>\arg \max _ { \theta } \int _ { x }[ P _ { d a t a } ( x ) \log P _ { G } ( x ; \theta ) -P _ { d a t a } ( x ) \log P _ { d a t a } ( x ) ]d x<br>$$</p>
<p>$$<br>=\arg \max _ { \theta } \int _ { x } P _ { d a t a } ( x ) \log \frac{P _ { G } ( x ; \theta )}{P _ { d a t a } ( x )} d x<br>$$</p>
<p>$$<br>=\arg \min _ { \theta } \int _ { x } P _ { d a t a } ( x ) \log \frac{P _ { d a t a } ( x )}{P _ { G } ( x ; \theta )} d x<br>$$</p>
<p>$$<br>=\arg \min _ { \theta } K L \left( P _ { d a t a } ( x ) | P _ { G } ( x ; \theta ) \right)<br>$$</p>
<p>中间最大值变最小值的步骤其实就相当于在公式前面乘一个负号，那么最大值自然就变成最小值。</p>
<p>好了，公式推到这里我们知道了，如果要去做一个模型的极大似然估计，那么相当于求真实模型和拟合模型之间的KL散度取最小值时的θ取值。</p>
<p>当然进一步想，假设这里求的不是KL散度，而是另外的一种距离，应该也是差不多的。</p>
<p>到了这一步，相信明眼人早已经看出来了，上面的推理不过就是对极大似然估计的式子做进一步的推导，其实还是跟GAN没什么关系。但那是基础，只能先推一推，然后再抛出一个问题：假设我们连带参数的式子都列不出来呢？</p>
<p>比如图像的生成问题。或许你现在还没意识到这个问题的难度，那么请你用一道公式写出世界上所有美女在图像中的表达式，那道公式就是：“我以后的女朋友”。恩，说远了，其实那道公式是，，，列不出来。。。</p>
<p>一脸懵逼了吧，哈哈，说实在的，本人以前做图像处理的时候遇到这种问题都是充满绝望的。</p>
<p>依照李教授视频的说法，有人尝试用高斯混合模型来做这件事情，但是效果很悲剧，就是因为高斯混合模型的复杂度和图像的复杂度比起来还是太小儿科了。可以做个简单的比较，曾经很流行的一个说法形容围棋的复杂度，说它的可能性比天上的星体还要多。而围棋也就19*19的361个交叉点，每个交叉点3种可能。图像哪怕是200 * 200的灰度图，每个点都有256种可能，这个数量级远非围棋可比！那么围棋用传统方法都解决不好的，图像怎么可能解决的好呢？</p>
<p>是的，要用传统方法在图像上解决问题一般限制比较多，最大的问题就是这里的这道模型公式真的很难列出来，除非你人为去加了很多限制，但这样做出来的模型泛化性又很差。而神经网络则不然，简单的讲，假设神经网络够复杂且训练的好，它可以拟合世间所有能拟合的东西，注意，是所有！因此有大神就想，要不就用神经网络来表述图像的模型好啦，于是GAN神经网络中的G(Gernerator)网络就诞生了，平地一声雷，逻辑图如下：<br><img src="/../images/GAN%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC/20181224170233872.png" alt="在这里插入图片描述"></p>
<p>看到这个图，相信很多人一开始也跟我一样是崩溃的。没事，崩溃是我们这一行的常态嘛。首先我们要搞清楚我们要用G来做什么，前面我们讲对于图像来说，哪怕你手头上有一类图像（比如说美女图片啥的），你也很难去刻画出美女的公式是什么，而G正是来帮我们列式的。我们让它去看遍天下所有美女的图片，不断通过与真实图像进行分布差距对比来优化自己学到的规律，最终学到炉火纯青，基本上可以做到手中无片，心中有片的最高境界，可能它看到远山娥黛，便画出了王语嫣，看到绝世出尘，便画出了小龙女（李若彤版）。总之你要什么它就来什么。</p>
<p>那么对于一个神经网络，它学的是什么呢？自然是里面的权重嘛，我们可以把它写作θ。</p>
<p>一般来讲我们人如果要去学习美女图片的规律，首先会真的去看各种美女图片然后总结规律。但对于科学推理它不是这个样子的，我们要假定美女图片是一种图片的分布形式，然后列一道式子让其输出符合这个分布，那么这个式子就是美女图片的模型。这里的式子是G定义的，而因为它一开始的参数是随机的，基本不可能刚刚好就符合输出是美女这一分布。因此我们要让它批量的输出一堆的图片，然后算这些图片的分布<br>$$<br>P _ { G } ( x ; \theta )<br>$$<br>和实际的分布<br>$$<br>P _ { d a t a } ( x )<br>$$<br>之间到底差了多少，以此来调整参数θ。也就是你不给它看美女的图片，而是让它直接画，然后每次都把它画的东西撕了，骂它画的是什么屎，然后告诉他美女并不是长这样的，回去慢慢悟。经过千锤百炼，沧海桑田，它终于有一天总结出了美女的规律，功成之日仰天长啸，哈哈哈哈哈。</p>
<p>那么，前面的z又是个什么鬼？它是一个分布函数，我们每次从这个函数中取出一个样本扔进去神经网络，然后让他输出一个样本。假设我们遍历完整个z的样本空间输出了全部对应的x，而对应的x的分布又跟真实数据的分布一样，那么我们的美女生成器就做成了！</p>
<p>这里这样解释是OK的，但有点不清楚。首先是为什么用z而不用x，我们知道当神经网络的参数固定住，你扔一个东西它必然会对应一个输出。假设x的可能空间比z大，那么这个网络不就无法完全拟合整个x空间了吗？是的，但我们本来也没有想拟合整个x空间，我们需要拟合的是x空间下美女这个子集，而只要z的复杂度足够，那么经过神经网络之后出来的xx应该就可以非常近似于这个子集。当然我们这么做，主要也是不想输入太复杂。</p>
<p>如果上面关于z的解释你完全看不懂，那么除了回去看数学之外，你还能这样理解。这里的z就是前面的“远山娥黛”、“绝世出尘”、“风华绝代”、“沉鱼落雁”、“闭月羞花”、“明眸善睐”等等等等，突然想去看一遍《洛神赋》哇槽。</p>
<p>推到这里我们就把逻辑图推完了，嘴角上扬，发出得意的奸笑。然后下一秒就僵硬了，因为这个看似天衣无缝的推导有个致命的问题，就是，算不了。。。</p>
<p>我们可以看看里面的<br>$$<br>P _ { G } ( x ; \theta )<br>$$<br>长什么样：<br>$$<br>P _ { G } ( x ) = \int _ { z } P _ { \text {prior} } ( z ) I _ { [ G ( z ) = x ] } d z<br>$$<br>长这样，这个公式的x是样本给的，z是一个随机分布，整体的意思是说我们对z进行积分，积分里面是z出现的可能性乘以z经过神经网络生出来的这个东西的分布与样本的比较结果（相同为1不同为0）。为什么是这样的？</p>
<p>因为我们前面说过，我们要用z来映射到x，假设映射关系已经确定，那么z出现的可能性就直接对应于x分布的可能性，当然也可能出现多个z对应一个x的映射。<br>$$<br> I _{ [ G ( z ) = x ]}<br>$$<br>就是我们判定z映射到x的标准。</p>
<p>但这公式算不了。因为这样我们给定一个样本，要做的是遍历整个z空间来找到映射关系，而G网络又是个很复杂的东西，基本上无法算出来（再说，我们之所以用G网络也就看中了它的复杂性）。因此推到这里就推死了！原因就是算不出来。</p>
<p>那么能不能通过一个神经网络来拟合<br>$$<br>P _ { G } ( x ; \theta )<br>$$<br>呢？可以应该是可以的，但问题是拟合出来的<br>$$<br>P _ { G } ( x ; \theta )<br>$$<br>哪怕比这货<br>$$<br>P _ { G } ( x ) = \int _ { z } P _ { \text {prior} } ( z ) I _ { [ G ( z ) = x ] } d z<br>$$<br>简单一点，但也是个很复杂的神经网络啊！这样后面拿它去算KL散度也没得算。因此进一步，能不能直接用神经网络来帮忙评估各个分布之间的距离呢？</p>
<p>D（Discriminator）网络就这么诞生了。这个D网络干的事情就是输入一个x来自真实样本或者拟合样本，然后分析它们来自哪里，并输出一个标量。这个标量你可以训练它为一个判定标准，就是如果是真实样本就输出接近1的数，拟合样本就输出接近0的数这样子。这样我们的判别器也就有了，把判别器对于真实样本和拟合样本的所有判别做比较处理，则我们G网络需要的分布距离也就有了。</p>
<p>上面说了那么多，其实实际上，GAN论文告诉我们只要让G和D各自来解下面这道式子就完事了（牛逼的人从来就是这样，不啰嗦，人狠话不多）。<br>$$<br>G ^ { * } = \arg \min _ { G } \max _ { D } V ( G , D )<br>$$<br>右边的<br>$$<br>\max _ { D } V ( G , D )<br>$$<br>假定G已经是确定的，那么就变成<br>$$<br>\arg\max _ { D } V ( D )<br>$$<br>。V这个函数算的是<br>$$<br>P _ { d a t a } ( x )<br>$$<br> 和<br>$$<br>P _ { G }<br>$$<br>之间的距离。那么我们这个时候就是要训练D网络来最大化这个距离，因为只有这样我们的判别器才是给力的。然后一旦我们的判别器非常给力了，那么我们只要定住它，训练G来使得<br>$$<br>\arg\min _ { G } V ( G )<br>$$<br>这道公式最小就可以了。因为这道公式最小说明我们通过神经网络实现了类似于极大似然法，找到了网络的最优解<br>$$<br>\theta  ^ { * }<br>$$<br>。</p>
<p>现在剩下的最后一个问题就是V这个算<br>$$<br>P _ { d a t a } ( x )<br>$$<br> 和<br>$$<br>P _ { G }<br>$$<br>之间距离的函数到底长什么样了。原生GAN的论文告诉我们V长这样：<br>$$<br>V = E _ { x \sim P _ { \text {data} } } [ \log D ( x ) ] + E _ { x \sim P _ { G } } [ \log ( 1 - D ( x ) ) ]<br>$$<br>看到这里我满脑子的“哇槽”，为什么啊！这为什么就是<br>$$<br>P _ { d a t a } ( x )<br>$$<br>和<br>$$<br>P _ { G }<br>$$<br>之间的距离啊？？？</p>
<p>想到头发白了之后终于明白了。假设我们训练出来的这个D网络输出的是样本是真样本的概率，那么公式第一项我们肯定希望这个D(x)越接近于1越好，而第二项希望它越接近于0越好，这样整个V取得最大值（注意这里两项的x不是同一个，李教授的视频这样写感觉不如原论文区分开来清楚），如果是一个真的无敌的神经网络上面这个区分它是做的到的（当然随着拟合越来越好要区分则越来越难，如果有拟合的数据和实际的数据重叠了，则无法取得理想的最大值）。反之，如果网络判断能力越差，则这个式子越小。因此它就是一个衡量<br>$$<br>P _ { d a t a } ( x )<br>$$<br>和<br>$$<br> P _ { G }<br>$$<br>之间的距离的公式。另外这里最妙的还在于后面，我们对公式做展开。<br>$$<br>V = E _ { x \sim P _ { d a t a } } [ \log D ( x ) ] + E _ { x \sim P _ { G } } [ \log ( 1 - D ( x ) ) ]<br>$$</p>
<p>$$<br>= \int _ { x } P _ { d a t a } ( x ) \log D ( x ) d x + \int _ { x } P _ { G } ( x ) \log ( 1 - D ( x ) ) d x<br>$$</p>
<p>$$<br>= \int_ { x }  \left[ P _ { d a t a } ( x ) \log D ( x ) + P _ { G } ( x ) \log ( 1 - D ( x ) ) \right] d x<br>$$</p>
<p>这里我们假设D(x)是无敌的，对于每个积分中的积分的x都能找到一个D(x)使得积分里面的式子最大，那么最后积分出来的值肯定就是最大的。所以我们现在如果要求使得上面这个式子最大的D(x)，就相当于求使得下面这个式子最大的D(x)<br>$$<br>P _ { d a t a } ( x ) \log D ( x ) + P _ { G } ( x ) \log ( 1 - D ( x ) )<br>$$<br>这里的计算就极其简单了（李教授表示小学生都会算），就是求导然后让式子等于0，求出这个时候D(x)是多少就行。最后求出来：<br>$$<br>D ^ { * } ( x ) = \frac { P _ { d a t a } ( x ) } { P _ { d a t a } ( x ) + P _ { G } ( x ) }<br>$$<br>可以看出<br>$$<br>D ^ { * } ( x )<br>$$<br>是大于0小于1的数，符合我们刚刚对D(x)的定义。</p>
<p>这样我们这道神话般的公式：<br>$$<br>G ^ { * } = \arg \min _ { G } \max _ { D } V ( G , D )<br>$$<br>的右边部分就有了。我们把<br>$$<br>D ^ { * } ( x )<br>$$<br>往公式V代入：<br>$$<br>V = E _ { x \sim P _ { d a t a } } [ \log D ( x ) ] + E _ { x \sim P _ { G } } [ \log ( 1 - D ( x ) ) ]<br>$$</p>
<p>$$<br>= E _ { x \sim P _ { d a t a } } \left[ \log \frac { P _ { d a t a } ( x ) } { P _ { d a t a } ( x ) + P _ { G } ( x ) } \right]+ E _ { x \sim P _ { G } } \left[ \log \frac { P _ { G } ( x ) } { P _ { d a t a } ( x ) + P _ { G } ( x ) } \right]<br>$$</p>
<p>$$<br>= \int _ { x } P _ { d a t a } ( x ) \log \frac { \frac { 1 } { 2 } P _ { d a t a } ( x ) } { \frac { P _ { d a t a } ( x ) + P _ { G } ( x ) } { 2 } } d x+ \int _ { x } P _ { G } ( x ) \log \frac { \frac { 1 } { 2 }P _ { G } ( x ) } { \frac { d a t a ( x ) + P _ { G } ( x ) } { 2 } } d x<br>$$</p>
<p>$$<br>=  2 \log \frac { 1 } { 2 }+\int _ { x } P _ { d a t a } ( x ) \log \frac {P _ { d a t a } ( x ) } { \frac { P _ { d a t a } ( x ) + P _ { G } ( x ) } { 2 } } d x+ \int _ { x } P _ { G } ( x ) \log \frac { P _ { G } ( x ) } { \frac { d a t a ( x ) + P _ { G } ( x ) } { 2 } } d x<br>$$</p>
<p>上面的<br>$$<br>2 \log \frac { 1 } { 2 }<br>$$<br>是把两项分子的<br>$$<br>\frac { 1 } { 2 }<br>$$<br>拿出来的结果，因为log里面相乘就等于外面相加，然后对<br>$$<br>P _ { d a t a } ( x )<br>$$<br>或<br>$$<br>P _ { G }( x )<br>$$<br>的整个空间进行积分结果都等于1。推导比较简单，就不写了。<br>$$<br>=  -2 \log 2+\int _ { x } P _ { d a t a } ( x ) \log \frac {P _ { d a t a } ( x ) } { \frac { P _ { d a t a } ( x ) + P _ { G } ( x ) } { 2 } } d x+ \int _ { x } P _ { G } ( x ) \log \frac { P _ { G } ( x ) } { \frac { d a t a ( x ) + P _ { G } ( x ) } { 2 } } d x<br>$$</p>
<p>$$<br>= - 2 \log 2 + \mathrm { KL } \left( \mathrm { P } _ { \text { data } } ( \mathrm { x } ) | \frac { \mathrm { P } _ { \mathrm { data } } ( \mathrm { x } ) + \mathrm { P } _ { \mathrm { G } } ( \mathrm { x } ) } { 2 } \right)+ \mathrm { KL } \left( \mathrm { P } _ { \mathrm { G } } ( \mathrm { x } ) | \frac { \mathrm { P } _ { \mathrm { data } } ( \mathrm { x } ) + \mathrm { P } _ { \mathrm { G } } ( \mathrm { x } ) } { 2 } \right)<br>$$</p>
<p>$$<br>= - 2 \log 2 + 2 J S  \left( P _ { \text {data} } ( x ) | P _ { G } ( x ) \right)<br>$$</p>
<p>推到这一步基本上没什么难度，当看到<br>$$<br>J S  \left( P _ { \text {data} } ( x ) | P _ { G } ( x ) \right)<br>$$<br>这一项出来的时候差点跪了下去，牛逼啊哇槽！因为这一项告诉我们，如果<br>$$<br>D ^ { * } ( x )<br>$$<br>取得最大值，那么V这个公式将直接变成衡量<br>$$<br>P _ { \text {data} } ( x )<br>$$<br>和<br>$$<br>P _ { G } ( x )<br>$$<br>之间差距的公式。这个时候只要我们求出对应的G的最小值就搞定了，巧得不要不要的。</p>
<p>还有更牛逼的，假设<br>$$<br>G ^ { * } = \arg \min _ { G } \max _ { D } V ( G , D )<br>$$<br>这倒公式的D定住了，我们可以把<br>$$<br>\max _ { D } V ( G , D )<br>$$<br>写成L(G)，它牛逼在哪？牛逼在于L(G)直接就是我们G网络的损失函数，我们要让L(G)取得最小值，不就是我们神经网络的目标吗！？完美！每每看到这里就不禁感慨大自然的神奇，数学的伟大和人类的渺小啥的。。。</p>
<p>到此我们就把全部数学推导过程全部做完了，感觉真是一把老泪掉下来，不知不觉写了五千多字，应该是写过的最长的一篇博客了。到此你可能已经明白了数学怎么来的了，但其实还有另外一半，那就是实际该怎么实现，<a href="https://aichn.cn/index/article/show/id/87.html">下篇文章</a>将讨论这个问题。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>JS散度</title>
    <url>/post/c7d146d6.html</url>
    <content><![CDATA[<p>前面我们介绍了<a href="https://aichn.cn/index/article/show/id/81.html">相对熵（KL散度）</a>的概念，知道了它可以用来表示两个概率分布之间的差异，但有个不大好的地方是它并不是对称的，因此有时用它来训练神经网络会有顺序不同造成不一样的训练结果的情况（其实个人觉得也就是训练时间差异罢了，也没那么严重）。为了克服这个问题，有人就提出了一个新的衡量公式，叫做JS散度，式子如下：<br>$$<br>J S \left( P _ { 1 } | P _ { 2 } \right) = \frac { 1 } { 2 } K L \left( P _ { 1 } | \frac { P _ { 1 } + P _ { 2 } } { 2 } \right) + \frac { 1 } { 2 } K L \left( P _ { 2 } | \frac { P _ { 1 } + P _ { 2 } } { 2 } \right)JS(P1∥P2)=21KL(P1∥2P1+P2)+21KL(P2∥2P1+P2)<br>$$<br>如果有一点数学功底的人可以轻易看出这个公式对于<br>$$<br>P _ { 1 }和P _ { 2 }<br>$$<br>是对称的，而且因为是两个KL的叠加，由相对熵的文章我们知道KL的值一定是大于等于0的，因此这个公式也一定大于等于0。</p>
<p>现在只剩下一个关键问题，就是什么时候等于0的问题了。同样参考相对熵的文章我们知道当两个分布相同的时候等于0，那么换到这里，也就是：<br>$$<br>P _ { 1 }=\frac { P _ { 1 } + P _ { 2 } }{ 2 }\ \qquad 且 \qquad P _ { 2 }=\frac { P _ { 1 } + P _ { 2 } } { 2 }P_ { 1 }=2P_ { 1 }+P_ { 2 } 且P_ { 2 }=2P_ { 1 }+P_ { 2 }<br>$$<br>的时候。可以轻易看出来，JS散度等于0的时候跟KL散度一样，就是<br>$$<br>P _ { 1 }和P _ { 2 }<br>$$<br>完全一样的时候。那么推到这里，用JS散度来表达两个概率分布的差异就问题不大了。</p>
<p>其实本人在看相对熵和JS散度的时候一直有疑问，就是当两个概率分布不一样的时候，它们的值是不是会随着距离的变大而变大，也就是说这两个公式跟概率分布的距离到底是不是一个单调的关系，但我没有看到别人在说这件事情。我自己想了半天之后得出的结论是不一定，可能随着概率分布的表达式不一样而有所变化。</p>
<p>当然因为没有人讲这件事我至今也不知道这样想是不是对的，因此有老哥想明白了麻烦留个言告诉我。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能 -大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 3 利用 Dlib 实现摄像头实时人脸识别</title>
    <url>/post/375ec5b6.html</url>
    <content><![CDATA[<p><strong>Python 3 利用 Dlib 实现摄像头实时人脸识别</strong></p>
<p><strong>0. 引言</strong></p>
<p>　　利用 Python 开发，借助 Dlib 库捕获摄像头中的人脸，提取人脸特征，通过计算特征值之间的欧氏距离，来和预存的人脸特征进行对比，判断是否匹配，达到人脸识别的目的；</p>
<p>　　可以从摄像头中抠取人脸图片存储到本地，然后提取构建预设人脸特征；</p>
<p>　　根据抠取的 / 已有的同一个人多张人脸图片提取 128D 特征值，然后计算该人的 128D 特征均值；</p>
<p>　　然后和摄像头中实时获取到的人脸提取出的特征值，计算欧氏距离，判定是否为同一张人脸；　　</p>
<p>　　Python + OpenCv + Dlib ; 　</p>
<p>　　<strong>Features :</strong></p>
<ul>
<li>支持人脸数据采集，自行建立人脸数据库 / Support face register</li>
<li>调用摄像头实时人脸检测和识别 / Using camera to real-time detect and recognize faces</li>
<li>支持多张人脸 / Support multi-faces</li>
</ul>
<p>　　<strong>人脸识别 / Face Recognition</strong> 的说明：</p>
<p>　　Wikipedia 上关于<strong>人脸识别系统 / Face Recognition System</strong> 的描述：<em>they work by comparing selected facial features from given image with faces within a database.</em></p>
<p>　　本项目中就是比较 <strong>预设的人脸的特征</strong> 和 <strong>摄像头实时获取到的人脸的特征</strong> ；</p>
<p>　　核心就是 <strong>提取 128D 人脸特征，然后计算 摄像头人脸特征 和 预设的特征脸的\</strong>欧式距离，**进行比对；**</p>
<p>　　效果如下：　　</p>
<p><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20181005123021947-1880770901.png" alt="img"> </p>
<p><strong>图 1 摄像头多个人脸时识别效果</strong> </p>
<p><strong>1. 总体流程</strong></p>
<p>　　先说下 <strong>人脸检测 ( Face detection )</strong> 和 <strong>人脸识别 ( Face Recognition )</strong> ，前者是达到检测出场景中人脸的目的就可以了，而后者不仅需要检测出人脸，还要和<strong>已有人脸数据进行比对</strong>，识别出是否在数据库中，或者进行身份标注之类处理，人脸检测和人脸识别两者有时候可能会被理解混淆；</p>
<p>　　我的之前一些项目都是用 Dlib 做人脸检测这块，这个项目想要实现的功能是人脸识别功能，借助的是 Dlib 官网中 face_recognition.py 这个例程 （ Link：<a href="http://dlib.net/face_recognition.py.html">http://dlib.net/face_recognition.py.html</a> ）；</p>
<p>　　核心在于 利用“dlib_face_recognition_resnet_model_v1.dat” 这个 model，提取<strong>人脸图像的 128D 特征</strong>，然后比对不同人脸图片的 128D 特征，设定阈值 <strong>计算欧氏距离</strong> 来判断是否为同一张脸；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1 # face recognition model, the object maps human faces into 128D vectors2 facerec &#x3D; dlib.face_recognition_model_v1(&quot;dlib_face_recognition_resnet_model_v1.dat&quot;)3 4 shape &#x3D; predictor(img, dets[0])5 face_descriptor &#x3D; facerec.compute_face_descriptor(img, shape)</span><br></pre></td></tr></table></figure>


<p>　　 </p>
<p><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20181005123055901-1748654455.png" alt="img"> </p>
<p><strong>图 2 总体设计流程</strong></p>
<p><strong>2.源码介绍</strong></p>
<p>　　主要有</p>
<p>　　　　<strong><em>get_face_from_camera.py\</em> ,</strong> </p>
<p>　　　　<strong><em>get_features_into_CSV.py\</em></strong> ，</p>
<p>　　　　<strong><em>face_reco_from_camera.py</em></strong></p>
<p>　　这三个 Python 文件，接下来会分别介绍实现功能；</p>
<p><strong>2.1 get_face_from_camera.py / 人脸注册录入</strong></p>
<p>　　人脸识别需要将 <strong>提取到的图像数据</strong> 和 <strong>已有图像数据</strong> 进行比对分析，所以这部分代码实现的功能就是 <strong>人脸录入</strong>；</p>
<p>　　程序会生成一个窗口，显示调用的摄像头实时获取的图像；</p>
<p>　　<em>（关于摄像头的调用方式可以参考这里： <a href="http://www.cnblogs.com/AdaminXie/p/8472743.html">Python 3 利用 Dlib 19.7 实现摄像头人脸检测特征点标定</a>）；</em></p>
<p>　　</p>
<p>　　然后根据键盘输入进行人脸捕获：</p>
<ul>
<li>“N” 新录入人脸，新建文件夹 person_X/ 用来存储某人的人脸图像</li>
<li> “S” 开始捕获人脸，将捕获到的人脸放到 person_X/ 路径下</li>
<li>“Q” 退出窗口</li>
</ul>
<p>　　</p>
<p>　　摄像头的调用是利用 opencv 库的 <em>cv2.VideoCapture(0),</em> 此处参数为 0 代表调用的是笔记本的默认摄像头，你也可以让它调用传入已有视频文件；</p>
<p>　<img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20181029163456334-85351276.png" alt="img"></p>
<p><strong>图 3 get_face_from_camera.py 的界面</strong></p>
<p> 　</p>
<p>　　捕获到的一组人脸示例；</p>
<p><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20181002221712503-768390199.png" alt="img"></p>
<p><strong>图 4 捕获到的一组人脸</strong></p>
<p>　　<strong>get_face_from_camera.py 源码</strong></p>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  </span><br></pre></td></tr></table></figure>
<p># 进行人脸录入 / face register</p>
<p># 录入多张人脸 / support multi-faces</p>
<p># Author:  coneypo</p>
<p># Blog:   <a href="http://www.cnblogs.com/AdaminXie">http://www.cnblogs.com/AdaminXie</a></p>
<p># GitHub:  <a href="https://github.com/coneypo/Dlib_face_recognition_from_camera">https://github.com/coneypo/Dlib_face_recognition_from_camera</a></p>
<p># Mail:   <a href="mailto:&#x63;&#x6f;&#x6e;&#101;&#121;&#112;&#x6f;&#64;&#x66;&#111;&#120;&#x6d;&#97;&#x69;&#108;&#x2e;&#x63;&#x6f;&#x6d;">&#x63;&#x6f;&#x6e;&#101;&#121;&#112;&#x6f;&#64;&#x66;&#111;&#120;&#x6d;&#97;&#x69;&#108;&#x2e;&#x63;&#x6f;&#x6d;</a></p>
<p># Created at 2018-05-11</p>
<p># Updated at 2018-10-29</p>
<p>import dlib     # 人脸处理的库 Dlib</p>
<p>import numpy as np # 数据处理的库 Numpy</p>
<p>import cv2     # 图像处理的库 OpenCv</p>
<p>import os      # 读写文件</p>
<p>import shutil    # 读写文件</p>
<p># Dlib 正向人脸检测器</p>
<p>detector = dlib.get_frontal_face_detector()</p>
<p># Dlib 68 点特征预测器</p>
<p>predictor = dlib.shape_predictor(‘data/data_dlib/shape_predictor_68_face_landmarks.dat’)</p>
<p># OpenCv 调用摄像头</p>
<p>cap = cv2.VideoCapture(0)</p>
<p># 设置视频参数</p>
<p>cap.set(3, 480)</p>
<p># 人脸截图的计数器</p>
<p>cnt_ss = 0</p>
<p># 存储人脸的文件夹</p>
<p>current_face_dir = 0</p>
<p># 保存的路径</p>
<p>path_make_dir = “data/data_faces_from_camera/“</p>
<p>path_csv = “data/data_csvs_from_camera/“</p>
<p># (optional) 删除之前存的人脸数据文件夹</p>
<p>def pre_clear():</p>
<p>  folders_rd = os.listdir(path_make_dir)</p>
<p>  for i in range(len(folders_rd)):</p>
<p>​    shutil.rmtree(path_make_dir+folders_rd[i])</p>
<p>  csv_rd = os.listdir(path_csv)</p>
<p>  for i in range(len(csv_rd)):</p>
<p>​    os.remove(path_csv+csv_rd[i])</p>
<p># 每次程序录入之前，删掉之前存的人脸数据</p>
<p>pre_clear()</p>
<p># 人脸种类数目的计数器</p>
<p>person_cnt = 0</p>
<p>while cap.isOpened():</p>
<p>  # 480 height * 640 width</p>
<p>  flag, img_rd = cap.read()</p>
<p>  kk = cv2.waitKey(1)</p>
<p>  img_gray = cv2.cvtColor(img_rd, cv2.COLOR_RGB2GRAY)</p>
<p>  # 人脸数 faces</p>
<p>  faces = detector(img_gray, 0)</p>
<p>  # 待会要写的字体</p>
<p>  font = cv2.FONT_HERSHEY_COMPLEX</p>
<p>  # 按下 ‘n’ 新建存储人脸的文件夹</p>
<p>  if kk == ord(‘n’):</p>
<p>​    person_cnt += 1</p>
<p>​    current_face_dir = path_make_dir + “person_” + str(person_cnt)</p>
<p>​    print(‘\n’)</p>
<p>​    for dirs in (os.listdir(path_make_dir)):</p>
<p>​      if current_face_dir == path_make_dir + dirs:</p>
<p>​        shutil.rmtree(current_face_dir)</p>
<p>​        print(“删除旧的文件夹:”, current_face_dir)</p>
<p>​    os.makedirs(current_face_dir)</p>
<p>​    print(“新建的人脸文件夹: “, current_face_dir)</p>
<p>​    # 将人脸计数器清零</p>
<p>​    cnt_ss = 0</p>
<p>  if len(faces) != 0:</p>
<p>​    # 检测到人脸</p>
<p>​    # 矩形框</p>
<p>​    for k, d in enumerate(faces):</p>
<p>​      # 计算矩形大小</p>
<p>​      # (x,y), (宽度width, 高度height)</p>
<p>​      pos_start = tuple([d.left(), d.top()])</p>
<p>​      pos_end = tuple([d.right(), d.bottom()])</p>
<p>​      # 计算矩形框大小</p>
<p>​      height = (d.bottom() - d.top())</p>
<p>​      width = (d.right() - d.left())</p>
<p>​      hh = int(height/2)</p>
<p>​      ww = int(width/2)</p>
<p>​      # 设置颜色 / The color of rectangle of faces detected</p>
<p>​      color_rectangle = (255, 255, 255)</p>
<p>​      if (d.right()+ww) &gt; 640 or (d.bottom()+hh&gt;480) or (d.left()-ww &lt; 0) or ( d.top()-hh &lt; 0):</p>
<p>​        cv2.putText(img_rd, “OUT OF RANGE”, (20, 300), font, 0.8, (0, 0, 255), 1, cv2.LINE_AA)</p>
<p>​        color_rectangle = (0, 0, 255)</p>
<p>​      else:</p>
<p>​        color_rectangle = (255, 255, 255)</p>
<p>​      cv2.rectangle(img_rd,</p>
<p>​             tuple([d.left() - ww, d.top() - hh]),</p>
<p>​             tuple([d.right() + ww, d.bottom() + hh]),</p>
<p>​             color_rectangle, 2)</p>
<p>​      # 根据人脸大小生成空的图像</p>
<p>​      im_blank = np.zeros((int(height<em>2), width</em>2, 3), np.uint8)</p>
<p>​      # 按下 ‘s’ 保存摄像头中的人脸到本地</p>
<p>​      if kk == ord(‘s’):</p>
<p>​        cnt_ss += 1</p>
<p>​        for ii in range(height*2):</p>
<p>​          for jj in range(width*2):</p>
<p>​            im_blank[ii][jj] = img_rd[d.top()-hh + ii][d.left()-ww + jj]</p>
<p>​        cv2.imwrite(current_face_dir + “/img_face_” + str(cnt_ss) + “.jpg”, im_blank)</p>
<p>​        print(“写入本地：”, str(current_face_dir) + “/img_face_” + str(cnt_ss) + “.jpg”)</p>
<p>​    # 显示人脸数</p>
<p>  cv2.putText(img_rd, “Faces: “ + str(len(faces)), (20, 100), font, 0.8, (0, 255, 0), 1, cv2.LINE_AA)</p>
<p>  # 添加说明</p>
<p>  cv2.putText(img_rd, “Face Register”, (20, 40), font, 1, (0, 0, 0), 1, cv2.LINE_AA)</p>
<p>  cv2.putText(img_rd, “N: New face folder”, (20, 350), font, 0.8, (0, 0, 0), 1, cv2.LINE_AA)</p>
<p>  cv2.putText(img_rd, “S: Save face”, (20, 400), font, 0.8, (0, 0, 0), 1, cv2.LINE_AA)</p>
<p>  cv2.putText(img_rd, “Q: Quit”, (20, 450), font, 0.8, (0, 0, 0), 1, cv2.LINE_AA)</p>
<p>  # 按下 ‘q’ 键退出</p>
<p>  if kk == ord(‘q’):</p>
<p>​    break</p>
<p>  # 窗口显示</p>
<p>  # cv2.namedWindow(“camera”, 0) # 如果需要摄像头窗口大小可调</p>
<p>  cv2.imshow(“camera”, img_rd)</p>
<p># 释放摄像头</p>
<p>cap.release()</p>
<p># 删除建立的窗口</p>
<p>cv2.destroyAllWindows()</p>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<p>考虑到有可能需要保存的矩形框超出摄像头范围，对于这种异常，如果矩形框超出范围，矩形框会从白变红，然后提示 “OUT OF RANGE”;</p>
<p><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20181029163559597-1249215749.png" alt="img"></p>
<p><strong>图 5 人脸录入异常处理</strong></p>
<p>　　<strong>get_face_from_camera.py 的输出 log</strong></p>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">删除旧的文件夹: F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1</span><br><span class="line">新建的人脸文件夹:  F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1&#x2F;img_face_1.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1&#x2F;img_face_2.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1&#x2F;img_face_3.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1&#x2F;img_face_4.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1&#x2F;img_face_5.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1&#x2F;img_face_6.jpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">删除旧的文件夹: F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_2</span><br><span class="line">新建的人脸文件夹:  F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_2</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_2&#x2F;img_face_1.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_2&#x2F;img_face_2.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_2&#x2F;img_face_3.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_2&#x2F;img_face_4.jpg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">删除旧的文件夹: F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3</span><br><span class="line">新建的人脸文件夹:  F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3&#x2F;img_face_1.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3&#x2F;img_face_2.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3&#x2F;img_face_3.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3&#x2F;img_face_4.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3&#x2F;img_face_5.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3&#x2F;img_face_6.jpg</span><br><span class="line">写入本地： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_3&#x2F;img_face_7.jpg</span><br></pre></td></tr></table></figure>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<p><strong>2.2</strong> <strong>get_features_into_CSV.py / 将图像文件中人脸数据提取出来存入 CSV</strong></p>
<p>　　这部分代码实现的功能是将之前捕获到的人脸图像文件，提取出 128D 特征，然后计算出某人人脸数据的特征均值存入 CSV 中，方便之后识别时候进行比对；</p>
<p>　　利用 numpy.mean() 计算特征均值；</p>
<p>　　<strong>get_features_into_CSV.py 源码：</strong></p>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p># 从人脸图像文件中提取人脸特征存入 CSV</p>
<p># Author:  coneypo</p>
<p># Blog:   <a href="http://www.cnblogs.com/AdaminXie">http://www.cnblogs.com/AdaminXie</a></p>
<p># GitHub:  <a href="https://github.com/coneypo/Dlib_face_recognition_from_camera">https://github.com/coneypo/Dlib_face_recognition_from_camera</a></p>
<p># Mail:   <a href="mailto:&#99;&#111;&#x6e;&#101;&#121;&#112;&#111;&#x40;&#x66;&#x6f;&#x78;&#x6d;&#x61;&#105;&#x6c;&#46;&#99;&#111;&#x6d;">&#99;&#111;&#x6e;&#101;&#121;&#112;&#111;&#x40;&#x66;&#x6f;&#x78;&#x6d;&#x61;&#105;&#x6c;&#46;&#99;&#111;&#x6d;</a></p>
<p># Created at 2018-05-11</p>
<p># Updated at 2018-10-29</p>
<p># 增加录入多张人脸到 CSV 的功能</p>
<p># return_128d_features()     获取某张图像的 128D 特征</p>
<p># write_into_csv()        获取某个路径下所有图像的特征，并写入 CSV</p>
<p># compute_the_mean()       从 CSV　中读取　128D 特征，并计算特征均值</p>
<p>import cv2</p>
<p>import os</p>
<p>import dlib</p>
<p>from skimage import io</p>
<p>import csv</p>
<p>import numpy as np</p>
<p>import pandas as pd</p>
<p>path_faces_rd = “data/data_faces_from_camera/“</p>
<p>path_csv = “data/data_csvs_from_camera/“</p>
<p># Dlib 正向人脸检测器</p>
<p>detector = dlib.get_frontal_face_detector()</p>
<p># Dlib 人脸预测器</p>
<p>predictor = dlib.shape_predictor(“data/data_dlib/shape_predictor_5_face_landmarks.dat”)</p>
<p># Dlib 人脸识别模型</p>
<p># Face recognition model, the object maps human faces into 128D vectors</p>
<p>facerec = dlib.face_recognition_model_v1(“data/data_dlib/dlib_face_recognition_resnet_model_v1.dat”)</p>
<p># 返回单张图像的 128D 特征</p>
<p>def return_128d_features(path_img):</p>
<p>  img = io.imread(path_img)</p>
<p>  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</p>
<p>  faces = detector(img_gray, 1)</p>
<p>  print(“检测的人脸图像：”, path_img, “\n”)</p>
<p>  # 因为有可能截下来的人脸再去检测，检测不出来人脸了</p>
<p>  # 所以要确保是 检测到人脸的人脸图像 拿去算特征</p>
<p>  if len(faces) != 0:</p>
<p>​    shape = predictor(img_gray, faces[0])</p>
<p>​    face_descriptor = facerec.compute_face_descriptor(img_gray, shape)</p>
<p>  else:</p>
<p>​    face_descriptor = 0</p>
<p>​    print(“no face”)</p>
<p>  # print(face_descriptor)</p>
<p>  return face_descriptor</p>
<p># 将文件夹中照片特征提取出来，写入 CSV</p>
<p>#  path_faces_personX:   图像文件夹的路径</p>
<p>#  path_csv:        要生成的 CSV 路径</p>
<p>def write_into_csv(path_faces_personX, path_csv):</p>
<p>  dir_pics = os.listdir(path_faces_personX)</p>
<p>  with open(path_csv, “w”, newline=””) as csvfile:</p>
<p>​    writer = csv.writer(csvfile)</p>
<p>​    for i in range(len(dir_pics)):</p>
<p>​      # 调用return_128d_features()得到128d特征</p>
<p>​      print(“正在读的人脸图像：”, path_faces_personX + “/“ + dir_pics[i])</p>
<p>​      features_128d = return_128d_features(path_faces_personX + “/“ + dir_pics[i])</p>
<p>​      # print(features_128d)</p>
<p>​      # 遇到没有检测出人脸的图片跳过</p>
<p>​      if features_128d == 0:</p>
<p>​        i += 1</p>
<p>​      else:</p>
<p>​        writer.writerow(features_128d)</p>
<p># 读取某人所有的人脸图像的数据，写入 person_X.csv</p>
<p>faces = os.listdir(path_faces_rd)</p>
<p>for person in faces:</p>
<p>  print(path_csv + person + “.csv”)</p>
<p>  write_into_csv(path_faces_rd + person, path_csv + person + “.csv”)</p>
<p># 从 CSV 中读取数据，计算 128D 特征的均值</p>
<p>def compute_the_mean(path_csv_rd):</p>
<p>  column_names = []</p>
<p>  # 128列特征</p>
<p>  for feature_num in range(128):</p>
<p>​    column_names.append(“features_” + str(feature_num + 1))</p>
<p>  # 利用pandas读取csv</p>
<p>  rd = pd.read_csv(path_csv_rd, names=column_names)</p>
<p>  # 存放128维特征的均值</p>
<p>  feature_mean = []</p>
<p>  for feature_num in range(128):</p>
<p>​    tmp_arr = rd[“features_” + str(feature_num + 1)]</p>
<p>​    tmp_arr = np.array(tmp_arr)</p>
<p>​    # 计算某一个特征的均值</p>
<p>​    tmp_mean = np.mean(tmp_arr)</p>
<p>​    feature_mean.append(tmp_mean)</p>
<p>  return feature_mean</p>
<p># 存放所有特征均值的 CSV 的路径</p>
<p>path_csv_feature_all = “data/features_all.csv”</p>
<p># 存放人脸特征的 CSV 的路径</p>
<p>path_csv_rd = “data/data_csvs_from_camera/“</p>
<p>with open(path_csv_feature_all, “w”, newline=””) as csvfile:</p>
<p>  writer = csv.writer(csvfile)</p>
<p>  csv_rd = os.listdir(path_csv_rd)</p>
<p>  print(“得到的特征均值 / The generated average values of features stored in: “)</p>
<p>  for i in range(len(csv_rd)):</p>
<p>​    feature_mean = compute_the_mean(path_csv_rd + csv_rd[i])</p>
<p>​    # print(feature_mean)</p>
<p>​    print(path_csv_rd + csv_rd[i])</p>
<p>​    writer.writerow(feature_mean)</p>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<p>　　我们可以看下对于某张图片，<strong>face_descriptor</strong> 这个 <strong>128D vectors</strong> 的输出结果：</p>
<p>　　绿色框内是我们的返回 128D 特征的函数；</p>
<p>　　在红色框内调用该函数来计算 img_face_13.jpg；</p>
<p>　　可以看到黄色框中的输出为 128D 的向量；</p>
<p><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20180511120053065-1934983472.png" alt="img"></p>
<p><strong>图 6 返回单张图像的 128D 特征的计算结果</strong></p>
<p>　　之后就需要人脸图像进行批量化操作，提取出 128D 的特征，然后计算特征均值，存入 features_all.csv；</p>
<p>　　features_all.csv 是一个 n 行 128 列的 CSV， n 是录入的人脸数，128 列是某人的 128D 特征；</p>
<p>　　这存储的就是 <strong>录入的人脸数据，</strong>之后 <strong>摄像头捕获的人脸</strong> 将要拿过来和 <strong>这些特征值 进行比对，如果欧式距离比较近的话，就可以认为是同一张人脸</strong>；</p>
<p> 　<strong>get_features_into_CSV.py 的输出 log：</strong></p>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;csvs_from_camera&#x2F;person_1.csv</span><br><span class="line">正在读的人脸图像： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1&#x2F;img_face_1.jpg</span><br><span class="line">检测的人脸图像： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_1&#x2F;img_face_1.jpg </span><br><span class="line">...正在读的人脸图像： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_5&#x2F;img_face_3.jpg</span><br><span class="line">检测的人脸图像： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_5&#x2F;img_face_3.jpg </span><br><span class="line"></span><br><span class="line">正在读的人脸图像： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_5&#x2F;img_face_4.jpg</span><br><span class="line">检测的人脸图像： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_5&#x2F;img_face_4.jpg </span><br><span class="line"></span><br><span class="line">正在读的人脸图像： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_5&#x2F;img_face_5.jpg</span><br><span class="line">检测的人脸图像： F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;faces_from_camera&#x2F;person_5&#x2F;img_face_5.jpg </span><br><span class="line"></span><br><span class="line">特征均值: </span><br><span class="line">F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;csvs_from_camera&#x2F;person_1.csv</span><br><span class="line">F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;csvs_from_camera&#x2F;person_2.csv</span><br><span class="line">F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;csvs_from_camera&#x2F;person_3.csv</span><br><span class="line">F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;csvs_from_camera&#x2F;person_4.csv</span><br><span class="line">F:&#x2F;code&#x2F;python&#x2F;P_dlib_face_reco&#x2F;data&#x2F;csvs_from_camera&#x2F;person_5.csv</span><br></pre></td></tr></table></figure>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<p><strong>2.3 face_reco_from_camera.py / 实时人脸识别对比分析</strong></p>
<p>　　这部分源码实现的功能：调用摄像头，捕获摄像头中的人脸，然后如果检测到人脸，将 <strong>摄像头中的人脸提取出 128D 的特征</strong>，然后和 <strong>之前录入人脸的 128D 特征</strong> 进行计算欧式距离，如果比较小，可以判定为一个人，否则不是一个人；</p>
<p>　　欧氏距离对比的阈值设定，是在 <em>return_euclidean_distance</em> 函数的 <em>dist</em> 变量；</p>
<p>　　我这里程序里面指定的 <strong>欧氏距离判断阈值是 0.4</strong>，具体阈值可以根据实际情况或者测得结果进行修改；</p>
<p>　　</p>
<p>　　这边做了一个，让人名跟随显示在头像下方，如果想要在人脸矩形框下方显示人名，首先需要知道 Dlib 生成的矩形框的尺寸怎么读取；</p>
<p>　　Dlib 返回的 dets 变量是一系列人脸的数据，此处对单张人脸处理，所以取 dets[0] 的参数；</p>
<p>　　可以通过 <strong>dets[0].top()</strong>, <strong>dets[0].bottom()</strong>, <strong>dets[0].left()</strong> 和 <strong>dets[0].right()</strong> 来确定要显示的人名的坐标；</p>
<p><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20181029164755617-126045850.png" alt="img"></p>
<p><strong>图 7 dets[0].top() 等参数说明</strong> </p>
<p>　　</p>
<p>　　得到矩形框的坐标，就可以获取人名的相对位置；</p>
<p>　　这是我这边取的坐标：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pos_text_1 &#x3D; tuple([dets[0].left(), int(dets[0].bottom()+(dets[0].bottom()-dets[0].top())&#x2F;4)])</span><br></pre></td></tr></table></figure>


<p>　　<img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20181004111207854-1934282753.png" alt="img"> </p>
<p><strong>图 8 face_reco_from_camera.py 生成的人脸识别窗口界面</strong></p>
<p>　<strong>face_reco_from_camera.py</strong> 源码：</p>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  </span><br></pre></td></tr></table></figure>
<p># created at 2018-05-11</p>
<p># updated at 2018-09-08</p>
<p># support multi-faces now</p>
<p># Author:  coneypo</p>
<p># Blog:   <a href="http://www.cnblogs.com/AdaminXie">http://www.cnblogs.com/AdaminXie</a></p>
<p># GitHub:  <a href="https://github.com/coneypo/Dlib_face_recogqnition_from_camera">https://github.com/coneypo/Dlib_face_recogqnition_from_camera</a></p>
<p>import dlib     # 人脸识别的库dlib</p>
<p>import numpy as np # 数据处理的库numpy</p>
<p>import cv2     # 图像处理的库OpenCv</p>
<p>import pandas as pd # 数据处理的库Pandas</p>
<p># face recognition model, the object maps human faces into 128D vectors</p>
<p>facerec = dlib.face_recognition_model_v1(“dlib_face_recognition_resnet_model_v1.dat”)</p>
<p># 计算两个向量间的欧式距离</p>
<p>def return_euclidean_distance(feature_1, feature_2):</p>
<p>  feature_1 = np.array(feature_1)</p>
<p>  feature_2 = np.array(feature_2)</p>
<p>  dist = np.sqrt(np.sum(np.square(feature_1 - feature_2)))</p>
<p>  print(“e_distance: “, dist)</p>
<p>  if dist &gt; 0.4:</p>
<p>​    return “diff”</p>
<p>  else:</p>
<p>​    return “same”</p>
<p># 处理存放所有人脸特征的 CSV</p>
<p>path_features_known_csv = “data/features_all.csv”</p>
<p>csv_rd = pd.read_csv(path_features_known_csv, header=None)</p>
<p># 存储的特征人脸个数</p>
<p># print(csv_rd.shape[0])</p>
<p># 用来存放所有录入人脸特征的数组</p>
<p>features_known_arr = []</p>
<p># known faces</p>
<p>for i in range(csv_rd.shape[0]):</p>
<p>  features_someone_arr = []</p>
<p>  for j in range(0, len(csv_rd.ix[i, :])):</p>
<p>​    features_someone_arr.append(csv_rd.ix[i, :][j])</p>
<p>  #  print(features_someone_arr)</p>
<p>  features_known_arr.append(features_someone_arr)</p>
<p>print(“Faces in Database：”, len(features_known_arr))</p>
<p># Dlib 预测器</p>
<p>detector = dlib.get_frontal_face_detector()</p>
<p>predictor = dlib.shape_predictor(‘shape_predictor_68_face_landmarks.dat’)</p>
<p># 创建 cv2 摄像头对象</p>
<p>cap = cv2.VideoCapture(0)</p>
<p># cap.set(propId, value)</p>
<p># 设置视频参数，propId 设置的视频参数，value 设置的参数值</p>
<p>cap.set(3, 480)</p>
<p># 返回一张图像多张人脸的 128D 特征</p>
<p>def get_128d_features(img_gray):</p>
<p>  dets = detector(img_gray, 1)</p>
<p>  if len(dets) != 0:</p>
<p>​    face_des = []</p>
<p>​    for i in range(len(dets)):</p>
<p>​      shape = predictor(img_gray, dets[i])</p>
<p>​      face_des.append(facerec.compute_face_descriptor(img_gray, shape))</p>
<p>  else:</p>
<p>​    face_des = []</p>
<p>  return face_des</p>
<p># cap.isOpened（） 返回true/false 检查初始化是否成功</p>
<p>while cap.isOpened():</p>
<p>  flag, img_rd = cap.read()</p>
<p>  kk = cv2.waitKey(1)</p>
<p>  # 取灰度</p>
<p>  img_gray = cv2.cvtColor(img_rd, cv2.COLOR_RGB2GRAY)</p>
<p>  # 人脸数 dets</p>
<p>  faces = detector(img_gray, 0)</p>
<p>  # 待会要写的字体</p>
<p>  font = cv2.FONT_HERSHEY_COMPLEX</p>
<p>  cv2.putText(img_rd, “Press ‘q’: Quit”, (20, 400), font, 0.8, (84, 255, 159), 1, cv2.LINE_AA)</p>
<p>  # 存储人脸名字和位置的两个 list</p>
<p>  # list 1 (faces): store the name of faces        Jack  unknown unknown Mary</p>
<p>  # list 2 (pos_namelist): store the positions of faces  12,1  1,21  1,13  31,1</p>
<p>  # 存储所有人脸的名字</p>
<p>  pos_namelist = []</p>
<p>  name_namelist = []</p>
<p>  # 检测到人脸</p>
<p>  if len(faces) != 0:</p>
<p>​    # 获取当前捕获到的图像的所有人脸的特征，存储到 features_cap_arr</p>
<p>​    features_cap_arr = []</p>
<p>​    for i in range(len(faces)):</p>
<p>​      shape = predictor(img_rd, faces[i])</p>
<p>​      features_cap_arr.append(facerec.compute_face_descriptor(img_rd, shape))</p>
<p>​    # 遍历捕获到的图像中所有的人脸</p>
<p>​    for k in range(len(faces)):</p>
<p>​      # 让人名跟随在矩形框的下方</p>
<p>​      # 确定人名的位置坐标</p>
<p>​      # 先默认所有人不认识，是 unknown</p>
<p>​      name_namelist.append(“unknown”)</p>
<p>​      # 每个捕获人脸的名字坐标</p>
<p>​      pos_namelist.append(tuple([faces[k].left(), int(faces[k].bottom() + (faces[k].bottom() - faces[k].top()) / 4)]))</p>
<p>​      # 对于某张人脸，遍历所有存储的人脸特征</p>
<p>​      for i in range(len(features_known_arr)):</p>
<p>​        print(“with person_”, str(i+1), “the “, end=’’)</p>
<p>​        # 将某张人脸与存储的所有人脸数据进行比对</p>
<p>​        compare = return_euclidean_distance(features_cap_arr[k], features_known_arr[i])</p>
<p>​        if compare == “same”: # 找到了相似脸</p>
<p>​          name_namelist[k] = “person_” + str(i+1)</p>
<p>​      # 矩形框</p>
<p>​      for kk, d in enumerate(faces):</p>
<p>​        # 绘制矩形框</p>
<p>​        cv2.rectangle(img_rd, tuple([d.left(), d.top()]), tuple([d.right(), d.bottom()]), (0, 255, 255), 2)</p>
<p>​    # 写人脸名字</p>
<p>​    for i in range(len(faces)):</p>
<p>​      cv2.putText(img_rd, name_namelist[i], pos_namelist[i], font, 0.8, (0, 255, 255), 1, cv2.LINE_AA)</p>
<p>  print(“Name list now:”, name_namelist, “\n”)</p>
<p>  cv2.putText(img_rd, “Face Register”, (20, 40), font, 1, (255, 255, 255), 1, cv2.LINE_AA)</p>
<p>  cv2.putText(img_rd, “Faces: “ + str(len(faces)), (20, 100), font, 1, (0, 0, 255), 1, cv2.LINE_AA)</p>
<p>  # 按下 q 键退出</p>
<p>  if kk == ord(‘q’):</p>
<p>​    break</p>
<p>  # 窗口显示</p>
<p>  cv2.imshow(“camera”, img_rd)</p>
<p># 释放摄像头</p>
<p>cap.release()</p>
<p># 删除建立的窗口</p>
<p>cv2.destroyAllWindows()</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<p>　<strong>face_reco_from_camera.py</strong> 输出 log：</p>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Faces in Database： 5Name list now: [] </span><br><span class="line"></span><br><span class="line">Name list now: [] </span><br><span class="line"></span><br><span class="line">Name list now: [] </span><br><span class="line"></span><br><span class="line">Name list now: [] </span><br><span class="line"></span><br><span class="line">Name list now: [] </span><br><span class="line"></span><br><span class="line">with person_ 1 the e_distance:  0.40770022710364756with person_ 2 the e_distance:  0.41082186674421134with person_ 3 the e_distance:  0.3961545573801463with person_ 4 the e_distance:  0.3881850644563972with person_ 5 the e_distance:  0.3495735780870818Name list now: [&#39;person_4&#39;] </span><br><span class="line"></span><br><span class="line">with person_ 1 the e_distance:  0.4314467101915446with person_ 2 the e_distance:  0.4299990464683071with person_ 3 the e_distance:  0.4182695008637471with person_ 4 the e_distance:  0.4173694262729763with person_ 5 the e_distance:  0.38357217732017734Name list now: [&#39;person_4&#39;] </span><br><span class="line"></span><br><span class="line">with person_ 1 the e_distance:  0.4262991040992263with person_ 2 the e_distance:  0.43254966504500664with person_ 3 the e_distance:  0.41576433114841965with person_ 4 the e_distance:  0.4122140311433292with person_ 5 the e_distance:  0.38073570942005236Name list now: [&#39;person_4&#39;] </span><br><span class="line"></span><br><span class="line">with person_ 1 the e_distance:  0.42088261541728456with person_ 2 the e_distance:  0.42064499551908163with person_ 3 the e_distance:  0.404443147870785with person_ 4 the e_distance:  0.4043774203639022with person_ 5 the e_distance:  0.37271089160417986Name list now: [&#39;person_4&#39;] </span><br></pre></td></tr></table></figure>
<p><a href="http:"><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/copycode.gif" alt="复制代码"></a></p>
<p>　　实时输出结果：</p>
<p><img src="/../images/Python%203%20%E5%88%A9%E7%94%A8%20Dlib%20%E5%AE%9E%E7%8E%B0%E6%91%84%E5%83%8F%E5%A4%B4%E5%AE%9E%E6%97%B6%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/1152352-20180511181802460-722994837.png" alt="img"></p>
<p><strong>图 9 实时输出的欧氏距离结果</strong></p>
<p>　　通过实时的输出结果，看的比较明显；</p>
<p>　　输出绿色部分：当是我自己时，计算出来的欧式距离基本都在 <strong>0.2 左右</strong>；</p>
<p>　　输出红色部分：而换一张图片上去比如特朗普，明显看到欧式距离计算结果 <strong>达到了 0.8</strong>，此时就可以判定，后来这张人脸不是一张人脸；</p>
<p>　　所以之前提到的欧式距离计算对比的阈值可以由此设定，本项目中取的是 <strong>dist=0.4；</strong></p>
<p>　　 <strong>dist 的确切取值自己权衡，<a href="http://dlib.net/face_recognition.py.html">http://dlib.net/face_recognition.py.html</a> 的说明：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#   When using a distance threshold of 0.6, the dlib model obtains an accuracy#   of 99.38% on the standard LFW face recognition benchmark, which is#   comparable to other state-of-the-art methods for face recognition as of#   February 2017. This accuracy means that, when presented with a pair of face#   images, the tool will correctly identify if the pair belongs to the same#   person or is from different people 99.38% of the time.</span><br></pre></td></tr></table></figure>
<p><strong>3. 总结</strong></p>
<p>　　核心就是 <strong>提取人脸特征，然后计算欧式距离和预设的特征脸进行比对；</strong></p>
<p>　　不过这个实时获取摄像头人脸进行比对，要实时的进行计算摄像头脸的特征值，然后还要计算欧氏距离，所以计算量比较大，可能摄像头视频流会出现卡顿；</p>
<p>　　此项目仅个人学习爱好研究，开源供大家一起学习；</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>-Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫的N种姿势</title>
    <url>/post/830562ef.html</url>
    <content><![CDATA[<p>问题的由来</p>
<p>  前几天，在微信公众号（Python爬虫及算法）上有个人问了笔者一个问题，如何利用爬虫来实现如下的需求，需要爬取的网页如下（网址为：<a href="https://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0%EF%BC%89%EF%BC%9A">https://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0）：</a></p>
<p><img src="/../images/Python%E7%88%AC%E8%99%AB%E7%9A%84N%E7%A7%8D%E5%A7%BF%E5%8A%BF/2019061709510421.png" alt="img"></p>
<p>  我们的需求为爬取红色框框内的名人（有500条记录，图片只展示了一部分）的 名字以及其介绍，关于其介绍，点击该名人的名字即可，如下图：</p>
<p><img src="/../images/Python%E7%88%AC%E8%99%AB%E7%9A%84N%E7%A7%8D%E5%A7%BF%E5%8A%BF/20190617095158684.png" alt="img"></p>
<p>这就意味着我们需要爬取500个这样的页面，即500个HTTP请求（暂且这么认为吧），然后需要提取这些网页中的名字和描述，当然有些不是名人，也没有描述，我们可以跳过。最后，这些网页的网址在第一页中的名人后面可以找到，如George Washington的网页后缀为Q23.<br>  爬虫的需求大概就是这样。</p>
<h3 id="爬虫的4种姿势"><a href="#爬虫的4种姿势" class="headerlink" title="爬虫的4种姿势"></a>爬虫的4种姿势</h3><p>  首先，分析来爬虫的思路：先在第一个网页（<a href="https://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0%EF%BC%89%E4%B8%AD%E5%BE%97%E5%88%B0500%E4%B8%AA%E5%90%8D%E4%BA%BA%E6%89%80%E5%9C%A8%E7%9A%84%E7%BD%91%E5%9D%80%EF%BC%8C%E6%8E%A5%E4%B8%8B%E6%9D%A5%E5%B0%B1%E7%88%AC%E5%8F%96%E8%BF%99500%E4%B8%AA%E7%BD%91%E9%A1%B5%E4%B8%AD%E7%9A%84%E5%90%8D%E4%BA%BA%E7%9A%84%E5%90%8D%E5%AD%97%E5%8F%8A%E6%8F%8F%E8%BF%B0%EF%BC%8C%E5%A6%82%E6%97%A0%E6%8F%8F%E8%BF%B0%EF%BC%8C%E5%88%99%E8%B7%B3%E8%BF%87%E3%80%82">https://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0）中得到500个名人所在的网址，接下来就爬取这500个网页中的名人的名字及描述，如无描述，则跳过。</a><br>  接下来，我们将介绍实现这个爬虫的4种方法，并分析它们各自的优缺点，希望能让读者对爬虫有更多的体会。实现爬虫的方法为：</p>
<ul>
<li>一般方法（同步，requests+BeautifulSoup）</li>
<li>并发（使用concurrent.futures模块以及requests+BeautifulSoup）</li>
<li>异步（使用aiohttp+asyncio+requests+BeautifulSoup）</li>
<li>使用框架Scrapy</li>
</ul>
<h3 id="一般方法"><a href="#一般方法" class="headerlink" title="一般方法"></a>一般方法</h3><p>  一般方法即为同步方法，主要使用requests+BeautifulSoup，按顺序执行。完整的Python代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始时间</span></span><br><span class="line">t1 = time.time()</span><br><span class="line">print(<span class="string">&#x27;#&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0&quot;</span></span><br><span class="line"><span class="comment"># 请求头部</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 发送HTTP请求</span></span><br><span class="line">req = requests.get(url, headers=headers)</span><br><span class="line"><span class="comment"># 解析网页</span></span><br><span class="line">soup = BeautifulSoup(req.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line"><span class="comment"># 找到name和Description所在的记录</span></span><br><span class="line">human_list = soup.find(<span class="built_in">id</span>=<span class="string">&#x27;mw-whatlinkshere-list&#x27;</span>)(<span class="string">&#x27;li&#x27;</span>)</span><br><span class="line"></span><br><span class="line">urls = []</span><br><span class="line"><span class="comment"># 获取网址</span></span><br><span class="line"><span class="keyword">for</span> human <span class="keyword">in</span> human_list:</span><br><span class="line">    url = human.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    urls.append(<span class="string">&#x27;https://www.wikidata.org&#x27;</span>+url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取每个网页的name和description</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parser</span>(<span class="params">url</span>):</span></span><br><span class="line">    req = requests.get(url)</span><br><span class="line">    <span class="comment"># 利用BeautifulSoup将获取到的文本解析成HTML</span></span><br><span class="line">    soup = BeautifulSoup(req.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    <span class="comment"># 获取name和description</span></span><br><span class="line">    name = soup.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&quot;wikibase-title-label&quot;</span>)</span><br><span class="line">    desc = soup.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&quot;wikibase-descriptionview-text&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> desc <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        print(<span class="string">&#x27;%-40s,\t%s&#x27;</span>%(name.text, desc.text))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    parser(url)</span><br><span class="line"></span><br><span class="line">t2 = time.time() <span class="comment"># 结束时间</span></span><br><span class="line">print(<span class="string">&#x27;一般方法，总共耗时：%s&#x27;</span> % (t2 - t1))</span><br><span class="line">print(<span class="string">&#x27;#&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="number">1234567891011121314151617181920212223242526272829303132333435363738394041</span></span><br></pre></td></tr></table></figure>
<p>输出的结果如下(省略中间的输出，以…代替)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">##################################################</span><br><span class="line">George Washington                       ,	first President of the United States</span><br><span class="line">Douglas Adams                           ,	British author and humorist (1952–2001)</span><br><span class="line">......</span><br><span class="line">Willoughby Newton                       ,	Politician from Virginia, USA</span><br><span class="line">Mack Wilberg                            ,	American conductor</span><br><span class="line">一般方法，总共耗时：724.9654655456543</span><br><span class="line">##################################################</span><br><span class="line">12345678</span><br></pre></td></tr></table></figure>
<p>使用同步方法，总耗时约725秒，即12分钟多。<br>  一般方法虽然思路简单，容易实现，但效率不高，耗时长。那么，使用并发试试看。</p>
<h3 id="并发方法"><a href="#并发方法" class="headerlink" title="并发方法"></a>并发方法</h3><p>  并发方法使用多线程来加速一般方法，我们使用的并发模块为concurrent.futures模块，设置多线程的个数为20个（实际不一定能达到，视计算机而定）。完整的Python代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor, wait, ALL_COMPLETED</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始时间</span></span><br><span class="line">t1 = time.time()</span><br><span class="line">print(<span class="string">&#x27;#&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0&quot;</span></span><br><span class="line"><span class="comment"># 请求头部</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 发送HTTP请求</span></span><br><span class="line">req = requests.get(url, headers=headers)</span><br><span class="line"><span class="comment"># 解析网页</span></span><br><span class="line">soup = BeautifulSoup(req.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line"><span class="comment"># 找到name和Description所在的记录</span></span><br><span class="line">human_list = soup.find(<span class="built_in">id</span>=<span class="string">&#x27;mw-whatlinkshere-list&#x27;</span>)(<span class="string">&#x27;li&#x27;</span>)</span><br><span class="line"></span><br><span class="line">urls = []</span><br><span class="line"><span class="comment"># 获取网址</span></span><br><span class="line"><span class="keyword">for</span> human <span class="keyword">in</span> human_list:</span><br><span class="line">    url = human.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    urls.append(<span class="string">&#x27;https://www.wikidata.org&#x27;</span>+url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取每个网页的name和description</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parser</span>(<span class="params">url</span>):</span></span><br><span class="line">    req = requests.get(url)</span><br><span class="line">    <span class="comment"># 利用BeautifulSoup将获取到的文本解析成HTML</span></span><br><span class="line">    soup = BeautifulSoup(req.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    <span class="comment"># 获取name和description</span></span><br><span class="line">    name = soup.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&quot;wikibase-title-label&quot;</span>)</span><br><span class="line">    desc = soup.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&quot;wikibase-descriptionview-text&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> desc <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        print(<span class="string">&#x27;%-40s,\t%s&#x27;</span>%(name.text, desc.text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用并发加速爬取</span></span><br><span class="line">executor = ThreadPoolExecutor(max_workers=<span class="number">20</span>)</span><br><span class="line"><span class="comment"># submit()的参数： 第一个为函数， 之后为该函数的传入参数，允许有多个</span></span><br><span class="line">future_tasks = [executor.submit(parser, url) <span class="keyword">for</span> url <span class="keyword">in</span> urls]</span><br><span class="line"><span class="comment"># 等待所有的线程完成，才进入后续的执行</span></span><br><span class="line">wait(future_tasks, return_when=ALL_COMPLETED)</span><br><span class="line"></span><br><span class="line">t2 = time.time() <span class="comment"># 结束时间</span></span><br><span class="line">print(<span class="string">&#x27;并发方法，总共耗时：%s&#x27;</span> % (t2 - t1))</span><br><span class="line">print(<span class="string">&#x27;#&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="number">12345678910111213141516171819202122232425262728293031323334353637383940414243444546</span></span><br></pre></td></tr></table></figure>
<p>输出的结果如下（省略中间的输出，以…代替)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">##################################################</span><br><span class="line">Larry Sanger                            ,	American former professor, co-founder of Wikipedia, founder of Citizendium and other projects</span><br><span class="line">Ken Jennings                            ,	American game show contestant and writer</span><br><span class="line">......</span><br><span class="line">Antoine de Saint-Exupery                ,	French writer and aviator</span><br><span class="line">Michael Jackson                         ,	American singer, songwriter and dancer</span><br><span class="line">并发方法，总共耗时：226.7499692440033</span><br><span class="line">##################################################</span><br><span class="line">12345678</span><br></pre></td></tr></table></figure>
<p>使用多线程并发后的爬虫执行时间约为227秒，大概是一般方法的三分之一的时间，速度有了明显的提升啊！多线程在速度上有明显提升，但执行的网页顺序是无序的，在线程的切换上开销也比较大，线程越多，开销越大。<br>  关于多线程与一般方法在速度上的比较，可以参考文章：<a href="https://blog.csdn.net/jclian91/article/details/80738749">Python爬虫之多线程下载豆瓣Top250电影图片</a>。</p>
<h3 id="异步方法"><a href="#异步方法" class="headerlink" title="异步方法"></a>异步方法</h3><p>  异步方法在爬虫中是有效的速度提升手段，使用aiohttp可以异步地处理HTTP请求，使用asyncio可以实现异步IO，需要注意的是，aiohttp只支持3.5.3以后的Python版本。使用异步方法实现该爬虫的完整Python代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始时间</span></span><br><span class="line">t1 = time.time()</span><br><span class="line">print(<span class="string">&#x27;#&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0&quot;</span></span><br><span class="line"><span class="comment"># 请求头部</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 发送HTTP请求</span></span><br><span class="line">req = requests.get(url, headers=headers)</span><br><span class="line"><span class="comment"># 解析网页</span></span><br><span class="line">soup = BeautifulSoup(req.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line"><span class="comment"># 找到name和Description所在的记录</span></span><br><span class="line">human_list = soup.find(<span class="built_in">id</span>=<span class="string">&#x27;mw-whatlinkshere-list&#x27;</span>)(<span class="string">&#x27;li&#x27;</span>)</span><br><span class="line"></span><br><span class="line">urls = []</span><br><span class="line"><span class="comment"># 获取网址</span></span><br><span class="line"><span class="keyword">for</span> human <span class="keyword">in</span> human_list:</span><br><span class="line">    url = human.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    urls.append(<span class="string">&#x27;https://www.wikidata.org&#x27;</span>+url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步HTTP请求</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span>(<span class="params">session, url</span>):</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> response:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> response.text()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 解析网页</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">parser</span>(<span class="params">html</span>):</span></span><br><span class="line">    <span class="comment"># 利用BeautifulSoup将获取到的文本解析成HTML</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    <span class="comment"># 获取name和description</span></span><br><span class="line">    name = soup.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&quot;wikibase-title-label&quot;</span>)</span><br><span class="line">    desc = soup.find(<span class="string">&#x27;span&#x27;</span>, class_=<span class="string">&quot;wikibase-descriptionview-text&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> desc <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        print(<span class="string">&#x27;%-40s,\t%s&#x27;</span>%(name.text, desc.text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理网页，获取name和description</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            html = <span class="keyword">await</span> fetch(session, url)</span><br><span class="line">            <span class="keyword">await</span> parser(html)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">            print(err)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用asyncio模块进行异步IO处理</span></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">tasks = [asyncio.ensure_future(download(url)) <span class="keyword">for</span> url <span class="keyword">in</span> urls]</span><br><span class="line">tasks = asyncio.gather(*tasks)</span><br><span class="line">loop.run_until_complete(tasks)</span><br><span class="line"></span><br><span class="line">t2 = time.time() <span class="comment"># 结束时间</span></span><br><span class="line">print(<span class="string">&#x27;使用异步，总共耗时：%s&#x27;</span> % (t2 - t1))</span><br><span class="line">print(<span class="string">&#x27;#&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="number">1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859</span></span><br></pre></td></tr></table></figure>
<p>输出结果如下（省略中间的输出，以…代替)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">##################################################</span><br><span class="line">Frédéric Taddeï                         ,	French journalist and TV host</span><br><span class="line">Gabriel Gonzáles Videla                 ,	Chilean politician</span><br><span class="line">......</span><br><span class="line">Denmark                                 ,	sovereign state and Scandinavian country in northern Europe</span><br><span class="line">Usain Bolt                              ,	Jamaican sprinter and soccer player</span><br><span class="line">使用异步，总共耗时：126.9002583026886</span><br><span class="line">##################################################</span><br><span class="line">12345678</span><br></pre></td></tr></table></figure>
<p>显然，异步方法使用了异步和并发两种提速方法，自然在速度有明显提升，大约为一般方法的六分之一。异步方法虽然效率高，但需要掌握异步编程，这需要学习一段时间。<br>  关于异步方法与一般方法在速度上的比较，可以参考文章：<a href="https://blog.csdn.net/jclian91/article/details/82691269">利用aiohttp实现异步爬虫</a>。<br>  如果有人觉得127秒的爬虫速度还是慢，可以尝试一下异步代码（与之前的异步代码的区别在于：仅仅使用了正则表达式代替BeautifulSoup来解析网页，以提取网页中的内容）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始时间</span></span><br><span class="line">t1 = time.time()</span><br><span class="line">print(<span class="string">&#x27;#&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0&quot;</span></span><br><span class="line"><span class="comment"># 请求头部</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 发送HTTP请求</span></span><br><span class="line">req = requests.get(url, headers=headers)</span><br><span class="line"><span class="comment"># 解析网页</span></span><br><span class="line">soup = BeautifulSoup(req.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line"><span class="comment"># 找到name和Description所在的记录</span></span><br><span class="line">human_list = soup.find(<span class="built_in">id</span>=<span class="string">&#x27;mw-whatlinkshere-list&#x27;</span>)(<span class="string">&#x27;li&#x27;</span>)</span><br><span class="line"></span><br><span class="line">urls = []</span><br><span class="line"><span class="comment"># 获取网址</span></span><br><span class="line"><span class="keyword">for</span> human <span class="keyword">in</span> human_list:</span><br><span class="line">    url = human.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">    urls.append(<span class="string">&#x27;https://www.wikidata.org&#x27;</span> + url)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步HTTP请求</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span>(<span class="params">session, url</span>):</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> session.get(url) <span class="keyword">as</span> response:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> response.text()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析网页</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">parser</span>(<span class="params">html</span>):</span></span><br><span class="line">    <span class="comment"># 利用正则表达式解析网页</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        name = re.findall(<span class="string">r&#x27;&lt;span class=&quot;wikibase-title-label&quot;&gt;(.+?)&lt;/span&gt;&#x27;</span>, html)[<span class="number">0</span>]</span><br><span class="line">        desc = re.findall(<span class="string">r&#x27;&lt;span class=&quot;wikibase-descriptionview-text&quot;&gt;(.+?)&lt;/span&gt;&#x27;</span>, html)[<span class="number">0</span>]</span><br><span class="line">        print(<span class="string">&#x27;%-40s,\t%s&#x27;</span> % (name, desc))</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理网页，获取name和description</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            html = <span class="keyword">await</span> fetch(session, url)</span><br><span class="line">            <span class="keyword">await</span> parser(html)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">            print(err)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用asyncio模块进行异步IO处理</span></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">tasks = [asyncio.ensure_future(download(url)) <span class="keyword">for</span> url <span class="keyword">in</span> urls]</span><br><span class="line">tasks = asyncio.gather(*tasks)</span><br><span class="line">loop.run_until_complete(tasks)</span><br><span class="line"></span><br><span class="line">t2 = time.time()  <span class="comment"># 结束时间</span></span><br><span class="line">print(<span class="string">&#x27;使用异步（正则表达式），总共耗时：%s&#x27;</span> % (t2 - t1))</span><br><span class="line">print(<span class="string">&#x27;#&#x27;</span> * <span class="number">50</span>)</span><br><span class="line"><span class="number">12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061</span></span><br></pre></td></tr></table></figure>
<p>输出的结果如下（省略中间的输出，以…代替)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">##################################################</span><br><span class="line">Dejen Gebremeskel                       ,	Ethiopian long-distance runner</span><br><span class="line">Erik Kynard                             ,	American high jumper</span><br><span class="line">......</span><br><span class="line">Buzz Aldrin                             ,	American astronaut</span><br><span class="line">Egon Krenz                              ,	former General Secretary of the Socialist Unity Party of East Germany</span><br><span class="line">使用异步（正则表达式），总共耗时：16.521944999694824</span><br><span class="line">##################################################</span><br><span class="line">12345678</span><br></pre></td></tr></table></figure>
<p>16.5秒，仅仅为一般方法的43分之一，速度如此之快，令人咋舌（感谢某人提供的尝试）。笔者虽然自己实现了异步方法，但用的是BeautifulSoup来解析网页，耗时127秒，没想到使用正则表达式就取得了如此惊人的效果。可见，BeautifulSoup解析网页虽然快，但在异步方法中，还是限制了速度。但这种方法的缺点为，当你需要爬取的内容比较复杂时，一般的正则表达式就难以胜任了，需要另想办法。</p>
<h3 id="爬虫框架Scrapy"><a href="#爬虫框架Scrapy" class="headerlink" title="爬虫框架Scrapy"></a>爬虫框架Scrapy</h3><p>  最后，我们使用著名的Python爬虫框架Scrapy来解决这个爬虫。我们创建的爬虫项目为wikiDataScrapy，项目结构如下：</p>
<p><img src="/../images/Python%E7%88%AC%E8%99%AB%E7%9A%84N%E7%A7%8D%E5%A7%BF%E5%8A%BF/20190617095223407.png" alt="img"></p>
<p>在settings.py中设置“ROBOTSTXT_OBEY = False”. <a href="http://修改items.py/">修改items.py</a>，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WikidatascrapyItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    desc = scrapy.Field()</span><br><span class="line"><span class="number">12345678</span></span><br></pre></td></tr></table></figure>
<p>然后，<a href="http://在spiders文件夹下新建wikispider.py/">在spiders文件夹下新建wikiSpider.py</a>，代码如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy.cmdline</span><br><span class="line"><span class="keyword">from</span> wikiDataScrapy.items <span class="keyword">import</span> WikidatascrapyItem</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取请求的500个网址，用requests+BeautifulSoup搞定</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_urls</span>():</span></span><br><span class="line">    url = <span class="string">&quot;http://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q5&amp;limit=500&amp;from=0&quot;</span></span><br><span class="line">    <span class="comment"># 请求头部</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">    <span class="comment"># 发送HTTP请求</span></span><br><span class="line">    req = requests.get(url, headers=headers)</span><br><span class="line">    <span class="comment"># 解析网页</span></span><br><span class="line">    soup = BeautifulSoup(req.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    <span class="comment"># 找到name和Description所在的记录</span></span><br><span class="line">    human_list = soup.find(<span class="built_in">id</span>=<span class="string">&#x27;mw-whatlinkshere-list&#x27;</span>)(<span class="string">&#x27;li&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    urls = []</span><br><span class="line">    <span class="comment"># 获取网址</span></span><br><span class="line">    <span class="keyword">for</span> human <span class="keyword">in</span> human_list:</span><br><span class="line">        url = human.find(<span class="string">&#x27;a&#x27;</span>)[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">        urls.append(<span class="string">&#x27;https://www.wikidata.org&#x27;</span> + url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># print(urls)</span></span><br><span class="line">    <span class="keyword">return</span> urls</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用scrapy框架爬取</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">bookSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;wikiScrapy&#x27;</span>  <span class="comment"># 爬虫名称</span></span><br><span class="line">    start_urls = get_urls()  <span class="comment"># 需要爬取的500个网址</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        item = WikidatascrapyItem()</span><br><span class="line">        <span class="comment"># name and description</span></span><br><span class="line">        item[<span class="string">&#x27;name&#x27;</span>] = response.css(<span class="string">&#x27;span.wikibase-title-label&#x27;</span>).xpath(<span class="string">&#x27;text()&#x27;</span>).extract_first()</span><br><span class="line">        item[<span class="string">&#x27;desc&#x27;</span>] = response.css(<span class="string">&#x27;span.wikibase-descriptionview-text&#x27;</span>).xpath(<span class="string">&#x27;text()&#x27;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行该爬虫，并转化为csv文件</span></span><br><span class="line">scrapy.cmdline.execute([<span class="string">&#x27;scrapy&#x27;</span>, <span class="string">&#x27;crawl&#x27;</span>, <span class="string">&#x27;wikiScrapy&#x27;</span>, <span class="string">&#x27;-o&#x27;</span>, <span class="string">&#x27;wiki.csv&#x27;</span>, <span class="string">&#x27;-t&#x27;</span>, <span class="string">&#x27;csv&#x27;</span>])</span><br><span class="line"><span class="number">123456789101112131415161718192021222324252627282930313233343536373839404142</span></span><br></pre></td></tr></table></figure>
<p>输出结果如下（只包含最后的Scrapy信息总结部分）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#39;downloader&#x2F;request_bytes&#39;: 166187,</span><br><span class="line"> &#39;downloader&#x2F;request_count&#39;: 500,</span><br><span class="line"> &#39;downloader&#x2F;request_method_count&#x2F;GET&#39;: 500,</span><br><span class="line"> &#39;downloader&#x2F;response_bytes&#39;: 18988798,</span><br><span class="line"> &#39;downloader&#x2F;response_count&#39;: 500,</span><br><span class="line"> &#39;downloader&#x2F;response_status_count&#x2F;200&#39;: 500,</span><br><span class="line"> &#39;finish_reason&#39;: &#39;finished&#39;,</span><br><span class="line"> &#39;finish_time&#39;: datetime.datetime(2018, 10, 16, 9, 49, 15, 761487),</span><br><span class="line"> &#39;item_scraped_count&#39;: 500,</span><br><span class="line"> &#39;log_count&#x2F;DEBUG&#39;: 1001,</span><br><span class="line"> &#39;log_count&#x2F;INFO&#39;: 8,</span><br><span class="line"> &#39;response_received_count&#39;: 500,</span><br><span class="line"> &#39;scheduler&#x2F;dequeued&#39;: 500,</span><br><span class="line"> &#39;scheduler&#x2F;dequeued&#x2F;memory&#39;: 500,</span><br><span class="line"> &#39;scheduler&#x2F;enqueued&#39;: 500,</span><br><span class="line"> &#39;scheduler&#x2F;enqueued&#x2F;memory&#39;: 500,</span><br><span class="line"> &#39;start_time&#39;: datetime.datetime(2018, 10, 16, 9, 48, 44, 58673)&#125;</span><br><span class="line">1234567891011121314151617</span><br></pre></td></tr></table></figure>
<p>可以看到，已成功爬取500个网页，耗时31秒，速度也相当OK。再来看一下生成的wiki.csv文件，它包含了所有的输出的name和description，如下图：</p>
<p><img src="/../images/Python%E7%88%AC%E8%99%AB%E7%9A%84N%E7%A7%8D%E5%A7%BF%E5%8A%BF/20190617095238505.png" alt="img"></p>
<p>可以看到，输出的CSV文件的列并不是有序的。至于<a href="https://segmentfault.com/q/1010000010632474">如何解决Scrapy输出的CSV文件有换行的问题</a>，请参考stackoverflow上的回答：<a href="https://stackoverflow.com/questions/39477662/scrapy-csv-file-has-uniform-empty-rows/43394566#43394566">https://stackoverflow.com/questions/39477662/scrapy-csv-file-has-uniform-empty-rows/43394566#43394566</a> 。</p>
<p>  Scrapy来制作爬虫的优势在于它是一个成熟的爬虫框架，支持异步，并发，容错性较好（比如本代码中就没有处理找不到name和description的情形），但如果需要频繁地修改中间件，则还是自己写个爬虫比较好，而且它在速度上没有超过我们自己写的异步爬虫，至于能自动导出CSV文件这个功能，还是相当实在的。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>  本文内容较多，比较了4种爬虫方法，每种方法都有自己的利弊，已在之前的陈述中给出，当然，在实际的问题中，并不是用的工具或方法越高级就越好，具体问题具体分析嘛~<br>  本文到此结束，感谢阅读哦~</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>-Python</tag>
      </tags>
  </entry>
  <entry>
    <title>VirtualminWebmin安装与使用强大的VPS服务器和虚拟主机管理系统</title>
    <url>/post/8ff6ed20.html</url>
    <content><![CDATA[<p>Webmin是一个开源免费并且功能非常强大的基于Web的Unix系统管理工具，支持绝大多数的Unix系统，另外还包括：AIX、HPUX、Solaris、Unixware、Irix和FreeBSD等，Webmin可以对服务器、磁盘、网络、硬件等进行全方位的管理，功能媲美地WHM。</p>
<p>Virtualmin是<a href="https://www.freehao123.com/tag/webmin/">Webmin</a>一个模块，是一个功能强大的虚拟主机管理系统，包括了DNS、数据库、用户、网络配置、配额限制、邮局等等，甚至是整个服务器都可以使用Virtualmin来管理，Virtualmin可以很好与Webmin配合，实现全方位地管理VPS和服务器。</p>
<p><a href="https://www.freehao123.com/tag/virtualminwebmin/">Virtualmin/Webmin</a>搭配起来就相当于WHM/Cpanel面板了，如果再搭上WHMCS，就可以实现在线销售和自助管理虚拟空间了。本篇文章就来分享一下<a href="https://www.freehao123.com/tag/virtualmin/">Virtualmin</a>/Webmin安装与使用，由于Virtualmin/Webmin功能非常地多，有兴趣的朋友还需要深入地研究一下。</p>
<p>如果你对搭建虚拟主机管理平台和VPS主机管理面板有兴趣，可以看看：</p>
<ul>
<li>1、合租方案：<a href="https://www.freehao123.com/vps-hezu/">VPS主机多人合租使用或多用户共享服务器使用方案-权限分配管理</a></li>
<li>2、免费VPS面板：<a href="https://www.freehao123.com/vestacp-whmcs/">Vestacp整合WHMCS实现自动销售开通虚拟主机服务</a></li>
<li>3、流行的组合：<a href="https://www.freehao123.com/whm-cpanel/">WHM使用教程:管理Cpanel账户,服务器配置和基本操作方法</a></li>
</ul>
<p><strong><a href="https://www.freehao123.com/tag/virtualmin/">Virtualmin</a>/Webmin安装与使用:强大的VPS服务器和虚拟主机管理系统</strong></p>
<p><strong>一、Virtualmin/Webmin安装方法</strong></p>
<p>1、Virtualmin/Webmin官网：</p>
<ul>
<li>1、<a href="https://www.freehao123.com/tag/webmin/">Webmin</a>：<a href="http://www.[webmin](https://www.freehao123.com/tag/webmin/).com/">http://www.[webmin](https://www.freehao123.com/tag/webmin/).com/</a></li>
<li>2、Virtualmin：<a href="https://www.virtualmin.com/">https://www.virtualmin.com/</a></li>
</ul>
<p>2、Virtualmin/Webmin安装只要执行以下命令就可以了，安装时间也很短，大概只要十几分钟。</p>
<table>
<thead>
<tr>
<th><code>1 2 3 </code></th>
<th><code>wget http://software.virtualmin.com/gpl/scripts/install.sh   chmod +x install.sh    ./install.sh</code></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>3、安装好了Virtualmin/Webmin后，使用<a href="https://ip:10000或者https://域名:10000来登录你的管理面板后台，用户名是root，密码是你的VPS的root密码。">https://ip:10000或者https://域名:10000来登录你的管理面板后台，用户名是root，密码是你的VPS的root密码。</a></p>
<p>4、第一次登录使用Virtualmin/Webmin时，会提示让你选择相关的配置，主要是以省内存为优先还是以效率为优先。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_01.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_01.gif" alt="Virtualmin/Webmin启动配置"></a></p>
<p>5、另外还会要求设置好MysqL数据库管理员密码。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_02.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_02.gif" alt="Virtualmin/Webmin设置MysqL密码"></a></p>
<p>6、如果有自己的NS服务器，这时可以填写，否则可以直接跳过。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_03.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_03.gif" alt="Virtualmin/Webmin直接跳过"></a></p>
<p>7、进入了Virtualmin/Webmin后，点击webmin下的Change Language And Theme。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_05.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_05.gif" alt="Virtualmin/Webmin设置语言"></a></p>
<p>8、在这里选择语言为中文简体，重新加载，Virtualmin/Webmin就变成了中文了。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_06.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_06.gif" alt="Virtualmin/Webmin切换为中文"></a></p>
<p>9、这就是Virtualmin的管理面板。（点击放大）</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_09.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_09-500x240.gif" alt="Virtualmin控制面板"></a></p>
<p>10、这是Webmin的管理面板。（点击放大）</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_10.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_10-500x240.gif" alt="Webmin控制面板"></a></p>
<p><strong>二、Virtualmin/Webmin新建虚拟主机</strong></p>
<p>1、在创建虚拟主机前，先可以设置用户权限的“服务器模板”，否则直接使用默认的服务器模板权限和Root是一样大。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_13.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_13.gif" alt="Virtualmin/Webmin新建服务器模板"></a></p>
<p>2、在编辑服务器模板中可以对子目录权限、计划任务、端口号、SSL证书等进行相关的设置。（点击放大）</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_14.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_14-500x240.gif" alt="Virtualmin/Webmin编辑模板"></a></p>
<p>3、另外记得添加一个主机套餐模板，主要是规定新开通的主机的绑定域名数量、空间大小、流量大小和相关的服务器权限等等。（点击放大）</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_15.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_15-500x240.gif" alt="Virtualmin/Webmin设置主机套餐"></a></p>
<p>4、现在我们就可以点击Virtualmin下的“Create Virtual Server”来开通新的主机了。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_12.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_12.gif" alt="Virtualmin/Webmin开通新的主机"></a></p>
<p>5、填写域名、密码，选择好服务器模板和主机套餐，确定后即可开通新的虚拟主机。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_16.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_16.gif" alt="Virtualmin/Webmin主机配额"></a></p>
<p><strong>三、Virtualmin/Webmin添加FTP和邮局账户</strong></p>
<p>1、在新添加的虚拟主机下方，会有一个“编辑用户”选项。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_17.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_17.gif" alt="Virtualmin/Webmin编辑用户"></a></p>
<p>2、在这里我们就可以创建新的FTP账户和邮箱账户了，创建账户时可以对账户的权限进行相应的调整。（点击放大）</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_18.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_18-500x240.gif" alt="Virtualmin/Webmin新建FTP账户"></a></p>
<p><strong>四、Virtualmin/Webmin管理MysqL数据库</strong></p>
<p>1、点击Virtualmin，在新添加的虚拟主机下方会有“编辑数据库”选项。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_21.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_21.gif" alt="Virtualmin/Webmin管理数据库"></a></p>
<p>2、在这里就可以创建新的数据库。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_22.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_22.gif" alt="Virtualmin/Webmin新建MysqL"></a></p>
<p>3、管理MysqL数据库密码、导入与导出数据库。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_23.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_23.gif" alt="Virtualmin/Webmin导入与导出"></a></p>
<p><strong>五、强大的Virtualmin/Webmin主机备份功能</strong></p>
<p>1、在Virtualmin中会有一个“备份和恢复”功能，这里即可以备份整个服务器相关的设置，也可以备份单个虚拟主机的文件。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_24.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_24.gif" alt="Virtualmin/Webmin备份"></a></p>
<p>2、选择你的备份文件、格式、存储目标等即可执行自动与定时备份。（点击放大）</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_25.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_25-500x240.gif" alt="Virtualmin/Webmin定时自动备份"></a></p>
<p><strong>六、Virtualmin/Webmin管理多个IP地址</strong></p>
<p>1、第一步：添加新的IP地址。如果想给Virtualmin/Webmin增加新的IP地址，进入Webmin-&gt;网络-&gt;网络配置-&gt;增加接口，如图：</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_26.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_26.gif" alt="Virtualmin/Webmin增加新的IP"></a></p>
<p>2、在这里可以看到服务器上已经有的IP地址，点击增加接口就是新增加IP地址。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_27.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_27.gif" alt="Virtualmin/Webmin新建端口"></a></p>
<p>3、填入名称、IP地址等，点击新建并应用，如果IP地址正确的话就会添加成功。（点击放大）</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_28.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_28-500x240.gif" alt="Virtualmin/Webmin添加IP成功"></a></p>
<p>4、第二步：增加虚拟主机共享IP。进入Virtualmin-&gt;Addresses and Networking。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_29.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_29.gif" alt="Virtualmin/Webmin增加共享IP"></a></p>
<p>5、在共享的IP地址中填入需要增加的IP，并保存。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_30.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_30.gif" alt="Virtualmin/Webmin输入IP地址"></a></p>
<p>6、第三步：绑定IP到虚拟主机上。要想将IP单独给某一个域名或者虚拟主机使用，需要进入Virtualmin-&gt;服务器配置的修改IP地址。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_31.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_31.gif" alt="Virtualmin/Webmin进入虚拟主机IP管理页面"></a></p>
<p>7、在Shared address的下拉菜单选择新增加的IP地址即可。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_32.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_32.gif" alt="Virtualmin/Webmin绑定IP到域名"></a></p>
<p><strong>七、Virtualmin/Webmin对服务器相关管理操作</strong></p>
<p>1、Virtualmin/Webmin升级也很简单，如果有新的升级会在控制面板中看到提示。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_07.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_07.gif" alt="Virtualmin/Webmin自动升级"></a></p>
<p>2、点击自动升级后，Virtualmin/Webmin会自动下载安装包执行安装命令，最后升级完成。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_08.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_08.gif" alt="Virtualmin/Webmin升级更新完成"></a></p>
<p>3、在Webmin-&gt;系统-&gt;引导和关机中，可以查看并管理Virtualmin/Webmin的相关进程，甚至可以重启VPS和关闭整个系统。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_34.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_34.gif" alt="Virtualmin/Webmin重启关闭服务器"></a></p>
<p>4、另外在检查服务器配置时，会提示“The mailman queue processor /usr/lib/mailman/bin/qrunner is not running on your system. It can be started in the Bootup and Shutdown module… your system is not ready for use by Virtualmin.”</p>
<p>5、我们只要在引导和关机中启动Mailman进程即可。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_11.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_11.gif" alt="Mailman启动进程"></a></p>
<p><strong>八、Virtualmin/Webmin安装使用小结</strong></p>
<p>1、Virtualmin/Webmin安装很简单，功能很强大，几乎整个服务器可以使用Virtualmin/Webmin来管理，适合搭建多用户共享使用VPS服务器的平台，个人使用感觉是有点复杂了。</p>
<p><a href="https://www.freehao123.com/wp-content/uploads/2014/05/Virtualmin_20.gif"><img src="/../images/VirtualminWebmin%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%BC%BA%E5%A4%A7%E7%9A%84VPS%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/Virtualmin_20.gif" alt="Virtualmin/Webmin限制资源连接"></a></p>
<p>2、Virtualmin/Webmin的中文语言包汉化不完全，Virtualmin和Webmin在功能分类上有些模糊，有时想要进行某项操作往往会感觉找不到地方。如果有一套免费的财务系统就更完美了。</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>-linux</tag>
      </tags>
  </entry>
  <entry>
    <title>K1/K2刷华硕固件开OpenVPN安装HTTP透明代理搭建手机云免流服务器(苹果未越狱免流量)</title>
    <url>/post/72ee8144.html</url>
    <content><![CDATA[<p>第1步：打开<a href="http://www.ip138.com检查你的ip是否与路由器的WAN口IP一样，如果不一样，请跳过第2-4步，参考：[华硕老毛子固件Ngrok内网穿透教程](http://www.ittel.cn/archives/494.html)。">www.ip138.com检查你的ip是否与路由器的WAN口IP一样，如果不一样，请跳过第2-4步，参考：[华硕老毛子固件Ngrok内网穿透教程](http://www.ittel.cn/archives/494.html)。</a></p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/11b7b531f931d92ef630812af5a8b895.png" alt="img"></p>
<p>第2步：注册花生壳帐号，<a href="http://hsk.oray.com/">http://hsk.oray.com</a></p>
<p>第3步：到域名管理，注册一个花生壳域名：<a href="http://hsk.oray.com/bang/domain/">http://hsk.oray.com/bang/domain/</a></p>
<p>不会注册的请参考：<a href="http://www.ittel.cn/archives/498.html">怎么注册花生壳免费域名</a>。</p>
<p>温馨提醒：每一步设置完之后都要在最下面点一下“应用本页面配置”。</p>
<p>第4步：在华硕固件中填写你的花生壳帐号和密码以及刚申请的花生壳域名（记得删除前面的#号）。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/e05172123ae95a75e469f4a53ebadfc1.png" alt="img"></p>
<p>第5步：启用华硕固件VPN服务器，VPN服务器协议选择OpenVPN，交通选择TCP，如下图。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/b8e950f260b4778fabb6e47f1fd36b01.png" alt="img"></p>
<p>第6步：生成OpenVPN的证书及密钥，点击生成即可，这里生成时间较长，请耐心等待一会，然后保存。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/f705d09c6ac051792b6edb547ac17930.png" alt="img"></p>
<p>第7步：添加OpenVPN用户，切换到设置页面，VPN服务器协议选择PPTP，这里是临时切换，不要保存本页面，然后到客户帐户里添加。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/7cbd716a6cc92bdaf74fb74ee9be3140.png" alt="img"></p>
<p>第8步：切换到VPN服务器设置页面，找到VPN隧道设置如下两项。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/12f86fac7248b0492abae79477b0e6c8.png" alt="img"></p>
<p>第9步：导出OpenVPN配置文件，点击出口client.ovpn，如果无法导出换个浏览器即可。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/06056c18e852096797271e963819c445.png" alt="img"></p>
<p>设置完成后点击右上角注销右边的重启按钮重启路由器，切勿断电再开机，否则就前功尽弃了。</p>
<p>第10步：到花生壳域名列表中点击域名诊断看是否与自己的宽带拨号WAN口IP一致，如果不一致就是第4步没有配置好。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/05cc13d35b54903bf967367198a1a56a.png" alt="img"></p>
<p>第11步：修改刚才导出的client.ovpn，如下图所示，这里的难点在于你们地区的免流代码。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/246b1da1b22a015a00df6ae51751d8c2.png" alt="img"></p>
<p>第12步：然后将client.ovpn配置文件导入你的手机即可。</p>
<p>总结搭建OpenVPN免流失败的原因：</p>
<p>①路由器WAN口地址不是外网IP。</p>
<p>②没有严格按照以上教程配置OpenVPN。</p>
<p>③免流代码无效。</p>
<p>视频教程观看地址：<a href="https://pan.baidu.com/s/1pyxNNQF0Cpj6ksmImOMFuw">http://pan.baidu.com/s/1mhQhPig</a></p>
<p>安卓OpenVPN客户端现在基本度已经自带里，或者百度搜索。</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/q-300x300.jpg" alt="img"></p>
<p>扫描加入群<a href="https://jq.qq.com/?_wv=1027&k=5xodyNl">点此加入刷机交流群：773721392</a></p>
<blockquote>
<p>二、接下来是如何安装TinyProxy透明代理+免流代码</p>
</blockquote>
<p><em>因为对Linux不熟悉，通过一定的学习和研究，已经请教了原帖作者bigandy（在此表示感谢），基本搞定TinyProxy代理安装（高手略过）</em><br>第一步：下载TinyProxy，地址</p>
<p><a href="https://coding.net/u/bigandy/p/rt-n56u-ext-bin/git/tree/master/bin">https://coding.net/u/bigandy/p/rt-n56u-ext-bin/git/tree/master/bin</a></p>
<p> 作者已修改的支持 sock4/5 的编译版本。<br>第二步：修改配置文件，将Port改为自己需要的，这里我保留作者的9999不动（当然这一步可以省略）<br>第三步：路由器开启SSH的情况下用WinSCP将下好的文件传到路由的 /etc/storage/bin 文件夹里面，没有的创建，不要改路径。<br>第四步：赋予bin文件夹7777权限，并在命令行中运行./tinyproxy -c /etc/storage/bin/tinyproxy.conf （确认当前运行路径是/etc/storage/bin）<br>第五步：如果运行后没有任何提示，则自己改IE代理验证是否成功。</p>
<p>如果运行后有如下错误<br>/etc/storage/bin$ tinyproxy<br>-sh: tinyproxy: not found</p>
<h1 id="请重启路由再试。如果需要长久运行，可以在路由后台改自定义脚本加入以上命令。"><a href="#请重启路由再试。如果需要长久运行，可以在路由后台改自定义脚本加入以上命令。" class="headerlink" title="请重启路由再试。如果需要长久运行，可以在路由后台改自定义脚本加入以上命令。"></a>请重启路由再试。如果需要长久运行，可以在路由后台改自定义脚本加入以上命令。</h1><p>三、部分核心免流代码简介<br>那么如何能手机免流呢？免流代码是关键！至于原理自己李彦宏，至于是否能成功，必须亲自测试，请看好是必须！<br>以下代码是用于替换或添加openvpn配置文件里的免流代码的，具体看第一部分最后的截图。<br>#########免流代码############<br>这是免流代码之前必须添加的部分<br>dev tun<br>connect-retry-max 5<br>connect-retry 5<br>resolv-retry 60<br>下面是核心免流代码，能否免流就看这儿的了！<br>移动免流代码举例：<br>一、4 G<br>http-proxy-option EXT1 “POST <a href="http://mmsc.monternet.com/">http://mmsc.monternet.com</a>“<br>二、<br>http-proxy-option EXT1 “POST <a href="http://wap.sc.10086.cn/">http://wap.sc.10086.cn</a>“<br>http-proxy-option EXT1 “GET <a href="http://wap.sc.10086.cn/">http://wap.sc.10086.cn</a>“<br>http-proxy-option EXT1 “X-Online-Host: wap.sc.10086.cn”<br>http-proxy-option EXT1 “POST <a href="http://wap.sc.10086.cn/">http://wap.sc.10086.cn</a>“<br>http-proxy-option EXT1 “X-Online-Host: wap.sc.10086.cn”<br>http-proxy-option EXT1 “POST <a href="http://wap.sc.10086.cn/">http://wap.sc.10086.cn</a>“<br>http-proxy-option EXT1 “Host: wap.sc.10086.cn”<br>http-proxy-option EXT1 “GET <a href="http://wap.sc.10086.cn/">http://wap.sc.10086.cn</a>“<br>http-proxy-option EXT1 “Host: wap.sc.10086.cn”<br>http-proxy 10.0.0.172 80<br>（记得把wap.sc.10086.cn换成所在地区的wap掌厅）<br>三、<br>http-proxy-option EXT1 “POST <a href="http://wap.cmvideo.cn/">http://wap.cmvideo.cn</a>“<br>http-proxy-option EXT1 “GET <a href="http://wap.cmvideo.cn/">http://wap.cmvideo.cn</a>“<br>http-proxy-option EXT1 “X-Online-Host: wap.cmvideo.cn”<br>http-proxy-option EXT1 “POST <a href="http://wap.cmvideo.cn/">http://wap.cmvideo.cn</a>“<br>http-proxy-option EXT1 “X-Online-Host: wap.cmvideo.cn”<br>http-proxy-option EXT1 “POST <a href="http://wap.cmvideo.cn/">http://wap.cmvideo.cn</a>“<br>http-proxy-option EXT1 “Host: wap.cmvideo.cn”<br>http-proxy-option EXT1 “GET <a href="http://wap.cmvideo.cn/">http://wap.cmvideo.cn</a>“<br>http-proxy-option EXT1 “Host: wap.cmvideo.cn”<br>http-proxy 106.2.108.242 80</p>
<p>常用移动免流host有：wap.xx.10086.cn (xx是代表地区，比如广西就是wap.gx.10086.cn) wap.cmvideo.cn rd.go.10086.cn<br>联通免流host有：wap.10010.com<br>电信免流host有：ltetp.tv189.com<br>以上代码任选，以能够实现免流为准！是否免流可以下载个大文件过10分钟到一小时后查询流量，如果只跑了几个k则是免流成功！<br>如果跑了你那个大文件的流量就是不免，不要来找我，自己悠着点！<br>亲测sd地区必须加http-proxy 10.0.0.172 80这句代码才可以免，4G峰值也很快哦！ </p>
<p>联通免流代码举例：<br>一、虾米模式<br>http-proxy-option EXT1 “Proxy-Authorization: Basic MzAwMDAwNDU5MDpGRDYzQTdBNTM0NUMxMzFF”<br>http-proxy xiami.gzproxy.10155.com 8143<br>二、<br>http-proxy-option EXT1 “Proxy-Authorization: Basic MzAwMDAwNDU5MDpGRDYzQTdBNTM0NUMxMzFF”<br>http-proxy kugou.gzproxy.10155.com 8143<br>三、<br>http-proxy-option EXT1 Proxy-Authorization:Basic YWs0NDc5OjZjOGJlMmRkYzU3MjM4MmYxNzMyMmJiMjlhNDNkZjJi<br>http-proxy 123.138.56.20 81439 </p>
<p>四、<br>http-proxy-option EXT1 “Proxy-Authorization:Basic YWs0NDc5OjZjOGJlMmRkYzU3MjM4MmYxNzMyMmJiMjlhNDNkZjJi”<br>http-proxy 10.0.0.172 80</p>
<p>五、<br>http-proxy-option EXT1 “POST <a href="http://wap.10010.com/">http://wap.10010.com</a>“<br>http-proxy-option EXT1 “GET <a href="http://wap.10010.com/">http://wap.10010.com</a>“<br>http-proxy-option EXT1 “X-Online-Host: wap.10010.com”<br>http-proxy-option EXT1 “POST <a href="http://wap.10010.com/">http://wap.10010.com</a>“<br>http-proxy-option EXT1 “X-Online-Host: wap.10010.com”<br>http-proxy-option EXT1 “POST <a href="http://wap.10010.com/">http://wap.10010.com</a>“<br>http-proxy-option EXT1 “Host: wap.10010.com”<br>http-proxy-option EXT1 “GET <a href="http://wap.10010.com/">http://wap.10010.com</a>“<br>http-proxy-option EXT1 “Host: wap.10010.com”<br>http-proxy 106.2.108.242 80</p>
<p>使用自己服务器建立透明代理，如Squid、TinyProxy、Mproxy等的免流代码最后一行改为<br>http-proxy 你的服务器ip 端口号<br>电信没有测试，在此没有发言权，请测试了的朋友自己开贴发教程，谢谢！</p>
<p>四、内网IP用户突破限制架设云免服务器有关内网用户，可能以为云免与其无缘，其实华硕固件自带了穿透模式，即ngrokc服务！<br>请先去<a href="http://www.ngrok.cc/">www.ngrok.cc</a>网站注册一下，然后设定一个域名和tcp转发端口</p>
<p><img src="/../images/K1K2%E5%88%B7%E5%8D%8E%E7%A1%95%E5%9B%BA%E4%BB%B6%E5%BC%80OpenVPN%E5%AE%89%E8%A3%85HTTP%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E6%90%AD%E5%BB%BA%E6%89%8B%E6%9C%BA%E4%BA%91%E5%85%8D%E6%B5%81%E6%9C%8D%E5%8A%A1%E5%99%A8(%E8%8B%B9%E6%9E%9C%E6%9C%AA%E8%B6%8A%E7%8B%B1%E5%85%8D%E6%B5%81%E9%87%8F)/forum.php" alt="img"></p>
<p>路由器里设置的命令 按要求修改  记得系统域名和端口要和ngrok.cc服务器设置的一样 有很多在这一步设置错误</p>
<p>代码1<br>ngrokc -SER[Shost:server.ngrok.cc,Sport:4443,Atoken:0*<strong>这个是你自己的token**</strong>e]*</p>
<p>-*AddTun[Type:tcp,Lhost:192.168.X.1,Lport:1194,Rport:<em>你自己的端口</em>] </p>
<p>*-AddTun[Type:http,Lhost:192.168.0.1,Lport:80,Sdname:<em>你自己的系统域名</em>]</p>
<p>代码2<br>ngrokc -SER[Shost:server.ngrok.cc,Sport:4443,Atoken:0*<strong>这个是你自己的token**</strong>e] -AddTun[Type:http,Lhost:192.168.X.1,Lport:80,Sdname:<em>你自己的系统域名</em>]<br>ngrokc -SER[Shost:server.ngrok.cc,Sport:4443,Atoken:0*<strong>这个是你自己的token**</strong>e] </p>
<p>*-AddTun[Type:tcp,Lhost:192.168.X.1,Lport:1194,Rport:<em>你自己的端口</em>] &amp;</p>
<p>这2种代码自选一个测试 楼主只能用代码1 群内很多群友用的代码2 应该都能使用 使用方法看下图 点击图片放大</p>
<p><img src="https://www.anywlan.com/forum.php?mod=attachment&aid=NjM1Mzk3fDE0Mzg4ZjNjfDE2MDkyMTEzMTZ8MHwzOTU4MzQ=&noupdate=yes" alt="img"> </p>
<p>如何检查是否穿透成功呢<br>比如我<a href="http://www.ngrok.cc/">ngrok.cc</a>设置的系统域名:admin TCP转发端口:8888</p>
<p>例如：<br>这个代码和路由自带的不一样  会多出-Addtun什么 后边的一部分是路由远程域名<br>一切设置好了登录admin.ngrok.cc 可以登录路由器管理界面就算穿透了<br>这个admin是你自己在<a href="http://www.ngrok.cc/">ngrok.cc</a>设置的系统域名 自己设置什么请对应填写什么 端口同样</p>
<p><img src="https://www.anywlan.com/forum.php?mod=attachment&aid=NjM1Mzk4fGY5YjBmMjdkfDE2MDkyMTEzMTZ8MHwzOTU4MzQ=&noupdate=yes" alt="img"></p>
<p>关于ngrokc更新问题 我用的是华硕5.26版本 没有更新ngrok插件写入代码直接可以用<br>内网也可以使用花生壳但是花生壳不出SN码 没办法  出SN码的自己实验提供一行代码<br>原贴地址:<a href="http://www.right.com.cn/forum/thread-161324-1-1.html">http://www.right.com.cn/forum/thread-161324-1-1.html</a>      6楼</p>
<p>我改了一份花生壳内网版的脚本，和adbyby一样独立运行在tmp下的脚本，麻烦楼主帮忙看看能不能合入到固件里，这样和ss分开，一些低内存没有usb口的机器也可以用了。此代码不用开启花生壳拓展  也不需要opt环境   只需一行代码就可以开启了</p>
<p>wget -t 10 -O /tmp/install_oray.sh <a href="http://code.taobao.org/svn/test43/phddns2/tmp/install_oray.sh">http://code.taobao.org/svn/test43/phddns2/tmp/install_oray.sh</a> &amp;&amp; sh /tmp/install<br>sleep 30<br>sh /home/root/startss.sh” </p>
<p>直接加在自定义脚本 运行路由启动后的脚本最下面<br>ngrok服务器映射没有想象中的稳定，要重复多次，大家可以多换几个服务器试试</p>
<p>如果有想法，也可以用小主机、树莓派搭建，效果要比路由器好，而且能够一次集成透明代理服务。<br>有关路由器的搭建方法到此结束，云主机、小主机搭建方法很多，网上有很多一键脚本，具体可以看如下链接，在此不再赘述。<br><a href="http://www.aeink.com/42.html0">http://www.aeink.com/42.html0</a> </p>
<p>贴中引用了部分作者的原创，在此表示感谢<a href="http://www.92zuanke.com/">www.92zuanke.com</a>（就爱赚客）、4G免流社区（<a href="http://www.4gml.com/">www.4gml.com</a>）、百度相关贴吧（云免、免流、移动免流、免流破解等等）</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>WNMPA一键环境 1.0.0.0 正式版发布</title>
    <url>/post/b5e8cb00.html</url>
    <content><![CDATA[<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/wnmpa.png" alt="wnmpa"></p>
<p>　　呼呼～～说好的WNMPA终于发布了，先简要说下WNMPA是什么吧。WNMPA是(Windows Nginx MySQL PHP Apache的一个集合包)以Nginx作为前端处理静态文件，Apache后端处理动态文件。当然如果你不需要这种结构，你也可以把A去掉，WNMP就够了。</p>
<p>最新动态：</p>
<p>今天无意中登陆了一下博客，发现居然还有人在下载WNMPA，这其实让我很意外。不过回头想想，我其实还是很欣慰的。</p>
<p>不过呢，其实我觉得大家可能其实根本用不到这么庞大的一个东西，毕竟光是各种软件的32位数跟64位就比同类集成环境大了一倍多，真正的实用性并不强，如果大家不喜欢折腾的话，我还是推荐XAMPP，毕竟那个已经稳定运行了那么久。我也动手将其汉化了一下，<a href="https://csharp.love/xampp_cn.html">点我查看</a>，实用性应该还是很强的。</p>
<p>好了说回正题，如果您打算继续使用wnmpa的话，那么你可能需要更新一下，</p>
<p>因为之前的版本好像有一些bug，比如在win7下关闭会报错什么的。</p>
<p>只不过我是个单文件控，所以我还是用软件加了个壳然后把附带的dll打了个包，可是杀毒软件又开始不乐意了……真难伺候，我自己把它排除了，大家就随意吧。</p>
<p>直接覆盖安装包里面的wnmpa.exe就行了。</p>
<p>下载：<a href="https://static.pzhacm.org/wp-upload/2012/07/wnmpa.7z">wnmpa</a>(密码wnmpa)</p>
<p>说在前面：</p>
<p>首先，要说明一点，我写这个东西并不是为了造福人类，而是因为我自己要用到，不小心被朋友看见了，觉得不错，让我分享，所以嘛，大家就别把这个软件看得这么严重，如果有Bug什么的，顺便告诉我一声，感激不尽。</p>
<p>说到这，可能各位看官又会问了：你说这种东西网上一抓一大把，比如<a href="http://go.ccc.xxx/fwlink/xampp">XAMPP</a>，你为啥要自己整个，你不有病么？——其实呢，不是我有病， 我肯定不会去搞一个一模一样的东西出来。怎么说呢，XAMPP的确很优秀，不过XAMPP侧重集成环境，连FTP服务端、邮件服务端都给准备了，而我平时用不到这些，所以干脆按照自己的需求整一个自己喜欢的。</p>
<p>其实我写的这个程序只有1.9M左右而已，但是安装包却有90多M左右，解压出来大概765M，那么为什么会这么大呢？原因很简单，我肯定不会让各位那么幸苦去自己下载服务端来安装的，我在这里一共准备了三个版本的php(32位的Non Thread Safe的、32位的Thread Safe的、64位的Thread Safe的)，和两个版本的Apache(32位版、64位版)、MySQL(32位版、64位版)、Tomcat(32位版、64位版)，这些玩意占了很大的空间。</p>
<p>一些小疑问：</p>
<ul>
<li>人家都用的5.2老版本php，你为啥非得用5.4，还有什么mysql啊，nginx啊，什么都用最新版的，多不稳定啊！<pre><code> 答：这个怎么说呢， 有个很简单的比喻：Win7和XP，Win7在发布正式版的时候，很多人不习惯，认为Win7“不稳定”，然后坚守XP阵营。而直到现在，依然有很大一批的老一辈革命家认为XP还能再战20年。
 那么各位再仔细回忆一下，当年Win98盛行的时候，又是怎么看待XP的呢？
 有些人一定有过这样的想法：这个破Win7，连XX软件都不支持，还有什么用，我还是换回XP吧。
 可是直到最后，依然摆脱不了换新版操作系统的命运。
 操作系统是这样的，那么同理php、mysql、apache也是这样， 我们当然可以等到周围所有人都用上新版本了，我们才慢慢悠悠更新。但是我个人却是个急性子，我可忍受不了新特性对我的诱惑。</code></pre>
</li>
<li>我电脑上有JDK啊，为啥Tomcat无法运行呢？<pre><code> 因为JDK默认是没有注册到环境变量里的，Tomcat是以系统里的%JAVA_HOME%作为JDK是否存在的判断依据的。</code></pre>
</li>
<li>为啥Nginx已经停止了，按钮却还是显示的“正在停止”或者“停止”呢？<pre><code> 因为Nginx本身不提供注册到系统服务这项功能，所以我使用了 instsrv.exe和srvany.exe来使Nginx注册为Windows服务，有时候Nginx的确停掉了，但是他的宿主进程没有被停掉，所以嘛……打开services.msc手动重启下呗～</code></pre>
</li>
<li>为啥我自己localhost访问可以，别人访问我就403呢？<pre><code> 亲，因为你访问的这个网站绑定的域名就是localhost，为了防止你服务器被人恶意指向(国内某些云主机，如果你的服务器被未备案的域名指向了，他们会关掉你的服务器)，我特地将Nginx的默认站点设置为直接返回403。如果想绑定域名，请在主界面添加虚拟站点。</code></pre>
</li>
<li>为什么你的这个WNMPA环境不能拿去作为生产环境呢？<pre><code> 因为我是个开发者，所以我使用的都是最新版的服务端，php也打开了所有函数，连有些可能会导致出问题的函数都被打开了。所以从一定角度上来说，直接解压出来以后，这个东西的确不应该用做生产环境，如果真的需要的话，就建议去百度一下php的php.ini、mysql的my.ini、apache和nginx的conf文件构成，然后自己改写一个安全而又适合自己的生产环境。</code></pre>
</li>
</ul>
<p>软件截图：</p>
<p>安装界面：</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image002.jpg" alt="img"></p>
<p>初始化调查界面：</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image003.jpg" alt="img"></p>
<p>主界面：</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image004.jpg" alt="img"></p>
<p>虚拟主机管理：</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image005.jpg" alt="img"></p>
<p>添加虚拟主机信息收集：</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image006.jpg" alt="img"></p>
<p>非线程安全php的phpinfo()：</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image008.jpg" alt="img"></p>
<p>线程安全php的phpinfo():</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image010.jpg" alt="img"></p>
<p>非线程安全的php(配合nginx fcgi方式运行)，加载了Zend Optimizer+：</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image012.jpg" alt="img"></p>
<p>退出之前询问：</p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image001.png" alt="img"></p>
<p><img src="/../images/WNMPA%E4%B8%80%E9%94%AE%E7%8E%AF%E5%A2%831000%E6%AD%A3%E5%BC%8F%E7%89%88%E5%8F%91%E5%B8%83/clip_image014.jpg" alt="img"></p>
<p> OK，下面放出下载地址：<br> <a href="http://down.pzhacm.org/wnmpa.exe">本地下载</a>、<a href="http://pan.baidu.com/share/link?shareid=104427&uk=2415932059">百度网盘</a>、<a href="http://dl.vmall.com/c0qghxr725">华为网盘</a></p>
<p>此版本存在一个已知问题：如果将Nginx注册成服务，则在主界面无法重启，需要进入services.msc找到Nginx_wnmpa手动重启。</p>
<p>测试过的操作系统：<br> Windows XP Professional SP3<br> Windows Server 2003 Enterprise SP2<br> Windows Server 2008 R2 Enterprise SP1<br> Windows 7 Ultimate x86 SP1</p>
<p>依赖的框架：<br> .NET Framework 2.0<br> Visual C++ 9.0 Runtime<br> Visual C++ 10.0 Runtime<br> 以上框架的所有安装包下载地址记录在安装目录下的[请先阅读.txt]中。</p>
<p>如果您想帮助WNMPA发展：</p>
<p><strong>&gt;**</strong>放心吧，不会让您捐赠的。我的意思是，如果您可以提供下载节点；**<br> <strong>&gt;**</strong>或者说是您的英语、日语、XXXXXXX语不错，可以帮忙翻译翻译这个软件；**<br> <strong>&gt;**</strong>或者您可以当一当小白，来测试这个软件。**</p>
<p><strong>都是对WNMPA最大的帮助！</strong> </p>
<p>最后唠叨一句：由于本环境使用程序版本较新，所以强烈建议只将本环境作为开发学习研究用，请勿用于生产环境！仅供学习交流！另外，还请那些高得我看不见的高射炮高抬贵手，不要用高傲的眼神来蔑视我。我只接受合理的意见、建议和指导。在我的博客里，请收回自己的优越感，谢谢合作！</p>
]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>-WNMPA</tag>
      </tags>
  </entry>
  <entry>
    <title>【教程固件】 酷比魔方Talk5H刷机指南,解救小白</title>
    <url>/post/11f986cf.html</url>
    <content><![CDATA[<p>安卓机最大的乐趣就是刷机了，鉴于很多5H的机油还不会刷机，只有写个教程出手一助了。提醒一句，刷机有风险，变砖的话LZ可不承担责任。</p>
<p>不过根据LZ多年的刷机经验。要想把手机刷成砖，也是需要一定技术的，大胆的尝试吧。</p>
<p>Talk5H刷机需要的几个工具下载</p>
<p><strong>1）一键ROOT工具</strong></p>
<p><a href="http://pan.baidu.com/share/link?shareid=2646370454&amp;uk=288410357">http://pan.baidu.com/share/link?shareid=2646370454&amp;uk=288410357</a></p>
<p>2）叔叔工具箱**<br><a href="http://pan.baidu.com/share/link?shareid=2650065834&amp;uk=288410357">http://pan.baidu.com/share/link?shareid=2650065834&amp;uk=288410357</a></p>
<p><strong>3）Recovery</strong></p>
<p>Talk5H第三方Recovery （用于刷<strong>Talk5H第三方ROM</strong>，如MIUI，原生精简版，MUSE UI等等）<br><a href="http://pan.baidu.com/share/link?shareid=2656531356&amp;uk=288410357">http://pan.baidu.com/share/link?shareid=2656531356&amp;uk=288410357</a></p>
<p>Talk5H官方Recovery （用于刷<strong>Talk5H官方ROM</strong>）<br><a href="http://pan.baidu.com/share/link?shareid=4107364334&amp;uk=288410357">http://pan.baidu.com/share/link?shareid=4107364334&amp;uk=288410357</a></p>
<p><strong>4）rom文件</strong></p>
<p>目前Talk5H的<strong>第三方rom</strong>有</p>
<p>作者 <strong>ccfly_89</strong> ；</p>
<p>完美、稳定、流畅ROM来了，移植Muse UI</p>
<p><a href="http://bbs.51cube.com/thread-77996-1-1.html">http://bbs.51cube.com/thread-77996-1-1.html</a></p>
<p>应该是最流畅最省电的ROM：原汁原味原生体验，Talk5H原生版ROM发布</p>
<p><a href="http://bbs.51cube.com/thread-78401-1-1.html">http://bbs.51cube.com/thread-78401-1-1.html</a></p>
<p>作者 <strong>米柚真威武</strong> ；</p>
<p>[MIUI-V5-ROM] <a href="http://bbs.ereadcn.com/forum-21-1.html">酷比魔方</a>Talk 5H【开发版第一期-13.8.16】</p>
<p><a href="http://bbs.51cube.com/thread-77722-1-1.html">http://bbs.51cube.com/thread-77722-1-1.html</a></p>
<p>[MIUI-V5-ROM] 酷比魔方Talk 5H【开发版第2期-13.8.23】</p>
<p><a href="http://bbs.51cube.com/thread-78356-1-1.html">http://bbs.51cube.com/thread-78356-1-1.html</a></p>
<p>移植红米真正完美MIUI V5稳定版【第一期】，再送近500个漂亮的MIUI收费主题爽到爆</p>
<p><a href="http://bbs.51cube.com/thread-78477-1-1.html">http://bbs.51cube.com/thread-78477-1-1.html</a></p>
<p>作者<strong>吉他</strong> ；</p>
<p>基于官方V1.01版，吉他发布TALK 5H【A5300】精简优化固件</p>
<p><a href="http://bbs.ereadcn.com/forum.php?mod=viewthread&amp;tid=99166&amp;fromuid=14">http://bbs.ereadcn.com/forum.php?mod=viewthread&amp;tid=99166&amp;fromuid=14</a></p>
<p>作者 <strong>wuxianlin</strong> ；</p>
<p>CUBE Talk 5H完美移植红米HBJ2.0 MIUI V5</p>
<p><a href="http://bbs.51cube.com/thread-78280-1-1.html">http://bbs.51cube.com/thread-78280-1-1.html</a></p>
<p>官方rom**有 </p>
<p>比魔方Talk 5H V1.01（出厂固件）发布，反馈BUG请跟帖</p>
<p><a href="http://bbs.51cube.com/thread-77711-1-1.html">http://bbs.51cube.com/thread-77711-1-1.html</a></p>
<p>5）如果觉得麻烦还可以下载 Talk 5H刷机工具箱 by wuxianlin V1.1<a href="http://bbs.51cube.com/thread-78236-1-1.html">http://bbs.51cube.com/thread-78236-1-1.html</a></p>
<p>这只工具箱集合了一键root，一键刷入recovery，一键安装谷歌服务套件等功能，非常强大，适合没有刷机经验的使用，配合PC鼠标点击操作，非常方便。</p>
<p>下面教程需要下载工具</p>
<p><strong>1）一键ROOT工具</strong></p>
<p><a href="http://pan.baidu.com/share/link?shareid=2646370454&amp;uk=288410357">http://pan.baidu.com/share/link?shareid=2646370454&amp;uk=288410357</a></p>
<p>2）叔叔工具箱**<br><a href="http://pan.baidu.com/share/link?shareid=2650065834&amp;uk=288410357">http://pan.baidu.com/share/link?shareid=2650065834&amp;uk=288410357</a></p>
<p>3）Recovery**</p>
<p>Talk5H第三方Recovery （用于刷<strong>Talk5H第三方ROM</strong>，如MIUI，原生精简版，MUSE UI等等）<br><a href="http://pan.baidu.com/share/link?shareid=2656531356&amp;uk=288410357">http://pan.baidu.com/share/link?shareid=2656531356&amp;uk=288410357</a></p>
<p><strong>4）rom文件</strong><br>第三方ROM任选</p>
<p><strong>一键ROOT工具在PC解压使用</strong></p>
<p>叔叔工具箱安装到5H中使用**</p>
<p>第三方Recovery放到手机根目录**</p>
<p>rom文件,放到手机或者卡中**</p>
<p>刷机教程；<br>1）root<br>2）安装 recovery</p>
<p>3）刷机<img src="http://www.ereadcn.com/data/attachment/forum/201308/31/0050009a1t1nzzn6aqw2a2.jpg" alt="img"><br><img src="http://www.ereadcn.com/data/attachment/forum/201308/31/005003ev5qe5pw3vvle0ua.jpg" alt="img"><br><img src="http://www.ereadcn.com/data/attachment/forum/201308/31/0050060jzjtt7bqscuf0mm.jpg" alt="img"> </p>
<p>要刷回官方ROM<br>需要安装官方recovery进行上述的操作</p>
<p><strong>3）Recovery</strong><br>Talk5H官方Recovery （用于刷<strong>Talk5H官方ROM</strong>）<br><a href="http://pan.baidu.com/share/link?shareid=4107364334&amp;uk=288410357">http://pan.baidu.com/share/link?shareid=4107364334&amp;uk=288410357</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>f-gan生成对抗神经网络进阶第一级</title>
    <url>/post/49c94cd0.html</url>
    <content><![CDATA[<p>在之前我们做始祖Gan的数学推导的时候，其实留下了一堆坑（不知道你注意到了没有哈哈）。当然，牛逼的人就是这样的，指明了一条光明大道，让人知道从哪里走，然后剩下的一些坑坑洼洼刚刚好就能帮助一些博士、硕士毕业或者一些人评副教授、教授啥的。</p>
<p>这篇文章介绍的f-gan就是填的其中一个坑，那就是给V(G,D)这个函数一个更加通用的描述。在始祖文章里面，这个函数是直接写出来的，虽然知道它巧妙得令人窒息，而且也确实是在算拟合网络和实际数据之间的数据分布距离（JS），但具体为什么能那么列式，那么列式之后为什么就刚刚好算的是分布间的某种距离其实我们是不大知道的，这导致的结果就是我们只能用它的，不能改进。而f-gan要解决的就是这个问题，它将告诉我们一道通用公式。在这道公式的约束下，你爱咋整咋整。</p>
<p>首先我们看怎么一般化的表述两个分布之间的距离，f-gan告诉我们是这样的：<br>$$<br>D _ { f } ( P | Q ) = \int _ { x } q ( x ) f \left( \frac { p ( x ) } { q ( x ) } \right) d x<br>$$<br>这里有两个约束，第一：f是凸函数；第二：f(1)=0</p>
<p>由始祖文章的数学推导我们知道，对于神经网络而言，我们去衡量两个分布之间的差距其实不需要那么准，只要当他们有差距的时候，损失函数输出一个正值，而没差距的时候输出一个0就OK。那么f(1)=0就很好理解，当两个分布相同，只要满足这一约束就能使得最后的<br>$$<br>D _ { f } ( P | Q )<br>$$<br>也等于0。剩下我们就只需要证明在两个分布不完全相等的情况下，<br>$$<br>D _ { f } ( P | Q )<br>$$<br>大于0，就可以认为这道式子在表达两个分布之间的某种距离。</p>
<p>证明的过程我们会用到<a href="https://aichn.cn/post/96895f36.html">琴生不等式</a>（要求f是凸函数也跟用到它有关，证明请移步链接所指文章），该不等式告诉我们：<br>$$<br>E ( f ( x ) ) \geq f ( E ( x ) )<br>$$<br>我们可以把<br>$$<br>f \left( \frac { p ( x ) } { q ( x ) } \right)看成f(x)，q(x)看成x的分布，那么D _ { f } ( P | Q )直接就变成E ( f ( x ) )E(f(x))<br>$$<br>，故：<br>$$<br>D _ { f } ( P | Q ) \geq f(\int _ { x } q ( x )  \left( \frac { p ( x ) } { q ( x ) } \right) d x)=f(1)=0<br>$$<br>注意，由于琴生不等式等于号只有在x分布完全均匀的时候取得（在这个应用中几乎不可能发生），因此基本可以判定除非<br>$$<br>D _ { f } ( P | Q )<br>$$<br>中的两个分布完全相等，不然不会取得等于号，这是极好的！避免了我们训练突然因为loss等于0而没反应的情况。</p>
<p>完成了上面的推理，我们得到了两个分布的某种距离的一般表达式。但它还不是V(G,D)，原因是这里面既没有G也没有D（其实有D就好了,G在D里面），也就是说这是道看起来很美但对于Gan完全没用的式子。</p>
<p>那怎么让这道式子跟D网络有关呢？我们可以想D是一个评价数据是不是真实分布的东西，当我们在训练D的时候，我们希望整个距离表达式最大。那么，能不能找到一个式子，当D使得距离表达式取最大值的时候，式子刚刚好就等于上面的<br>$$<br>D _ { f } ( P | Q )= \int _ { x } q ( x ) f \left( \frac { p ( x ) } { q ( x ) } \right) d x<br>$$<br>呢？</p>
<p>要求有点多，但还真有办法实现！</p>
<p>那就是利用<a href="https://aichn.cn/post/e66f8853.html">共轭函数</a>（具体见链接所指博客或自行google），它的定义如下：<br>$$<br>f ^ { * } ( t ) = \max _ { x \in \operatorname { dom } ( f ) } { x t - f ( x ) }<br>$$<br>它告诉我们，假设f(x)是一个凸函数，那么它存在一个共轭函数长上面描述的那样，写作<br>$$<br>f ^ { * } ( t )。<br>$$</p>
<p>$$<br>f ^ { * } ( t )<br>$$</p>
<p>本身也是凸函数，且它的共轭函数是f(x)。也就有：<br>$$<br>f( x ) = \max _ { t \in \operatorname { dom } ( f  ^ { * } ) } { x t - f  ^ { * } ( t ) }<br>$$<br>假设这个时候我们把<br>$$<br>f \left( \frac { p ( x ) } { q ( x ) } \right)<br>$$<br>看成是f(x)（前提是，<br>$$<br>f( 1 ) = \max _ { t \in \operatorname { dom } ( f  ^ { * } ) } { t - f  ^ { * } ( t ) }=0<br>$$<br>，这样f(x)就完全符合<br>$$<br>$D _ { f } ( P | Q ) $<br>$$<br>的要求），可得到：<br>$$<br>D _ { f } ( P | Q ) = \int _ { x } q ( x ) \max _ { t \in \operatorname { dom } ( f  ^ { * } ) } { \frac { p ( x ) } { q ( x ) } t - f  ^ { * } ( t ) } d x<br>$$<br>这个时候的公式其实还是跟D和G网络没什么关系，接着的这一步闪瞎眼，因为它做出了一个神之假设，假设有个神经网络D，输入是x，然后输出是t，这样上面的式子直接就变成<br>$$<br>D _ { f } ( P | Q ) = \int _ { x } q ( x ) \max _ { D(x) \in \operatorname { dom } ( f  ^ { * } ) } { \frac { p ( x ) } { q ( x ) } D(x) - f  ^ { * } ( D(x) ) } d x<br>$$</p>
<p>$$<br>\geq\int _ { x } q ( x ) { \frac { p ( x ) } { q ( x ) } D(x) - f  ^ { * } ( D(x) ) } d x<br>$$</p>
<p>等于号在D(x)刚刚好等于使得积分中的全部式子最大的t的集合时取得。将式子进一步化简得到<br>$$<br>=\int _ { x } p ( x )D(x) - q ( x )f  ^ { * } ( D(x) )  d x<br>$$<br>这道式子牛逼的地方不知道你看出来了没有，它就在于这个≥号，回忆一下始祖gan，D网络的目标是最大化距离式子。而上面这道式子，我们恰恰好就能训练D网络来使得式子取得最大值。这个时候，式子可以写成下面的形式：</p>
<p><img src="/../images/f-gan%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E9%98%B6%E7%AC%AC%E4%B8%80%E7%BA%A7/HxmWegThKvG1sNjwAnfobKQJWGk8c_rBCTiWt8DHgfY.original.fullsize.png" alt="img"></p>
<p>对于G网络而言，我们目的是最小化距离式子，则写成如下形式：</p>
<p><img src="/../images/f-gan%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E9%98%B6%E7%AC%AC%E4%B8%80%E7%BA%A7/image-20210102233819152.png" alt="image-20210102233819152"></p>
<p>不知各位看出来没有，它就是通用版本的gan距离计算公式。真的对弄出这个东西的数学家跪服，太牛逼了！</p>
<p>有了这个公式，我们只要找出一个凸函数（这里文章是这么写的，但其实非凸函数的共轭函数也是凸函数，因此不太清楚为什么要有这一条件，先存疑吧，有老哥知道麻烦留意告诉我）符合正实数域上有取值且是连续的，满足t−f(1)=0就可以作为<br>$$<br>f^*。<br>$$<br>文章中也列举了个可选的函数：<br><img src="/../images/f-gan%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E9%98%B6%E7%AC%AC%E4%B8%80%E7%BA%A7/20190204011004991.png" alt="在这里插入图片描述"><br>经过该篇文章，我们解放了距离函数的限制，让它可以带着镣铐跳舞了，而不是一动不动的木乃伊。</p>
<p>但其实它证明了一个让人哭笑不得的结论，始祖gan之所以效果不太好，跟我们选用的距离函数没有太大关系。也就是说，它的贡献主要在于帮助我们排除了一个错误答案。。。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>iPhone6/6 Plus怎么换电池</title>
    <url>/post/24717.html</url>
    <content><![CDATA[<p>苹果手机越来越不耐用：用着用着就自动关机，或者一天充2、3次电。这时也许你会有是不是该换手机电池的疑问，外面换个电池不懂好不好、价钱也高！于是迷就试着自己换了电池！整个过程可谓惊心动魄啊！（不小心拆坏了一个配件）换电池看教程好像很简单，但是这绝对不是手残星人的专利，除非你是维修大能，不然iPhone的手机电池绝非网上标榜的能轻轻松松随意更换。自己动手，等待你的可能是更大的损失！所以换不换自己掂量咯！PS：迷的iPhone6自行换的淘宝所谓的原装拆机电池，到现在不到三个月就已经不行了！建议大家还是买第三方牌子有保修的正规电池更换！**</p>
<p>详细步骤：第1步：出门左拐马云家获取下列工具和零件——iPhone 6电池和iPhone维修工具包。主要需要购买一块新电池，一个专用螺丝刀，一个撬片，和一个屏幕吸盘。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/TB2JTvEiKtTMeFjSZFOXXaTiVXa_70246596.jpg" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第2步：找到手机充电接口两侧的两颗五角形螺丝。打开iPhone 6你只需要拧开这两颗螺丝。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/ab701685e416b4bcf7a26a0902b4b12f.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第3步：关掉手机电源，使用工具包里的五角形螺丝刀拧下螺丝。螺丝刀的头部很小，但它跟 iPhone 6底部的小螺丝是匹配的。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/4c5288512ddfe7a4f34f131390346720.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第4步：使用吸盘在主页键(Home)上方拉出屏幕。把吸盘固定在主页键的正上方，另一只手握住机身，然后往外拉。你只需要在屏幕和机身之间撬开足以塞进一个塑料片的空间。（如果有贴钢化膜记得撕掉）</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/0d40969027ed29d20dc228ae736d481b.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第5步：使用撬片撬出屏幕。从主页键开始绕着屏幕一点一点向上撬。切记不可暴力从下方直接拉开！</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/814366689d16a385343ed0ea8d765639.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第6步：把屏幕部分立起呈90度，但不要超过这个角度。屏幕顶部仍然跟机身连接在一起，所以不要用力拉扯。如图所示，你最多可以把屏幕立起呈90度。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/8b739a449f362670fb8fac96d9f07ced.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第7步：找到并拧下固定屏幕连线的螺丝。在移除电池的时候取下屏幕是一个好主意，因为电池是用胶水固定的，要移除它可能很费事。拧下保护盖上的螺丝，然后把保护盖也取下来。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/4107bad4b76eec5ec63c7a58b0582411.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第8步：拆开屏幕的连接器。屏幕和机身之间的连接器有好几个，你可以用小拨子或薄指甲锉把它们从端口中挑出来。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/7247a4071e0154d5ad157bd461069f64.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第9步：取下电池连接器保护盖。电池连接器保护盖由两个螺丝固定，把它们拧下来，然后把金属保护盖也取走。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/39312a278dfbd924cc0d21f4fdfa00c4.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第10步：拆开电池连接器。电池跟电路板之间的连接器只有一个，你可以用小拨子或薄指甲锉把它挑开。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/4a4143bb484614bf838d29c60021ecc2.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第11步：用电吹风加热后盖，把胶水吹软。iPhone 6使用了大量胶水来固定电池，它们需要软化才能把电池取下来。你可以用电吹风加热手机后盖，达到软化胶水的目的。不要使用温度比这更高的加热工具，要以加热时仍能舒服将把手机拿在手中为度。加热过程大概五分钟左右就可以了！或者把胶片拔出来，参考<a href="http://www.usbmi.com/2025.html">自己动手给iPhone5s更换电池详细图文教程</a>的第16个步骤！</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/ff6b1e7cde7220c584d09cb06ba49c39.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第12步：使用信用卡或塑料拨片慢慢撬开电池。你可以使用银行卡、薄拨片或矬子在底部一点一点撬开电池。避开顶部靠近屏幕连接器的部分，因为下面还藏着连接器。另外，不要拿手机零部件当撬电池的支点。尽量让胶水附着在机壳之上，这样你在之后还能将其重新利用起来。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/b0a9608517f9c198bedc81e2bcba87af.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第13步：连上新电池，并折下连接器。如果没剩下太多胶水，那可以使用超薄双面胶来固定新电池。连接器只需要用一点点力就能回到槽位，但对齐位置可能有点繁琐，需要你花些时间。原来的电池连接器是折叠下来的，所以现在也是一样。如图所示，你可以用小拨子或薄金属锉把它压下去。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/411431bb76b5d9840163062072110536.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第14步：重新连上屏幕连接器，重新安装电池和屏幕连接器的金属保护盖。按照跟刚才相反的顺序连上屏幕连接器，首先从机身顶部的连接器开始，然后重新安装金属保护盖。</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/eb7b6defe6f08e05b2a9802e69ee09ad.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
<p>第15步：合上机壳，安装螺丝。大功告成，开机！</p>
<p><img src="/../images/iPhone66Plus%E6%80%8E%E4%B9%88%E6%8D%A2%E7%94%B5%E6%B1%A0/e01d564fda1800d67657b76e9482eb20.png" alt="自己动手给iphone6/6 plus更换电池详细图文步骤"></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>linux文件共享之nfs和smaba</title>
    <url>/post/f6a907c.html</url>
    <content><![CDATA[<p> nfs和samba</p>
<p>1、NFS简介</p>
<p>NFS（Network File System）即网络文件系统，是FreeBSD支持的文件系统中的一种，它允许网络中的计算机之间通过TCP/IP网络共享资源。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样。</p>
<p>类unix系统之间实现文件共享功能，不能实现跟windows系统之间实现共享；</p>
<p>2、NFS工作过程：</p>
<p>nfs依赖于rpc服务才能工作；</p>
<p>nfs工作过程：nfs客户端/nfs服务端</p>
<p>1、nfs服务端，在本地分区上创建一个extX的文件系统，并将该分区挂载至一个空目录上，注意，此时在服务端，文件系统是extX；</p>
<p>2、nfs服务端，上有个nfs协议，他的目的是，监听服务端套接字，接入用户关于nfs协议的请求，去帮忙访问本地基于extX文件系统的目录数据；</p>
<p>3、nfs客户端也是利用nfs协议。当有用户访问关于远程nfs服务端数据时，其实是启用nfs协议利用rpc的远程过程调用，去调用nfs服务端的extX文件系统的分区目录数据；</p>
<p>注意：nfs客户端能够直接操作本地映射的关于nfs服务器上的资源，是通过客户端利用vfs文件系统转换成nfs结合rpc的远程过程调用来完成的；</p>
<p>nfs服务端，监听关于nfs协议的rpc套接字，将用户请求的资源直接映射到本地的其他文件系统的资源目录中；</p>
<p>nfs客户端其实是通过nfs协议+rpc的远程过程调用去访问远程nfs服务端资源的。资源并不是指nfs文件系统格式的资源。他只是一个协议；</p>
<p>先由rpc监听111端口，再转到nfs的2049端口；</p>
<p>3、NFS安装：</p>
<p>nfs程序包：nfs-utils</p>
<p>[root@localhost ~]# yum -y install nfs-utils      ：安装nfs服务；</p>
<p>[root@localhost ~]# yum -y install rpcbind       ：安装rpc服务；</p>
<p>[root@localhost ~]# service nfs start<br>启动 NFS 服务：                      [确定]<br>关掉 NFS 配额：                      [确定]<br>启动 NFS mountd：                     [确定]<br>启动 NFS 守护进程：                    [确定]<br>正在启动 RPC idmapd：                   [确定]<br>[root@localhost ~]# service nfs status<br>rpc.svcgssd 已停<br>rpc.mountd (pid 2200) 正在运行…<br>nfsd (pid 2215 2214 2213 2212 2211 2210 2209 2208) 正在运行…<br>rpc.rquotad (pid 2196) 正在运行…<br>[root@localhost ~]#                     ：安装和启用nfs服务；</p>
<p>[root@localhost ~]# rpcinfo -p localhost          ：查看nfs启用了哪些进程，及进程端口号；</p>
<p>4、配置和使用nfs：</p>
<p>nfs服务端配置：</p>
<p>共享方式：</p>
<p>在服务端上将共享目录导出到nfs共享目录，然后配置权限，客户端就能访问了；</p>
<p>nfs共享目录的配置格式：</p>
<p>文件系统  客户端1（文件系统属性） 客户端2（文件系统属性）</p>
<p>文件系统：要共享的目录；</p>
<p>客户端：</p>
<p>主机地址。1.1.1.1；</p>
<p>网络名，test.aaa.com；</p>
<p>网段地址,1.1.1.0/24；</p>
<p>文件系统属性：也叫共享权限，多个属性用逗号分开；</p>
<p>rw：读写；</p>
<p>asvnc：异步（默认）；</p>
<p>sync：同步（性能差）；</p>
<p>root_squash：压缩root用户（默认）。如果使用客户端root去访问服务端nfs共享时，则需要基于imapd，自动将root通过网络访问时转换为nfsnobody用户（guest账户）；</p>
<p>注意：guest用户的权限是很小的，压缩很安全；</p>
<p>no_root_squash：不压缩root用户（不安全）；</p>
<p>注意：root可以直接使用自身去访问nfs共享目录了，权限无限制；</p>
<p>all_squash：压缩所有用户。客户端所有用户都不能使用自己的什么去访问服务端上的共享目录（“不能拿自己家的钥匙去开别人家的门”）。提高服务端安全；</p>
<p>anonuid或anongid：指定匿名用户映射为系统上的UID和GID。默认是映射到nfsnobody这个guest账号上来。提高服务端安全；</p>
<p>id nfsnobody ：查看guest账号的uid和gid</p>
<p>nohide：隐藏交叉导出时的目录文件，允许交叉挂载；</p>
<p>例如：/var/nfstest/ 导出来，被客户端挂载了。/var/nfstest/a/导出来，也被客户端挂在了。现在不想让双方客户端看到对方的挂载目录下的文件，怎么办？就是设置nohide属性，挂载到/var/nfstest/下的客户端无法看到/var/nfstest/a/下的所有文件了。安全；</p>
<p>crossmnt：允许交叉挂载。意义同上反过来；</p>
<p>示例1：将NFS服务器上的目录/var/nfstest共享出去；</p>
<p>[root@localhost ~]# vim /etc/exports</p>
<p>/var/nfstest  172.16.0.0/16(rw,no_root_squash)     ：读写挂载，且不压缩root账户</p>
<p>[root@localhost ~]# mkdir /var/nfstest</p>
<p>[root@localhost ~]# service nfs restart</p>
<p>客户端操作：</p>
<p>[root@localhost ~]# mkdir /mnt/nfs</p>
<p>[root@localhost ~]# mount -t nfs 172.16.1.107:/var/nfstest /mnt/nfs<br>[root@localhost ~]# cd /mnt/nfs/</p>
<p>[root@localhost nfs]# touch aa.txt<br>[root@localhost nfs]# touch bb.txt<br>[root@localhost nfs]# ll<br>总用量 0<br>-rw-r–r–. 1 root root 0 4月  4 21:19 aa.txt<br>-rw-r–r–. 1 root root 0 4月  4 21:19 bb.txt<br>[root@localhost nfs]#</p>
<p>：客户端使用挂载的方式，来访问nfs服务端上的文件内容，二者内容是同步的；</p>
<p>示例2：文件共享权限：</p>
<p>场景：在nfs服务端上各自创建一个账号，且uid一样。观察相互在共享目录下创建文件后，各自看到的文件属主和属组；</p>
<p>nfs服务端：</p>
<p>[root@localhost ~]# useradd -u 502 hadoop<br>[root@localhost ~]# vim /etc/exports</p>
<p>/var/nfstest  172.16.0.0/16(rw,no_root_squash)</p>
<p>[root@localhost ~]# setfacl -m u:502:rwx /var/nfstest/    ：为hadoop账号设置访问共享目录的权限；</p>
<p>[root@localhost ~]# service nfs restart</p>
<p>nfs客户端：</p>
<p>[root@localhost /]# useradd -u 502 nfsuser<br>[root@localhost /]# mount -t nfs 172.16.1.107:/var/nfstest /mnt/nfs/<br>[root@localhost /]#                     ：客户端上创建同uid的账号：</p>
<p>[root@localhost /]# su - nfsuser<br>[nfsuser@localhost ~]$<br>[nfsuser@localhost ~]$<br>[nfsuser@localhost ~]$ cd /mnt/nfs/<br>[nfsuser@localhost nfs]$ touch test1.txt<br>[nfsuser@localhost nfs]$ touch test2.txt<br>[nfsuser@localhost nfs]$ ll<br>总用量 0<br>-rw-r–r–. 1 root  root  0 4月  4 21:19 aa.txt<br>-rw-r–r–. 1 root  root  0 4月  4 21:19 bb.txt<br>-rw-rw-r–. 1 nobody nobody 0 4月  4 21:28 test1.txt<br>-rw-rw-r–. 1 nobody nobody 0 4月  4 21:28 test2.txt<br>[nfsuser@localhost nfs]$     ：使用新建的账号去共享目录中创建两个文件；</p>
<p>发现：使用这个uid编号跟服务端uid编号一样的用户去创建文件是的属主和属组都是nobody，并不是自己；</p>
<p>[root@localhost ~]# useradd -u 509 aaa<br>[root@localhost ~]# su - aaa<br>[aaa@localhost ~]$ cd /mnt/nfs/<br>[aaa@localhost nfs]$ touch ttt.txt<br>touch: 无法创建”ttt.txt”: 权限不够<br>[aaa@localhost nfs]$</p>
<p>发现：当我在客户端上重新再创建一个用户时，切换到该用户，去共享目录下新建文件，提示权限不够；</p>
<p>来到nfs服务端：</p>
<p>[root@localhost ~]# cd /var/nfstest/<br>[root@localhost nfstest]# ll<br>总用量 0<br>-rw-r–r–. 1 root  root  0 4月  4 21:19 aa.txt<br>-rw-r–r–. 1 root  root  0 4月  4 21:19 bb.txt<br>-rw-rw-r–. 1 hadoop hadoop 0 4月  4 21:28 test1.txt<br>-rw-rw-r–. 1 hadoop hadoop 0 4月  4 21:28 test2.txt<br>[root@localhost nfstest]#</p>
<p>发现：原本在客户端上创建的文件的属主和属组变成了hadoop了；</p>
<p>权限总结：</p>
<p>1、nfs客户端用户在访问时，其实是映射到服务端上同uid的用户权限上了；</p>
<p>2、服务端同uid用户的权限就是客户端用户的权限；</p>
<p>3、共享目录的权限是文件系统跟nfs配置权限的交集；</p>
<p>4、客户端用户在共享目录下创建的文件统统都会显示成nobody用户；</p>
<p>因此，客户端用户要想在共享目录中有权限，需要两点儿：</p>
<p>1、客户端上用户的uid编号在服务端上必须也有；</p>
<p>2、服务端同uid账号的对共享目录拥有权限；</p>
<p>5、nfs服务端端口优化：</p>
<p>问题：nfs服务端启动后，基于rpc的进程会从rpc中随机得到一个端口号，次端口号有可能会被其他已知服务占用。因此要固定下来；</p>
<p>[root@localhost nfstest]# vim /etc/sysconfig/nfs</p>
<p>MOUNTD_PORT=892</p>
<p>STATD_PORT=662</p>
<p>STATD_OUTGOING_PORT=2020     ：去掉这些原有的注释，启用固定端口；</p>
<p>[root@localhost nfstest]# service nfs restart</p>
<p>[root@localhost nfstest]# rpcinfo -p localhost   ：查看被gudingde端口号；</p>
<p>结束！</p>
<p>2、Samba简介：</p>
<p>Samba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成。SMB（Server Messages Block，信息服务块）是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。SMB协议是客户机/服务器型协议，客户机通过该协议可以访问服务器上的共享文件系统、打印机及其他资源。通过设置“NetBIOS over TCP/IP”使得Samba不但能与局域网络主机分享资源，还能与全世界的电脑分享资源。</p>
<p>可以实现linux与windows，linux与linux系统之间的文件共享。不基于nfs；</p>
<p>1、samba安装：</p>
<p>客户端程序：samba-client；</p>
<p>服务器端程序：samba；</p>
<p>[root@localhost ~]# yum -y install samba</p>
<p>[root@localhost samba]# service smb start<br>启动 SMB 服务：                      [确定]<br>[root@localhost samba]# service nmb start<br>启动 NMB 服务：                      [确定]<br>[root@localhost samba]#                  ：启动samba服务；</p>
<p>2、samba用户：</p>
<p>在系统用户的基础之上，为该用户创建访问samba服务de密码即可；</p>
<p>3、samba服务的配置文件：</p>
<p>vim /etc/samba/smb.conf</p>
<p>#开头的都是纯文字注释信息；</p>
<p>;开头的都是可启用的注释选项；</p>
<p>workgroup = ：工作组名称；</p>
<p>server string = ：显示的samba服务器版本；</p>
<p>netbios name = ：netbios的名称；</p>
<p>interfaces = ：表示samba启用的监听接口；</p>
<p>hosts allow = ：表示访问控制白名单。允许哪些段的主机访问；</p>
<p>注意：如果启用了，没写到这里的都会拒绝掉。因为它是白名单。没写入白名单的都拒绝；</p>
<p>log file = ：日志文件位置。%m：宏，表示客户端名称。所以，每个客户端都会生成一个日志文件；</p>
<p>max log size = ：日志文件最大大小；</p>
<p>security = ：安全级别（默认）；</p>
<p>user：根据账号密码认证；</p>
<p>share：无需账号密码，直接访问；</p>
<p>server：集中式账号密码；</p>
<p>passdb backend = ：账号密码的存放格式。默认是tdbsam；</p>
<p>域：</p>
<p>sercurity = domain ：这是域下的安全级别，domain；</p>
<p>passdb backend = ：账号密码存放格式；</p>
<p>password server = ：域认证服务器名；</p>
<p>名称解析选项：wins是windows的本地名称解析服务；</p>
<p>wins support = ：是否启用wins；</p>
<p>wins server =  ：wins服务器；</p>
<p>wins proxy =  ：wins的代理；</p>
<p>dns proxy =</p>
<p>打印机选项：共享打印机</p>
<p>load printers = ：加载打印服务；</p>
<p>文件系统选项；</p>
<p>……..<br>[共享名]                ：共享名；</p>
<p>comment =    ：共享备注信息；</p>
<p>path =     ：实际共享目录路径；</p>
<p>guest ok =   ：是否允许来宾账号查看某些目录；</p>
<p>public =    ：登录samba的用户不是某些共享目录的属主和属组时，是否允许浏览和显示；</p>
<p>browseable =  ：登录samba的用户不是当前共享目录的属主和属组时，是否允许浏览和显示</p>
<p>也就是说，一个目录在共享目录下，当用户不属于我的属主和属组时，当该用户访问时，我是否显示出来。最好别显示，为了安全；</p>
<p>writable =   ：是否启用共享可写权限。针对全部访问者；</p>
<p>write list =  ：共享可写用户列表。只针对该列表中的用户；</p>
<p>read only =   ：是否允许只读。定义了只读，则write list和writable=yes就没有意义了；</p>
<p>示例1：我为samba服务器端创建用户，提供文件共享：<br>[root@localhost ~]# smbpasswd -a centos<br>New SMB password:<br>Retype new SMB password:<br>Added user centos.<br>[root@localhost ~]#</p>
<p>[root@localhost ~]# smbpasswd -a hadoop<br>New SMB password:<br>Retype new SMB password:<br>Added user hadoop.</p>
<p>[root@localhost ~]# service smb restart<br>关闭 SMB 服务：                      [确定]<br>启动 SMB 服务：                      [确定]<br>[root@localhost ~]# service nmb restart<br>关闭 NMB 服务：                      [确定]<br>启动 NMB 服务：                      [确定]<br>[root@localhost ~]#                     ：重启samba服务；</p>
<p>验证上面创建的用户是否能够登录samba服务端：</p>
<p>在windows是上使用unc的方式访问：</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKioL1Uf1_2ibkokAADDjxfgCXg785.jpg" alt="wKioL1Uf1_2ibkokAADDjxfgCXg785.jpg"></p>
<p>输入hadoop的用户名和密码，成功访问到samba中的共享目录：其实访问的是用户自己的家目录；</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKiom1Uf102BPxYcAAEcVH54JrI618.jpg" alt="wKiom1Uf102BPxYcAAEcVH54JrI618.jpg"></p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKioL1Uf2MLBLVAQAABNnbWtSC0832.jpg" alt="wKioL1Uf2MLBLVAQAABNnbWtSC0832.jpg"></p>
<p>示例2：基于用户控制，访问公共共享目录；</p>
<p>[root@localhost ~]# mkdir /share/test -pv<br>mkdir: 已创建目录 “/share”<br>mkdir: 已创建目录 “/share/test”<br>[root@localhost ~]# setfacl -m u:centos:rwx /share/test/<br>[root@localhost ~]# vim /etc/samba/smb.conf</p>
<p>[myshared]<br>comment = my share test<br>path = /share/test<br>writable = yes               ：添加共享记录，将目录共享出去；</p>
<p>[root@localhost ~]# testparm                ：检测一下配置文件中的内容；</p>
<p>[root@localhost ~]# service smb restart<br>关闭 SMB 服务：                      [确定]<br>启动 SMB 服务：                      [确定]<br>[root@localhost ~]# service nmb restart<br>关闭 NMB 服务：                      [确定]<br>启动 NMB 服务：                      [确定]<br>[root@localhost ~]#                     ：重启一下samba服务；</p>
<p>使用客户端去测试：</p>
<p>使用centos帐号去测试：</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKioL1Uf2yLA4-1FAAEmi-ZXy8s213.jpg" alt="wKioL1Uf2yLA4-1FAAEmi-ZXy8s213.jpg"></p>
<p>可以看到，能够显示新建的共享目录了。因为设置了文件acl，使得centos账户可以访问这个目录：</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKiom1Uf2jvgprcFAABjTzURfwc095.jpg" alt="wKiom1Uf2jvgprcFAABjTzURfwc095.jpg"></p>
<p>可以新建文件：</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKioL1Uf3PTQOiKaAACGIGDIzdA403.jpg" alt="wKioL1Uf3PTQOiKaAACGIGDIzdA403.jpg"></p>
<p>再次使用hadoop登录查看：</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKioL1Uf3AGhKqgIAAEwut8IChs180.jpg" alt="wKioL1Uf3AGhKqgIAAEwut8IChs180.jpg"></p>
<p>ok，都能看到新建的共享目录了：</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKioL1Uf3A-j-OEUAAB4OSMZiS8949.jpg" alt="wKioL1Uf3A-j-OEUAAB4OSMZiS8949.jpg"></p>
<p>但是hadoop却没权限使用该共享目录；</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKioL1Uf3J3wb4_FAAD5RYqE8rk162.jpg" alt="wKioL1Uf3J3wb4_FAAD5RYqE8rk162.jpg"></p>
<p>注意：共享文件的最终权限取决于文件系统和共享权限二者的交集；</p>
<p>提醒：</p>
<p>基于windows客户端去访问共享时，由于缓存的原因，可能导致有时不能更换账号，可以如下解决：</p>
<p>cmd</p>
<p>net use</p>
<p>net use \共享服务器ip /del                  ：清楚共享账号缓存；</p>
<p>4、smbclient命令：一种使用在samba客户端上的命令：</p>
<p>1、查看samba服务器上的所有共享目录：</p>
<p>格式：smbclient -L SERVER -U USERNAME</p>
<p>例如：</p>
<p>[root@localhost ~]# smbclient -L 172.16.1.105 -U hadoop<br>Enter hadoop’s password:<br>Domain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.23-14.el6_6]</p>
<p>Sharename    Type   Comment</p>
<hr>
<p>myshared    Disk   my share test<br>IPC$      IPC    IPC Service (Samba Server Version 3.6.23-14.el6_6)<br>hadoop     Disk   Home Directories<br>Domain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.23-14.el6_6]</p>
<p>Server        Comment</p>
<hr>
<p>LOCALHOST      Samba Server Version 3.6.23-14.el6_6</p>
<p>Workgroup      Master</p>
<hr>
<p>MYGROUP       LOCALHOST<br>WORKGROUP      CHEN<br>[root@localhost ~]#          ：可以看到刚刚新建的共享目录了；</p>
<p>2、以交互式的方式连入samba服务器共享目录：</p>
<p>格式：smbclient //SERVER/SHARED -U USERNAME</p>
<p>如：</p>
<p>[root@localhost ~]# smbclient //172.16.1.105/myshared -U centos<br>Enter centos’s password:<br>Domain=[MYGROUP] OS=[Unix] Server=[Samba 3.6.23-14.el6_6]<br>smb: &gt; ls                  ：输入命令，去操作共享目录中的内容；</p>
<p>5、挂载共享目录至客户端本地：</p>
<p>1、临时挂载：</p>
<p>格式：mount -t cifs //server/shared /path/to/mount_point -o username=smbuser</p>
<p>[root@localhost ~]# mkdir /mnt/samba<br>[root@localhost ~]# mount -t cifs //172.16.1.105/myshared /mnt/samba -o username=centos<br>Password:</p>
<p>[root@localhost samba]# ll<br>总用量 0<br>-rwxr–r–. 1 centos centos 0 4月  5 04:39 新建文本文档.txt<br>[root@localhost samba]#                    ：临时执行一次手动挂载；</p>
<p>2、开机自动挂载：</p>
<p>vim /etc/fstab</p>
<p>//172.16.1.105/myshared /mnt/samba cifs  defaults,<strong>_netdev</strong>,username=centos,password=password2020   [root@localhost /]# mount -a          ：重载/etc/fstab文件；<br>[root@localhost /]#</p>
<p>[root@localhost /]# mount<br>/dev/mapper/VolGroup-lv_root on / type ext4 (rw)<br>proc on /proc type proc (rw)<br>sysfs on /sys type sysfs (rw)<br>devpts on /dev/pts type devpts (rw,gid=5,mode=620)<br>tmpfs on /dev/shm type tmpfs (rw,rootcontext=”system_u:object_r:tmpfs_t:s0”)<br>/dev/sda1 on /boot type ext4 (rw)<br>none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)<br>//172.16.1.105/myshared on /mnt/samba type cifs (rw)  ：可以看到，成功被挂载了；</p>
<p>注意：/etc/fstab中有个参数：“_netdev”：表示当无法挂载时放弃挂载。因为共享是基于网络的，当无法挂载时，服务器是无法开机的。所以，要主动放弃；</p>
<p>[root@localhost /]# cd /mnt/sa——mba/<br>[root@localhost samba]#<br>[root@localhost samba]# ll<br>总用量 0<br>-rwxr–r–. 1 centos centos 0 4月  5 04:39 新建文本文档.txt<br>[root@localhost samba]#                   ：挂载成功；</p>
<p>6、web方式管理配置samba：</p>
<p>[root@localhost /]# yum -y install samba-swat xinetd    ：安装samba-swat和xinetd服务；</p>
<p>[root@localhost /]# vim /etc/xinetd.d/swat</p>
<p>port      = 901                ：端口号默认901；</p>
<p>only_from    = 172.16.0.0/16           :修改客户端限制；</p>
<p>disable     = no                ：修改此处为“no”；</p>
<p>[root@localhost /]# service xinetd start<br>正在启动 xinetd：</p>
<p>[root@localhost /]# chkconfig | grep swat<br>swat:        启用                    ：启用samba-swat；</p>
<p>web访问配置：成功访问，可以执行配置了；</p>
<p><img src="/../images/linux%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E4%B9%8Bnfs%E5%92%8Csmaba/wKioL1Uf5q7jyAHAAAGL28uh2QI264.jpg" alt="wKioL1Uf5q7jyAHAAAGL28uh2QI264.jpg"></p>
<p>结束！</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>-linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Python实现简单的API接口</title>
    <url>/post/ac5db05f.html</url>
    <content><![CDATA[<h1 id="get方法"><a href="#get方法" class="headerlink" title="get方法"></a>get方法</h1><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p># coding:utf-8</p>
<p>import json<br>from urlparse import parse_qs<br>from wsgiref.simple_server import make_server</p>
<p># 定义函数，参数是函数的两个参数，都是python本身定义的，默认就行了。<br>def application(environ, start_response):<br># 定义文件请求的类型和当前请求成功的code<br>start_response(‘200 OK’, [(‘Content-Type’, ‘text/html’)])<br># environ是当前请求的所有数据，包括Header和URL，body，这里只涉及到get<br># 获取当前get请求的所有数据，返回是string类型<br>params = parse_qs(environ[‘QUERY_STRING’])<br># 获取get中key为name的值<br>name = params.get(‘name’, [‘’])[0]<br>no = params.get(‘no’, [‘’])[0]</p>
<p># 组成一个数组，数组中只有一个字典<br>dic = {‘name’: name, ‘no’: no}</p>
<p>return [json.dumps(dic)]</p>
<p>if <strong>name</strong> == “<strong>main</strong>“:<br>port = 5088<br>httpd = make_server(“0.0.0.0”, port, application)<br>print “serving http on port {0}…”.format(str(port))<br>httpd.serve_forever()</p>
<h2 id="请求实例"><a href="#请求实例" class="headerlink" title="请求实例"></a>请求实例</h2><p><img src="/../images/Python%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84API%E6%8E%A5%E5%8F%A3/20170712171923385" alt="这里写图片描述"></p>
<h1 id="post方法"><a href="#post方法" class="headerlink" title="post方法"></a>post方法</h1><h2 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h2><p># coding:utf-8</p>
<p>import json<br>from wsgiref.simple_server import make_server</p>
<p># 定义函数，参数是函数的两个参数，都是python本身定义的，默认就行了。<br>def application(environ, start_response):<br># 定义文件请求的类型和当前请求成功的code<br>start_response(‘200 OK’, [(‘Content-Type’, ‘application/json’)])<br># environ是当前请求的所有数据，包括Header和URL，body</p>
<p>request_body = environ[“wsgi.input”].read(int(environ.get(“CONTENT_LENGTH”, 0)))<br>request_body = json.loads(request_body)</p>
<p>name = request_body[“name”]<br>no = request_body[“no”]</p>
<p># input your method here<br># for instance:<br># 增删改查</p>
<p>dic = {‘myNameIs’: name, ‘myNoIs’: no}</p>
<p>return [json.dumps(dic)]</p>
<p>if <strong>name</strong> == “<strong>main</strong>“:<br>port = 6088<br>httpd = make_server(“0.0.0.0”, port, application)<br>print “serving http on port {0}…”.format(str(port))<br>httpd.serve_forever()</p>
<p>请求实例<img src="/../images/Python%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84API%E6%8E%A5%E5%8F%A3/20170712172008278" alt="这里写图片描述"></p>
<p>``疑问</p>
<ol>
<li>怎么实现请求的路径限制？</li>
<li>怎么限制接口调用方的headers？</li>
</ol>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>-Python</tag>
      </tags>
  </entry>
  <entry>
    <title>php实现事件监听与触发的方法</title>
    <url>/post/a76a0e8c.html</url>
    <content><![CDATA[<p>这篇文章主要介绍了php实现事件监听与触发的方法,可实现时间的绑定、触发与注销等功能,具有一定的参考借鉴价值,需要的朋友可以参考下</p>
<p>..本文实例讲述了php实现事件监听与触发的方法。分享给大家供大家参考。具体分析如下：</p>
<p>闲来无事，想了想PHP如何实现事件监听，参考了jQuery的事件绑定思路，简单的实现了一下。</p>
<p>主要功能：</p>
<p>1.绑定事件 支持一个事件绑定多个动作，支持绑定一次性事件</p>
<p>2.触发事件</p>
<p>3.注销事件</p>
<p>复制代码 代码如下:</p>
<p>class Event</p>
<p>{</p>
<p>protected static $listens    = array();</p>
<p>public static function listen($event, $callback, $once=false){</p>
<p>if(!is_callable($callback)) return false;</p>
<p>self::$listens[$event][]   = array(‘callback’=&gt;$callback, ‘once’=&gt;$once);</p>
<p>return true;</p>
<p>}</p>
<p>public static function one($event, $callback){</p>
<p>return self::listen($event, $callback, true);</p>
<p>}</p>
<p>public static function remove($event, $index=null){</p>
<p>if(is_null($index))</p>
<p>unset(self::$listens[$event]);</p>
<p>else</p>
<p>unset(self::$listens[$event][$index]);</p>
<p>}</p>
<p>public static function trigger(){</p>
<p>if(!func_num_args()) return;</p>
<p>$args            = func_get_args();</p>
<p>$event            = array_shift($args);</p>
<p>if(!isset(self::$listens[$event])) return false;</p>
<p>foreach((array) self::$listens[$event] as $index=&gt;$listen){</p>
<p>$callback        = $listen[‘callback’];</p>
<p>$listen[‘once’] &amp;&amp; self::remove($event, $index);</p>
<p>call_user_func_array($callback, $args);</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p>以下是一些调用的例子：</p>
<p>复制代码 代码如下:// 增加监听walk事件</p>
<p>Event::listen(‘walk’, function(){</p>
<p>echo “I am walking…n”;</p>
<p>});</p>
<p>// 增加监听walk一次性事件</p>
<p>Event::listen(‘walk’, function(){</p>
<p>echo “I am listening…n”;</p>
<p>}, true);</p>
<p>// 触发walk事件</p>
<p>Event::trigger(‘walk’);</p>
<p>/*</p>
<p>I am walking…</p>
<p>I am listening…</p>
<p>*/</p>
<p>Event::trigger(‘walk’);</p>
<p>/*</p>
<p>I am walking…</p>
<p>*/</p>
<p>Event::one(‘say’, function($name=’’){</p>
<p>echo “I am {$name}n”;</p>
<p>});</p>
<p>Event::trigger(‘say’, ‘deeka’); // 输出 I am deeka</p>
<p>Event::trigger(‘say’, ‘deeka’); // not run</p>
<p>class Foo</p>
<p>{</p>
<p>public function bar(){</p>
<p>echo “Foo::bar() is calledn”;</p>
<p>}</p>
<p>public function test(){</p>
<p>echo “Foo::foo() is called, agrs:”.json_encode(func_get_args()).”n”;</p>
<p>}</p>
<p>}</p>
<p>$foo   = new Foo;</p>
<p>Event::listen(‘bar’, array($foo, ‘bar’));</p>
<p>Event::trigger(‘bar’);</p>
<p>Event::listen(‘test’, array($foo, ‘test’));</p>
<p>Event::trigger(‘test’, 1, 2, 3);</p>
<p>class Bar</p>
<p>{</p>
<p>public static function foo(){</p>
<p>echo “Bar::foo() is calledn”;</p>
<p>}</p>
<p>}</p>
<p>Event::listen(‘bar1’, array(‘Bar’, ‘foo’));</p>
<p>Event::trigger(‘bar1’);</p>
<p>Event::listen(‘bar2’, ‘Bar::foo’);</p>
<p>Event::trigger(‘bar2’);</p>
<p>function bar(){</p>
<p>echo “bar() is calledn”;</p>
<p>}</p>
<p>Event::listen(‘bar3’, ‘bar’);</p>
<p>Event::trigger(‘bar3’);</p>
<p>希望本文所述对大家的PHP程序设计有所帮助。</p>
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>-php</tag>
      </tags>
  </entry>
  <entry>
    <title>php7 windows版本启动提示丢失vcruntime140.dll</title>
    <url>/post/d058b584.html</url>
    <content><![CDATA[<p>php7 windows版本启动提示丢失vcruntime140.dll</p>
<p>6月13日 php7终于没有跳票发布了alpha 版本啦，于是在自己的windows8.1上面安装准备体验一下，没想到启动的时候还是提示丢失vcruntime140.dll这个文件，于是上网百度搜索了半天没任何内容（这里严重鄙视百度） 天朝又不让用google 所以只能去官方网站爬一爬英文说明了，发现了点端倪，原来需要安装微软的vc++2015版本才行，下载地址在下方：</p>
<p>VC14需要</p>
<p><a href="https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=48145">https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=48145</a></p>
<p>VC11需要</p>
<p><a href="http://www.microsoft.com/en-us/download/details.aspx?id=30679">http://www.microsoft.com/en-us/download/details.aspx?id=30679</a></p>
<p>VC9需要</p>
<p>64bit: <a href="http://www.microsoft.com/en-us/download/details.aspx?id=15336">http://www.microsoft.com/en-us/download/details.aspx?id=15336</a></p>
<p>32bit: <a href="http://www.microsoft.com/en-us/download/details.aspx?id=5582">http://www.microsoft.com/en-us/download/details.aspx?id=5582</a></p>
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>-php</tag>
      </tags>
  </entry>
  <entry>
    <title>python三步实现人脸识别</title>
    <url>/post/e86121cf.html</url>
    <content><![CDATA[<p>Face Recognition软件包</p>
<p>这是世界上最简单的人脸识别库了。你可以通过<a href="http://www.roncoo.com/course/view/82b3a098750545f1b80fe789a72d5a81">Python</a>引用或者命令行的形式使用它，来管理和识别人脸。</p>
<p>该软件包使用dlib中最先进的人脸识别深度学习算法，使得识别准确率在《Labled Faces in the world》测试基准下达到了99.38%。</p>
<p>它同时提供了一个叫face_recognition的命令行工具，以便你可以用命令行对一个文件夹中的图片进行识别操作。</p>
<p>特性</p>
<p>在图片中识别人脸</p>
<p>找到图片中所有的人脸</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/2C5ibeGc6h6RE3NWwi7njZj3Bh6bEXYB.jpg" alt="face/2C5ibeGc6h6RE3NWwi7njZj3Bh6bEXYB.jpg"></p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/8J2Cs7fx6KQsAHjpsRR4nFTjQdjbHcHh.jpg" alt="images/8J2Cs7fx6KQsAHjpsRR4nFTjQdjbHcHh.jpg"></p>
<p>找到并操作图片中的脸部特征</p>
<p>获得图片中人类眼睛、鼻子、嘴、下巴的位置和轮廓</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/c24aXPRWF2ye3WdTKbC2bdFGZmBCwrtG.jpg" alt="face/c24aXPRWF2ye3WdTKbC2bdFGZmBCwrtG.jpg"></p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/K5mzWPj8Fn253RNJnyfC4hrc55bEpKCC.jpg" alt="face/K5mzWPj8Fn253RNJnyfC4hrc55bEpKCC.jpg"></p>
<p>找到脸部特征有很多超级有用的应用场景，当然你也可以把它用在最显而易见的功能上：美颜功能（就像美图秀秀那样）。</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/d77HG2fa3SHWKH4bnyGW7nYrdXGhMwMJ.jpg" alt="face/d77HG2fa3SHWKH4bnyGW7nYrdXGhMwMJ.jpg"></p>
<p>鉴定图片中的脸</p>
<p>识别图片中的人是谁。</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/ayWXswfWKNZxAT7QGTxzXmxYSTsrfirx.jpg" alt="face/ayWXswfWKNZxAT7QGTxzXmxYSTsrfirx.jpg"></p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/a37YQjhYKN3Gn7Dd4HGSKa2ssPcH8ciM.jpg" alt="images/a37YQjhYKN3Gn7Dd4HGSKa2ssPcH8ciM.jpg"></p>
<p>你甚至可以用这个软件包做人脸的实时识别。</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/KyZfSapDPiyisCinDSN6FZSkEQAxDikd.png" alt="face/KyZfSapDPiyisCinDSN6FZSkEQAxDikd.png"></p>
<p>这里有一个实时识别的例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ageitgey&#x2F;face_recognition&#x2F;blob&#x2F;master&#x2F;examples&#x2F;facerec_from_webcam_faster.py</span><br></pre></td></tr></table></figure>
<p>安装</p>
<p>环境要求</p>
<ul>
<li>Python3.3+或者Python2.7</li>
<li>MacOS或者Linux（Windows不做支持，但是你可以试试，也许也能运行）</li>
</ul>
<p>安装步骤</p>
<p>在MacOS或者Linux上安装</p>
<p>首先，确保你安装了dlib，以及该软件的Python绑定接口。如果没有的话，看这篇安装说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;gist.github.com&#x2F;ageitgey&#x2F;629d75c1baac34dfa5ca2a1928a7aeaf</span><br></pre></td></tr></table></figure>
<p>然后，用pip安装这个软件包：</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/dWRaCAPQaJJew5MypJQKeyRCDSNatSYz.jpg" alt="face/dWRaCAPQaJJew5MypJQKeyRCDSNatSYz.jpg"></p>
<p>如果你安装遇到问题，可以试试这个安装好了的虚拟机：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;medium.com&#x2F;@ageitgey&#x2F;try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b</span><br></pre></td></tr></table></figure>
<p>在树莓派2+上安装</p>
<p>看这篇说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;gist.github.com&#x2F;ageitgey&#x2F;1ac8dbe8572f3f533df6269dab35df65</span><br></pre></td></tr></table></figure>
<p>在Windows上安装</p>
<p>虽然Windows不是官方支持的，但是有热心网友写出了一个Windows上的使用指南，请看这里：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ageitgey&#x2F;face_recognition&#x2F;issues&#x2F;175#issue-257710508</span><br></pre></td></tr></table></figure>
<p>使用已经配置好的虚拟机（支持VMWare和VirtualBox）</p>
<p>看这篇说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;medium.com&#x2F;@ageitgey&#x2F;try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b</span><br></pre></td></tr></table></figure>
<p>使用方法</p>
<p>命令行接口</p>
<p>如果你已经安装了face_recognition，那么你的系统中已经有了一个名为face_recognition的命令，你可以使用它对图片进行识别，或者对一个文件夹中的所有图片进行识别。</p>
<p>首先你需要提供一个文件夹，里面是所有你希望系统认识的人的图片。其中每个人一张图片，图片以人的名字命名。</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/3RQG35tpC2cSSjrwwZmSk7aJx8a7h7GE.jpg" alt="images/3RQG35tpC2cSSjrwwZmSk7aJx8a7h7GE.jpg"></p>
<p>然后你需要准备另一个文件夹，里面是你要识别的图片。</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/RGAYWwBEkai7KiwBbsrG3HF8YGrX6x64.jpg" alt="images/RGAYWwBEkai7KiwBbsrG3HF8YGrX6x64.jpg"></p>
<p>然后你就可以运行face_recognition命令了，把刚刚准备的两个文件夹作为参数传入，命令就会返回需要识别的图片中都出现了谁。</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/iRJb7d4H2Emyfa2wjYabJfR6X4RcextK.jpg" alt="face/iRJb7d4H2Emyfa2wjYabJfR6X4RcextK.jpg"></p>
<p>输出中，识别到的每张脸都单独占一行，输出格式为</p>
<p>通过Python模块使用</p>
<p>你可以通过导入face_recognition模块来使用它，使用方式超级简单，文档在这里：<a href="https://face-recognition.readthedocs.io/">https://face-recognition.readthedocs.io</a></p>
<p>自动找到图片中所有的脸</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/7FGab4SdRTHPYKn3fFeFPwrAy6pTHNaN.jpg" alt="face/7FGab4SdRTHPYKn3fFeFPwrAy6pTHNaN.jpg"></p>
<p>看看这个例子自己实践一下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ageitgey&#x2F;face_recognition&#x2F;blob&#x2F;master&#x2F;examples&#x2F;find_faces_in_picture_cnn.py</span><br></pre></td></tr></table></figure>
<p>你还可以自定义替换人类识别的深度学习模型。</p>
<p>注意：想获得比较好的性能的话，你可能需要GPU加速（使用英伟达的CUDA库）。所以编译的时候你也需要开启dlib的GPU加速选项。</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/zPjiMHkQQ3pGbQaTbWTKFAS6DPeRMiNJ.jpg" alt="images/zPjiMHkQQ3pGbQaTbWTKFAS6DPeRMiNJ.jpg"></p>
<p>你也可以通过这个例子实践一下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ageitgey&#x2F;face_recognition&#x2F;blob&#x2F;master&#x2F;examples&#x2F;find_faces_in_batches.py</span><br></pre></td></tr></table></figure>
<p>如果你有很多图片和GPU，你也可以并行快速识别，看这篇文章：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ageitgey&#x2F;face_recognition&#x2F;blob&#x2F;master&#x2F;examples&#x2F;find_facial_features_in_picture.py</span><br></pre></td></tr></table></figure>
<p>自动识别人脸特征</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/ADK7prbbQy5nahFGTA5C3AmdXchYe5WH.jpg" alt="face/ADK7prbbQy5nahFGTA5C3AmdXchYe5WH.jpg"></p>
<p>试试这个例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#96;&#96;&#x2F;&#x2F;github.com&#x2F;ageitgey&#x2F;face_recognition&#x2F;blob&#x2F;master&#x2F;examples&#x2F;find_facial_features_in_picture.py</span><br></pre></td></tr></table></figure>


<p>识别人脸鉴定是哪个人</p>
<p><img src="/../images/python%E4%B8%89%E6%AD%A5%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/7GCiTet4wtxJCKMWR8cdtpWyATT534NZ.jpg" alt="images/7GCiTet4wtxJCKMWR8cdtpWyATT534NZ.jpg"></p>
<p>这里是一个例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ageitgey&#x2F;face_recognition&#x2F;blob&#x2F;master&#x2F;examples&#x2F;recognize_faces_in_pictures.py</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>-Python</tag>
      </tags>
  </entry>
  <entry>
    <title>win10 网络连接0x80070035</title>
    <url>/post/afa9daf5.html</url>
    <content><![CDATA[<p>按window+R键输入gpedit.msc 来启动本地组策略编辑器。</p>
<p>依次找到“计算机配置-管理模板-网络-Lanman工作站”这个节点，在右侧内容区可以看到“启用不安全的来宾登录”这一条策略设置。状态是“未配置”。</p>
<p>双击“启用不安全的来宾登录”这一条策略设置，将其状态修改为“已启用”并单击确定按钮。</p>
<p>设置完成再次尝试访问发现可以正常访问了。</p>
]]></content>
      <categories>
        <category>win10</category>
      </categories>
      <tags>
        <tag>-win10</tag>
      </tags>
  </entry>
  <entry>
    <title>《上古卷轴5：天际》人物美化过程</title>
    <url>/post/6f1c150b.html</url>
    <content><![CDATA[<p>一步一步美化老滚5的人物</p>
<p>首先，论坛上已经有很多版本的一键美化包了，不过里面的东西太多太全，一般使用者不知道里面都有什么，每一个组件是什么版本，作者（或者整合者）是以什么先后顺序整合这些美化补丁组件的。有些人只需要单项的优化，比如眉毛或嘴唇之类的。所以我写了这个帖子，介绍一下自己安装美化人物的各种mod的先后顺序，大家完全可以举一反三，把其中的组件换成自己想要的，打造自己“独一无二”的美化补丁。</p>
<p>其次，本帖不提供下载，仅提供s网链接。一是因为本人网络龟速，二是因为这些mod更新的很快，所以希望大家直接去s网下载，顺便给作者好评。</p>
<p>第三，这里的美化仅指身体模型、身体和脸部贴图、面部细节（眉毛、嘴唇、疤痕等）和头发的美化，包括丰胸、提臀、美白、去皱，不包括npc面部模型改变（即“换脸”）。</p>
<p>最后，纯新手向，老鸟勿喷~~~</p>
<hr>
<p>美化原则，或者说美化思路：</p>
<p>人物美化无非就两件事：模型（这里单指体型）美化和贴图（材质，或者说皮肤）美化。从这个角度讲没有什么必须装的美化补丁，s网美化mod浩如烟海，根据每个人审美观不同各取所需吧。女性的话对我而言，体型常用的是cbbe和unp，我眼拙实在分不出好坏来，考虑到cbbe资源多一些，干脆选它好了；脸部材质更多，我倾向真实系，所以修眉过重的coverwoman和过于幼齿的nidia face是不会用的。这里必须说一下，建议新手选择身体、脸部贴图时尽量选择同一作者的，防止脸和身体出现色差。</p>
<hr>
<p>准备知识：</p>
<p>1.老滚5的人物模型（即身体、头部、手脚模型）、动作文件、人物骨骼文件都放在Meshes\actors文件夹下；人物皮肤、头发贴图之类的都放在Textures\actors文件夹下;</p>
<p>2.更换身体模型、皮肤和头发的材质等，主角和NPC都会同时改变。</p>
<p>3.下面的安装，除了注明可用NMM的外，均不推荐用NMM安装。</p>
<hr>
<p>下面开始正文：</p>
<hr>
<p>首先是女性：</p>
<p>一、安装CHSBHC - BBP - Nude and Jiggly Mod（即俗称的乳摇系统，必装）</p>
<p>下载地址：<a href="http://skyrim.nexusmods.com/downloads/file.php?id=4888">点击进入</a></p>
<p>下载CHSBHC-Body-Physics-ModV2-4-1，把meshes和textures解压到data文件夹下。</p>
<p>简单说一下这个mod的作用。这个mod提供了一个叫CHSBHC的女性体型和对应的皮肤贴图，还提供了一个叫BBP的动作系统，就是大家耳熟能详的乳摇系统了。有了这个BBP系统，再配合对应的身形或衣服，就能实现乳摇。这个CHSBHC身形相对而言不是很受欢迎，所以我们接下来会用其他的体型（和对应的皮肤贴图）替换掉这个身形，但是保留其中的BBP系统。所以这个mod必须最先装。</p>
<p>二、安装Calientes Female Body Mod Big Bottom Edition（即俗称的CBBE身形，目前版本3.1，必装）</p>
<p>下载地址：<a href="http://skyrim.nexusmods.com/downloads/file.php?id=2666">点击进入</a></p>
<p>下载Caliente Female Body Mod BBE v3-1，把meshes和textures解压到data文件夹下，覆盖掉原先的文件。</p>
<p>这个mod提供了一个简称CBBE的女性体型和对应的皮肤贴图，也是现在最通用，资源也是最多的女性身体模型。s网上看到“xxx for cbbe”，基本就能确定这是可以穿的，不会出现断手断脚的问题。</p>
<p>做完这一步，你已经得到了一个可以乳摇的cbbe的体型了，完全可以穿各种支持BBP的衣服，正常乳摇而不会跳出。缺点是貌似不支持果体乳摇，这一点我也不确定，不过无所谓，我们接下来用支持果体乳摇的身形文件把CBBE默认的身形替换掉。但是CBBE安装包里带了手、脚的模型文件还有对应的身体、手贴图，这些是不用替换的，所以这个CBBE必须第二位、在接下来的身形之前安装。</p>
<p>三、安装支持乳摇的CBBE V3M身形（选装，强烈推荐）</p>
<p>下载地址：<a href="http://bbs.3dmgame.com/thread-3078908-1-1.html">点击进入</a></p>
<p>把meshes解压到data文件夹下，覆盖掉原先的文件。</p>
<p>这个mod提供了smgygfa修改的CBBE V3M身形，兼容CBBE v3身形，所以手脚之类的不会出现裂痕。CBBE V3M是s网MAK修改的CBBE v3身形，臀部和大腿更丰满。smgygfa修改后支持果体乳摇。但是安装文件里没有对应的手脚模型和身体贴图，所以必须先安装CBBE v3.1。</p>
<p>四、安装The skeleton of female models（即俗称的女性九头身骨骼，选装，推荐）</p>
<p>下载地址：<a href="http://skyrim.nexusmods.com/downloads/file.php?id=11064">点击进入</a></p>
<p>把meshes解压到data文件夹下，覆盖掉原先的文件。</p>
<p>没啥好说的，女性骨骼文件（和体型不冲突），装了以后女性不管用什么身形，下半身更修长，整体比例更好。</p>
<p>五、安装CBBE skin texture V2 V3 plus Thepal and UNP compatible （cbbe可选身体/面部贴图，选装，强烈推荐）</p>
<p>下载地址：<a href="http://skyrim.nexusmods.com/downloads/file.php?id=6554">点击进入</a></p>
<p>这个mod可选项较多，包括CBBE可用的皮肤、脸部贴图，均有多种贴图可选。</p>
<p>1.CBBE skin texture v1_8 shaved MAIN FILE (lite)是身体贴图，带LITE的是低分辨率版，机器差可以用</p>
<p>2.Female Face skin v1_8 Fuller Lips v2 （LITE） 是脸部贴图，带LITE的是低分辨率版，机器差可以用</p>
<p>3.Vanilla skin texture那几个是原版游戏风格的皮肤，不推荐</p>
<p>4.CBBE skin texture v1_8 feminine arm toned abs PATCH这个是让女性手臂线条更柔和的补丁，推荐</p>
<p>5.CBBE skin texture v1_8 hairy landingstrip (strip/wild/trimmed)body PATCH 这几个是修改女性死厨毛发的补丁，我用的是landingstrip，推荐用photoshop打开贴图挨个看看，自己选择</p>
<p>6.CBBE skin texture v1_8 muscular body PATCH 女性身体更多肌肉的贴图，喜欢的可以试试</p>
<p>7.Darker liptint mask for more opaque lip color</p>
<p>Female Face skin v1_8 rev1 Fuller Lips and more character PATCH</p>
<p>Female Face skin v1_8 rev1 Fuller Lips with makeup PATCH这几个好像改了女性面部和嘴唇的贴图，我装了第三个，可选装</p>
<p>8.后面几个带 Vanilla字眼的都是原版风格贴图，不推荐</p>
<p>最后说一下我装的吧，注意安装顺序：</p>
<p>CBBE_skin_texture_v1_8_shaved_MAIN_FILE-6554-1-8.7z</p>
<p>Female_Face_skin_v1_8_Fuller_Lips_v2_-6554.7z</p>
<p>CBBE_skin_texture_v1_8_feminine_arm_toned_abs_PATCH-6554-1-8.7z</p>
<p>CBBE_skin_texture_v1_8_hairy_landingstrip_body_PATCH-6554-1-8.7z</p>
<p>Female_Face_skin_v1_8_rev1_Fuller_Lips_with_makeup_PATCH-6554-1-8.7z</p>
<p>这样保证了身体材质和脸部材质都是同一个作者，不会出现色差。</p>
<p>六、安装HD Normals v1 - Female Faces （选装，推荐）</p>
<p>下载地址：<a href="http://skyrim.nexusmods.com/downloads/file.php?id=1039">点击进入</a></p>
<p>注意这个mod只需要其中一个文件！即Data\Textures\Actors\Character\femaleold\femalehead_msn.dds，复制到游戏目录对应的目录下覆盖掉原文件，其他的文件不要安装。</p>
<p>为什么要覆盖掉这个文件？因为步骤五里安装了脸部贴图，其中老年女性的面部贴图跟原版相差甚远，几乎没啥皱纹，所以用这个文件替换一下。其实不替换也没啥问题。</p>
<p>至此女性美化文件基本安装完了（其实没完，看下边），我们来看看男性美化。</p>
<p>更多相关内容请关注：<a href="http://www.gamersky.com/z/tes5/">上古卷轴5专区</a></p>
<p>更多相关内容请关注：<a href="http://www.gamersky.com/z/tes5/">上古卷轴5：天际专区</a></p>
]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>-游戏</tag>
      </tags>
  </entry>
  <entry>
    <title>【刷机教程】【四核RK3128芯迪优美特X5】4个最新安卓固件〖附详细教程〗</title>
    <url>/post/a50b72fa.html</url>
    <content><![CDATA[<p>（1月24日更新添加2个固件，3月6日再增加一个最快固件，共4个固件供大家选择)四核RK3128芯片刷安卓最新刷机包教程和固件：</p>
<p>不同盒子有不同的固件，市面上四核的盒子有部分都是 3128芯片的，（拆开盒子最显眼的那个芯片上面有标注） 理论讲，提供的这个固件适用与所有rk3128芯片的盒子 确认盒子是不是3128不一定非要拆机，进YunOS后，系统信息里显示 R31或者R312X或者XX28都是RK3128芯片，实在不知道什么芯片的就找到原厂包（官网下载）后直接刷安卓包，不能开就刷回原厂包，线刷不怕变砖！！</p>
<p>刷机方法：详细教程在云盘里面</p>
<p>提前准备双USB线（双公头）</p>
<p>拿<a href="http://www.tvapk.net/forum-74-1.html">迪优美特</a>X5做例子四核RK3128芯片刷安卓</p>
<p>1、安装驱动（下面云盘下载） 解压3128刷机工具，打开“3128刷机工具\usb驱动工具\Release_DriverAssitant\DriverInstall.exe”安装驱动很简单 2、刷机工具 打开“3128刷机工具\工厂工具\FactoryTool_v1.303\FactoryTool.exe”点击固件，加载固件后，升级改为修复然后点启动 3、连接盒子刷机（刷机是不用连接电源或其他设备） 迪优美特X5需要拆机短接，按住复位键，插上USB，等3.4秒钟后放开复位键，电脑识别到迪优美特，再拿下短接线，这样电脑就可以自动装上迪优美特驱动。然后再用刷机工具，选择修复，然后启动，就可以刷机了。</p>
<p>好多新手卡在了这里，不同的盒子不同的短接方式</p>
<p><img src="/../images%5C%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image001.jpg" alt="img"></p>
<p>短接点在右侧红圈处</p>
<p>迪优美特X5 1.短接：智美视和迪优美特是拆机后里面有两个需要短路的点，然后插USB 2.按住复位键（两个USB中间小孔里按键）插USB（靠网口的USB口）</p>
<p><img src="/../images%5C%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image002.jpg" alt="img"></p>
<p>用导线短接红圈处</p>
<p>型号太多不列举了，自己度娘下你的盒子的短接方式</p>
<p>如果没提示发现新硬件那就换个USB试试，一般是挨着网线插口的那个USB</p>
<p>刷机工具界面 出现正在低格然后写入程序，出百分比直至完成。</p>
<p>另：如果刷机后不能开机或遥控不匹配，请刷回原厂固件（官网一般都有）或者换其他安卓版本，总有一款适合你</p>
<p>注意：迪优美特部分机型做了底包加密，刷机时出现“测试设备失败”或者“低格失败”，先下载原厂包刷一下，等出现“正在低格0%”快速拔下USB，换安卓固件后就可以刷了。</p>
<p>迪优美特X5原厂固件下载地址</p>
<h4 id="本帖隐藏的内容"><a href="#本帖隐藏的内容" class="headerlink" title="本帖隐藏的内容"></a>本帖隐藏的内容</h4><p><a href="http://pan.baidu.com/s/1hqyfJUG">http://pan.baidu.com/s/1hqyfJUG</a></p>
<p>其实刷盒子比刷手机简单，刷机没想象中那么复杂，一回生二回熟，刷成一个你才发现刷机这么简单工具和固件地址（只适合rk3128芯片的，方法交给大家了其他型号固件自己找吧，多多利用度娘.</p>
<p>1。刷机工具和当贝桌面固件地址和详细方法：</p>
<h4 id="本帖隐藏的内容-1"><a href="#本帖隐藏的内容-1" class="headerlink" title="本帖隐藏的内容"></a>本帖隐藏的内容</h4><p><a href="http://pan.baidu.com/s/1bn5H3AJ">http://pan.baidu.com/s/1bn5H3AJ</a></p>
<p>备用链接: <a href="http://pan.baidu.com/s/1gduJUJD">http://pan.baidu.com/s/1gduJUJD</a> 密码:</p>
<h4 id="本帖隐藏的内容-2"><a href="#本帖隐藏的内容-2" class="headerlink" title="本帖隐藏的内容"></a>本帖隐藏的内容</h4><p>5myb</p>
<p><img src="/../images%5C%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image003.jpg" alt="img"></p>
<p><img src="/../images%5C%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image004.jpg" alt="img"></p>
<p><img src="/../images%5C%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image005.jpg" alt="img"></p>
<p>2、沙发桌面简洁版本介绍：色彩艳丽，流畅不卡，可以自由下载直播<a href="http://www.znds.com/bbs-37-1.html">软件</a>。</p>
<p>桌面简洁版本固件下载地址：</p>
<h4 id="本帖隐藏的内容-3"><a href="#本帖隐藏的内容-3" class="headerlink" title="本帖隐藏的内容"></a>本帖隐藏的内容</h4><p><a href="http://pan.baidu.com/s/1mgTS3wO">http://pan.baidu.com/s/1mgTS3wO</a> 密码: 6sfh</p>
<p><img src="/../images%5C%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image006.jpg" alt="img"></p>
<p><img src="/../images%5C%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image007.jpg" alt="img"></p>
<p>3、最新桌面丰富版本介绍：色彩艳丽，流畅不卡，已经下载直播软件。</p>
<p>桌面丰富版本固件下载地址：</p>
<h4 id="本帖隐藏的内容-4"><a href="#本帖隐藏的内容-4" class="headerlink" title="本帖隐藏的内容"></a>本帖隐藏的内容</h4><p><a href="http://pan.baidu.com/s/1c0OJg7e">http://pan.baidu.com/s/1c0OJg7e</a> 密码: a61g</p>
<p><img src="/../images%5C%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image008.jpg" alt="img"></p>
<p><img src="/../images/%E3%80%90%E5%88%B7%E6%9C%BA%E6%95%99%E7%A8%8B%E3%80%91%E3%80%90%E5%9B%9B%E6%A0%B8RK3128%E8%8A%AF%E8%BF%AA%E4%BC%98%E7%BE%8E%E7%89%B9X5%E3%80%914%E4%B8%AA%E6%9C%80%E6%96%B0%E5%AE%89%E5%8D%93%E5%9B%BA%E4%BB%B6%E3%80%96%E9%99%84%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B%E3%80%97/clip_image009.jpg" alt="img"></p>
<p>4、四核RK3128芯片刷安卓16年最流畅极速版刷机包16年3月6日发布，版本介绍：是色彩艳丽，最流畅不会卡，速度最快的版本。 固件下载地址：<a href="http://www.tvapk.net/forum.php?mod=viewthread&tid=1626995&extra=page=1&page=1">http://www.tvapk.net/forum.php?mod=viewthread&amp;tid=1626995&amp;extra=page%3D1&amp;page=1</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>【君子兰】如何强制刷新MSI的VBIOS让Clevo蓝天的5870M支持Powerplay自动降频,Overdrive超频教程</title>
    <url>/post/945e81c2.html</url>
    <content><![CDATA[<p>对于买到了Clevo蓝天的5870M这张卡准备给自己的M15X或者M17X的兄弟们应该非常郁闷吧<br>这张Clevo蓝天的卡真是巨雷无比,不支持overdrive超频,更可怕的是不能支持powerplay自动降频降压…<br>GPU全天候的工作在700 1000 1.15V的电压下<br>电池撑不了多久,温度也非常的高</p>
<p>不过前一阵子MSI给GX740发布了新的VBIOS 0.31版 (2011年5月16号)<br>经过测试,Clevo蓝天的5870M强刷了MSI的这个VBIOS后可以非常完美的支持powerplay降频降压,以及overdrive超频了<br>同时,3D模式下的电压被控制在1.05V 2D被控制在0.9V,温度也降低了很多</p>
<p>刷新显卡VBIOS有风险,而且只适合Clevo蓝天的5870m一款显卡,其他的牌子请勿尝试!!!<br>如果刷新了MSI的VBIOS之后发现有闪屏情况,请刷回原始的VBIOS(工具包里面有)</p>
<p>现在来说说步骤<br>需要的工具以及软件:<br>\1. U盘一个<br>\2. USBoot<br>\3. MSI已经Clevo蓝天的BIOS<br>(2和3都可以在附件里面下载)</p>
<p>步骤:<br>\1. 首先将U盘插入电脑,格式化,接着打开USBoot,点击U盘,在”点击此处选择工作模式”里面选择”ZIP模式” (中间会要求你拔出U盘,接着重新插入,制作成功会有提示)</p>
<p>\2. 将工具包里面的VBIOS文件夹复制到U盘的根目录, 里面应该有 “5870mmsi.rom” “5870mstock.rom” “atiflash.chg” “atiflash” 和 “VFalsh” 这几个文件</p>
<p>\3. 重新启动机器,开机按F12,选择USB Device启动项,或者进入BIOS吧USB Device设置成最先启动</p>
<p>\4. 这时候你应该已经进入DOS了,<br>先输入 cd vbios<br>接着输入 atiflash -p -f 0 5870mmsi.rom<br>等待VBIOS刷新完成,系统会提示reboot,也就是重启电脑</p>
<p>重启电脑之后,进系统,进入CCC里面,你应该会发现overdrive出现了,而且你现在2D运行在 100 150 0.90V下面了<br>我在overdrive里面只能超频到 750 1050,运行甜甜圈1920X1080 4X MSAA近1小时,温度稳定在74-75度</p>
<p>来张刷完后的图图</p>
<p><img src="/../images/%E3%80%90%E5%90%9B%E5%AD%90%E5%85%B0%E3%80%91%E5%A6%82%E4%BD%95%E5%BC%BA%E5%88%B6%E5%88%B7%E6%96%B0MSI%E7%9A%84VBIOS%E8%AE%A9Clevo%E8%93%9D%E5%A4%A9%E7%9A%845870M%E6%94%AF%E6%8C%81Powerplay%E8%87%AA%E5%8A%A8%E9%99%8D%E9%A2%91Overdrive%E8%B6%85%E9%A2%91%E6%95%99%E7%A8%8B/1004403rvrvyvrbrvr2by2.jpg" alt="img"></p>
<p>PS: 刷新到了MSI这个VBIOS之后是无法修改VBIOS的电压,以及频率,因此在1.05的电压下我的显卡最多也只能超到750 1050绝对稳定(也许个别同学的神卡可以超到860 1200),看个人RP了. 所以不用尝试的调节VBIOS的各种设定了,即使刷上去了还是原始的设置</p>
<p>还有关于屏幕闪动问题<br>进CCC里面的powerplay设置,把接电源改成,电池最大化(原始应该是性能最大化),这样2D频率就会从100 150变成200 1000了……(虽然很奇怪,但是这样之后屏幕就不会闪动了)</p>
<p>驱动请下D大的驱动: <a href="http://dell.benyouhui.it168.com/thread-1920699-1-1.html">http://dell.benyouhui.it168.com/thread-1920699-1-1.html</a></p>
<p>分割线————————————————————————————————————————————————–</p>
<p>如果你不幸的刷黑屏了,工具包里面还有一个Clevo蓝天我备份的原始VBIOS, 文件名是 5870mstock.rom</p>
<p>\1. 插入优盘,启动电脑,一直按F12,差不多感觉ok了按一下下键,接着按ENTER (个人建议一开始就把USB Device设置成最先启动)</p>
<p>\2. 输入 cd vbios<br>  输入 atiflash -p -f 0 5870mstock.rom<br>  等待2分钟之后重启电脑,应该就能亮了,如果没亮,再重新开始一次<br>  如果试过好几次都不行那就是显卡烧掉了或者其他的问题了</p>
<p><img src="/../images/%E3%80%90%E5%90%9B%E5%AD%90%E5%85%B0%E3%80%91%E5%A6%82%E4%BD%95%E5%BC%BA%E5%88%B6%E5%88%B7%E6%96%B0MSI%E7%9A%84VBIOS%E8%AE%A9Clevo%E8%93%9D%E5%A4%A9%E7%9A%845870M%E6%94%AF%E6%8C%81Powerplay%E8%87%AA%E5%8A%A8%E9%99%8D%E9%A2%91Overdrive%E8%B6%85%E9%A2%91%E6%95%99%E7%A8%8B/rar.gif" alt="img"> <a href="http://dell.benyouhui.it168.com/forum.php?mod=misc&action=attachpay&aid=2092791&tid=1927022">工具包.rar</a> <em>(764.29 KB, 下载次数: 84,)</em> </p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>【2016-02-22】改华硕【N14U N54U】5G 2G的7620老毛子Padavan固件(百度云同步 aria2 QOS)</title>
    <url>/post/4248109d.html</url>
    <content><![CDATA[<p>固件是免费、开源<br>这固件是从<a href="https://bitbucket.org/padavan/rt-n56u/src">Padavan固件源码:</a><a href="https://bitbucket.org/padavan/rt-n56u/src%E6%90%AC%E8%BF%90%E6%BA%90%E7%A0%81%E6%B1%89%E5%8C%96%E5%90%8E%E7%BC%96%E8%AF%91%E5%87%BA%E6%9D%A5%E7%9A%84%E3%80%82%E5%A6%82%E6%9C%89%E9%9C%80%E8%A6%81%E5%8F%AF%E4%BB%A5%E5%88%B0%E7%BD%91%E7%9B%98%E4%B8%8B%E8%BD%BD%E6%B1%89%E5%8C%96%E6%96%87%E4%BB%B6%E8%87%AA%E8%A1%8C%E7%BC%96%E8%AF%91%E3%80%82%EF%BC%88[HowToMakeFirmware](https://bitbucket.org/padavan/rt-n56u/wiki/EN/HowToMakeFirmware)%E7%BC%96%E8%AF%91%E6%95%99%E7%A8%8B%E8%A7%81%E7%BD%91%E7%9B%98%EF%BC%89">https://bitbucket.org/padavan/rt-n56u/src搬运源码汉化后编译出来的。如有需要可以到网盘下载汉化文件自行编译。（[HowToMakeFirmware](https://bitbucket.org/padavan/rt-n56u/wiki/EN/HowToMakeFirmware)编译教程见网盘）</a></p>
<p>清除配置方法：<br>由于刷机不清除配置，如果按键10秒也不能清除配置，或者开机后不能启动，可能是配置冲突，需要手动清除配置(nvram)重置机器。<br>（操作前备份编程器固件以备不时之需(已经备份可以跳过)）<br>清除方法：进入breed - 恢复出厂设置 - 选择 【Config 分区 公版】- 上传华硕固件 - 更新</p>
<p>如果出现升级固件后没更新内容，可以换其他浏览器试试，因为有些IE内核浏览器的兼容问题导致升级固件失败。如果aria2配置失败也可能是兼容问题，建议换用Chrome浏览器</p>
<p>由于有些路由兼容性问题，中继显示连接失败，可以试试改WIFI的信道带宽20MHz。有网友试过改WIFI的信道带宽20MHz后中继连接正常。</p>
<p>2016年02月22日 同步Padavan源码更新<br>源码更新内容：<a href="https://bitbucket.org/padavan/rt-n56u/commits/all">https://bitbucket.org/padavan/rt-n56u/commits/all</a> 本次更新到：  <a href="https://bitbucket.org/padavan/rt-n56u/commits/fd112f7350f8bf420103fab72fade4177efb8791">fd112f7</a>    固件版本升到3.4.3.9-099</p>
<p>注意事项:配置说明看下面内容，有些路由刷入后WAN和LAN接口反转<br>很多附加功能都是脚本命令实现的，如果觉得启用功能太多导致不稳定，可以不启用附加功能，这样就是原版固件了，也可以清空脚本。<br>很多人启动S-S后不能用。估计是DNS被污染了。可以电脑设置：DNS自动获取路由的ip。电脑运行cmd输入【ipconfig /flushdns】，清理浏览器缓存。</p>
<p>2016-02-22更新：新增优酷路由宝挖坑功能；新增s-s脚本指定WAN的域名或IP中转设置。<br><a href="http://www.newbandeng.com/thread-24798-1-1.html">感谢陈生的优酷插件</a>，感谢<a href="http://www.right.com.cn/forum/space-uid-286223.html">101048689</a> 提供优酷插件脚本支持 和提供 <a href="http://www.right.com.cn/forum/thread-182340-1-1.html">7620老毛子Padavan固件 ngrok使用教程 </a><br>2016-02-22更新注意事项：本次更新了脚本。更新、复位脚本方法：①升级到最新固件②进入管理页面 - 路由器内部存储 (/etc/storage) - 原厂默认值（第二个红色按钮）<br>2016-02-22更新注意事项：（本次更新了opt文件，需要启动自动更新或者删除U盘根目录“opt”文件夹后重启自动下载更新，也可手动下载opt解压覆盖文件更新，安装方法看下面说明）</p>
<p>旧更新记录：<br>2016-02-16更新：新增脚本自动更新（重启后更新）；新增s-s脚本的UDP转发（能用来玩游戏了）；建议转发的TCP端口填上22,80,443【强烈建议更新此版本后更新脚本】<br>2016-02-04更新：①在使用防火墙 - 网址过滤、 MAC访问控制的过滤程序时，若启动adbyby、SS，需要开启【阻止访问路由器的主机】功能，才能成功过滤。<br>②S-S脚本修改，不用每次启动下载chnroutes。<br>2016-01-30更新：①降低闪存的SPI频率（估计以前的频率太高有些路由不能开机）。<br>②S-S添加DNS 服务程序选择，抵抗DNS污染（如果出现一些网页不能打开，可以尝试其他DNS 服务程序）。<br>③添加计划任务开关（默认关闭，需要手动开启【系统管理 - 服务 - cron守护程序】）。<br>如果百度云不能启动，需要把U盘的opt删掉，等脚本自动更新就能启动了<br>2016-01-22更新：1、感谢<a href="http://www.right.com.cn/forum/space-uid-13905.html">bigandy</a>提供的S-S源码和WebUI模板，现在已经内置固件里面了。<br>2、添加了WebUI，经过十来天的脚本代码重构适配WebUI，初步测试可以用，但是脚本大改后会出现BUG，大量BUG等你发现。(遇到问题请回贴说明设置、日志等情况，我都会看的)<br>3、修复百度云同步软件1小时后关闭问题，添加adbyby的IPSET过滤模式。<br>2016-01-02 更新：修复01-01版本的VPN错误；添加KMS服务程序（在【运行路由器启动后】脚本设置启动）；添加排除IP设置，可停用指定IP的S-S、adbyby功能；更新aria2-1.19.3。<br>2015-12-28更新：【重要，建议更新】修复24号脚本一处BUG：只启用adbyby时添加规则错误问题。添加中继守护功能。添加按钮启动功能：可不设置脚本启动参数启动功能<br>添加【youkuL2】和【newifi2D1】固件【cpu:7621】，注意备份：原厂uboot、eeprom<br>修正脚本添加ADbyby的加白名单方式，建议不要用第三方规则，免得过滤失效。<br>建议开启【opt 自动更新】（替换覆盖opt文件夹） upopt=1<br>1、修复爱奇艺播放器黑屏【需要更新、复位脚本】，添加Pcap_DNSProxy选项(替换ChinaDNS、pdnsd)，脚本增加resolveip，server_ip可输入域名和IP<br>2、使用 pdnsd+chinadns、添加自定义Crontab定时任务配置、添加自定义按钮脚本、添加一个自动下载更新opt文件选项(默认关闭，也可手动下载opt解压覆盖文件更新)<br>3、添加Emong’s Qos脚本，添加adbyby过滤白名单（删除规则实现加白），花生壳内网版(可免U盘运行)、添加迅雷快鸟脚本(可免U盘运行)、添加自动切换中继信号功能、添加VPN智能分流脚本<br>4、支持任意网段限速、固件版本号添加日期以便区分、添加WIFI的SSID中文支持<br>5、添加多次检测断线后自动重启功能、更新脚本修复自动安装自定义名称的U盘失效问题、可以安装到SD卡。<br>6、修复中文乱码、Busybox支持中文显示、添加迅雷脚本、添加QOS脚本、增加多次检测断线后自动重启功能、修复代理方案一CPU占用100%的问题、修复aria2配置错误问题<br>7、添加安装到内存运行轻量级隧道代理启（需要空余内存：10M）、添加代理方案二，提醒一下，电脑的DNS服务器的IP设置路由IP，全部交给路由器去解析<br>8、调整脚本配置到一个页面，添加SyncY——可在路由器上运行的百度网盘同步软件<br>9、添加轻量级隧道代理启动脚本（可以ss和adbyby同时运行），下面有设置教程<br>10、自定义脚本adbyby添加CPU负载监控（满负载自动关闭adbyby），自定义adblock规则、重启和DDNS子程序（32M内存建议不要用adblock规则）</p>
<p>Y1S的3个USB能正常供电使用了，感谢绿色的蝈蝈提供gpio<br>根据<a href="http://www.right.com.cn/forum/space-uid-6034.html">luhua</a>分享的定时任务方法，脚本添加定时重启设置<br>轻量级隧道代理启动脚本大部分参考<a href="http://www.router008.com/">HOUZI的博客</a>内容，谢谢提供</p>
<p>改华硕[N14U N54U]5G 2G的7620老毛子Padavan固件(有transmission aria2)</p>
<p>Padavan固件的UI打开、设置速度比原厂固件响应迅速，虽然Padavan固件去掉QoS(和IPv4 H/W NAT一起工作会出现问题), 但是添加很多功能,有transmission、aria2和HWNAT硬件加速的功能。</p>
<p><img src="/" alt="img"> </p>
<p>默认密码<br>192.168.1.1<br>admin/admin<br>wifi:1234567890<br>刷机不恢复默认值</p>
<p>注意事项<br>1、按键10秒原厂默认值<br>2、使用transmission、aria前，需要在u盘上建一个transmission目录或aria目录。（文件名必须小写字母）<br>3、使用Optware、Entware前，需要在u盘上建一个opt目录。（文件名必须小写字母）</p>
<p>转：[N56U、N65U、N54U、N14U]Padavan韧体学习与研究：（云盘有doc版）<br><a href="http://www.5i01.cn/topicdetail.php?f=110&amp;t=3772592&amp;p=1">http://www.5i01.cn/topicdetail.php?f=110&amp;t=3772592&amp;p=1</a></p>
<p>Padavan固件源码：<br><a href="https://bitbucket.org/padavan/rt-n56u/src">https://bitbucket.org/padavan/rt-n56u/src</a></p>
<p>建议配合使用H大的breed使用：<br><a href="http://www.right.com.cn/forum/thread-161906-1-1.html">http://www.right.com.cn/forum/thread-161906-1-1.html</a></p>
<p>下载地址：<br><a href="http://pan.baidu.com/s/1qWr367y">http://pan.baidu.com/s/1qWr367y</a></p>
<p>固件说明<br>基本上CPU是MT7620A/N的路由，只要配置相同，复位键相同就能用</p>
<table>
<thead>
<tr>
<th>固件</th>
<th>配置</th>
</tr>
</thead>
<tbody><tr>
<td>RT-N14U_GPIO_1_OYE01_128M</td>
<td>MT7620A/N通用，复位键GPIO#1，16M闪存，128M内存，2.4GWi-Fi，USB，SD卡</td>
</tr>
<tr>
<td>RT-N14U_GPIO_1_youku1_128M</td>
<td>优酷路由宝，复位键GPIO#1，16M闪存，128M内存，2.4GWi-Fi，USB，SD卡</td>
</tr>
<tr>
<td>RT-N14U_GPIO_12_xiaodu_ji1S_128M</td>
<td>小度路由/极路由-极壹S（HC5661），复位键GPIO#12，16M闪存，128M内存，2.4GWi-Fi，USB，SD卡</td>
</tr>
<tr>
<td>RT-N14U_GPIO_1_RY1_64M</td>
<td>如意云ry1，复位键GPIO#1，8/16M闪存，64M内存，2.4GWi-Fi，USB，SD卡</td>
</tr>
<tr>
<td>RT-N14U_GPIO_26_ZTEQ7_64M</td>
<td>中兴ZTEQ7，复位键GPIO#26，8/16M闪存，64M内存，2.4GWi-Fi，USB，SD卡</td>
</tr>
<tr>
<td>RT-N14U_GPIO_2_FIR300M_32M</td>
<td>斐讯FIR300M/302M，复位键GPIO#2，4M闪存，32M内存，2.4GWi-Fi</td>
</tr>
<tr>
<td>RT-AC51U_GPIO_12_ji2_128M</td>
<td>极路由-极贰（HC5761），复位键GPIO#12，16M闪存，128M内存，2.4/5GWi-Fi，USB，SD卡</td>
</tr>
<tr>
<td>RT-AC54U_GPIO_11_newifimini_128M</td>
<td>联想Y1（newifi mini），复位键GPIO#11，16M闪存，128M内存，2.4/5GWi-Fi，USB</td>
</tr>
<tr>
<td>RT-AC54U_GPIO_30_xiaomimini_128M</td>
<td>小米Mini，复位键GPIO#30，16M闪存，128M内存，2.4/5GWi-Fi，USB</td>
</tr>
<tr>
<td>RT-AC1200HP_GPIO_11_Y1S_256M</td>
<td>联想Y1S（newifi），复位键GPIO#11，16M闪存，256M内存，2.4/5GWi-Fi，USB * 3个，WAN、LAN各一个千兆口（端口反转）</td>
</tr>
<tr>
<td>RT-N14U-GPIO-53-BUFFALO-WHR-300HP2-64M</td>
<td>BUFFALO-WHR-300HP2，WPS键GPIO#53，8M闪存，64M内存，2.4GWi-Fi</td>
</tr>
<tr>
<td>RT-AC51U_GPIO_1_PSG712_64M</td>
<td>斐讯PSG712，WPS键GPIO#1，8M闪存，64M内存，2.4/5GWi-Fi</td>
</tr>
<tr>
<td>RT-AC54U_GPIO_1_PSG1208_64M</td>
<td>斐讯PSG1208，WPS键GPIO#1，8M闪存，64M内存，2.4/5GWi-Fi</td>
</tr>
<tr>
<td>RT-N14U_GPIO_1_WT3020H_64M</td>
<td>乐携WT3020迷你无线路由器，WPS键GPIO#1，8M闪存，64M内存，2.4Wi-Fi，USB</td>
</tr>
<tr>
<td>RT-N56UB1_newif2D1_256M</td>
<td>联想newif2(D1)，WPS键GPIO#15，复位键键GPIO#18，32M闪存，256M内存，2.4/5GWi-Fi，USB2.0 * 2个，SD卡</td>
</tr>
<tr>
<td>RT-N56UB1_youkuL2_256M</td>
<td>优酷路由宝L2，WPS键GPIO#17，复位键键GPIO#18，16M闪存，256M内存，2.4/5GWi-Fi，USB3.0，SD卡</td>
</tr>
<tr>
<td>RT-AC51U、RT-N56U、RT-N65U</td>
<td>RT-AC51U、RT-N56U、RT-N65U华硕专用版</td>
</tr>
</tbody></table>
<p>更新、复位脚本方法</p>
<p>①升级到最新固件②路由器内部存储 (/etc/storage) - 原厂默认值</p>
<p>共享查看SD卡说明</p>
<p>管理网页UI那里只显示U盘，不显示SD卡，很多人以为SD不能用，其实极1S和极2的固件我都启用的SD卡驱动， 插入SD卡后，你到看看路由是否有这个文件 【/dev/mmcblk[0-9]p[0-9]】<br>如果有，就说明驱动成功，正常情况会自动挂载到【/media/AiDisk_01】路径。<br>再去看看【/media/AiDisk_01】，如果有文件夹就说明自动挂载成功（需要共享查看可以看下面图片设置），可以在脚本选择opt安装模式1，就能把opt放到SD卡里。</p>
<p><img src="/" alt="img"> </p>
<p>控制台说明<br>控制台刷breed或者原厂uboot方法<br>1.查看uboot分区名：cat /proc/mtd<br>2.通过winscp或其他方式，将breed.bin文件上传至路由器/tmp/目录下，breed.bin必须小于等于128kb。<br>3.mtd_write write /tmp/breed.bin Bootloader<br>4.等2秒搞定，重启<br><img src="/" alt="img"> </p>
<p>VPN客户端智能分流脚本<br>由于有些外服游戏限制IP，而且游戏端口无法使用S/s端口，所以用VPN能解决大部分游戏封锁<br>加入智能分流脚本后就能减轻vpn的负担, 和增加访问国内网站的速度.（VPN分流脚本来自：<a href="https://github.com/fivesheep/chnroutes%EF%BC%89">https://github.com/fivesheep/chnroutes）</a><br>首页要有VPN的账号密码，接下来按照下图设置保存设置。</p>
<p><img src="/" alt="img"> </p>
<p>轻量级隧道代理、ADBYBY脚本（可以ss和adbyby同时运行）</p>
<p>①更新、复位脚本方法：①升级到最新固件②路由器内部存储 (/etc/storage) - 原厂默认值</p>
<p><img src="/" alt="img"> </p>
<p>②ADBYBY默认关闭的，需要进入脚本修改启动。（自定义设置 - 脚本 - 运行路由器启动后：)</p>
<p><img src="/" alt="img"> </p>
<p>③轻量级隧道代理默认关闭的，需要进入脚本修改启动。（自定义设置 - 脚本 - 运行后WAN上/下活动：)<br>自动安装（替换覆盖opt文件夹）方法：<br>一、安装到U盘<br>1、拔出U盘<br>2、用电脑删除U盘根目录“opt”文件夹（自动安装时会自动创建）【下载地址失效时手动安装方法：网盘下载opt.tgz到U盘的opt文件夹里面】<br>3、【1；安装到U盘】请设置：①修改脚本参数：installs=1；修改服务器信息，②USB 应用程序 - 其它设置 - 允许运行Optware？选择”Entware”<br>4、插入U盘<br>5、应用设置，点击右上角重启按钮（不能断电重启，要点击右上角重启按钮）<br>6、重启后完成</p>
<p>二、安装到内存<br>1、拔出U盘<br>2、【2；安装到内存，需要空余内存：10M】①修改脚本参数：syncys=0；installs=2；修改服务器信息，②请设置：USB 应用程序 - 其它设置 - 允许运行Optware？选择”否”<br>3、应用设置，点击右上角重启按钮（不能断电重启，要点击右上角重启按钮）<br>4、重启后完成</p>
<p><img src="/" alt="img"> </p>
<p>可添加方案二的gfwlist内部网络(LAN) - DHCP服务器 - 自定义配置文件 “dnsmasq.servers”<br>添加例子<br>server=/.tvb.com/208.67.222.222#443<br>ipset=/.tvb.com/gfw_black_list</p>
<p>额外功能:<br>使用内网访问控制：禁止指定的 IP 可以使用轻量级隧道代理（清除DNS缓存、重启浏览器或重启该 IP 的电脑后生效）禁止以下 IP 使用 轻量级隧道代理（系统管理 - 控制台输入以下命令）<br>ipset add ss_spec_lan_ac 192.168.1.17 #把该内网IP加入该ss_spec_lan_ac集合<br>取消禁止方法：<br>ipset del ss_spec_lan_ac 192.168.1.17 #把该内网IP从该ss_spec_lan_ac集合中删除</p>
<p>自定义按钮脚本</p>
<p>按钮控制脚本在【按WPS / FN 运行按钮脚本：】</p>
<p><img src="/" alt="img"> </p>
<p>SyncY同步软件脚本<br>SyncY——可在路由器上运行的百度网盘同步软件<br>SyncY同步软件技术博客：<a href="http://www.syncy.cn/">http://www.syncy.cn/</a><br>自动安装（替换覆盖opt文件夹）方法：<br>按照上面【一、安装到U盘】的方式设置后，把修改参数syncys=1，修改脚本参数：installs=1，重启后完成</p>
<p># syncy 功能 0关闭；1启动(需要插入U盘安装opt)<br>syncys=1<br>#SyncY配置文件路径（写字板打开修改）：\192.168.1.1\Media\AiDisk_a1\opt\etc\syncy<br>#配置说明：<a href="http://www.syncy.cn/index.php/syncyconfighelp/">http://www.syncy.cn/index.php/syncyconfighelp/</a><br>#同步模式类型：upload,upload+,download,download+,sync （同步模式需要自行打开配置文件修改）</p>
<p>#SyncY配置文件路径（记事本打开修改）：\192.168.1.1\Media\AiDisk_a1\opt\etc\syncy<br>#SyncY配置文件说明：<a href="http://www.syncy.cn/index.php/syncyconfighelp/&quot;">http://www.syncy.cn/index.php/syncyconfighelp/&quot;</a><br>#可以多个同步目录，直接修改配置文件：复制多一个config syncpath配置节，然后修改相应的localpath、remotepath等就可以了。<br>#默认本地同步目录：option localpath ‘/media/AiDisk_a1/SyncY’<br>#默认云端目录（与/我的应用数据/SyncY的相对目录）：option remotepath ‘/apps/SyncY/AiDisk_a1’<br>#默认同步模式-本地上传云端备份（如需下载或同步模式可按照上面网页说明修改配置）：option synctype ‘upload+’</p>
<p>第一次绑定设备需要不断点击“刷新”获取用户码进行进行授权（请在出现用户码后100秒内进行绑定，超时需重启路由重再次授权）<br>百度授权页面 <a href="https://openapi.baidu.com/device">https://openapi.baidu.com/device</a><br><img src="/" alt="img"><br>删除授权方法：修改配置文件，删除config syncytoken配置节内容即可</p>
<p>自定义DDNS脚本、花生壳内网版<br>自定义DDNS脚本（取自网络）<br><img src="/" alt="img"> </p>
<p>花生壳内网版<br>需要安装opt<br>设置脚本开关1启动功能<br>需要CPU、内存比较多，建议使用swap增加内存<br>运行后【刷新日志】获取SN码。使用SN账号在【 <a href="http://b.oray.com/">http://b.oray.com</a> 】默认密码是admin登录.。默认密码是admin，然后进行修改默认密码、手机验证、邮箱验证和已有的花生壳账号绑定，首次使用需要支付宝验证。<br>绑定后需【提交】内部存储，不然重启会丢失绑定。需要重新短信验证再绑定<br>系统管理 - 恢复/导出/上传设置 - 路由器内部存储 (/etc/storage) - 【提交】</p>
<p><img src="/" alt="img"><br>如果打勾连不上可以试试取消打勾</p>
<p><img src="/" alt="img"> </p>
<p>启动：/opt/phddns2/oraynewph.sh start &amp;<br>查看状态：/opt/phddns2/oraynewph.sh status &amp;<br>重置应用：/opt/phddns2/oraynewph.sh reset &amp;<br>停止：/opt/phddns2/oraynewph.sh stop &amp;<br>卸载：/opt/phddns2/oraynewph.sh uninstall &amp;<br>卸载能解除SN绑定</p>
<p>swap分区自动挂载功能<br>用MiniTool分区U盘，前面NTFS分区格式，后面swap分区格式。插入后就能自动挂载了。<br>![img](../images/【2016-02-22】改华硕【N14U N54U】5G 2G的7620老毛子Padavan固件【百度云同步 aria2 QOS】/223637bazt2t1sqtzo8sea.jpg)</p>
<p>Aria2下载管理器<br>1、使用Aria2前，需要在u盘上建一个aria目录。（文件名必须小写字母）<br>2、打开 <a href="http://aria2c.com/">http://aria2c.com/</a> 进行设置，默认没加密：<a href="http://192.168.1.1:6800/jsonrpc">http://192.168.1.1:6800/jsonrpc</a><br><img src="/" alt="img"> </p>
<p>3、如果提示 Aria2 RPC 服务器错误 按照以下方法修改（如配置失败可清空aria目录重新开始配置）<br>如需加密请手动修改配置文件<br>选项设置为: 配置文件中rpc-secret=xxxxxx<br>选项设置为: <a href="http://token:xxxxxx@host:port/jsonrpc">http://token:xxxxxx@host:port/jsonrpc</a><br>host: 指运行 Aria2 所在机器的 IP 或者DDNS绑定的网址<br>port: 使用 –rpc-listen-port 选项设置的端口, 未设置则是 6800<br>配置DDNS使用能达到远程下载的效果</p>
<p>迅雷远程下载安装<br>1、改脚本中参数1<br># 迅雷远程下载xunlei 功能【0关闭】；【1启动】说明看系统日志<br>xunleis=1<br>2、启动后系统日志会提示说明</p>
<p>启动xunlei,绑定设备页面<a href="http://yuancheng.xunlei.com/">http://yuancheng.xunlei.com</a><br>在浏览器中输入<a href="http://192.168.1.1:9000/getsysinfo%EF%BC%88IP%E6%9B%BF%E6%8D%A2%E4%B8%BA%E4%BD%A0%E8%B7%AF%E7%94%B1%E5%99%A8%E7%9A%84IP%EF%BC%8C%E7%AB%AF%E5%8F%A3%E6%8D%A2%E4%B8%BA%E4%BD%A0%E7%9A%84%E6%8E%A7%E5%88%B6%E7%AB%AF%E5%8F%A3%EF%BC%89%EF%BC%8C%E4%BC%9A%E7%9C%8B%E5%88%B0%E7%B1%BB%E4%BC%BC%E5%A6%82%E4%B8%8B%E4%BF%A1%E6%81%AF%EF%BC%9A">http://192.168.1.1:9000/getsysinfo（IP替换为你路由器的IP，端口换为你的控制端口），会看到类似如下信息：</a><br>     [ 0, 1, 1, 0, “42SND1”,1, “201_2.1.3.121”, “”, 1 ]<br>其中有用的几项为：<br>第一项：0表示返回结果成功<br>第二项：1表示检测网络正常，0表示检测网络异常<br>第四项：1表示已绑定成功，0表示未绑定<br>第五项：未绑定的情况下，为绑定的需要的激活码<br>第六项：1表示磁盘挂载检测成功，0表示磁盘挂载检测失败</p>
<p>迅雷快鸟<br>一个可以运行在路由器的迅雷快鸟(diǎo)客户端（脚本来自：<a href="https://github.com/fffonion/Xunlei-FastDick%EF%BC%89">https://github.com/fffonion/Xunlei-FastDick）</a></p>
<p>①在【运行路由器启动后：】脚本里配置功能开关改为1、迅雷账号和密码，修改脚本参数：installs=1，重启。（需要插入U盘安装opt）<br>②根据提示，稍等几分钟，可以ssh到路由，或者控制台输入ps命令查看swjsq进程是否存在，是否正常启动，提速是否成功。<br>③由于是后台脚本运行，看不到输出信息提示，如果想看什么错误问题，可以在控制台输入【python /opt/FastDick/swjsq.py】查看错误信息</p>
<p>修复Entware安装问题</p>
<p>感谢twovl提供Entware安装方法：<br>Entware按照github上不好用，还得按照google code上说的才行，主要就是在u盘上创建opt文件夹，然后卸载u盘，打开entware功能，再重新插上u盘就好了（如果/opt/里面没文件可以试试先关闭再打开entware功能刷新文件）<br>Entware出现【’/opt/lib/libstdc++.so.6’ is not an ELF file】错误修复方法：<a href="http://www.right.com.cn/forum/thread-164518-1-1.html">http://www.right.com.cn/forum/thread-164518-1-1.html</a><br>Entware软件: <a href="https://www.hqt.ro/category/entware/">https://www.hqt.ro/category/entware/</a>  <a href="https://www.asuswrt.eu/category/entware/">https://www.asuswrt.eu/category/entware/</a><br>Entware软件安装例子:<a href="http://www.chiphell.com/thread-933249-1-1.html">http://www.chiphell.com/thread-933249-1-1.html</a></p>
<p>SD卡问题<br>SD卡不能激活USB程序的服务，服务功能还是需要插U盘</p>
<p>手动挂载命令（按自己需求修改路径）：<br>“exfat”<br>mount -t exfat /dev/mmcblk0p1 /media/AiDisk_01 -o noatime,umask=0,iocharset=utf8</p>
<p>“vfat”<br>mount -t vfat /dev/mmcblk0p1 /media/AiDisk_01 -o noatime,umask=0,iocharset=utf8,codepage=936,shortname=winnt</p>
<p>“ntfs”<br>mount -t ufsd /dev/mmcblk0p1 /media/AiDisk_01 -o noatime,sparse,nls=utf8,force</p>
<p>“ext4”<br>mount -t ext4 -o noatime /dev/mmcblk0p1 /media/AiDisk_01</p>
<p>无线中继方法<br>建议使用 20MHz 信道带宽<br>AP + AP Client，受限制的万能，兼容任何厂牌的上级AP，毋须设置上级AP，受上级AP的信道影响。（需要固定上级路由的信道，增强功能：可用自动切换中继信号脚本搜寻信道、信号）<br>路由中继选项：<br>无线AP-Client角色：接LAN就要关闭本路由DHCP，上级路由开启DHCP，本路由的IP不能和上级一样。例子：一个是192.168.1.1，另一个是192.168.1.2。<br>无线AP-Client角色：接WAN就要开启本路由DHCP，上级路由开启DHCP，本路由的IP不能和上级同网段。例子：一个是192.168.1.1，另一个是192.168.2.1。</p>
<p><img src="/" alt="img"> </p>
<p>首先取得中继信号的配置信息，按照下图说明填写参数。<br>当在中继状态下断线，路由会自动搜寻设定的信号</p>
<p>启动功能需要配置两个参数：<br># AP中继连接守护功能，当中继信号断开时启动自动搜寻<br>apauto=1</p>
<p># 【自动切换中继信号】功能 0关闭；填写配置参数启动<br>ap2g5g=”2@4@1@ASUS@1234567890”</p>
<p><img src="/" alt="img"> </p>
<p>QOS脚本</p>
<p>建议只使用脚本1<br>脚本①任意网段限速QOS脚本：<br>1、改脚本中参数1启动脚本<br>#qos 功能 0关闭；1启动<br>qoss=1<br>2、配置参数<br>禁用硬件NAT：”请设置：①外部网络(WAN) - 互联网设置 -&gt; Hardware Offload NAT/Routing IPv4(HWNAT加速)： -&gt; Disable”<br>①IP限速设置，单位[KB/S]<br>一定要设置IP限速，未定义的IP带宽减半，如启用adbyby，因7620的CPU瓶颈，宽带峰值50M<br>配置单IP自定义限制速率，注意数字之间的空格： （可选项：删除前面的#可生效）<br>IP地址 最大下载速度 下载保证速度 最大上传速度 上传保证速度<br>#192.168.1.115 2560 100 200 20<br>192.168.1.2-192.168.1.244 2560 100 100 15</p>
<p>②连接数限制<br>如果开启该功能后，打开下载软件可能会导致QQ等聊天软件掉线。（因为连接数量会被占光）<br>IP地址 TCP连接数 UDP连接数 （可选项：删除前面的#可生效）<br>#192.168.1.10 100 100<br>192.168.1.20-192.168.1.25 100 100</p>
<p>③端口优先优先端口不会被打标记进入列队（不会被流量控制和处理优先级），可添加对延迟要求高的应用端口。<br>请勿添加下载应用的端口80、8080等等。由于没有被流量控制和处理优先级，下载应用会占用大量资源导致网络卡<br>（可选项：删除前面的#可生效）<br>UDP 53<br>TCP 22<br>TCP 23<br>#TCP 443<br>TCP 1723<br>#TCP 3389<br>TCP 3724,1119,1120<br>TCP 28012,10008,13006,2349,7101:7103<br>UDP 2349,12000:12175</p>
<p><img src="/" alt="img"> </p>
<p>3、点击应用保存脚本并重启，不能断电重启，要点击右上角重启按钮</p>
<p>备注：此脚本是从Emong’s Qos脚本修改移植</p>
<p>脚本②：<br>启动方法：<br>1、禁用硬件NAT：”QOS” “请设置：①外部网络(WAN) - 互联网设置 -&gt; Hardware Offload NAT/Routing IPv4(HWNAT加速)： -&gt; Disable”<br>2、SSH（OR WinSCP）打开路由器/etc/storage/qos.conf的配置文件：修改的QoS功能的变量QOS_ENABLED=”YES”（全部大写）<br>3、重启后生效</p>
<p>由于只有优先级控制，比较鸡肋的QOS，有能力大神可以尝试整合其他Tomato QOS脚本<br>## 变量的顺序是（优先级最低在前）：<br>## TCP_BULK, UDP_BULK, TCP_PRIO, UDP_PRIO, TCP_EXPR, UDP_EXPR<br>## TOS_BULK,             TOS_PRIO,            TOS_EXPR<br>## DSCP_BULK,            DSCP_PRIO,           DSCP_EXPR<br>## IP_BULK,                IP_PRIO,              IP_EXPR</p>
<p>备注：此脚本是从moonman的QOS脚本修改移植，原文地址：<a href="https://github.com/moonman/rt-n56u">https://github.com/moonman/rt-n56u</a></p>
<p>SSH可执行命令：</p>
<table>
<thead>
<tr>
<th>Pcap_DNSProxy</th>
<th>killall</th>
<th>restart_firewall</th>
</tr>
</thead>
<tbody><tr>
<td>[</td>
<td>klogd</td>
<td>restart_networkmap</td>
</tr>
<tr>
<td>[[</td>
<td>l2tp-control</td>
<td>restart_vpn_client</td>
</tr>
<tr>
<td>addgroup</td>
<td>l2tpd</td>
<td>restart_vpn_server</td>
</tr>
<tr>
<td>adduser</td>
<td>lan_eeprom_mac</td>
<td>restart_wan</td>
</tr>
<tr>
<td>aria.sh</td>
<td>lanauth</td>
<td>rm</td>
</tr>
<tr>
<td>aria2c</td>
<td>ldconfig</td>
<td>rmdir</td>
</tr>
<tr>
<td>arp</td>
<td>ldd</td>
<td>rmmod</td>
</tr>
<tr>
<td>arping</td>
<td>lld2d</td>
<td>route</td>
</tr>
<tr>
<td>ash</td>
<td>ln</td>
<td>rpc.mountd</td>
</tr>
<tr>
<td>automount.sh</td>
<td>logger</td>
<td>rpc.nfsd</td>
</tr>
<tr>
<td>awk</td>
<td>login</td>
<td>rstats</td>
</tr>
<tr>
<td>badblocks</td>
<td>lpd</td>
<td>rt2860apd</td>
</tr>
<tr>
<td>basename</td>
<td>ls</td>
<td>rtinicapd</td>
</tr>
<tr>
<td>bash</td>
<td>lsmod</td>
<td>run_aria</td>
</tr>
<tr>
<td>bcrelay</td>
<td>lsof</td>
<td>run_firefly</td>
</tr>
<tr>
<td>blkid</td>
<td>lsusb</td>
<td>run_ftp</td>
</tr>
<tr>
<td>brctl</td>
<td>md5sum</td>
<td>run_ftpsamba</td>
</tr>
<tr>
<td>bunzip2</td>
<td>mdev</td>
<td>run_minidlna</td>
</tr>
<tr>
<td>busybox</td>
<td>mdev_lp</td>
<td>run_nfsd</td>
</tr>
<tr>
<td>bzcat</td>
<td>mdev_net</td>
<td>run_samba</td>
</tr>
<tr>
<td>bzip2</td>
<td>mdev_sd</td>
<td>run_telnetd</td>
</tr>
<tr>
<td>cat</td>
<td>mdev_sg</td>
<td>run_transmission</td>
</tr>
<tr>
<td>check_svc.sh</td>
<td>mdev_sr</td>
<td>scp</td>
</tr>
<tr>
<td>chgrp</td>
<td>mdev_tty</td>
<td>sed</td>
</tr>
<tr>
<td>chinadns</td>
<td>mdev_wdm</td>
<td>sendmail</td>
</tr>
<tr>
<td>chmod</td>
<td>microcom</td>
<td>seq</td>
</tr>
<tr>
<td>chown</td>
<td>mii_mgr</td>
<td>sh</td>
</tr>
<tr>
<td>chpasswd</td>
<td>mii_mgr_cl45</td>
<td>shutdown</td>
</tr>
<tr>
<td>chroot</td>
<td>minidlnad</td>
<td>sleep</td>
</tr>
<tr>
<td>clear</td>
<td>miniupnpd</td>
<td>smbd</td>
</tr>
<tr>
<td>comgt</td>
<td>mkdir</td>
<td>smbmulti</td>
</tr>
<tr>
<td>cp</td>
<td>mke2fs</td>
<td>smbpasswd</td>
</tr>
<tr>
<td>cpu</td>
<td>mkfs.ext2</td>
<td>sn_youku</td>
</tr>
<tr>
<td>crond</td>
<td>mkfs.ext3</td>
<td>sort</td>
</tr>
<tr>
<td>crontab</td>
<td>mkfs.ext4</td>
<td>spindown.sh</td>
</tr>
<tr>
<td>curl</td>
<td>mknod</td>
<td>ss-local</td>
</tr>
<tr>
<td>cut</td>
<td>mkswap</td>
<td>ss-redir</td>
</tr>
<tr>
<td>date</td>
<td>modprobe</td>
<td>ss-rules</td>
</tr>
<tr>
<td>dd</td>
<td>more</td>
<td>ss-server</td>
</tr>
<tr>
<td>ddns_updated</td>
<td>mount</td>
<td>ss-tunnel</td>
</tr>
<tr>
<td>detect_internet</td>
<td>mountpoint</td>
<td>ssh</td>
</tr>
<tr>
<td>detect_link</td>
<td>mt-daapd</td>
<td>sshd.sh</td>
</tr>
<tr>
<td>detect_wan</td>
<td>mtd_storage.sh</td>
<td>start-stop-daemon</td>
</tr>
<tr>
<td>dev_init.sh</td>
<td>mtd_write</td>
<td>start_ddns</td>
</tr>
<tr>
<td>df</td>
<td>mtk_esw</td>
<td>stat</td>
</tr>
<tr>
<td>dhcp6c</td>
<td>mv</td>
<td>stop_aria</td>
</tr>
<tr>
<td>dirname</td>
<td>netstat</td>
<td>stop_firefly</td>
</tr>
<tr>
<td>dmesg</td>
<td>networkmap</td>
<td>stop_ftp</td>
</tr>
<tr>
<td>dnsdomainname</td>
<td>nfsd.sh</td>
<td>stop_ftpsamba</td>
</tr>
<tr>
<td>dnsmasq</td>
<td>nice</td>
<td>stop_minidlna</td>
</tr>
<tr>
<td>dos2unix</td>
<td>nmbd</td>
<td>stop_nfsd</td>
</tr>
<tr>
<td>dosfsck</td>
<td>nslookup</td>
<td>stop_samba</td>
</tr>
<tr>
<td>dropbear</td>
<td>ntpc_updated</td>
<td>stop_transmission</td>
</tr>
<tr>
<td>dropbearconvert</td>
<td>ntpd</td>
<td>stop_wan</td>
</tr>
<tr>
<td>dropbearkey</td>
<td>nvram</td>
<td>strings</td>
</tr>
<tr>
<td>dropbearmulti</td>
<td>on_hotplug_printer.sh</td>
<td>swapoff</td>
</tr>
<tr>
<td>du</td>
<td>on_wps.sh</td>
<td>swapon</td>
</tr>
<tr>
<td>e2fsck</td>
<td>openssl</td>
<td>switch</td>
</tr>
<tr>
<td>e2undo</td>
<td>openvpn</td>
<td>switch_root</td>
</tr>
<tr>
<td>e4defrag</td>
<td>openvpn-cert.sh</td>
<td>sync</td>
</tr>
<tr>
<td>ebtables</td>
<td>opkg</td>
<td>sysctl</td>
</tr>
<tr>
<td>echo</td>
<td>opkg.sh</td>
<td>syslogd</td>
</tr>
<tr>
<td>egrep</td>
<td>opt-ipkg-upd.sh</td>
<td>tail</td>
</tr>
<tr>
<td>eject</td>
<td>opt-mkswap</td>
<td>tar</td>
</tr>
<tr>
<td>ejusb</td>
<td>opt-mount.sh</td>
<td>tc</td>
</tr>
<tr>
<td>ejusb1</td>
<td>opt-opkg-upd.sh</td>
<td>tcpdump</td>
</tr>
<tr>
<td>env</td>
<td>opt-start.sh</td>
<td>tee</td>
</tr>
<tr>
<td>ether-wake</td>
<td>opt-umount.sh</td>
<td>telnetd</td>
</tr>
<tr>
<td>exportfs</td>
<td>ovpn_export_client</td>
<td>test</td>
</tr>
<tr>
<td>expr</td>
<td>p910nd</td>
<td>test_share</td>
</tr>
<tr>
<td>FALSE</td>
<td>parted</td>
<td>time</td>
</tr>
<tr>
<td>fdisk</td>
<td>passwd</td>
<td>top</td>
</tr>
<tr>
<td>fgrep</td>
<td>pdnsd</td>
<td>touch</td>
</tr>
<tr>
<td>find</td>
<td>pdnsd-ctl</td>
<td>tr</td>
</tr>
<tr>
<td>flock</td>
<td>pgrep</td>
<td>traceroute</td>
</tr>
<tr>
<td>free</td>
<td>pidof</td>
<td>traceroute6</td>
</tr>
<tr>
<td>fsck.ext2</td>
<td>pids</td>
<td>transmission-daemon</td>
</tr>
<tr>
<td>fsck.ext3</td>
<td>ping</td>
<td>transmission.sh</td>
</tr>
<tr>
<td>fsck.ext4</td>
<td>ping6</td>
<td>TRUE</td>
</tr>
<tr>
<td>fuser</td>
<td>portmap</td>
<td>tune2fs</td>
</tr>
<tr>
<td>getykbdlink</td>
<td>pppd</td>
<td>u2ec</td>
</tr>
<tr>
<td>grep</td>
<td>pptpctrl</td>
<td>udhcpc</td>
</tr>
<tr>
<td>guard</td>
<td>pptpd</td>
<td>udpxy</td>
</tr>
<tr>
<td>gunzip</td>
<td>printf</td>
<td>umount</td>
</tr>
<tr>
<td>gzip</td>
<td>ps</td>
<td>uname</td>
</tr>
<tr>
<td>halt</td>
<td>pwd</td>
<td>uniq</td>
</tr>
<tr>
<td>hddtune.sh</td>
<td>python</td>
<td>unix2dos</td>
</tr>
<tr>
<td>hdparm</td>
<td>python2</td>
<td>unlink</td>
</tr>
<tr>
<td>head</td>
<td>python2.7</td>
<td>update_iptables.sh</td>
</tr>
<tr>
<td>hostname</td>
<td>qos.sh</td>
<td>uptime</td>
</tr>
<tr>
<td>hotplug</td>
<td>radio2_disable</td>
<td>uqmi</td>
</tr>
<tr>
<td>httpd</td>
<td>radio2_eeprom_mac</td>
<td>usb_modeswitch</td>
</tr>
<tr>
<td>https-cert.sh</td>
<td>radio2_enable</td>
<td>usleep</td>
</tr>
<tr>
<td>hub-ctrl</td>
<td>radio2_guest_disable</td>
<td>vconfig</td>
</tr>
<tr>
<td>hw_nat</td>
<td>radio2_guest_enable</td>
<td>vi</td>
</tr>
<tr>
<td>ifconfig</td>
<td>radio2_restart</td>
<td>vsftpd</td>
</tr>
<tr>
<td>igmpproxy</td>
<td>radio2_toggle</td>
<td>wan_eeprom_mac</td>
</tr>
<tr>
<td>ikuacc</td>
<td>radio2_toggle_off</td>
<td>watch</td>
</tr>
<tr>
<td>inadyn</td>
<td>radio2_toggle_on</td>
<td>watchdog</td>
</tr>
<tr>
<td>inetd</td>
<td>radio5_disable</td>
<td>wc</td>
</tr>
<tr>
<td>infosvr</td>
<td>radio5_eeprom_mac</td>
<td>wget</td>
</tr>
<tr>
<td>init</td>
<td>radio5_enable</td>
<td>which</td>
</tr>
<tr>
<td>insmod</td>
<td>radio5_guest_disable</td>
<td>whoami</td>
</tr>
<tr>
<td>ip</td>
<td>radio5_guest_enable</td>
<td>wpa_cli</td>
</tr>
<tr>
<td>ip6tables</td>
<td>radio5_restart</td>
<td>wpa_supplicant</td>
</tr>
<tr>
<td>ip6tables-restore</td>
<td>radio5_toggle</td>
<td>xargs</td>
</tr>
<tr>
<td>ip6tables-save</td>
<td>radio5_toggle_off</td>
<td>xl2tpd</td>
</tr>
<tr>
<td>ipkg.sh</td>
<td>radio5_toggle_on</td>
<td>xtables-multi</td>
</tr>
<tr>
<td>ipset</td>
<td>radvd</td>
<td>xupnpd</td>
</tr>
<tr>
<td>iptables</td>
<td>rc</td>
<td>yes</td>
</tr>
<tr>
<td>iptables-restore</td>
<td>reboot</td>
<td>zcat</td>
</tr>
<tr>
<td>iptables-save</td>
<td>reset_ss.sh</td>
<td>zcip</td>
</tr>
<tr>
<td>iwconfig</td>
<td>reset_to_defaults</td>
<td>zerocd</td>
</tr>
<tr>
<td>iwpriv</td>
<td>restart_dhcpd</td>
<td></td>
</tr>
<tr>
<td>kill</td>
<td>restart_dns</td>
<td></td>
</tr>
</tbody></table>
<p>![img](../images/【2016-02-22】改华硕【N14U N54U】5G 2G的7620老毛子Padavan固件【百度云同步 aria2 QOS】/zip.gif) <a href="http://www.right.com.cn/forum/plugin.php?id=imc_attachad:ad&aid=MTA5MTE3fDRhMmU1ZmVjfDE0NTYzNjkyMzB8MHwxNjEzMjQ=">padavan华硕固件源码汉化文件2015-5-17.zip</a> (535.61 KB, 下载次数: 303) </p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>Python数据挖掘-回归分析</title>
    <url>/post/f16a9029.html</url>
    <content><![CDATA[<p>本文用Python实现数据回归，包括线性回归（一元线性+多元线性回归）、Logistics回归。主要通过实验验证，部分例题来自网络。</p>
<p>注：更多资源及软件请W信关注“*<strong>*学娱汇聚门**</strong>”</p>
<p><strong>一、一元线性回归</strong></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101170859622" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101171054155" alt="img"></p>
<p>举例及代码实现：</p>
<p>汽车卖家做电视广告数量与卖出的汽车数量：</p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101171545114" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101171806904" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101172224712" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101172342045" alt="img"></p>
<p>代码：</p>
<p>1.3 Python代码实现：</p>
<p>import numpy as np</p>
<p>def fitSLR(x, y):</p>
<p>  n = len(x)</p>
<p>  dinominator = 0</p>
<p>  numerator = 0</p>
<p>  for i in range(0, n):</p>
<p>​    numerator += (x[i] - np.mean(x))*(y[i] - np.mean(y))</p>
<p>​    dinominator += (x[i] - np.mean(x))**2</p>
<p>  b1 = numerator/float(dinominator)</p>
<p>  b0 = np.mean(y)/float(np.mean(x))</p>
<p>  return b0, b1</p>
<p>def predict(x, b0, b1):</p>
<p>  return b0 + x*b1</p>
<p>x = [1, 3, 2, 1, 3]</p>
<p>y = [14, 24, 18, 17, 27]   </p>
<p>b0, b1 = fitSLR(x, y)</p>
<p>print “intercept:”, b0, “ slope:”, b1</p>
<p>x_test = 6</p>
<p>y_test = predict(6, b0, b1)</p>
<p>print “y_test:”, y_test</p>
<p>二、多元线性回归：</p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101173001844" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101173121542" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101173525224" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101173711759" alt="img"></p>
<p>实例：</p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101173811610" alt="img"></p>
<p>Python代码：</p>
<p>from numpy import genfromtxt</p>
<p>import numpy as np</p>
<p>from sklearn import datasets, linear_model</p>
<p>dataPath = r”D:\MaiziEdu\DeepLearningBasics_MachineLearning\Datasets\Delivery.csv”</p>
<p>deliveryData = genfromtxt(dataPath, delimiter=’,’)</p>
<p>print “data”</p>
<p>print deliveryData</p>
<p>X = deliveryData[:, :-1]</p>
<p>Y = deliveryData[:, -1]</p>
<p>print “X:”</p>
<p>print X</p>
<p>print “Y: “</p>
<p>print Y</p>
<p>regr = linear_model.LinearRegression()</p>
<p>regr.fit(X, Y)</p>
<p>print “coefficients”</p>
<p>print regr.coef_</p>
<p>print “intercept: “</p>
<p>print regr.intercept_</p>
<p>xPred = [102, 6]</p>
<p>yPred = regr.predict(xPred)</p>
<p>print “predicted y: “</p>
<p>print yPred</p>
<h1 id="三、Logistic回归："><a href="#三、Logistic回归：" class="headerlink" title="三、Logistic回归："></a>三、Logistic回归：</h1><p>3.1 Logistic回归原理</p>
<p>线性回归模型通常是处理因变量是连续变量的问题，如果因变量是定性变量，线性回归模型就不再适用了，需采用逻辑回归模型解决。</p>
<p>逻辑回归（Logistic Regression<strong>）</strong>是用于处理因变量为分类变量的回归问题，常见的是二分类或二项分布问题，也可以处理多分类问题，它实际上是属于一种分类方法。<br>二分类问题的概率与自变量之间的关系图形往往是一个S型曲线，如图所示，采用的Sigmoid函数实现。</p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101214056500" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101214216549" alt="img"></p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101214400536" alt="img"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Sigmoid</span>(<span class="params">x</span>):</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x= np.arange(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">h = Sigmoid(x)            <span class="comment">#Sigmoid函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.plot(x, h)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.axvline(<span class="number">0.0</span>, color=<span class="string">&#x27;k&#x27;</span>)   <span class="comment">#坐标轴上加一条竖直的线（0位置）</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.axhspan(<span class="number">0.0</span>, <span class="number">1.0</span>, facecolor=<span class="string">&#x27;1.0&#x27;</span>, alpha=<span class="number">1.0</span>, ls=<span class="string">&#x27;dotted&#x27;</span>)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.axhline(y=<span class="number">0.5</span>, ls=<span class="string">&#x27;dotted&#x27;</span>, color=<span class="string">&#x27;k&#x27;</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.yticks([<span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">1.0</span>])  <span class="comment">#y轴标度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.ylim(-<span class="number">0.1</span>, <span class="number">1.1</span>)       <span class="comment">#y轴范围</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()  </span><br></pre></td></tr></table></figure>


<p>由于篇幅有限，逻辑回归构造损失函数J函数，求解最小J函数及回归参数θ的方法就不在叙述，原理和前面小节一样，请读者下去深入研究。</p>
<p>3.2LogisticRegression回归算法</p>
<p>LogisticRegression回归模型在Sklearn.linear_model子类下，调用sklearn逻辑回归算法步骤比较简单，即：<br>  (1) 导入模型。调用逻辑回归LogisticRegression()函数。<br>  (2) fit()训练。调用fit(x,y)的方法来训练模型，其中x为数据的属性，y为所属类型。<br>  (3) predict()预测。利用训练得到的模型对数据集进行预测，返回预测结果。</p>
<p>代码如下：</p>
<ol>
<li><strong>from</strong> sklearn.linear_model <strong>import</strong> LogisticRegression #导入逻辑回归模型  </li>
<li>clf = LogisticRegression() </li>
<li><strong>print</strong> clf </li>
<li>clf.fit(train_feature,label) </li>
<li>predict[‘label’] = clf.predict(predict_feature) </li>
</ol>
<p>输出结果如下：</p>
<p><strong>[python]</strong> <a href="http://blog.csdn.net/Eastmount/article/details/77920470#">view plain</a> <a href="http://blog.csdn.net/Eastmount/article/details/77920470#">copy</a></p>
<ol>
<li>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, </li>
<li>​     intercept_scaling=1, max_iter=100, multi_class=’ovr’, n_jobs=1, </li>
<li>​     penalty=’l2’, random_state=None, solver=’liblinear’, tol=0.0001, </li>
<li>​     verbose=0, warm_start=False) </li>
</ol>
<p>其中，参数penalty表示惩罚项（L1、L2值可选。L1向量中各元素绝对值的和，作用是产生少量的特征，而其他特征都是0，常用于特征选择；L2向量中各个元素平方之和再开根号，作用是选择较多的特征，使他们都趋近于0。）；C值的目标函数约束条件：s.t.||w||1&lt;C，默认值是0，C值越小，则正则化强度越大。</p>
<p>3.3. 分析鸢尾花数据集</p>
<p>下面将结合Scikit-learn官网的逻辑回归模型分析鸢尾花示例，给大家进行详细讲解及拓展。由于该数据集分类标签划分为3类（0类、1类、2类），很好的适用于逻辑回归模型。</p>
<h3 id="1-鸢尾花数据集"><a href="#1-鸢尾花数据集" class="headerlink" title="1. 鸢尾花数据集"></a>1. <strong>鸢尾花数据集</strong></h3><p>在Sklearn机器学习包中，集成了各种各样的数据集，包括前面的糖尿病数据集，这里引入的是鸢尾花卉（Iris）数据集，它是很常用的一个数据集。鸢尾花有三个亚属，分别是山鸢尾（Iris-setosa）、变色鸢尾（Iris-versicolor）和维吉尼亚鸢尾（Iris-virginica）。</p>
<p>该数据集一共包含4个特征变量，1个类别变量。共有150个样本，iris是鸢尾植物，这里存储了其萼片和花瓣的长宽，共4个属性，鸢尾植物分三类。如表17.2所示：</p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101214949361" alt="img"></p>
<p>iris里有两个属性iris.data，iris.target。data是一个矩阵，每一列代表了萼片或花瓣的长宽，一共4列，每一列代表某个被测量的鸢尾植物，一共采样了150条记录。</p>
<p><strong>[python]</strong></p>
<ol>
<li>from sklearn.datasets import load_iris  #导入数据集iris </li>
<li>iris = load_iris() #载入数据集</li>
<li>print iris.data </li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris   <span class="comment">#导入数据集iris</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iris = load_iris()  <span class="comment">#载入数据集</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> iris.data</span><br></pre></td></tr></table></figure>


<p>输出如下所示：</p>
<p><strong>[python]</strong></p>
<ol>
<li>[[ 5.1 3.5 1.4 0.2] </li>
<li> [ 4.9 3.  1.4 0.2] </li>
<li> [ 4.7 3.2 1.3 0.2] </li>
<li> [ 4.6 3.1 1.5 0.2] </li>
<li> …. </li>
<li> [ 6.7 3.  5.2 2.3] </li>
<li> [ 6.3 2.5 5.  1.9] </li>
<li> [ 6.5 3.  5.2 2. ] </li>
<li> [ 6.2 3.4 5.4 2.3] </li>
<li> [ 5.9 3.  5.1 1.8]] </li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[[ <span class="number">5.1</span>  <span class="number">3.5</span>  <span class="number">1.4</span>  <span class="number">0.2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [ <span class="number">4.9</span>  <span class="number">3.</span>   <span class="number">1.4</span>  <span class="number">0.2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [ <span class="number">4.7</span>  <span class="number">3.2</span>  <span class="number">1.3</span>  <span class="number">0.2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [ <span class="number">4.6</span>  <span class="number">3.1</span>  <span class="number">1.5</span>  <span class="number">0.2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> ....</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [ <span class="number">6.7</span>  <span class="number">3.</span>   <span class="number">5.2</span>  <span class="number">2.3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [ <span class="number">6.3</span>  <span class="number">2.5</span>  <span class="number">5.</span>   <span class="number">1.9</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [ <span class="number">6.5</span>  <span class="number">3.</span>   <span class="number">5.2</span>  <span class="number">2.</span> ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [ <span class="number">6.2</span>  <span class="number">3.4</span>  <span class="number">5.4</span>  <span class="number">2.3</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> [ <span class="number">5.9</span>  <span class="number">3.</span>   <span class="number">5.1</span>  <span class="number">1.8</span>]]</span><br></pre></td></tr></table></figure>


<p>target是一个数组，存储了data中每条记录属于哪一类鸢尾植物，所以数组的长度是150，数组元素的值因为共有3类鸢尾植物，所以不同值只有3个。种类为山鸢尾、杂色鸢尾、维吉尼亚鸢尾。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span> iris.target          <span class="comment">#输出真实标签  </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(iris.target)      <span class="comment">#150个样本 每个样本4个特征  </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> iris.data.shape    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span>  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span>]  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">150</span>  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(<span class="number">150L</span>, <span class="number">4L</span>)  </span><br></pre></td></tr></table></figure>










<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span> iris.target          <span class="comment">#输出真实标签</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="built_in">len</span>(iris.target)      <span class="comment">#150个样本 每个样本4个特征</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> iris.data.shape  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="number">2</span> <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">150</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(<span class="number">150L</span>, <span class="number">4L</span>)</span><br></pre></td></tr></table></figure>
<p>从输出结果可以看到，类标共分为三类，前面50个类标位0，中间50个类标位1，后面为2。下面给详细介绍使用决策树进行对这个数据集进行测试的代码。</p>
<h3 id="2-散点图绘制"><a href="#2-散点图绘制" class="headerlink" title="2. 散点图绘制"></a>2. <strong>散点图绘制</strong></h3><p>下列代码主要是载入鸢尾花数据集，包括数据data和标签target，然后获取其中两列数据或两个特征，核心代码为：X = [x[0] for x in DD]，获取的值赋值给X变量，最后调用scatter()函数绘制散点图。</p>
<ol>
<li><strong>import</strong> matplotlib.pyplot as plt </li>
<li><strong>import</strong> numpy as np </li>
<li><strong>from</strong> sklearn.datasets <strong>import</strong> load_iris  #导入数据集iris </li>
<li></li>
<li>#载入数据集  </li>
<li>iris = load_iris()  </li>
<li><strong>print</strong> iris.data     #输出数据集  </li>
<li><strong>print</strong> iris.target     #输出真实标签  </li>
<li>#获取花卉两列数据集  </li>
<li>DD = iris.data  </li>
<li>X = [x[0] <strong>for</strong> x <strong>in</strong> DD]  </li>
<li><strong>print</strong> X  </li>
<li>Y = [x[1] <strong>for</strong> x <strong>in</strong> DD]  </li>
<li><strong>print</strong> Y  </li>
<li></li>
<li>#plt.scatter(X, Y, c=iris.target, marker=’x’) </li>
<li>plt.scatter(X[:50], Y[:50], color=’red’, marker=’o’, label=’setosa’) #前50个样本 </li>
<li>plt.scatter(X[50:100], Y[50:100], color=’blue’, marker=’x’, label=’versicolor’) #中间50个 </li>
<li>plt.scatter(X[100:], Y[100:],color=’green’, marker=’+’, label=’Virginica’) #后50个样本 </li>
<li>plt.legend(loc=2) #左上角 </li>
<li>plt.show() </li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris    <span class="comment">#导入数据集iris</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#载入数据集  </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">iris = load_iris()  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> iris.data          <span class="comment">#输出数据集  </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> iris.target         <span class="comment">#输出真实标签  </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取花卉两列数据集  </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DD = iris.data  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> DD]  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> X  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Y = [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> DD]  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> Y  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#plt.scatter(X, Y, c=iris.target, marker=&#x27;x&#x27;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.scatter(X[:<span class="number">50</span>], Y[:<span class="number">50</span>], color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;setosa&#x27;</span>) <span class="comment">#前50个样本</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.scatter(X[<span class="number">50</span>:<span class="number">100</span>], Y[<span class="number">50</span>:<span class="number">100</span>], color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>) <span class="comment">#中间50个</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.scatter(X[<span class="number">100</span>:], Y[<span class="number">100</span>:],color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, label=<span class="string">&#x27;Virginica&#x27;</span>) <span class="comment">#后50个样本</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.legend(loc=<span class="number">2</span>) <span class="comment">#左上角</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>绘制散点图如图所示：</p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101215456017" alt="img"></p>
<h3 id="3-逻辑回归分析"><a href="#3-逻辑回归分析" class="headerlink" title="3. 逻辑回归分析"></a>3. 逻辑回归分析</h3><p>从图中可以看出，数据集线性可分的，可以划分为3类，分别对应三种类型的鸢尾花，下面采用逻辑回归对其进行分类预测。前面使用X=[x[0] for x in DD]获取第一列数据，Y=[x[1] for x in DD]获取第二列数据，这里采用另一种方法，iris.data[:, :2]获取其中两列数据（两个特征），完整代码如下：</p>
<ol>
<li><strong>import</strong> matplotlib.pyplot as plt </li>
<li><strong>import</strong> numpy as np </li>
<li><strong>from</strong> sklearn.datasets <strong>import</strong> load_iris   </li>
<li><strong>from</strong> sklearn.linear_model <strong>import</strong> LogisticRegression  </li>
<li></li>
<li>#载入数据集 </li>
<li>iris = load_iris()      </li>
<li>X = X = iris.data[:, :2]  #获取花卉两列数据集 </li>
<li>Y = iris.target       </li>
<li></li>
<li>#逻辑回归模型 </li>
<li>lr = LogisticRegression(C=1e5)  </li>
<li>lr.fit(X,Y) </li>
<li></li>
<li>#meshgrid函数生成两个网格矩阵 </li>
<li>h = .02 </li>
<li>x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5 </li>
<li>y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5 </li>
<li>xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)) </li>
<li></li>
<li>#pcolormesh函数将xx,yy两个网格矩阵和对应的预测结果Z绘制在图片上 </li>
<li>Z = lr.predict(np.c_[xx.ravel(), yy.ravel()]) </li>
<li>Z = Z.reshape(xx.shape) </li>
<li>plt.figure(1, figsize=(8,6)) </li>
<li>plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired) </li>
<li></li>
<li>#绘制散点图 </li>
<li>plt.scatter(X[:50,0], X[:50,1], color=’red’,marker=’o’, label=’setosa’) </li>
<li>plt.scatter(X[50:100,0], X[50:100,1], color=’blue’, marker=’x’, label=’versicolor’) </li>
<li>plt.scatter(X[100:,0], X[100:,1], color=’green’, marker=’s’, label=’Virginica’)  </li>
<li></li>
<li>plt.xlabel(‘Sepal length’) </li>
<li>plt.ylabel(‘Sepal width’) </li>
<li>plt.xlim(xx.min(), xx.max()) </li>
<li>plt.ylim(yy.min(), yy.max()) </li>
<li>plt.xticks(()) </li>
<li>plt.yticks(()) </li>
<li>plt.legend(loc=2)  </li>
<li>plt.show() </li>
</ol>
<p>下面作者对导入数据集后的代码进行详细讲解。</p>
<p><strong>lr = LogisticRegression(C=1e5)</strong><br><strong>lr.fit(X,Y)</strong><br>初始化逻辑回归模型并进行训练，C=1e5表示目标函数。</p>
<p>x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5<br>y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5<br>xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))<br>获取的鸢尾花两列数据，对应为花萼长度和花萼宽度，每个点的坐标就是(x,y)。 先取X二维数组的第一列（长度）的最小值、最大值和步长h（设置为0.02）生成数组，再取X二维数组的第二列（宽度）的最小值、最大值和步长h生成数组， 最后用meshgrid函数生成两个网格矩阵xx和yy，如下所示：</p>
<ol>
<li>[[ 3.8  3.82 3.84 …, 8.36 8.38 8.4 ] </li>
<li> [ 3.8  3.82 3.84 …, 8.36 8.38 8.4 ] </li>
<li> …,  </li>
<li> [ 3.8  3.82 3.84 …, 8.36 8.38 8.4 ] </li>
<li> [ 3.8  3.82 3.84 …, 8.36 8.38 8.4 ]] </li>
<li>[[ 1.5  1.5  1.5 …, 1.5  1.5  1.5 ] </li>
<li> [ 1.52 1.52 1.52 …, 1.52 1.52 1.52] </li>
<li> …,  </li>
<li> [ 4.88 4.88 4.88 …, 4.88 4.88 4.88] </li>
<li> [ 4.9  4.9  4.9 …, 4.9  4.9  4.9 ]] </li>
</ol>
<p><strong>Z = lr.predict(np.c_[xx.ravel(), yy.ravel()])</strong><br>调用ravel()函数将xx和yy的两个矩阵转变成一维数组，由于两个矩阵大小相等，因此两个一维数组大小也相等。np.c_[xx.ravel(), yy.ravel()]是获取矩阵，即：</p>
<ol>
<li>xx.ravel()  </li>
<li>[ 3.8  3.82 3.84 …, 8.36 8.38 8.4 ] </li>
<li>yy.ravel()  </li>
<li>[ 1.5 1.5 1.5 …, 4.9 4.9 4.9] </li>
<li>np.c_[xx.ravel(), yy.ravel()] </li>
<li>[[ 3.8  1.5 ] </li>
<li> [ 3.82 1.5 ] </li>
<li> [ 3.84 1.5 ] </li>
<li> …,  </li>
<li> [ 8.36 4.9 ] </li>
<li> [ 8.38 4.9 ] </li>
<li> [ 8.4  4.9 ]] </li>
</ol>
<p>总结下：上述操作是把第一列花萼长度数据按h取等分作为行，并复制多行得到xx网格矩阵；再把第二列花萼宽度数据按h取等分，作为列，并复制多列得到yy网格矩阵；最后将xx和yy矩阵都变成两个一维数组，调用np.c_[]函数组合成一个二维数组进行预测。<br>调用predict()函数进行预测，预测结果赋值给Z。即：</p>
<ol>
<li>Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()]) </li>
<li>[1 1 1 …, 2 2 2] </li>
<li>size: 39501 </li>
</ol>
<p><strong>Z = Z.reshape(xx.shape)</strong><br>调用reshape()函数修改形状，将其Z转换为两个特征（长度和宽度），则39501个数据转换为171*231的矩阵。Z = Z.reshape(xx.shape)输出如下：</p>
<ol>
<li>[[1 1 1 …, 2 2 2] </li>
<li> [1 1 1 …, 2 2 2] </li>
<li> [0 1 1 …, 2 2 2] </li>
<li> …,  </li>
<li> [0 0 0 …, 2 2 2] </li>
<li> [0 0 0 …, 2 2 2] </li>
<li> [0 0 0 …, 2 2 2]]</li>
</ol>
<p><strong>plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)</strong><br>调用pcolormesh()函数将xx、yy两个网格矩阵和对应的预测结果Z绘制在图片上，可以发现输出为三个颜色区块，分布表示分类的三类区域。cmap=plt.cm.Paired表示绘图样式选择Paired主题。输出的区域如下图所示：</p>
<p><strong>plt.scatter(X[:50,0], X[:50,1], color=’red’,marker=’o’, label=’setosa’)</strong><br>调用scatter()绘制散点图，第一个参数为第一列数据（长度），第二个参数为第二列数据（宽度），第三、四个参数为设置点的颜色为红色，款式为圆圈，最后标记为setosa。</p>
<p>输出如下图所示，经过逻辑回归后划分为三个区域，左上角部分为红色的圆点，对应setosa鸢尾花；右上角部分为绿色方块，对应virginica鸢尾花；中间下部分为蓝色星形，对应versicolor鸢尾花。散点图为各数据点真实的花类型，划分的三个区域为数据点预测的花类型，预测的分类结果与训练数据的真实结果结果基本一致，部分鸢尾花出现交叉<strong>plt.scatter(X[:50,0], X[:50,1], color=’red’,marker=’o’, label=’setosa’)</strong><br>调用scatter()绘制散点图，第一个参数为第一列数据（长度），第二个参数为第二列数据（宽度），第三、四个参数为设置点的颜色为红色，款式为圆圈，最后标记为setosa。</p>
<p>输出如下图所示，经过逻辑回归后划分为三个区域，左上角部分为红色的圆点，对应setosa鸢尾花；右上角部分为绿色方块，对应virginica鸢尾花；中间下部分为蓝色星形，对应versicolor鸢尾花。散点图为各数据点真实的花类型，划分的三个区域为数据点预测的花类型，预测的分类结果与训练数据的真实结果结果基本一致，部分鸢尾花出现交叉<img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101221000935" alt="img"></p>
<p><strong>plt.scatter(X[:50,0], X[:50,1], color=’red’,marker=’o’, label=’setosa’)</strong><br>调用scatter()绘制散点图，第一个参数为第一列数据（长度），第二个参数为第二列数据（宽度），第三、四个参数为设置点的颜色为红色，款式为圆圈，最后标记为setosa。</p>
<p>输出如下图所示，经过逻辑回归后划分为三个区域，左上角部分为红色的圆点，对应setosa鸢尾花；右上角部分为绿色方块，对应virginica鸢尾花；中间下部分为蓝色星形，对应versicolor鸢尾花。散点图为各数据点真实的花类型，划分的三个区域为数据点预测的花类型，预测的分类结果与训练数据的真实结果结果基本一致，部分鸢尾花出现交叉.</p>
<p><img src="/../images/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/20180101221140797" alt="img"></p>
<p>回归算法作为统计学中最重要的工具之一，它通过建立一个回归方程用来预测目标值，并求解这个回归方程的回归系数。本篇文章详细讲解了逻辑回归模型的原理知识，结合Sklearn机器学习库的LogisticRegression算法分析了鸢尾花分类情况。更多知识点希望读者下来后进行拓展，也推荐大家从Sklearn开源知识官网学习最新的实例。</p>
<p>注：本文Logistic回归用了sklearn包，算法已经封装好了，如果想了解具体的实现方法，可以参考《机器学习实战》一书，或参考此博文是关于使用statesmodels的<a href="http://en.wikipedia.org/wiki/Logit">Logit</a>函数：</p>
<h1 id="Python实现逻辑回归-Logistic-Regression-in-Python-："><a href="#Python实现逻辑回归-Logistic-Regression-in-Python-：" class="headerlink" title="Python实现逻辑回归(Logistic Regression in Python) ："></a><a href="http://blog.csdn.net/zj360202/article/details/78688070">Python实现逻辑回归(Logistic Regression in Python) ：</a></h1><p><a href="http://blog.csdn.net/zj360202/article/details/78688070">http://blog.csdn.net/zj360202/article/details/78688070</a></p>
<p>参考文献：</p>
<p><a href="http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">scikit-learn文档</a>：<a href="http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression</a></p>
<p>纯Python实现logistc回归：<a href="http://blog.smellthedata.com/2009/06/python-logistic-regression-with-l2.html">http://blog.smellthedata.com/2009/06/python-logistic-regression-with-l2.html</a></p>
<p>Logistic在线交互界面：<a href="http://www.vassarstats.net/logreg1.html">http://www.vassarstats.net/logreg1.html</a></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>-Python</tag>
      </tags>
  </entry>
  <entry>
    <title>【吉他伴奏版】See You Again【Igor Presnyakov】</title>
    <url>/post/22e374f1.html</url>
    <content><![CDATA[<p>【吉他伴奏版】See You Again【Igor Presnyakov】</p>
<p><a href="http://static.hdslb.com/miniloader.swf?aid=3291901&amp;page=1">http://static.hdslb.com/miniloader.swf?aid=3291901&amp;page=1</a></p>
]]></content>
      <categories>
        <category>音乐</category>
      </categories>
      <tags>
        <tag>-音乐</tag>
      </tags>
  </entry>
  <entry>
    <title>【教程】自制解锁bios，加slic，改logo和添加序列号</title>
    <url>/post/89080ece.html</url>
    <content><![CDATA[<p>今日放假，给大家发些我的心得，其实技术就是一层纸，一捅就破解锁bios什么的听起来高大上，其实没什么难度。我现在就给大家分享一下。（各种电脑bios解锁原理大同小异，今天以p775dm2g为例）</p>
<p>用到的工具有rw everything，AMIBCP5.01.0014 ，UEFITool ， ChangeLogo 5.0.0.2 ，phoenixtool 。</p>
<p>教程开始</p>
<p>首先根据电脑型号在<a href="http://jump.bdimg.com/safecheck/index?url=rN3wPs8te/qbcLzWBl/RW4zMiwubX/xvWaradDzoQEzXjPfwV/i0jfMRfhec8gePPLBQPbWwUIJiRR7/sVRYQw7xFUSAhTAdBah3aBIyVP8ZkoQYdFPNPPXl0gK0SNcDzgGXzQWatLPKq8EYKcRO9DA8Zu4mdgY0">https://repo.palkeo.com/clevo-mirror </a>里找到对应bios刷新包并下载，我的775下载后得到一个P7xxDM3G_B10602.zip文件，解压后找到到一个8m的P7xxDM3.bin和一个5m的P7xxDM3.rom因为要修改序列号（bios文件中没有序列号，需要我们自己添加，否则会导致修改后的bios刷入后没有序列号的问题，各种用了大神的解锁bios的已经中枪，因为fpt刷新bios会覆盖原来所以block，如果刷入的bios没有序列号，那么刷完就没有）所以我们用8m的P7xxDM3.bin进行修改。</p>
<p>用AMIBCP打开P7xxDM3.bin打开DMI Tables</p>
<p><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/142bd243ad4bd113fdb0fa6e53afa40f4afb05af.jpg" alt="img"></p>
<p>再打开rw everything</p>
<p><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/5d753adbb6fd5266ac527048a218972bd50736ab.jpg" alt="img"><br>点击上面的倒数第八项sm bios会出现上图，这时点击左侧第三项 bios board information<br>会出现下图<img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/6080b23533fa828be9e3d2bff41f4134950a5aec.jpg" alt="img"><br>我们可以看到 serial number 对应的是string4 </p>
<p>再到rw everything左侧点击第二项system information，也会看到一个 serial number条目，对应的也是string4，这时可以关闭rw everything了回到AMIBCP 我们之前就已经在DMI Tables选项卡了 如下图所示<br><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/82618eb1cb13495434f9a1385f4e9258d3094ac1.jpg" alt="img"></p>
<p>右下角的第四条就是string4 但是我们需要修改2条这个号码，一个是左边第二个选项卡system information的string4 一个是左边第三个选项卡base board的string4，把它替换为自己的序列号，一般电脑后面都有贴，那些刷过大神制作的解锁bios的人可以通过这个补救（刚才在rw everything中serial number后面的引号里就是序列号，这里可以直接粘贴过来要是显示为Not Applicable说明序列号被刷掉了）然后点击上面的保存即可。</p>
<p>下面开始解锁bios在AMIBCP中打开setup configuration选项卡<img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/155416ce36d3d53942bc459f3387e950342ab02c.jpg" alt="img"><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/aab74836acaf2eddb38ffcb5841001e9380193aa.jpg" alt="img">点击上图所示加号弹出下图<img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/8b9212dfa9ec8a13a10ae3bcfe03918fa1ecc09d.jpg" alt="img"></p>
<p>打开setup的加号我这里为了示范打开main选项卡后弹出下图<img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/ed13c8ef76094b36a109afb1aacc7cd98c109d15.jpg" alt="img"></p>
<p>所谓解锁就是有些选项卡的Access/Use默认是Default可能是不开放的，我们把权限强制调整为user在低权限下开放就行这个bios有好多可以调整的地方，方便起见我解锁上面那页。<br><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/4bb4334e251f95ca9f9524eac0177f3e6609524c.jpg" alt="img"></p>
<p>总之要解锁什么就把对应条目的Access/Use由Default改成user即可（有的Default在默认状态下也是显示的，不用改。还有些空条目如第十四行，这些保持Default就好，不用动了。）解锁完保存就行。添加slic模块<br>添加slic模块可以oem激活windows，除了win10 win8以外windows都可以激活，但是win10 可以用windows server 2016代替，win8可以用server 2012代替，所以其实变相激活了win10 win8 而且服务器版本windows更加稳定，功能齐全。就是有些繁琐。适合能琢磨的人。</p>
<p>打开phoenixtool（最新版本2.66）用phoenixtool打开修改好的bios文件P7xxDM3.bin，选好主板厂商（主板厂商没有clevo，直接选个dell 戴尔）和slic文件这里我们刷dell的slic2.4（等下会提供地址）<br><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/d069922397dda1445019d1eebbb7d0a20df4869d.jpg" alt="img"><br>点击高级，并勾除常规选项里的2，3，5项<br><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/68318f5494eef01f1ce3a599e9fe9925bd317d31.jpg" alt="img"></p>
<p>点击完成后回到主页面再点击执行，会生成一个P7xxDM3_SLIC.bin的文件，我们下面就用这个文件进行操作。</p>
<p>为了安全起见，我们还需要再向P7xxDM3_SLIC.bin中加一个slic头文件来确保成功（不添加没试过，这里不评论，此处引用<a href="http://jump.bdimg.com/safecheck/index?url=x+Z5mMbGPAsDFYW2HqnwkaDRjkrD11q/cYQkE10N22RcMgJTrvpu7I8isJhwUWTPGmT1ugAiyeQYQSBtpbfyfjywUD21sFCCYkUe/7FUWEMO8RVEgIUwHQWod2gSMlT/GZKEGHRTzTz15dICtEjXA84Bl80FmrSzyqvBGCnETvQwPGbuJnYGNA==">http://bbs.bios.net.cn/thread-4527211-1-1.html</a>)打开UEFItool，并用UEFItool打开P7xxDM3_SLIC.bin按照上面的引用贴的方法找到需要添加的位置（由于我们之前用了phoenixtool，会含有pubkey模块和marker模块所以我们直接搜索这些模块的GUID就可以直接确定位置）我们打开搜索框转到搜索GUID选项卡输入69009842<img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/bf9961d0f703918f0c359396583d26975beec4c1.jpg" alt="img"><br>摁ok下面的messages框里会出现上面的消息，点击第二条消息，会把你直接带到要找的模块。<br><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/be6ef403918fa0eca523ca512f9759ee3f6ddbc1.jpg" alt="img"></p>
<p>在那个模块上摁右键点击insert before，插入4C494E55-5849-5342-4554-544552212121.ffs文件（等下提供，这个不能用引用贴的slic表头文件，这里是slic2.4，引用贴是slic2.3，表头文件不同。然后点击UEFItool左上角的file，点save image file保存，这时软件会自动重新构架这个bios文件，并提示你是否打开修改过的文件，我们选择是，下面就是重点了。</p>
<p>注意，这步很重要，要删除8m的bios文件中多余的部分，有些人会问为什么不直接用5m的P7xxDM3.rom，因为5m的bios可以解锁bios（有些不能），可以加slic2.4，可以改logo，但是不能改序列号，因此不选用。</p>
<p>如图展开intel image项<img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/a74a09d162d9f2d3f6868fb3a0ec8a136227cc12.jpg" alt="img"></p>
<p>在bios region上摁右键点击extract as is…会让你保存。随便保存一个名字，但是扩展名为.rgn我们直接把.rgn改成.rom就行。这样提取的bios就是5m了，前面3m是校验用的。下面更改logo<br>用ChangeLogo 5.0.0.2打开上面的文件，直接用想用的logo替换里面的logo就行，但是要注意logo文件大小和画面大小还有文件格式，这里不做太多说明。</p>
<p>最后就是刷入了，我们选用fpt方法刷入，用<a href="http://tieba.baidu.com/p/4936939406">@827270744</a><br>大神提供的工具<br><img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/e994c55c103853432156137d9a13b07ecb808814.jpg" alt="img"></p>
<p>做好启动盘后把我们修改完的bios重命名为P7DM2G.ROM，替换原来启动盘里的P7DM2G.ROM，然后重启进入dos，执行fpt.bat刷新就行。<img src="/../images/%E3%80%90%E6%95%99%E7%A8%8B%E3%80%91%E8%87%AA%E5%88%B6%E8%A7%A3%E9%94%81bios%EF%BC%8C%E5%8A%A0slic%EF%BC%8C%E6%94%B9logo%E5%92%8C%E6%B7%BB%E5%8A%A0%E5%BA%8F%E5%88%97%E5%8F%B7/6d8b30fa828ba61e8ee259734834970a314e5998.jpg" alt="img"> 下面提供所用工具和各种文件<br><img src="http://imgsrc.baidu.com/forum/w%3D580/sign=f76968d36581800a6ee58906813433d6/6d8b30fa828ba61e8ee259734834970a314e5998.jpg" alt="img"></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>【数据可视化】电视产品精准营销推荐</title>
    <url>/post/89c41659.html</url>
    <content><![CDATA[<p>获奖经历：</p>
<p>2017年4月:美国大学生数学建模竞赛二等奖</p>
<p>2017年11月:数学建模竞赛国家一等奖</p>
<p>2017年11月:数学竞赛国家二等奖</p>
<p>2018年4月:美国大学生数学建模竞赛二等奖</p>
<p>2018年5月:泰迪杯数据挖掘竞赛国家二等家</p>
<p>兴趣爱好：羽毛球，读书</p>
<p>个人生活照：（1-2张）</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-6aa9dfa6d6d152c4f2772709a2a1645a_hd.jpg" alt="img"></p>
<p><strong>一、实验目的</strong></p>
<p>1、实验背景</p>
<p>本实验项目来自于第六届泰迪杯数据挖掘竞赛，共包含用户观看信息和电视产品信息两组数据，通过对数据进行处理，实现产品的精准营销推荐，并将并将结果进行可视化展示。</p>
<p>2、实验目的</p>
<p>基于电视产品及用户信息数据对产品进行精准营销推荐，并将结果进行可视化展示。主要实现以下两个目的：</p>
<p>（1）产品的精准营销推荐</p>
<p>根据用户观看记录信息数据，分析用户的收视偏好，并给出电视产品的营销推荐方案。</p>
<p>（2）相似偏好用户的产品打包推荐</p>
<p>为了更好地为用户服务，扩大营销范围，利用数据对相似偏好的用户进行分类（用户标签），对产品进行分类打包（产品标签），并给出营销推荐方案。</p>
<p>3、实验内容与要求</p>
<p>（1）对数据进行处理，并根据用户的收视信息对用户偏好进行分析，将分析结果用图像进行表示。</p>
<p>（2）整理产品信息，重新对产品分类，将产品类别通过可视化方式表达。</p>
<p>（3）利用推荐算法和聚类算法对产品进行推荐，将具体过程进行展示。</p>
<p>（4）对结果进行分析，得出精准的营销推荐方案以及有效的可视化展示结果。</p>
<p>4、实验所用工具</p>
<p>l Excle</p>
<p>利用其中的统计和编程工具对数据进行处理和分析</p>
<p>l Echarts</p>
<p>含有多类图像，在没有可视化思路时，可以利用它寻找灵感，代码易改易实施</p>
<p>l Rstudio</p>
<p>其中的ggplot/echarts绘画包中图像丰富，语句简单</p>
<p>l Microsoft Visio</p>
<p>适合流程图说明图的绘制，简单易操作</p>
<p><strong>二、实验过程</strong></p>
<p>1、数据介绍</p>
<p>数据来源于泰迪杯数据挖掘竞赛官网，包括用户收看电视的信息记录和产品的各项参数。</p>
<p>用户信息：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-7843daa10ca16682f8ee2eec62fd3bb0_hd.jpg" alt="img"></p>
<p>图1.用户信息数据</p>
<p>产品信息：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-74c8bce2a6c41f42c435698510b93c2b_hd.jpg" alt="img"></p>
<p>图2.产品信息数据</p>
<p>2、数据清洗</p>
<p>（1）删除重复内容，以及错误信息：对数据进行初步整理，删掉无效数据</p>
<p>（2）提取产品标签 =TEXT(E2,”h:mm”)转化时间</p>
<p>=TEXT(H2-G2,”[m]”)求时间差</p>
<p>用数据透视表求频数</p>
<p>（3）提取用户标签，分析用户偏好：将产品类别与用户信息偏好类别进行统一，在用户信息表中添加偏好类型、是否高清、时间段、观看频数、时长标签</p>
<p>3、清洗后数据</p>
<p>用户信息：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-77a3ca99d39565ebd4194ff15daa95e7_hd.jpg" alt="img"></p>
<p>产品信息：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-81cdcd6f0673f75820c8b561f4ea5999_hd.jpg" alt="img"></p>
<p>图3.数据清洗后数据</p>
<p><strong>三、可视化展示及结果</strong></p>
<p>1.旭日图</p>
<p>主题：对产品类别进行展示（使用工具：Echarts ）</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-882533662c432170019ffeeab963aee8_hd.jpg" alt="img"></p>
<p>图4.产品类别图</p>
<p>由图可知产品主要分为两类：电影和电视剧，其中电影又分为：动作电影、恐怖电影、爱情电影、动画电影、喜剧电影与其他；</p>
<p>电视剧又分为：抗日剧、古装剧、综艺娱乐、仙侠科幻、都市情感与动画片；</p>
<p>电影类产品中动作类电影产品最多；其中产品“碟中谍”热度最高</p>
<p>电视剧中古装剧产品最多，其中“独孤天下”热度最高</p>
<p>2.嵌套环形图</p>
<p>主题：以10853号用户为例，对用户偏好进行展示（使用工具：Echarts）</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-173e2ed83e61fafa367ab8978c6ae8c6_hd.jpg" alt="img"></p>
<p>图5.用户偏好</p>
<p>10853用户喜欢四类产品类型：家庭影院、纪录片、综艺娱乐、大陆剧场，其中最喜欢观看家庭影院类型产品，在众多节目中喜欢观看舌尖上的中国和味道中国等美食节目。</p>
<p>3.碎石图</p>
<p>主题：针对本文所研究的问题，需要对影视产品进行打包，进而以产品包为单位向用户进行推荐。为此我们引入K-means 聚类分析理论，将同种类型的产品进行打包，此时问题重点是探索所推荐的产品包中影视产品的最佳数量和产品包的最终分类结果。</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-4f03d0fca6b3b21c7c2e1a0d8f17a87f_hd.jpg" alt="img"></p>
<p>由图可知，最佳聚类数目分别为2和6，电视剧场/欧美剧场分类中还可以将产品细分为2类，大陆剧场/日韩剧场这个分类中则可以将产品细化为6类。</p>
<p>\4. 折线图</p>
<p>对产品进行打包后，采用推荐算法对产品进行推荐。本项目采用协同过滤推荐算法、热点推荐算法和随机推荐算法三种推荐方式。为了实现产品的个性化推荐，自定义推荐产品包数目，通过十折交叉验证检测准确率和召回率。</p>
<p>两个主题：</p>
<p>（1）通过准确率和召回率对三种推荐方式进行比较。</p>
<p>（2）选择合适的产品包推荐数目。</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-03e8ebf306066033233f7a96a0c1c571_hd.jpg" alt="img"></p>
<p>图7.三种推荐方式对比</p>
<p>由图知，热点推荐模型和协同过滤推荐模型的准确度和召回率均远远高于随机推荐，说明热点推荐模型和协同过滤模型对于重要价值用户的个性化推荐效果显著。其中热点推荐效模型效果好于协同过滤推荐，并且，热点推荐和协同过滤推荐在产品包推荐数目为 1 时同时达到精准率最大值，同时也是召回率最小值。当推荐打包数为 20 个时，协同过滤推荐和热点推荐的召回率均达到最大值，但此时精准率达到最小值。</p>
<p>5.气泡图</p>
<p>因为精准率与召回率二者评价模型的标准均为越接近于1越好，但是在保证精准率的前提下，召回率就难以得到保障，同样地在保障召回率的前提下，精准率就不能得到保障，因此，本文根据精准率和召回率计算得到平衡F分数（F1 的值，它可以同时兼顾模型的精准率和召回率，如下：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-c5702ce83ae2c8ef0ee5a8540a273172_hd.jpg" alt="img"></p>
<p>两个主题：</p>
<p>（1）通过可视化寻找三类推荐算法用户最佳推荐个数，根据最佳推荐个数为用户推荐产品</p>
<p>（2）对三类推荐算法进行比较，选择平衡分数最高的推荐算法进行推荐。</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-11362594149cd0bd979a616b4275a781_hd.jpg" alt="img"></p>
<p>图7.平衡分数</p>
<p>由图可知热点推荐模型形状最大，其平衡分数最高，协同过滤推荐其次，随机推荐最低</p>
<p>6.产品介绍图</p>
<p>主题：对协同过滤推荐算法的具体过程及原理进行介绍（使用工具：Microsoft Visio）</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-2fee4e20f7b3835a3066739fa4a6c806_hd.jpg" alt="img"></p>
<p>基于用户的协同过滤算法：我们知道樱桃小丸子喜欢葡萄、草莓、西瓜和橘子，而我们通过某种方法了解到小丸子和花伦有相似的喜好，所以我们会把小丸子喜欢的而花伦还未选择的水果（葡萄和橘子）推荐给花伦。</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-81c610cd2702a6bea1d6e68a39383292_hd.jpg" alt="img"></p>
<p>图9.基于物品的协同过滤算法</p>
<p>基于物品的协同过滤算法：给用户推荐那些和他们之前喜欢的物品相似的物品。比如，我们知道樱桃小丸子和小玉都喜欢葡萄和西瓜，那么我们就认为葡萄和西瓜有较高的相似度，在花伦选择了西瓜的情况下，我们会把葡萄推荐给花伦。</p>
<p>\7. 漏斗图</p>
<p>主题：以10853号用户为例，对推荐结果进行展示（使用工具：Echarts ）</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-760c22a1e97c9aa1f67b72823d88929f_hd.jpg" alt="img"></p>
<p>图10.推荐结果展示</p>
<p>根据推荐算法进行分析，共对用户10853推荐8个产品。其中英超联赛推荐指数最高，新闻联播次之。</p>
<p><strong>四、图表制作</strong></p>
<p>1、旭日图制作</p>
<p>步骤：</p>
<p>（1）对一级指标“电影/电视剧”进行修改，将data第一个name标签内容替换。</p>
<p>（2）对二级指标“动作电影/喜剧电影等”修改，将第一个children类下的name标签替换。</p>
<p>（3）对三级指标产品名称如“摔跤吧爸爸”等进行修改，将第二个children类下的name标签内容替换。</p>
<p>（4）若多增加标签，则增添children[{name:’’},{name:’’}]</p>
<p>程序：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-35229aea6165fc1e58a4fc5aae1aaaf3_hd.jpg" alt="img"></p>
<p>图11.旭日图程序</p>
<p>2.嵌套环形图制作</p>
<p>步骤：</p>
<p>（1）对图像标题进行修改</p>
<p>（2）对图像内容进行替换，并将各部分占比进行修改</p>
<p>程序：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-f1bb592944773ee628d96b07cbb926b4_hd.jpg" alt="img"></p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-31e971f029d030c9025dd9792b5b161c_hd.jpg" alt="img"></p>
<p>图12.嵌套环形图程序</p>
<p>3.碎石图制作</p>
<p>步骤：</p>
<p>（1）对于产品内容进行中文分词，并构成 dtm 矩阵。</p>
<p>（2）基于dtm 矩阵，采用 Kmeans 均值聚类计算产品数目大于30的类别之间的距离，采用碎石图，得到每一个一级标签分类的最佳聚类数</p>
<p>形成的dtm矩阵如下：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-1fba03748172a555ad72b2c51ff68ea8_hd.jpg" alt="img"></p>
<p>图13.DTM矩阵</p>
<p>程序：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-c733035f3d41d485489cc90934c114d9_hd.jpg" alt="img"></p>
<p>4.折线图制作</p>
<p>步骤：</p>
<p>（1）采用三种推荐算法，基于用户偏好进行产品推荐。</p>
<p>（2）通过十折交叉验证对推荐结果进行验证，得到不同推荐产品包数目的结果准确率与召回率，这里探究自定义产品包数目为（1,3,5,7, 8,10,15,20）时的准确率与召回率。</p>
<p>（3）对三种推荐算法在不同推荐情况下的准确率与召回率进行可视化表达，探索最优算法</p>
<p>程序：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-8a35fc29bd35c9da24d3f6156b4d0b1c_hd.jpg" alt="img"></p>
<p>5.气泡图制作</p>
<p>步骤：</p>
<p>（1）导入平衡分数计算公式</p>
<p>（2）对三类推荐算法在不同推荐情况下的平衡分数进行可视化表达，对折线图、气泡图两种表达方式进行对比，最终选择气泡图，因为其可以动态的表示每点数据情况。</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-56188e430a46333cd9b6abb378f5afd3_hd.jpg" alt="img"></p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-11362594149cd0bd979a616b4275a781_hd.jpg" alt="img"></p>
<p>图14.推荐算法比较</p>
<p>程序：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-11f7bd323058a8307ed1b4bc49f41741_hd.jpg" alt="img"></p>
<p>6.产品介绍图制作</p>
<p>步骤：</p>
<p>（1）使用visio2003创建一个新文件</p>
<p>（2）选择对应形状拖动进绘画板</p>
<p>（3）文件保存，发布</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-20bdfac8ac2625f59a30d3bf3e087277_hd.jpg" alt="img"></p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-ee6d21f434a5dc1d6c922dae698cf427_hd.jpg" alt="img"></p>
<p>图15.visio绘图</p>
<p>7.漏斗图制作</p>
<p>步骤：</p>
<p>1.对legend数据框中data的内容进行修改，对图例内容进行替换。</p>
<p>2.对图中数据进行替换，并对各数据占比进行修改，数据皆为百分制</p>
<p>程序：</p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-a167093b48fb988b52138cad18e0d790_hd.jpg" alt="img"></p>
<p><img src="/../images/%E3%80%90%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E3%80%91%E7%94%B5%E8%A7%86%E4%BA%A7%E5%93%81%E7%B2%BE%E5%87%86%E8%90%A5%E9%94%80%E6%8E%A8%E8%8D%90/v2-78c6498505976e674e7a84f660e2d962_hd.jpg" alt="img"></p>
<p>图16.漏斗图程序</p>
<p><a href="http://link.zhihu.com/?target=http://weixin.qq.com/r/GT9EXHfEnyrgrTM-92oL">http://weixin.qq.com/r/GT9EXHfEnyrgrTM-92oL</a> (二维码自动识别)</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>-大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>【算法】超详细的遗传算法(Genetic Algorithm)解析</title>
    <url>/post/d601a254.html</url>
    <content><![CDATA[<h1 id="00-目录"><a href="#00-目录" class="headerlink" title="00 目录"></a>00 目录</h1><ul>
<li>遗传算法定义</li>
<li>生物学术语</li>
<li>问题导入</li>
<li>大体实现</li>
<li>具体细节</li>
<li>代码实现</li>
</ul>
<h1 id="01-什么是遗传算法？"><a href="#01-什么是遗传算法？" class="headerlink" title="01 什么是遗传算法？"></a>01 什么是遗传算法？</h1><h2 id="1-1-遗传算法的科学定义"><a href="#1-1-遗传算法的科学定义" class="headerlink" title="1.1 遗传算法的科学定义"></a>1.1 遗传算法的科学定义</h2><p>遗传算法（Genetic Algorithm, GA）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。</p>
<p>其主要特点是直接对结构对象进行操作，不存在求导和函数连续性的限定；具有内在的隐并行性和更好的全局寻优能力；采用概率化的寻优方法，不需要确定的规则就能自动获取和指导优化的搜索空间，自适应地调整搜索方向。</p>
<p>遗传算法以一种群体中的所有个体为对象，并利用随机化技术指导对一个被编码的参数空间进行高效搜索。其中，选择、交叉和变异构成了遗传算法的遗传操作；参数编码、初始群体的设定、适应度函数的设计、遗传操作设计、控制参数设定五个要素组成了遗传算法的核心内容。</p>
<h2 id="1-2-遗传算法的执行过程-参照百度百科"><a href="#1-2-遗传算法的执行过程-参照百度百科" class="headerlink" title="1.2 遗传算法的执行过程(参照百度百科)"></a>1.2 遗传算法的执行过程(参照百度百科)</h2><p>遗传算法是从代表问题可能潜在的解集的一个种群（population）开始的，而一个种群则由经过基因（gene）编码的一定数目的个体(individual)组成。每个个体实际上是染色体(chromosome)带有特征的实体。</p>
<p>染色体作为遗传物质的主要载体，即多个基因的集合，其内部表现（即基因型）是某种基因组合，它决定了个体的形状的外部表现，如黑头发的特征是由染色体中控制这一特征的某种基因组合决定的。因此，在一开始需要实现从表现型到基因型的映射即编码工作。由于仿照基因编码的工作很复杂，我们往往进行简化，如二进制编码。</p>
<p>初代种群产生之后，按照适者生存和优胜劣汰的原理，逐代（generation）演化产生出越来越好的近似解，在每一代，根据问题域中个体的适应度（fitness）大小选择（selection）个体，并借助于自然遗传学的遗传算子（genetic operators）进行组合交叉（crossover）和变异（mutation），产生出代表新的解集的种群。</p>
<p>这个过程将导致种群像自然进化一样的后生代种群比前代更加适应于环境，末代种群中的最优个体经过解码（decoding），可以作为问题近似最优解。</p>
<h2 id="1-3-遗传算法过程图解"><a href="#1-3-遗传算法过程图解" class="headerlink" title="1.3 遗传算法过程图解"></a>1.3 遗传算法过程图解</h2><p><img src="/../images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95-Genetic-Algorithm-%E8%A7%A3%E6%9E%90/10386940-f6a0d1d8226405fa.jpg" alt="img"></p>
<p>image</p>
<h1 id="02-相关生物学术语"><a href="#02-相关生物学术语" class="headerlink" title="02 相关生物学术语"></a>02 相关生物学术语</h1><p>为了大家更好了解遗传算法，在此之前先简单介绍一下相关生物学术语，大家了解一下即可。</p>
<ul>
<li>基因型(genotype)：性状染色体的内部表现；</li>
<li>表现型(phenotype)：染色体决定的性状的外部表现，或者说，根据基因型形成的个体的外部表现；</li>
<li>进化(evolution)：种群逐渐适应生存环境，品质不断得到改良。生物的进化是以种群的形式进行的。</li>
<li>适应度(fitness)：度量某个物种对于生存环境的适应程度。</li>
<li>选择(selection)：以一定的概率从种群中选择若干个个体。一般，选择过程是一种基于适应度的优胜劣汰的过程。</li>
<li>复制(reproduction)：细胞分裂时，遗传物质DNA通过复制而转移到新产生的细胞中，新细胞就继承了旧细胞的基因。</li>
<li>交叉(crossover)：两个染色体的某一相同位置处DNA被切断，前后两串分别交叉组合形成两个新的染色体。也称基因重组或杂交；</li>
<li>变异(mutation)：复制时可能（很小的概率）产生某些复制差错，变异产生新的染色体，表现出新的性状。</li>
<li>编码(coding)：DNA中遗传信息在一个长链上按一定的模式排列。遗传编码可看作从表现型到基因型的映射。</li>
<li>解码(decoding)：基因型到表现型的映射。</li>
<li>个体（individual）：指染色体带有特征的实体；</li>
<li>种群（population）：个体的集合，该集合内个体数称为种群</li>
</ul>
<h1 id="03-问题引出与解决"><a href="#03-问题引出与解决" class="headerlink" title="03 问题引出与解决"></a>03 问题引出与解决</h1><h2 id="3-1-一元函数最大值问题"><a href="#3-1-一元函数最大值问题" class="headerlink" title="3.1 一元函数最大值问题"></a>3.1 一元函数最大值问题</h2><p>如下的函数图像：</p>
<p><img src="/../images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95-Genetic-Algorithm-%E8%A7%A3%E6%9E%90/10386940-8f50b192fccef92e.jpg" alt="img"></p>
<p>image</p>
<blockquote>
<p>现在我们要在既定的区间内找出函数的最大值。</p>
</blockquote>
<p>学过高中数学的孩纸都知道，上面的函数存在着很多的极大值和极小值。而最大值则是指定区间的极大值中的最大的那一个。从图像上具体表现为，极大值像是一座座山峰，极小值则是像一座座山谷。因此，我们也可以把遗传算法的过程看作是一个在多元函数里面求最优解的过程。</p>
<p>这些山峰对应着局部最优解，其中有一个山峰是海拔最高的，这个山峰则对应的是全局最优解。那么，遗传算法要做的就是尽量爬到最高峰，而不是困在较低的小山峰上。（如果问题求解是最小值，那么要做的就是尽量走到最低谷，道理是一样的）。</p>
<p><img src="/../images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95-Genetic-Algorithm-%E8%A7%A3%E6%9E%90/10386940-517221056cd4af43.jpg" alt="img"></p>
<h2 id="3-2-“袋鼠蹦跳”"><a href="#3-2-“袋鼠蹦跳”" class="headerlink" title="3.2 “袋鼠蹦跳”"></a>3.2 “袋鼠蹦跳”</h2><p>既然我们把函数曲线理解成一个一个山峰和山谷组成的山脉。那么我们可以设想所得到的每一个解就是一只袋鼠，我们希望它们不断的向着更高处跳去，直到跳到最高的山峰。<strong>所以求最大值的过程就转化成一个“袋鼠跳”的过程。</strong></p>
<p>下面介绍介绍“袋鼠跳”的几种方式。</p>
<ul>
<li>爬山算法：一只袋鼠朝着比现在高的地方跳去。它找到了不远处的最高的山峰。但是这座山不一定是最高峰。这就是爬山算法，它不能保证局部最优值就是全局最优值。</li>
<li>模拟退火：袋鼠喝醉了。它随机地跳了很长时间。这期间，它可能走向高处，也可能踏入平地。但是，它渐渐清醒了并朝最高峰跳去。这就是模拟退火算法。</li>
<li>遗传算法：有很多袋鼠，它们降落到喜玛拉雅山脉的任意地方。这些袋鼠并不知道它们的任务是寻找珠穆朗玛峰。但每过几年，就在一些海拔高度较低的地方射杀一些袋鼠。于是，不断有袋鼠死于海拔较低的地方，而越是在海拔高的袋鼠越是能活得更久，也越有机会生儿育女。就这样经过许多年，这些袋鼠们竟然都不自觉地聚拢到了一个个的山峰上，可是在所有的袋鼠中，只有聚拢到珠穆朗玛峰的袋鼠被带回了美丽的澳洲。</li>
</ul>
<h1 id="04-大体实现过程"><a href="#04-大体实现过程" class="headerlink" title="04 大体实现过程"></a>04 大体实现过程</h1><p>遗传算法中每一条染色体，对应着遗传算法的一个解决方案，一般我们用适应性函数（fitness function）来衡量这个解决方案的优劣。所以从一个基因组到其解的适应度形成一个映射。<strong>遗传算法的实现过程实际上就像自然界的进化过程那样。</strong></p>
<p>下面我们用袋鼠跳中的步骤一一对应解释，以方便大家理解：</p>
<ol>
<li>首先寻找一种对问题潜在解进行“数字化”编码的方案。（建立表现型和基因型的映射关系）</li>
<li>随机初始化一个种群（那么第一批袋鼠就被随意地分散在山脉上），种群里面的个体就是这些数字化的编码。</li>
<li>接下来，通过适当的解码过程之后（得到袋鼠的位置坐标）。</li>
<li>用适应性函数对每一个基因个体作一次适应度评估（袋鼠爬得越高当然就越好，所以适应度相应越高）。</li>
<li>用选择函数按照某种规定择优选择（每隔一段时间，射杀一些所在海拔较低的袋鼠，以保证袋鼠总体数目持平。）。</li>
<li>让个体基因变异（让袋鼠随机地跳一跳）。</li>
<li>然后产生子代（希望存活下来的袋鼠是多产的，并在那里生儿育女）。</li>
</ol>
<p><strong>遗传算法并不保证你能获得问题的最优解，但是使用遗传算法的最大优点在于你不必去了解和操心如何去“找”最优解。（你不必去指导袋鼠向那边跳，跳多远。）而只要简单的“否定”一些表现不好的个体就行了。（把那些总是爱走下坡路的袋鼠射杀，这就是遗传算法的精粹！）</strong></p>
<p>由此我们可以得出遗传算法的一般步骤：</p>
<ol>
<li>随机产生种群。</li>
<li>根据策略判断个体的适应度，是否符合优化准则，若符合，输出最佳个体及其最优解，结束。否则，进行下一步。</li>
<li>依据适应度选择父母，适应度高的个体被选中的概率高，适应度低的个体被淘汰。</li>
<li>用父母的染色体按照一定的方法进行交叉，生成子代。</li>
<li>对子代染色体进行变异。</li>
</ol>
<p><strong>由交叉和变异产生新一代种群，返回步骤2，直到最优解产生。</strong></p>
<p>具体图解可以回到1.3查看。</p>
<h1 id="05-开始我们的进化-具体实现细节"><a href="#05-开始我们的进化-具体实现细节" class="headerlink" title="05 开始我们的进化(具体实现细节)"></a>05 开始我们的进化(具体实现细节)</h1><h2 id="5-1-先从编码说起"><a href="#5-1-先从编码说起" class="headerlink" title="5.1 先从编码说起"></a>5.1 先从编码说起</h2><p>编码是应用遗传算法时要解决的首要问题，也是设计遗传算法时的一个关键步骤。编码方法影响到交叉算子、变异算子等遗传算子的运算方法，大很大程度上决定了遗传进化的效率。</p>
<p>迄今为止人们已经提出了许多种不同的编码方法。总的来说，这些编码方法可以分为三大类：二进制编码法、浮点编码法、符号编码法。下面分别进行介绍：</p>
<h3 id="5-1-1-二进制编码法"><a href="#5-1-1-二进制编码法" class="headerlink" title="5.1.1 二进制编码法"></a>5.1.1 二进制编码法</h3><p>就像人类的基因有AGCT 4种碱基序列一样。不过在这里我们只用了0和1两种碱基,然后将他们串成一条链形成染色体。一个位能表示出2种状态的信息量，因此足够长的二进制染色体便能表示所有的特征。这便是二进制编码。如下：<br>1110001010111</p>
<p>它由二进制符号0和1所组成的二值符号集。它有以下一些优点：</p>
<ol>
<li>编码、解码操作简单易行</li>
<li>交叉、变异等遗传操作便于实现</li>
<li>合最小字符集编码原则</li>
<li>利用模式定理对算法进行理论分析。</li>
</ol>
<p>二进制编码的缺点是：对于一些连续函数的优化问题，由于其随机性使得其局部搜索能力较差，如对于一些高精度的问题（如上题），当解迫近于最优解后，由于其变异后表现型变化很大，不连续，所以会远离最优解，达不到稳定。</p>
<h3 id="5-1-２-浮点编码法"><a href="#5-1-２-浮点编码法" class="headerlink" title="5.1.２ 浮点编码法"></a>5.1.２ 浮点编码法</h3><p>二进制编码虽然简单直观，但明显地。但是存在着连续函数离散化时的映射误差。个体长度较短时，可能达不到精度要求，而个体编码长度较长时，虽然能提高精度，但增加了解码的难度，使遗传算法的搜索空间急剧扩大。</p>
<p>所谓浮点法，是指个体的每个基因值用某一范围内的一个浮点数来表示。在浮点数编码方法中，必须保证基因值在给定的区间限制范围内，遗传算法中所使用的交叉、变异等遗传算子也必须保证其运算结果所产生的新个体的基因值也在这个区间限制范围内。如下所示：</p>
<p>1.2-3.2-5.3-7.2-1.4-9.7</p>
<p>浮点数编码方法有下面几个优点：</p>
<ol>
<li>适用于在遗传算法中表示范围较大的数</li>
<li>适用于精度要求较高的遗传算法</li>
<li>便于较大空间的遗传搜索</li>
<li>改善了遗传算法的计算复杂性，提高了运算交率</li>
<li>便于遗传算法与经典优化方法的混合使用</li>
<li>便于设计针对问题的专门知识的知识型遗传算子</li>
<li>便于处理复杂的决策变量约束条件</li>
</ol>
<h3 id="5-1-3-符号编码法"><a href="#5-1-3-符号编码法" class="headerlink" title="5.1.3 符号编码法"></a>5.1.3 符号编码法</h3><p>符号编码法是指个体染色体编码串中的基因值取自一个无数值含义、而只有代码含义的符号集如｛A,B,C…｝。<br>符号编码的主要优点是：</p>
<ol>
<li>符合有意义积术块编码原则</li>
<li>便于在遗传算法中利用所求解问题的专门知识</li>
<li>便于遗传算法与相关近似算法之间的混合使用。</li>
</ol>
<h2 id="5-2-为我们的袋鼠染色体编码"><a href="#5-2-为我们的袋鼠染色体编码" class="headerlink" title="5.2 为我们的袋鼠染色体编码"></a>5.2 为我们的袋鼠染色体编码</h2><p>在上面介绍了一系列编码方式以后，那么，如何利用上面的编码来为我们的袋鼠染色体编码呢？首先我们要明确一点：编码无非就是建立从基因型到表现型的映射关系。这里的表现型可以理解为个体特征（比如身高、体重、毛色等等）。那么，在此问题下，我们关心的个体特征就是：袋鼠的位置坐标（因为我们要把海拔低的袋鼠给杀掉）。无论袋鼠长什么样，爱吃什么。我们关心的始终是袋鼠在哪里，并且只要知道了袋鼠的位置坐标（位置坐标就是相应的染色体编码，可以通过解码得出），我们就可以：</p>
<ol>
<li>在喜马拉雅山脉的地图上找到相应的位置坐标，算出海拔高度。（相当于通过自变量求得适应函数的值）然后判读该不该射杀该袋鼠。</li>
<li>可以知道染色体交叉和变异后袋鼠新的位置坐标。</li>
</ol>
<p>回到3.1中提的求一元函数最大值的问题。在上面我们把极大值比喻为山峰，那么，袋鼠的位置坐标可以比喻为区间[-1, 2]的某一个x坐标（有了x坐标，再通过函数表达式可以算出函数值 &lt;==&gt; 得到了袋鼠染色体编码，解码得到位置坐标，在喜马拉雅山脉地图查询位置坐标算出海拔高度）。这个x坐标是一个实数，现在，说白了就是怎么对这个x坐标进行编码。下面我们以二进制编码为例讲解，不过这种情况下以二进制编码比较复杂就是了。（如果以浮点数编码，其实就很简洁了，就一浮点数而已。）</p>
<p>我们说过，一定长度的二进制编码序列，只能表示一定精度的浮点数。在这里假如我们要求解精确到六位小数，由于区间长度为2 - (-1) = 3 ,为了保证精度要求，至少把区间[-1,2]分为3 × 10^6等份。又因为</p>
<blockquote>
<p>2^21 = 2097152 &lt; 3*10^6 &lt; 2^22 = 4194304</p>
</blockquote>
<p>所以编码的二进制串至少需要22位。</p>
<p><strong>把一个二进制串(b0,b1,….bn)转化为区间里面对应的实数值可以通过下面两个步骤：</strong></p>
<ol>
<li><p>将一个二进制串代表的二进制数转化为10进制数：</p>
<p><img src="/../images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95-Genetic-Algorithm-%E8%A7%A3%E6%9E%90/10386940-bdafc578b24fa1c6.jpg" alt="img"></p>
<p>image</p>
</li>
<li><p>对应区间内的实数：</p>
<p><img src="/../images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95-Genetic-Algorithm-%E8%A7%A3%E6%9E%90/10386940-1f0dda5c0fab787b.jpg" alt="img"></p>
<p>image</p>
</li>
</ol>
<p>例如一个二进制串(1000101110110101000111)2通过上面换算以后，表示实数值0.637197。</p>
<p>好了，上面的编码方式只是举个例子让大家更好理解而已，编码的方式千奇百怪，层出不穷，每个问题可能采用的编码方式都不一样。在这一点上大家要注意。</p>
<h2 id="5-3-评价个体的适应度–适应度函数（fitness-function）"><a href="#5-3-评价个体的适应度–适应度函数（fitness-function）" class="headerlink" title="5.3 评价个体的适应度–适应度函数（fitness function）"></a>5.3 评价个体的适应度–适应度函数（fitness function）</h2><p>前面说了，适应度函数主要是通过个体特征从而判断个体的适应度。在本例的袋鼠跳中，我们只关心袋鼠的海拔高度，以此来判断是否该射杀该袋鼠。这样一来，该函数就非常简单了。只要输入袋鼠的位置坐标，在通过相应查找运算，返回袋鼠当前位置的海拔高度就行。</p>
<p>适应度函数也称评价函数，是根据目标函数确定的用于区分群体中个体好坏的标准。适应度函数总是非负的，而目标函数可能有正有负，故需要在目标函数与适应度函数之间进行变换。</p>
<p>评价个体适应度的一般过程为：</p>
<ol>
<li>对个体编码串进行解码处理后，可得到个体的表现型。</li>
<li>由个体的表现型可计算出对应个体的目标函数值。</li>
<li>根据最优化问题的类型，由目标函数值按一定的转换规则求出个体的适应度。</li>
</ol>
<h2 id="5-4-射杀一些袋鼠–选择函数（selection）"><a href="#5-4-射杀一些袋鼠–选择函数（selection）" class="headerlink" title="5.4 射杀一些袋鼠–选择函数（selection）"></a>5.4 射杀一些袋鼠–选择函数（selection）</h2><p>遗传算法中的选择操作就是用来确定如何从父代群体中按某种方法选取那些个体，以便遗传到下一代群体。选择操作用来确定重组或交叉个体，以及被选个体将产生多少个子代个体。前面说了，我们希望海拔高的袋鼠存活下来，并尽可能繁衍更多的后代。但我们都知道，在自然界中，适应度高的袋鼠越能繁衍后代，但这也是从概率上说的而已。毕竟有些适应度低的袋鼠也可能逃过我们的眼睛。</p>
<p>那么，怎么建立这种概率关系呢？</p>
<p><strong>下面介绍几种常用的选择算子：</strong></p>
<ol>
<li><p>轮盘赌选择（Roulette Wheel Selection）：是一种回放式随机采样方法。每个个体进入下一代的概率等于它的适应度值与整个种群中个体适应度值和的比例。选择误差较大。</p>
</li>
<li><p>随机竞争选择（Stochastic Tournament）：每次按轮盘赌选择一对个体，然后让这两个个体进行竞争，适应度高的被选中，如此反复，直到选满为止。</p>
</li>
<li><p>最佳保留选择：首先按轮盘赌选择方法执行遗传算法的选择操作，然后将当前群体中适应度最高的个体结构完整地复制到下一代群体中。</p>
</li>
<li><p>无回放随机选择（也叫期望值选择Excepted Value Selection）：根据每个个体在下一代群体中的生存期望来进行随机选择运算。方法如下:</p>
<p>（1） 计算群体中每个个体在下一代群体中的生存期望数目N。</p>
<p>（2） 若某一个体被选中参与交叉运算，则它在下一代中的生存期望数目减去0.5，若某一个体未  被选中参与交叉运算，则它在下一代中的生存期望数目减去1.0。</p>
<p>（3） 随着选择过程的进行，若某一个体的生存期望数目小于0时，则该个体就不再有机会被选中。</p>
</li>
<li><p>确定式选择：按照一种确定的方式来进行选择操作。具体操作过程如下：</p>
<p>（1） 计算群体中各个个体在下一代群体中的期望生存数目N。</p>
<p>（2） 用N的整数部分确定各个对应个体在下一代群体中的生存数目。</p>
<p>（3） 用N的小数部分对个体进行降序排列，顺序取前M个个体加入到下一代群体中。至此可完全确定出下一代群体中Ｍ个个体。</p>
</li>
<li><p>无回放余数随机选择：可确保适应度比平均适应度大的一些个体能够被遗传到下一代群体中，因而选择误差比较小。</p>
</li>
<li><p>均匀排序：对群体中的所有个体按期适应度大小进行排序，基于这个排序来分配各个个体被选中的概率。</p>
</li>
<li><p>最佳保存策略：当前群体中适应度最高的个体不参与交叉运算和变异运算，而是用它来代替掉本代群体中经过交叉、变异等操作后所产生的适应度最低的个体。</p>
</li>
<li><p>随机联赛选择：每次选取几个个体中适应度最高的一个个体遗传到下一代群体中。</p>
</li>
<li><p>排挤选择：新生成的子代将代替或排挤相似的旧父代个体，提高群体的多样性。</p>
</li>
</ol>
<p>下面以轮盘赌选择为例给大家讲解一下：</p>
<p>假如有５条染色体，他们的适应度分别为５、８、３、７、２。</p>
<p>那么总的适应度为：F = 5 + 8 + 3 + 7 + 2 = 25。</p>
<p>那么各个个体的被选中的概率为：</p>
<p>α1 = ( 5 / 25 ) * 100% = 20%</p>
<p>α2 = ( 8 / 25 ) * 100% = 32%</p>
<p>α3 = ( 3 / 25 ) * 100% = 12%</p>
<p>α4 = ( 7 / 25 ) * 100% = 28%</p>
<p>α5 = ( 2 / 25 ) * 100% = 8%</p>
<p>所以转盘如下：</p>
<p><img src="/../images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95-Genetic-Algorithm-%E8%A7%A3%E6%9E%90/10386940-bf5ce56a414e10db.jpg" alt="img"></p>
<p>image</p>
<p>当指针在这个转盘上转动，停止下来时指向的个体就是天选之人啦。可以看出，适应性越高的个体被选中的概率就越大。</p>
<h2 id="5-５-遗传–染色体交叉-crossover"><a href="#5-５-遗传–染色体交叉-crossover" class="headerlink" title="5.５ 遗传–染色体交叉(crossover)"></a>5.５ 遗传–染色体交叉(crossover)</h2><p>遗传算法的交叉操作，是指对两个相互配对的染色体按某种方式相互交换其部分基因，从而形成两个新的个体。</p>
<p>适用于二进制编码个体或浮点数编码个体的交叉算子：</p>
<ol>
<li><p>单点交叉（One-point Crossover）：指在个体编码串中只随机设置一个交叉点，然后再该点相互交换两个配对个体的部分染色体。</p>
</li>
<li><p>两点交叉与多点交叉：</p>
<p>(1) 两点交叉（Two-point Crossover）：在个体编码串中随机设置了两个交叉点，然后再进行部分基因交换。</p>
<p>(2) 多点交叉（Multi-point Crossover）</p>
</li>
<li><p>均匀交叉（也称一致交叉，Uniform Crossover）：两个配对个体的每个基因座上的基因都以相同的交叉概率进行交换，从而形成两个新个体。</p>
</li>
<li><p>算术交叉（Arithmetic Crossover）：由两个个体的线性组合而产生出两个新的个体。该操作对象一般是由浮点数编码表示的个体。</p>
</li>
</ol>
<p>咳咳，根据国际惯例。还是抓一个最简单的二进制单点交叉为例来给大家讲解讲解。</p>
<p>二进制编码的染色体交叉过程非常类似高中生物中所讲的同源染色体的联会过程――随机把其中几个位于同一位置的编码进行交换，产生新的个体。</p>
<p><img src="/../images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95-Genetic-Algorithm-%E8%A7%A3%E6%9E%90/10386940-38df5ee1440b2fbc.jpg" alt="img"></p>
<p>image</p>
<p>对应的二进制交叉：</p>
<p><img src="/../images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95-Genetic-Algorithm-%E8%A7%A3%E6%9E%90/10386940-dba7fdf2300f0e55.jpg" alt="img"></p>
<p>image</p>
<h2 id="5-6-变异–基因突变-Mutation"><a href="#5-6-变异–基因突变-Mutation" class="headerlink" title="5.6 变异–基因突变(Mutation)"></a>5.6 变异–基因突变(Mutation)</h2><p>遗传算法中的变异运算，是指将个体染色体编码串中的某些基因座上的基因值用该基因座上的其它等位基因来替换，从而形成新的个体。</p>
<p>例如下面这串二进制编码：</p>
<p>101101001011001</p>
<p>经过基因突变后，可能变成以下这串新的编码：</p>
<p><strong>0</strong>011010<strong>1</strong>1011001</p>
<p>以下变异算子适用于二进制编码和浮点数编码的个体：</p>
<ol>
<li>基本位变异（Simple Mutation）：对个体编码串中以变异概率、随机指定的某一位或某几位仅因座上的值做变异运算。</li>
<li>均匀变异（Uniform Mutation）：分别用符合某一范围内均匀分布的随机数，以某一较小的概率来替换个体编码串中各个基因座上的原有基因值。（特别适用于在算法的初级运行阶段）</li>
<li>边界变异（Boundary Mutation）：随机的取基因座上的两个对应边界基因值之一去替代原有基因值。特别适用于最优点位于或接近于可行解的边界时的一类问题。</li>
<li>非均匀变异：对原有的基因值做一随机扰动，以扰动后的结果作为变异后的新基因值。对每个基因座都以相同的概率进行变异运算之后，相当于整个解向量在解空间中作了一次轻微的变动。</li>
<li>高斯近似变异：进行变异操作时用符号均值为Ｐ的平均值，方差为P**2的正态分布的一个随机数来替换原有的基因值。</li>
</ol>
<h1 id="06-代码实现环节"><a href="#06-代码实现环节" class="headerlink" title="06 代码实现环节"></a>06 代码实现环节</h1><p>好了，上面我们介绍了一大截具体原理。现在就是把各个具体的零部件组装起来，动手写我们的代码了。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>-算法</tag>
      </tags>
  </entry>
  <entry>
    <title>一条短信直接崩溃iPhone，几乎所有iOS设备躺枪</title>
    <url>/post/3420606c.html</url>
    <content><![CDATA[<p>iPhone 又出 Bug 了！国外有网友发现，只要给用 iPhone 的好友发送一段含有特殊字符的短信或者是 iMessage 消息，就会让对方的 iPhone 崩溃重启，这条信息最先出现在 Reddit 网站。这段字符信息包含了英文、阿拉伯文、中文和特殊符号：</p>
<p><img src="/" alt="messagescrashingbug.jpg"></p>
<blockquote>
<p>Power<br>لُلُصّبُلُلصّبُررً ॣ ॣh ॣ ॣ<br>冗</p>
</blockquote>
<p>如果用户接收到这条短信，就会导致短信程序崩溃，手机重启。如果以短信应用的消息列表打开收到的短信，则会发生再次崩溃，如果进入了这条包含特殊字符的消息列表，这个对话窗口并不会崩溃，但如果再跳转到其他对话，消息应用又会崩溃，进入一个死循环。</p>
<p>这个 BUG 目前影响苹果运行 iOS 8.3 的设备，包括 iPhone 和 iPad，也包括其他版本的 iOS 系统。如果 iPhone 处于安全模式下，则攻击不会生效，如果 iPhone 已经越狱，则越狱的 iPhone 会转入到安全模式。</p>
<p>这可能是 iOS 通知中心预览功能处理 Unicode 字符时存在的一个 BUG，通知中心会在推送时会直接打开预览功能，所以会导致整个系统崩溃。</p>
<p>如果收到这种短信，解决的办法有以下几种，例如能够在短信应用打开这条短信，可以回复对方一条短信来解决崩溃（例如再发送一条同样的短信进行报复 XD），如果是在消息列表中收到这种短信，可以尝试使用其他方法例如语音控制或者是社交软件分享一条消息给自己来解决崩溃。</p>
<p>目前苹果已经知道了这个问题，正在进行修复，会不会提前发布小更新或者让 iOS 8.4 提前发布暂时还未清楚。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-其他</tag>
      </tags>
  </entry>
  <entry>
    <title>【解决方案】WordPress无法建立到WordPress。org的安全连接</title>
    <url>/post/17062.html</url>
    <content><![CDATA[<p>服务器一直使用03系统，为了更好的满足需求决定升级系统，然而升级的路程的坎坷的，各种问题不曾间断，经过一夜努力终于在第二天的天明前完成了系统的各项配置。</p>
<p>自以为风雨过后能见彩虹了，没想到这才是开始…</p>
<p>安装好wordpress后发现许多需要跟wordpress.org进行连接的页面都无法打开了。</p>
<p>期初以为是因为程序卡导致链接超时无法打开，于是就想到WordPress 的主题还有它的后台都会用到 Google 字体，在国内访问 Google 会遇到问题，这就是打开 WordPress 网站慢的主要原因。</p>
<p>解决的办法是去安装一个叫 useso-take-over-google 的插件，它会用国内的 useso 替换 google，但是安装好后之前的问题仍然存在。</p>
<p>于是又想到 WordPress 默认为用户使用的是 Gravatar 头像，我们访问这个网站也会遇到问题，虽然已经有现成的解决方案但仍然不太理想。</p>
<p>解决办法：我们可以先禁用掉用户的头像功能，打开 <em>设置 – 讨论 – 头像显示</em>，去掉勾选显示头像，保存更改。</p>
<p>OK 现在应该不会卡慢了，但是问题依旧，没办法自己的能力有限只能搜搜往上看有没有人遇到同样的问题。</p>
<p>结果搜到了很多同样的问题，但是都没有得到解决，只有个别说到是因为空间商屏蔽了wordpress服务器IP，还有个别说要修改DNS为谷歌的DNS。</p>
<p>但在尝试过后发现都不可用，于是我的脑细胞又开始了疯狂的自杀…</p>
<p>想到曾经谷歌翻译不能用的时候会在host文件里添加记录就可以使用谷歌翻译了，于是开始尝试向host文件添加记录，首先ping一下api.wordpress.org的服务器IP得到66.155.40.249 打开host文件添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">66.155.40.249 api.wordpress.org</span><br></pre></td></tr></table></figure>
<p>保存，刷新后台，完美！！</p>
<p>win系统下host文件路径：c:\windows\system32\drivers\etc</p>
<p>linux系统的host文件路径？</p>
<p>施主请百度去吧，贫僧没搞过啊！！！</p>
]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么交叉熵能作为损失函数及其弥补了平方差损失什么缺陷</title>
    <url>/post/7c5ef9ec.html</url>
    <content><![CDATA[<p>在很多二分类问题中，特别是正负样本不均衡的分类问题中，常使用交叉熵作为loss对模型的参数求梯度进行更新，那为何交叉熵能作为损失函数呢，我也是带着这个问题去找解析的。</p>
<p>以下仅为个人理解，如有不当地方，请读到的看客能指出。</p>
<p>我们都知道，各种机器学习模型都是模拟输入的分布，使得模型输出的分布尽量与训练数据一致，最直观的就是MSE（均方误差，Mean squared deviation), 直接就是输出与输入的差值平方，尽量保证输入与输出相同。这种loss我们都能理解。</p>
<p>以下按照（1）熵的定义（2）交叉熵的定义 (3) 交叉熵的由来 （4）交叉熵作为loss的优势 作为主线来一步步理清思路。</p>
<p>（1）熵的定义 各种熵的名称均来自信息论领域，这方面的背景就不介绍了，随便就能找到很多。</p>
<p>根据维基的定义，熵的定义如下：熵是接收的每条消息中包含的信息的平均量，又被称为信息熵、信源熵、平均自信息量。直白地解释就是信息中含的信息量的大小，其定义如下：</p>
<p><img src="/../images/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%A4%E5%8F%89%E7%86%B5%E8%83%BD%E4%BD%9C%E4%B8%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BC%A5%E8%A1%A5%E4%BA%86%E5%B9%B3%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7/20170827110906555" alt="img"></p>
<p>其曲线如下所示：</p>
<p><img src="/../images/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%A4%E5%8F%89%E7%86%B5%E8%83%BD%E4%BD%9C%E4%B8%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BC%A5%E8%A1%A5%E4%BA%86%E5%B9%B3%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7/20170827111213829" alt="img"></p>
<p>可以看出，一个事件的发生的概率离0.5越近，其熵就越大，概率为0或1就是确定性事件，不能为我们带信息量。也可以看作是一件事我们越难猜测是否会发生，它的信息熵就越大</p>
<p>（2）交叉熵的定义 交叉熵的公式定义如下：</p>
<p><img src="/../images/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%A4%E5%8F%89%E7%86%B5%E8%83%BD%E4%BD%9C%E4%B8%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BC%A5%E8%A1%A5%E4%BA%86%E5%B9%B3%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7/20170827112109611" alt="img"></p>
<p>其中p(x)在机器学习中为样本label，q(x)为模型的预估，分别代表训练样本和模型的分布，如果只是根据这个公式，是看不出来什么的，暂且放下，继续往下看</p>
<p>（3）交叉熵的由来 将上面的交叉熵的公式减去一个固定的值（H(p), 训练样本的熵，训练样本定，该值即为固定值），即训练样本分布p(x)的熵，可得如下：</p>
<p><img src="/../images/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%A4%E5%8F%89%E7%86%B5%E8%83%BD%E4%BD%9C%E4%B8%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BC%A5%E8%A1%A5%E4%BA%86%E5%B9%B3%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7/20170827181853299" alt="img"></p>
<p>最后得到的为相对熵或KL散度(Kullback-Leibler divergence), 亦可称为KL距离，是用于评判两个分布的差异程序，看到这里，应该明白为何交叉熵为何能作为loss了。即可以使得模型输出的分布尽量与训练样本的分布一致</p>
<p>（4）交叉熵作为loss的优势 模型训练的loss有很多，交叉熵作为loss有很多应用场景，其最大的好处我认为是可以避免梯度消散，因为一般我们使用平方差作为损失函数，（<img src="/../images/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%A4%E5%8F%89%E7%86%B5%E8%83%BD%E4%BD%9C%E4%B8%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BC%A5%E8%A1%A5%E4%BA%86%E5%B9%B3%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7/gif.latex" alt="\hat{y}">-y）^2作为损失函数，这种损失函数在进行梯度下降计算的时候会出现梯度弥散，导致学习速率下降，使用交叉熵作为损失函数可以很好的解决这个问题。</p>
<p>那我们再讨论一下，平方差为什么会梯度弥散，而交叉熵不会：</p>
<p><img src="/../images/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%A4%E5%8F%89%E7%86%B5%E8%83%BD%E4%BD%9C%E4%B8%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BC%A5%E8%A1%A5%E4%BA%86%E5%B9%B3%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7/20180924084311715" alt="img"></p>
<p>因为y求导为y(y-1)所以趋近于0或1时上述倒数趋近于零，梯度弥散。</p>
<p><img src="/../images/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BA%A4%E5%8F%89%E7%86%B5%E8%83%BD%E4%BD%9C%E4%B8%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BC%A5%E8%A1%A5%E4%BA%86%E5%B9%B3%E6%96%B9%E5%B7%AE%E6%8D%9F%E5%A4%B1%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7/20180924084812961" alt="img"></p>
<p>与sigmoid导数无关，从而避免了梯度弥散。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>不拆机仅用SD卡为Thinkpad E450 E460作磁盘永久缓存加速</title>
    <url>/post/c234aa14.html</url>
    <content><![CDATA[<p>**Thinkpad E450 E460 的特点：<br>**一般标配机械硬盘，没有多余的光驱和内置硬盘接口。<br>ngff M.2接口被阉割，截至目前，有人尝试自行焊接M.2插槽，失败。可能是BIOS里面的问题，而不是仅仅焊接一个插槽这么简单。个人猜测，未经验证。</p>
<p><strong>Windows Superfetch：</strong><br>将你经常运行的程序、经常读写的文件建立一个磁盘缓存，在系统预测的时刻读进内存。并且，将用户使用过程中的文件在内存复制一份，下次读写，只要文件内容没改，直接在内存中读取。<br>缺点：开机后才有效，不能加速启动过程。</p>
<p><strong>Windows ReadyBoost：</strong><br>利用闪存盘的随机读写远大于机械硬盘特点，将superfetch的文件放置在优盘等闪存上，实现硬盘读写的加速。<br>注意ReadyBoost不是扩展内存。<br>缺点：<br>ReadyBoost每次关机都会清除缓存文件，每次开机再次从C盘将缓存文件读出来在闪存中重建。</p>
<p><strong>联想ExpressCache：</strong><br>本来是用在固态硬盘为机械硬盘作高速缓存的机型上。它是将磁盘经常都写的文件在缓存盘（原装SSD）作永久缓存，开关机不会消失。<br>在启动过程中，只要ExpressCache的驱动载入后，即可享受缓存加速的效果，此时系统还未完全启动完毕，用户还未登录。所以，加速启动是有效果的。</p>
<p><strong>使用SD卡做为ExpressCache的载体：</strong> Thinkpad E450 E460既然不能加装SSD，作为高速缓存或者RAID。那么结合Readyboost闪存读写快读和Express永久缓存的优点，绕过了readyboost关机后缓存消失的缺点，提出使用SD卡做为ExpressCache的载体方案。</p>
<p><strong>购买一个SD卡：</strong><br>我用的是Sandisk 8GB Class10<br>插入内置读卡器，在左手掌托下。不要用外置读卡器。</p>
<p><strong>软件下载：</strong><br>ExpressCache Software for Windows 10 (64bit) - Laptop, ThinkCentre联想官方下载：<br><a href="http://support.lenovo.com/us/en/downloads/ds104444">http://support.lenovo.com/us/en/downloads/ds104444</a><br>正常安装。重启。</p>
<p><strong>准备磁盘：</strong></p>
<ol>
<li>Microsoft Windows [Version 10.0.10586]</li>
<li>(c) 2015 Microsoft Corporation. All rights reserved.</li>
<li>C:\Windows\system32&gt;diskpart</li>
<li>Microsoft DiskPart version 10.0.10586</li>
<li>Copyright (C) 1999-2013 Microsoft Corporation.</li>
<li>On computer: ***</li>
<li>DISKPART&gt; list disk</li>
<li> Disk ### Status      Size   Free   Dyn Gpt</li>
<li><hr>
</li>
<li> Disk 0  Online      465 GB 6144 KB     *</li>
<li> Disk 1  Online     7580 M    0 B</li>
<li>DISKPART&gt; select disk 1</li>
<li>Disk 1 is now the selected disk.</li>
<li>DISKPART&gt; list partition</li>
<li> Partition ### Type         Size   Offset</li>
<li><hr>
</li>
<li> Partition 1  Primary     7578 M 1024 KB</li>
<li>DISKPART&gt; select partition 1</li>
<li>Partition 1 is now the selected partition.</li>
<li>DISKPART&gt;</li>
</ol>
<p><em>复制代码</em></p>
<p>记住7578 MB这个数字，下一步会用到。这是你的SD卡磁盘分区格式化最大可用空间，不是7580 MB那个数字。</p>
<p>windows10 系统下，管理员权限运行命令提示符，Win+X，A。<br>eccmd命令查看用法</p>
<ol>
<li>eccmd /?</li>
</ol>
<p><em>复制代码</em></p>
<p>作者默认读者机器上没有其它硬盘优盘，只有内置硬盘和一个SD卡。</p>
<ol>
<li>eccmd -partition 1 7578</li>
<li>eccmd -format</li>
</ol>
<p><em>复制代码</em></p>
<p>格式化后用DiskGennius查看分区格式为73，是HFS么？求证。如果后期不小心把SD卡弹出了，或格式化为fat、ntfs，再插进去是没法用的，必须再次执行eccmd的分区与格式化。<br>此时使用以下命令可以查看SD卡里的缓存情况</p>
<ol>
<li>eccmd -info</li>
</ol>
<p><em>复制代码</em></p>
<p>刚建立，什么都没有，运行一段时间再次查看，Cache Read Percent  : x.xx% Cache Write Percent : x.xx%这两组数字应该变大。<br>多重启几次，这个数字应该更大，作者的情况是，缓存读取比例可大于80%。<br>完毕。</p>
<p><strong>讨论：</strong><br>SD卡毕竟不是SSD，加速效果有限，但仍然比内置机械硬盘快，在4K随机读写性能上。</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>交叉熵</title>
    <url>/post/ea101373.html</url>
    <content><![CDATA[<p>我们简单介绍了相对熵的概念，知道了相对熵可以用来表达真实事件和理论拟合出来的事件之间的差异。</p>
<p>相对熵的公式如下：<br>$$<br>D _ { K L } ( p | q ) = \sum _ { i = 1 } ^ { N }p \left( x _ { i } \right)\log p \left( x _ { i } \right)-\sum _ { i = 1 } ^ { N }p \left( x _ { i } \right)\log q \left( x _ { i } \right)<br>$$<br>可以看到前面一项是真实事件的信息熵取反，我们可以直接写成<br>$$<br>D _ { K L } ( p | q ) = -H(p)-\sum _ { i = 1 } ^ { N }p \left( x _ { i } \right)\log q \left( x _ { i } \right)<br>$$<br>在神经网络训练中，我们要训练的是<br>$$<br>q ( x _ { i })<br>$$<br>使得其与真实事件的分布越接近越好，也就是说在神经网络的训练中，相对熵会变的部分只有后面的部分，我们希望它越小越好，而前面的那部分是不变的。因此我们可以把后面的部分单独取出来，那部分就是交叉熵，写作：<br>$$<br>H(p，q) = -\sum _ { i = 1 } ^ { N }p \left( x _ { i } \right)\log q \left( x _ { i } \right)<br>$$<br>这就是我们经常在神经网络训练中看到的交叉熵损失函数。如果要了解它的内涵，要回头去看相对熵。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能神经网络四种算法</title>
    <url>/post/cbd530a7.html</url>
    <content><![CDATA[<p>人工神经网络的许多算法已在智能信息处理系统中获得广泛采用，尤为突出是是以下4种算法：ART网络、LVQ网络、Kohonen网络Hopfield网络，下面就具体介绍一下这这四种算法：</p>
<p><strong>1．自适应谐振理论（ART）网络</strong></p>
<p>自适应谐振理论（ART）网络具有不同的方案。一个ART-1网络含有两层一个输入层和一个输出层。这两层完全互连，该连接沿着正向（自底向上）和反馈（自顶向下）两个方向进行。</p>
<p>当ART-1网络在工作时，其训练是连续进行的，且包括下列算法步骤：</p>
<p>（1）对于所有输出神经元，如果一个输出神经元的全部警戒权值均置为1，则称为独立神经元，因为它不被指定表示任何模式类型。</p>
<p>（2）给出一个新的输入模式x。</p>
<p>（3）使所有的输出神经元能够参加激发竞争。</p>
<p>（4）从竞争神经元中找到获胜的输出神经元，即这个神经元的x·W值为最大；在开始训练时或不存在更好的输出神经元时，优胜神经元可能是个独立神经元。</p>
<p>（5）检查该输入模式x是否与获胜神经元的警戒矢量V足够相似。</p>
<p>（6）如果r≥p，即存在谐振，则转向步骤（7）；否则，使获胜神经元暂时无力进一步竞争，并转向步骤（4），重复这一过程直至不存在更多的有能力的神经元为止。</p>
<p><img src="/../images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9B%9B%E7%A7%8D%E7%AE%97%E6%B3%95/u=1076120041,773083672&fm=173&app=49&f=JPEG" alt="img">ART网络</p>
<p><strong>2．学习矢量量化（LVQ）网络</strong></p>
<p>学习矢量量化（LVQ）网络，它由三层神经元组成，即输入转换层、隐含层和输出层。该网络在输入层与隐含层之间为完全连接，而在隐含层与输出层之间为部分连接，每个输出神经元与隐含神经元的不同组相连接。</p>
<p>最简单的LVQ训练步骤如下：</p>
<p>（1）预置参考矢量初始权值。</p>
<p>（2）供给网络一个训练输入模式。</p>
<p>（3）计算输人模式与每个参考矢量间的Euclidean距离。</p>
<p>（4）更新最接近输入模式的参考矢量（即获胜隐含神经元的参考矢量）的权值。如果获胜隐含神经元以输入模式一样的类属于连接至输出神经元的缓冲器，那么参考矢量应更接近输入模式。否则，参考矢量就离开输人模式。</p>
<p>（5）转至步骤（2），以某个新的训练输入模式重复本过程，直至全部训练模式被正确地分类或者满足某个终止准则为止。</p>
<p><img src="/../images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9B%9B%E7%A7%8D%E7%AE%97%E6%B3%95/u=81949266,355555348&fm=173&app=49&f=JPEG" alt="img">LVQ网络</p>
<p><strong>3．Kohonen网络</strong></p>
<p>Kohonen网络或自组织特征映射网络含有两层，一个输入缓冲层用于接收输入模式，另一个为输出层，输出层的神经元一般按正则二维阵列排列，每个输出神经元连接至所有输入神经元。连接权值形成与已知输出神经元相连的参考矢量的分量。</p>
<p>训练一个Kohonen网络包含下列步骤：</p>
<p>（1）对所有输出神经元的参考矢量预置小的随机初值。</p>
<p>（2）供给网络一个训练输入模式。</p>
<p>（3）确定获胜的输出神经元，即参考矢量最接近输入模式的神经元。参考矢量与输入矢量间的Euclidean距离通常被用作距离测量。</p>
<p>（4）更新获胜神经元的参考矢量及其近邻参考矢量。这些参考矢量（被引至）更接近输入矢量。对于获胜参考矢量，其调整是最大的，而对于离得更远的神经元，减少调整个神经元邻域的大小随着训练的进行而相对减小，到训练结束，只有获胜神经元的参考矢量被调整。</p>
<p><img src="/../images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9B%9B%E7%A7%8D%E7%AE%97%E6%B3%95/u=3981122705,166961606&fm=173&app=49&f=JPEG" alt="img">Kohonen网络</p>
<p><strong>4．Hopfield网络</strong></p>
<p>Hopfield网络是一种典型的递归网络，这种网络通常只接受二进制输入（0或1）以及双极输入（+1或-1）。它含有一个单层神经元，每个神经元与所有其他神经元连接，形成递归结构。</p>
<p><img src="/../images/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9B%9B%E7%A7%8D%E7%AE%97%E6%B3%95/20180112110954464" alt="img"></p>
<p>上图为Hopfield神经网络结构图。</p>
<p>   首先，网络结构上，Hopfield神经网络是一种单层互相全连接的反馈型神经网络。每个神经元既是输入也是输出，网络中的每一个神经元都将自己的输出通过连接权传送给所有其它神经元，同时又都接收所有其它神经元传递过来的信息。即：网络中的神经元在t时刻的输出状态实际上间接地与自己t-1时刻的输出状态有关。神经元之间互连接，所以得到的权重矩阵将是对称矩阵。</p>
<p>​    同时，Hopfield神经网络成功引入能量函数的概念，使网络运行地稳定性判断有了可靠依据。基本的Hopfield神经网络是一个由非线性元件构成的全连接型单层递归系统。其状态变化可以用差分方程来表示。递归型网络的一个重要特点就是它具有稳定状态‘当网络达到稳定状态的时候，也就是它的能量函数达到最小的时候。这里的能量函数不是物理意义上的能量函数，而是在表达形式上与物理意义上的能量概念一致，即它表征网络状态的变化趋势，并可以依据Hopfield网络模型的工作运行规则不断地进行状态变化，最终能够到达具有某个极小值的目标函数。网络收敛就是指能量函数达到极小值。</p>
<p>​    如果把一个最优化在着递归信号，网络的状态是随时间的变化而变化的，其运动轨迹必然存在着稳定性的问题。这就是递归网络与前向网络在网络性能分析上最大的区别之一在使用递归网络时，必须对其稳定性进行专门的分析与讨论，合理选择网络的参数变化范围，才能确保递归网络的正常工作。</p>
<p>​    Hopfield神经网络模型有离散型和连续性两种，离散型适用于联想记忆，连续性适合处理优化问题。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能 -神经网络 -算法</tag>
      </tags>
  </entry>
  <entry>
    <title>似然函数</title>
    <url>/post/fbf175a6.html</url>
    <content><![CDATA[<p>似然（likelihood）这个词其实和概率（probability）是差不多的意思，但是在统计里面，似然函数和概率函数却是两个不同的概念。</p>
<p>对于函数：P(x∣θ)，输入有两个：x表示某一个具体的数据；θ表示模型的参数。</p>
<p>如果θ是确定的，x是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。</p>
<p>比如我们已经知道了一个箱子里有19个黑球和一个白球，现在问你从箱子里抽出两个球，是两个黑球的概率是多少，这个时候我们的模型参数是完全知道了，就是19个黑球和一个白球，不知道的是抽出的具体的球是什么。这个时候，P(x∣θ)就是概率函数。</p>
<p>如果x是已知确定的，θ是变量，这个函数叫做似然函数(likelihood function)，它描述对于不同的模型参数，出现x这个样本点的概率是多少。</p>
<p>比如我们有一箱子球，已经从里面抽出了1个黑球8个白球，问你箱子里面黑球和白球的分布模型参数是什么。这个时候我们是不知道箱子里面的具体情况的，但我们知道抽出球的样本分布，那么我们要用样本的分布来评估箱子里的球的模型分布，这个时候P(x∣θ)就是似然函数。</p>
<p>参考文章：<a href="https://blog.csdn.net/u011508640/article/details/72815981">https://blog.csdn.net/u011508640/article/details/72815981</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>使用python来访问Hadoop HDFS存储实现文件的操作</title>
    <url>/post/2073f49.html</url>
    <content><![CDATA[<h2 id="使用python来访问Hadoop-HDFS存储实现文件的操作"><a href="#使用python来访问Hadoop-HDFS存储实现文件的操作" class="headerlink" title="使用python来访问Hadoop HDFS存储实现文件的操作"></a>使用python来访问Hadoop HDFS存储实现文件的操作</h2><p>在调试环境下，咱们用hadoop提供的shell接口测试增加删除查看，但是不利于复杂的逻辑编程</p>
<p><a href="https://s1.51cto.com/attachment/201307/101434538.jpg"><img src="/../images/%E4%BD%BF%E7%94%A8python%E6%9D%A5%E8%AE%BF%E9%97%AEHadoop%20HDFS%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E7%9A%84%E6%93%8D%E4%BD%9C/5f38c33fa291a41a946f34d91a38131f.JPEG" alt="101434538.jpg"></a></p>
<p>查看文件内容</p>
<p><a href="https://s1.51cto.com/attachment/201307/101517360.jpg"><img src="/../images/%E4%BD%BF%E7%94%A8python%E6%9D%A5%E8%AE%BF%E9%97%AEHadoop%20HDFS%E5%AD%98%E5%82%A8%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E7%9A%84%E6%93%8D%E4%BD%9C/8b7eab9bb5459f7e06596ec5519011d4.JPEG" alt="101517360.jpg"></a></p>
<p>用python访问hdfs是个很头疼的事情。。。。</p>
<p>这个是pyhdfs的库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pyhdfs</span><br><span class="line">fs &#x3D; pyhdfs.connect(&quot;192.168.1.1&quot;, 9000)</span><br><span class="line">pyhdfs.get(fs, &quot;&#x2F;rui&#x2F;111&quot;, &quot;&#x2F;var&#x2F;111&quot;)</span><br><span class="line">f &#x3D; pyhdfs.open(fs, &quot;&#x2F;test&#x2F;xxx&quot;, &quot;w&quot;)</span><br><span class="line">pyhdfs.write(fs, f, &quot;fuck\0gfw\n&quot;)</span><br><span class="line">pyhdfs.close(fs, f)</span><br><span class="line">pyhdfs.disconnect(fs)</span><br></pre></td></tr></table></figure>


<p>pyhdfs的安装过程很吐血</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">svn checkout http:&#x2F;&#x2F;libpyhdfs.googlecode.com&#x2F;svn&#x2F;trunk&#x2F; libpyhdfs</span><br><span class="line">cd libpyhdfs</span><br><span class="line">cp &#x2F;usr&#x2F;lib&#x2F;hadoop-0.20&#x2F;hadoop-core-0.20.2-cdh3u0.jar lib&#x2F;hadoop-0.20.1-core.jar</span><br><span class="line">cp &#x2F;usr&#x2F;lib&#x2F;hadoop-0.20&#x2F;lib&#x2F;commons-logging-1.0.4.jar lib&#x2F;</span><br><span class="line">cp &#x2F;usr&#x2F;lib&#x2F;libhdfs.so.0 lib&#x2F;</span><br><span class="line">ln –s lib&#x2F;libhdfs.so.0 lib&#x2F;libhdfs.so</span><br><span class="line">python setup.py install --prefix&#x3D;&quot;&#x2F;usr&#x2F;local&quot;</span><br></pre></td></tr></table></figure>


<p>还有就是把 selinux也给关了   不然会出现莫名的问题</p>
<p>如果出现</p>
<p>/usr/lib/jvm/java-6-sun/include/jni.h:27:20: error: jni_md.h: No such file or directory</p>
<p>搜下find / -name jni.h</p>
<p>然后修改#include “jni_md.h”  为  #include “linux/jni_md.h”</p>
<p>这个是用pydoop的库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pydoop.hdfs as hdfs</span><br><span class="line">with hdfs.open(&#39;&#x2F;user&#x2F;myuser&#x2F;filename&#39;) as f:</span><br><span class="line">    for line in f:</span><br><span class="line">        print(line)</span><br></pre></td></tr></table></figure>




<p>我现在使用的方法是用subprocess ，哈哈，方法很搓吧，主要原因是我这边没有太多的性能估计，只是单纯的把mapreduce的接口给搞出来而已。</p>
<p>这么简单用用也还可以的~</p>
<p>需要把很多自己常用的指定都封装成库  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &#x3D; subprocess.Popen([&quot;hadoop&quot;, &quot;fs&quot;, &quot;-cat&quot;, &quot;&#x2F;path&#x2F;to&#x2F;myfile&quot;], stdout&#x3D;subprocess.PIPE)</span><br><span class="line">for line in cat.stdout:</span><br><span class="line">    print line</span><br></pre></td></tr></table></figure>




<p>补充下（从视hadoop为儿戏到现在对mapreduce半斤八两，对我自己来说，还是有很大的进步的。所以关于hadoop python操作不能再用以前的方法啦。）：</p>
<p>   最近了解了更加方便的库，算是文档和利用最好的了。</p>
<p>pyhdfs是对libhdfs的python封装库. 它提供了一些常用方法来处理HDFS上的文件和目录, 比如读写文件, 枚举目录文件, 显示HDFS可用空间, 显示文件的复制块数等。</p>
<p>libhdfs 是HDFS的底层C函数库, 由hadoop官方提供, pyhdfs使用swig技术, 对libhdfs提供的绝大多数函数进行了封装, 目的是提供更简单的调用方式.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">如何连接hadoop集群？</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何获取当前工作目录?</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.getWorkingDirectory()</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何更改当前工作目录？</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.setWorkingDirectory(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&quot;)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如果目录不存在setWorkingDirectory()返回-1,如果执行成功，返回0</span><br><span class="line">如果目录不存在setWorkingDirectory()返回-1,如果执行成功，返回0</span><br><span class="line">如何判断某个文件&#x2F;目录是否存在？</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.pathExists(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&quot;)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">文件&#x2F;目录存在，返回0，如果不存在，返回-1</span><br><span class="line">如何创建一个目录?</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.createDirectory(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&quot;)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如果目录已经存在，则返回-1，如果目录创建成功，返回0</span><br><span class="line">如何获得当前默认块大小？</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.getDefaultBlockSize()</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何获得当期目录下的文件&#x2F;目录？</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.listDirectory(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&quot;)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何移动一个文件&#x2F;目录?</span><br><span class="line">同一HDFS内移动文件：</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.move(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&quot;,&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj_new&quot;)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">不同HDFS之间移动文件：</span><br><span class="line">    target_fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.move(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&quot;,&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj_new&quot;,target_fs)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何删除一个文件&#x2F;目录?</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.delete(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj_new&quot;)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何重命名一个文件&#x2F;目录?</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.rename(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&quot;,&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj1&quot;)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何修改一个文件&#x2F;目录的权限?</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.chmod(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&quot;,7)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何文件块所在的服务器名?</span><br><span class="line">有时我们需要查找某些文件块所在的服务器名是什么，可以如下使用:</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.getHosts(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&#x2F;a&quot;,0,1)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">返回包含服务器名的列表.</span><br><span class="line">   $ python gethosts.py</span><br><span class="line">   [&#39;xxxx&#39;]</span><br><span class="line">如何获取一个文件&#x2F;目录的信息?</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    pathinfo &#x3D; fs.getPathInfo(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&quot;)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">getPathInfo()返回一个hdfsFileInfo类。</span><br><span class="line">如何指定文件的备份数?</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    print fs.setReplication(&quot;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&#x2F;a&quot;,3)</span><br><span class="line">    fs.disconnect()</span><br><span class="line">如何打开一个文件，并读取数据?</span><br><span class="line">要操作文件，需要创建一个HadoopFile对象，并利用read()方法读取数据.</span><br><span class="line">    fs &#x3D; hadoop.HadoopDFS(&quot;username&quot;,&quot;password&quot;,&quot;ugi&quot;,64310)</span><br><span class="line">    fh &#x3D; hadoop.HadoopFile(fs,&#39;&#x2F;user&#x2F;ns-lsp&#x2F;logs&#x2F;cjj&#x2F;a&#39;)</span><br><span class="line">    print fh.read()</span><br><span class="line">    fh.close()</span><br><span class="line">    fs.disconnect()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>-python</tag>
      </tags>
  </entry>
  <entry>
    <title>人類學雜記——24. 中國人的超級祖先</title>
    <url>/post/13526.html</url>
    <content><![CDATA[<p>人類學雜記——24. 中國人的超級祖先</p>
<p> <img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image002.png" alt="http://simg.sinajs.cn/blog7style/images/common/sg_trans.gif"> (2013-10-18 12:53:53)</p>
<p>（溫馨提示：簡化字版本見後。）</p>
<p>2013年10月15日，我在arXiv文章數據庫掛出了一篇文章（<a href="http://arxiv.org/abs/1310.3897">http://arxiv.org/abs/1310.3897</a> ，帶附件的下載地址見<a href="http://vdisk.weibo.com/s/qGPNPvCSIf0t">http://vdisk.weibo.com/s/qGPNPvCSIf0t</a> ），題目是«Y Chromosomes of 40% Chinese Are Descendants of Three Neolithic Super-grandfathers»，即《40%的中國人的Y染色體來自三個新石器時代的超級祖先》，基本內容如下：首先是對110個東亞樣本做Y染色體測序，得到質量可以接受的序列共78個。從裏面找到了4000多個新的SNP位點，命名以F（復旦）打頭。因爲我們捕獲來測序的範圍是隨機的（取的Y染色體上沒有重複的約4 Mbp的很多不連續片段的集合，與已知支系信息無關），範圍又比較大，所以可以畫一棵明確且沒有偏向的演化樹（因爲絕大多數位點都是沒有回復突變的），然後就能按傳統的分子鐘方法計算時閒了。</p>
<p>計算相對時閒只要數每支的突變個數再相比就行了（因爲有波動，具體時閒還是按最大似然法綜合算的），但絕對時閒，就是說平均一個突變到底需要多少年，是需要標定的。這裏我們先只用了一個1×10-9/年/鹼基的突變率。文裏用SNP算的相對時閒能比用STR算出來的準很多（文中說了，準確度的誤差範圍和用於計算時閒的SNP數開根号成反比）。標定的絕對年代（即SNP的絕對突變率）也許還有些誤差，但至少結果也在以往各種方法估出來的範圍之中（以往算出走出非洲年齡最小的不到4万年，最大的8万年，我們算出5.4万）。</p>
<p><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image004.jpg" alt="img"></p>
<p> <img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image006.jpg" alt="img"></p>
<p>文章的結論</p>
<p>文章最大的亮點有兩個，一個是<strong>能相對以往準確得多地算出分支時閒，至少是相對時閒</strong>，另一個是<strong>發現**</strong>O3**<strong>下面的三個大的星狀擴張</strong>（下面具體談到）。以往用Y-SNP不能算時閒是因爲實驗是特地挑的已知SNP來做的，數量少，且本身帶有偏向性。而本實驗是不帶任何人羣方面的預設來找的SNP，是不帶偏向性的。線粒體全測能算時閒也是同樣道理。當然因爲Y染色體位點多，平均每100年左右就能有一個突變（用全序，即10Mbp左右的範圍），而線粒體平均要2000多年纔能在全長上有一次突變，因此Y染色體算出的時閒精度能比線粒體好很多。</p>
<p>支系方面比較重要的結論有以下幾點：</p>
<p>\1. 走出非洲的C、DE、F三大支的分支年代在5万多年。雖然C和F在一起而DE是早分出的，而因爲E主體的分佈是在非洲，本來有人提出CF和D可能是兩批分別走出非洲的，但我們發現CF共有的SNP只有3個，對應大概不到1000年，這樣C, DE和F仍是準三叉，根據奧卡姆剔刀原理，還是M168+整體遷出非洲然後E那支再回流非洲的可能性稍大一些。</p>
<p>\2. F支經歷過極強的瓶頸，以致於和C分開後過了差不多2万年纔再一次產生下游分支G, H, IJ, K，K下面的分化也很快（NO, P和LT目前來看也是個準三叉，M和S因爲沒有樣本，現在拓撲關係還不明朗），也就是說，F支下面按字母分的單倍羣從樹幹上分出的時閒大體都在3.6 – 2.4万年前之閒，尤其3.6 – 3万年前是一個快速擴張的時期。O3-M122與O1-M119、O2-M268分開後不久，O1、O2再分開。而下游的分化總的次序是O2最早，其次O3，而O1最晚（不過可能和這次測序的O1樣本多數取自華東有關，多取一些南方少數民族的O1樣本可能會有一些更早的分支。）</p>
<p>\3. O系的地理佈散，尤其是O3a-M324（占中國人口的一半以上），主要發生在1.9 – 1万年前，即末次冰盛期（2.3 – 1.8万年前）之後的舊石器時代。這段時閒全球氣候逐漸回暖，海平面從現在海面以下上百米一直升到和目前海平面接近的高度，人類的可活動範圍大大擴展，技術上也有了一些創新，比如陶器的發明，農業也出現了萌芽。</p>
<p>\4. 在樹上觀察到，<strong>5000**</strong>到**<strong>6000**</strong>多年前左右，在中國出現了三個超級祖先，一個在**<strong>M117**</strong>下，一個在**<strong>M134**</strong>的另一個分支，即**<strong>F444**</strong>下，還有一個在**<strong>002611**</strong>的下游**<strong>F11**</strong>下<strong>。這三個超級祖先出現的年代很接近（次序按不同方法算出來有所區別）。</strong>我把他們分別稱爲**<strong>Oα, Oβ**</strong>和**<strong>Oγ**</strong>，算作對現有單倍羣命名系統的一個改進<strong>。</strong>這三個大約**<strong>6000**</strong>年前的人的後代構成了現在漢族人羣的**<strong>40%**</strong>以上<strong>。之所以很特別（因爲一個人羣往上推總會推到某個時候有個祖先的後代占了一大半），是因爲在</strong>這三個擴張以前的**<strong>Y**</strong>染色體樹的所有分支，都是二叉，而這三個擴張是星狀擴張**，即突然從一個人演化出難以分出先後（這篇文章的測序精度是平均250年一個突變）的5 – 7個支系，而且這5 – 7支是都有後代一直延續到現在的。長支或二叉當中的那些古人當然不是說那些人都沒有兄弟，而是說無數輩的兄弟都沒能傳下男性後代，當時的人口擴張也相對緩慢，只有這幾支幸運兒的後代終於活到了現代。</p>
<p>\5. C3-M217是占中國10%左右的大支系，很清楚分爲南北兩支，2.6万年前分開，比O3和O1’2分開還略早。結合STR結果來看，漢族的C3基本都是南支，且存在一個6000多年前的擴張（可能比O3下的三大簇略早）。漢族和北方民族都常見的C3d-M407屬於南支那個擴張下游的。而星簇（star cluster，以前Zerjal et al.說是成吉思汗生出來的）、448-del兩個重要支系（應該也有C3c-M48）屬於北支。C3的北支基本在漢族裏不存在。關於C單倍羣的更多細節，我的同事蘭海應該會發表一篇paper來說明。</p>
<p>\6. N單倍羣的最早分化也在1.6万年前。也分爲南北兩支。結合STR來看，原先的N1a-M128和N1c-M46（應該也有N1b-P43）都是北支的。關於N的更多細節，我也會另外寫一篇paper來講。</p>
<p>文章裏沒寫的（因爲文章本來要投大雜誌的，因篇幅有限或說了會被審稿人挑刺所以沒放在文章裏，或者被別人搶去的，或是證據不足的猜想）：</p>
<p>\7. 時閒估計的不精確性。因爲原先文章裏的用STR計算突變率有一些問題，在後來投的稿裏這部分被砍掉了。但相對的STR時閒計算是沒有問題的。這裏給出兩張散點圖，比較相同的兩個樣本用17-STR得出的時閒和直接數相差的SNP數的對比。前一張圖是所有樣本閒的兩兩比較。後一張圖是Oγ星狀擴張中每對共祖於星點的兩個樣本的STR計算時閒和相差的SNP數的對比。因爲是同一個星，理論上兩個樣本的共祖時閒幾乎相同。可見<strong>SNP**</strong>算出的時閒精度遠好於**<strong>STR**</strong>算出的，而**<strong>STR**</strong>得到的結果經常可能差出一個數量級以上**。或者說，兩個樣本STR很遠的可以排除近期的共祖，但STR近的，實際共祖時閒可能很晚但也不排除實際很早但是因爲巧合而STR接近了。經常有人問，我們兩個人STR差4個點，到底能差多少年，我說100年到1万年都沒準，這確實不是搪塞。</p>
<p><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image008.jpg" alt="img"></p>
<p><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image010.jpg" alt="img"></p>
<p>\8. 這三個超級祖先到底是什麼人。首先，這個擴張年代正好在五六千年前，屬新石器時代晚期，對應的文化包括仰韶時代晚期和大汶口文化晚期等（我知道有人認爲這三個擴張不是發生於黃河流域的，留以後發現更多證據，尤其是古DNA證據來回答了。）這個時代我知道的有兩個大的變革，一個是農業的大發展，穀類從採集、狩獵的輔助食物變成了食物的主體部分，人們的食物開始嚴重依賴農業，同時聚落的分佈密度大大增加，說明人口增加。同時又有一個社會結構的變化，墓葬從羣體葬逐漸發展出了單人葬和對偶葬，說明社會從母系社會變成了父系社會。因此，對於這三個超級祖先，有兩種解釋：其一，他們是最早的集約化農民，因爲生產力（穀物和人口的）大幅發展，成了超級祖先，因此<strong>稱**</strong>Oα, Oβ**<strong>和**</strong>Oγ**<strong>分別爲**</strong>“**<strong>農民甲**</strong>”**<strong>、**</strong>“**<strong>農民乙**</strong>”**<strong>和**</strong>“**<strong>農民丙**</strong>”<strong>。有人不相信這種解釋，認爲他們肯定是很偉大的部落首領，有巨大的權力而能占有很多女人，建議用三皇來稱呼，我按照計算出的時閒，分別把</strong>Oγ, Oβ**<strong>和**</strong>Oα**<strong>分別稱作**</strong>“**<strong>天皇**</strong>”**<strong>、**</strong>“**<strong>地皇**</strong>”**<strong>和**</strong>“**<strong>泰皇**</strong>”**。（還有建議把他們稱作“炎帝”、“黃帝”和“蚩尤”的，因爲時閒不符合，而且因爲可能有歷史原型而對應支系可能被證僞，再加上“蚩尤”從民族學上看大概對應苗瑤的O3a2b-M7而不屬這三大簇，所以我覺得還是用純神化的三皇更合適一些。）當然用三皇命名有些人會覺得神棍一些，甯可用“農民”，不過其實把人類父系共祖稱作“Y染色體亞當”同樣神棍。我覺得反正這三簇是客觀存在的，短時閒也不容易證明到底他們是什麼樣的人物，那稱作農民還是三皇就看個人信仰了。</p>
<p>\9. 除了三個O3下面的超級祖先，另有兩支也需要關注，一個是C3下面F1144的下游擴張，即南支，擴張時閒可能比O3的三大簇略早，另一個是O1a1下面F78的下游擴張，年代可能只有4000年不到。這兩支的人口大概也各占了漢族的10%上下，但因爲高通量測序時沒有足夠的樣本或有的樣本測序質量不好，尚未能表現出星狀擴張，但我相信如果能擴大測序樣本的數目，也是能找到類似星簇的擴張的。（我還暫時沒有給這兩支起名字。）這樣，把這兩支也加上，<strong>這五個新石器祖先的後代就能占到漢族及中國人**</strong>60%<strong>**的比例</strong>了。</p>
<p><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image012.png" alt="img"><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image014.png" alt="img"><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image016.png" alt="img"><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image018.png" alt="img"><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image020.png" alt="img"></p>
<p> （上圖是五支祖先大致的分佈範圍和所占人口比例。不是嚴格計算，漢族之外的支系判斷可能有錯。）</p>
<p>\10. 關於華夏的起源。因爲這篇文章計算了時閒，所以明確了，<strong>漢族（或中華民族）的大多數姓氏的都起源於一個幾千年前叫黃帝的共同父系祖先必然是不可能的</strong>。新石器時代晚期最大的簇（Oα）也不過占漢族父系的16%。不過，這篇文章同樣也說明了，史前不遠的時代，<strong>華夏確實有少數幾個超級祖先，他們短時閒繁殖出了大量的後代，也就是說這些有關共同祖先的傳說確實是有其原型的，只不過其重要程度被誇大了</strong>。</p>
<p>文章發表歷經的坎坷</p>
<p>很多人，包括愛好者和業內人士，都知道我的結果早就出來了，這兩年一直都在催問我文章什麼時候能出來，位點什麼時候能公佈。首先，按照通常的科硏規範，似乎文章沒有經過同行評議，文章沒有發出，是不能對外發佈消息的。其次，文章是實驗室老師辛苦申請基金、多人多年合作做出的結果，隨便公佈數據而沒有相應文章發表是損害實驗室利益的，而今後繼續申請科硏基金、評職稱等等，按目前中國的體制，全看文章的影響因子，且只有一作和通訊作者算數。其他的，至少對於生物學來說，發中文文章不算有效工作，合作作者不算，出書不算，做科普不算，這些只能在有閑的時候做。所以，對於這篇文章，首先只能攷慮發paper，而且雜誌分數越高越好。</p>
<p>這篇文章首次投出是2011年11月，這兩年先後投過Nature, Science, Nature Genetics, Nature Communications, PNAS。有的雜誌是被編輯直接斃掉，還有的雜誌是跟審稿人撦了好幾次皮，先後投過3個版本，歷經9個月，最後被拒掉的。幾次投出之閒還有過好幾次大的內容的刪改，比如突變率的計算方法和SNP-STR對照比較等，還有改文章的着重點等。前一次拒掉和下一次投出之閒改文章經常又要花幾個月。這兩年，好幾篇實驗做得並不如我們的文章登上了Science或Genome Research這樣的雜誌，我們文章的新穎性也越來越差。</p>
<p>最終爲了避免文章中的發現變得一錢不值，我出於促進知識傳播和對我的青春負責的理念，決定還是先把文章公開到arXiv上。這個數據庫是沒有同行評審的，也就是說只有靠讀者來衡量文章的價值。但這上面的文章能被引用。有同行評審的雜誌我也還在投着，就算能發出去，分數也沒多少了。從攷覈體系角度看，這四年的我和同事的工作和花的硏究經費就算餵狗了，我的穩定教职也沒戲了，只能繼續做一個二站的博後。（話說，有時候很明顯從編輯和審稿人打回的意見裏能感覺到對中國或東方人的歧視。這篇文章的作者全都是中國人，復旦大學或者中科院計算生物所的成員。因爲發表時閒拖久了，文章本來的亮點一個個被別人的文章搶了去，也只得把題目從一個全球性的時閒計算改成關於中國人祖先擴張的，導致文章更難發表。如果是關於猶太人或者歐洲人的文章，經常是隨便一點兒數據都能發到高分雜誌。之前曹操後代那篇文章也只投到了日本的Journal of Human Genetics雜誌。）</p>
<p>這期閒我如果做錯了什麼，或者什麼原因造成的文章難以發表，有什麼更好的信息發佈方案，都可以幫忙指出，如果有辦法能同時兼顧知識傳播和實驗室利益，我會很感激的。</p>
<p>===============以下是簡化字版本=================</p>
<p>2013年10月15日，我在arXiv文章数据库挂出了一篇文章（<a href="http://arxiv.org/abs/1310.3897">http://arxiv.org/abs/1310.3897</a> ，带附件的下载地址见<a href="http://vdisk.weibo.com/s/qGPNPvCSIf0t">http://vdisk.weibo.com/s/qGPNPvCSIf0t</a> ），题目是«Y Chromosomes of 40% Chinese Are Descendants of Three Neolithic Super-grandfathers»，即《40%的中国人的Y染色体来自三个新石器时代的超级祖先》，基本内容如下：首先是对110个东亚样本做Y染色体测序，得到质量可以接受的序列共78个。从里面找到了4000多个新的SNP位点，命名以F（复旦）打头。因为我们捕获来测序的范围是随机的（取的Y染色体上没有重复的约4 Mbp的很多不连续片段的集合，与已知支系信息无关），范围又比较大，所以可以画一棵明确且没有偏向的演化树（因为绝大多数位点都是没有回复突变的），然后就能按传统的分子钟方法计算时间了。</p>
<p>计算相对时间只要数每支的突变个数再相比就行了（因为有波动，具体时间还是按最大似然法综合算的），但绝对时间，就是说平均一个突变到底需要多少年，是需要标定的。这里我们先只用了一个1×10-9/年/碱基的突变率。文里用SNP算的相对时间能比用STR算出来的准很多（文中说了，准确度的误差范围和用于计算时间的SNP数开根号成反比）。标定的绝对年代（即SNP的绝对突变率）也许还有些误差，但至少结果也在以往各种方法估出来的范围之中（以往算出走出非洲年龄最小的不到4万年，最大的8万年，我们算出5.4万）。</p>
<p><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image021.jpg" alt="img"></p>
<p> <img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image022.jpg" alt="img"></p>
<p>文章的结论</p>
<p>文章最大的亮点有两个，一个是<strong>能相对以往准确得多地算出分支时间，至少是相对时间</strong>，另一个是<strong>发现**</strong>O3**<strong>下面的三个大的星状扩张</strong>（下面具体谈到）。以往用Y-SNP不能算时间是因为实验是特地挑的已知SNP来做的，数量少，且本身带有偏向性。而本实验是不带任何人群方面的预设来找的SNP，是不带偏向性的。线粒体全测能算时间也是同样道理。当然因为Y染色体位点多，平均每100年左右就能有一个突变（用全序，即10Mbp左右的范围），而线粒体平均要2000多年才能在全长上有一次突变，因此Y染色体算出的时间精度能比线粒体好很多。</p>
<p>支系方面比较重要的结论有以下几点：</p>
<p>\1. 走出非洲的C、DE、F三大支的分支年代在5万多年。虽然C和F在一起而DE是早分出的，而因为E主体的分布是在非洲，本来有人提出CF和D可能是两批分别走出非洲的，但我们发现CF共有的SNP只有3个，对应大概不到1000年，这样C, DE和F仍是准三叉，根据奥卡姆剔刀原理，还是M168+整体迁出非洲然后E那支再回流非洲的可能性稍大一些。</p>
<p>\2. F支经历过极强的瓶颈，以致于和C分开后过了差不多2万年才再一次产生下游分支G, H, IJ, K，K下面的分化也很快（NO, P和LT目前来看也是个准三叉，M和S因为没有样本，现在拓扑关系还不明朗），也就是说，F支下面按字母分的单倍群从树干上分出的时间大体都在3.6 – 2.4万年前之间，尤其3.6 – 3万年前是一个快速扩张的时期。O3-M122与O1-M119、O2-M268分开后不久，O1、O2再分开。而下游的分化总的次序是O2最早，其次O3，而O1最晚（不过可能和这次测序的O1样本多数取自华东有关，多取一些南方少数民族的O1样本可能会有一些更早的分支。）</p>
<p>\3. O系的地理布散，尤其是O3a-M324（占中国人口的一半以上），主要发生在1.9 – 1万年前，即末次冰盛期（2.3 – 1.8万年前）之后的旧石器时代。这段时间全球气候逐渐回暖，海平面从现在海面以下上百米一直升到和目前海平面接近的高度，人类的可活动范围大大扩展，技术上也有了一些创新，比如陶器的发明，农业也出现了萌芽。</p>
<p>\4. 在树上观察到，<strong>5000**</strong>到**<strong>6000**</strong>多年前左右，在中国出现了三个超级祖先，一个在**<strong>M117**</strong>下，一个在**<strong>M134**</strong>的另一个分支，即**<strong>F444**</strong>下，还有一个在**<strong>002611**</strong>的下游**<strong>F11**</strong>下<strong>。这三个超级祖先出现的年代很接近（次序按不同方法算出来有所区别）。</strong>我把他们分别称为**<strong>Oα, Oβ**</strong>和**<strong>Oγ**</strong>，算作对现有单倍群命名系统的一个改进。这三个大约**<strong>6000**</strong>年前的人的后代构成了现在汉族人群的**<strong>40%**</strong>以上<strong>。之所以很特别（因为一个人群往上推总会推到某个时候有个祖先的后代占了一大半），是因为</strong>在这三个扩张以前的**<strong>Y**</strong>染色体树的所有分支，都是二叉，而这三个扩张是**<strong>星状扩张</strong>，即突然从一个人演化出难以分出先后（这篇文章的测序精度是平均250年一个突变）的5 – 7个支系，而且这5 – 7支是都有后代一直延续到现在的。长支或二叉当中的那些古人当然不是说那些人都没有兄弟，而是说无数辈的兄弟都没能传下男性后代，当时的人口扩张也相对缓慢，只有这几支幸运儿的后代终于活到了现代。</p>
<p>\5. C3-M217是占中国10%左右的大支系，很清楚分为南北两支，2.6万年前分开，比O3和O1’2分开还略早。结合STR结果来看，汉族的C3基本都是南支，且存在一个6000多年前的扩张（可能比O3下的三大簇略早）。汉族和北方民族都常见的C3d-M407属于南支那个扩张下游的。而星簇（star cluster，以前Zerjal et al.说是成吉思汗生出来的）、448-del两个重要支系（应该也有C3c-M48）属于北支。C3的北支基本在汉族里不存在。关于C单倍群的更多细节，我的同事兰海应该会发表一篇paper来说明。</p>
<p>\6. N单倍群的最早分化也在1.6万年前。也分为南北两支。结合STR来看，原先的N1a-M128和N1c-M46（应该也有N1b-P43）都是北支的。关于N的更多细节，我也会另外写一篇paper来讲。</p>
<p>文章里没写的（因为文章本来要投大杂志的，因篇幅有限或说了会被审稿人挑刺所以没放在文章里，或者被别人抢去的，或是证据不足的猜想）：</p>
<p>\7. 时间估计的不精确性。因为原先文章里的用STR计算突变率有一些问题，在后来投的稿里这部分被砍掉了。但相对的STR时间计算是没有问题的。这里给出两张散点图，比较相同的两个样本用17-STR得出的时间和直接数相差的SNP数的对比。前一张图是所有样本间的两两比较。后一张图是Oγ星状扩张中每对共祖于星点的两个样本的STR计算时间和相差的SNP数的对比。因为是同一个星，理论上两个样本的共祖时间几乎相同。可见<strong>SNP**</strong>算出的时间精度远好于**<strong>STR**</strong>算出的，而**<strong>STR**</strong>得到的结果经常可能差出一个数量级以上**。或者说，两个样本STR很远的可以排除近期的共祖，但STR近的，实际共祖时间可能很晚但也不排除实际很早但是因为巧合而STR接近了。经常有人问，我们两个人STR差4个点，到底能差多少年，我说100年到1万年都没准，这确实不是搪塞。</p>
<p><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image023.jpg" alt="img"></p>
<p><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image024.jpg" alt="img"></p>
<p>\8. 这三个超级祖先到底是什么人。首先，这个扩张年代正好在五六千年前，属新石器时代晚期，对应的文化包括仰韶时代晚期和大汶口文化晚期等（我知道有人认为这三个扩张不是发生于黄河流域的，留以后发现更多证据，尤其是古DNA证据来回答了。）这个时代我知道的有两个大的变革，一个是农业的大发展，谷类从采集、狩猎的辅助食物变成了食物的主体部分，人们的食物开始严重依赖农业，同时聚落的分布密度大大增加，说明人口增加。同时又有一个社会结构的变化，墓葬从群体葬逐渐发展出了单人葬和对偶葬，说明社会从母系社会变成了父系社会。因此，对于这三个超级祖先，有两种解释：其一，他们是最早的集约化农民，因为生产力（谷物和人口的）大幅发展，成了超级祖先，因此<strong>称**</strong>Oα, Oβ**<strong>和**</strong>Oγ**<strong>分别为**</strong>“**<strong>农民甲**</strong>”**<strong>、**</strong>“**<strong>农民乙**</strong>”**<strong>和**</strong>“**<strong>农民丙**</strong>”<strong>。有人不相信这种解释，认为他们肯定是很伟大的部落首领，有巨大的权力而能占有很多女人，建议用三皇来称呼，我按照计算出的时间，分别</strong>把**<strong>Oγ, Oβ**</strong>和**<strong>Oα**</strong>分别称作**<strong>“**</strong>天皇**<strong>”**</strong>、**<strong>“**</strong>地皇**<strong>”**</strong>和**<strong>“**</strong>泰皇**<strong>”</strong>。（还有建议把他们称作“炎帝”、“黄帝”和“蚩尤”的，因为时间不符合，而且因为可能有历史原型而对应支系可能被证伪，再加上“蚩尤”从民族学上看大概对应苗瑶的O3a2b-M7而不属这三大簇，所以我觉得还是用纯神化的三皇更合适一些。）当然用三皇命名有些人会觉得神棍一些，宁可用“农民”，不过其实把人类父系共祖称作“Y染色体亚当”同样神棍。我觉得反正这三簇是客观存在的，短时间也不容易证明到底他们是什么样的人物，那称作农民还是三皇就看个人信仰了。</p>
<p>\9. 除了三个O3下面的超级祖先，另有两支也需要关注，一个是C3下面F1144的下游扩张，即南支，扩张时间可能比O3的三大簇略早，另一个是O1a1下面F78的下游扩张，年代可能只有4000年不到。这两支的人口大概也各占了汉族的10%上下，但因为高通量测序时没有足够的样本或有的样本测序质量不好，尚未能表现出星状扩张，但我相信如果能扩大测序样本的数目，也是能找到类似星簇的扩张的。（我还暂时没有给这两支起名字。）这样，把这两支也加上，<strong>这五个新石器祖先的后代就能占到汉族及中国人**</strong>60%<strong>**的比例了</strong>。</p>
<p><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image025.png" alt="img"><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image026.png" alt="img"><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image027.png" alt="img"><img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image028.png" alt="img"></p>
<p> <img src="/../images/%E4%BA%BA%E9%A1%9E%E5%AD%B8%E9%9B%9C%E8%A8%98%E2%80%94%E2%80%9424%E4%B8%AD%E5%9C%8B%E4%BA%BA%E7%9A%84%E8%B6%85%E7%B4%9A%E7%A5%96%E5%85%88/clip_image029.png" alt="img"></p>
<p>（上图是五支祖先大致的分布范围和所占人口比例。不是严格计算，汉族之外的支系判断可能有错。）</p>
<p>\10. 关于华夏的起源。因为这篇文章计算了时间，所以明确了，<strong>汉族（或中华民族）的大多数姓氏的都起源于一个几千年前叫黄帝的共同父系祖先必然是不可能的</strong>。新石器时代晚期最大的簇（Oα）也不过占汉族父系的16%。不过，这篇文章同样也说明了，史前不远的时代，<strong>华夏确实有少数几个超级祖先，他们短时间繁殖出了大量的后代，也就是说这些有关共同祖先的传说确实是有其原型的，只不过其重要程度被夸大了</strong>。</p>
<p>文章发表历经的坎坷</p>
<p>很多人，包括爱好者和业内人士，都知道我的结果早就出来了，这两年一直都在催问我文章什么时候能出来，位点什么时候能公布。首先，按照通常的科研规范，似乎文章没有经过同行评议，文章没有发出，是不能对外发布消息的。其次，文章是实验室老师辛苦申请基金、多人多年合作做出的结果，随便公布数据而没有相应文章发表是损害实验室利益的，而今后继续申请科研基金、评职称等等，按目前中国的体制，全看文章的影响因子，且只有一作和通讯作者算数。其他的，至少对于生物学来说，发中文文章不算有效工作，合作作者不算，出书不算，做科普不算，这些只能在有闲的时候做。所以，对于这篇文章，首先只能考虑发paper，而且杂志分数越高越好。</p>
<p>这篇文章首次投出是2011年11月，这两年先后投过Nature, Science, Nature Genetics, Nature Communications, PNAS。有的杂志是被编辑直接毙掉，还有的杂志是跟审稿人撦了好几次皮，先后投过3个版本，历经9个月，最后被拒掉的。几次投出之间还有过好几次大的内容的删改，比如突变率的计算方法和SNP-STR对照比较等，还有改文章的着重点等。前一次拒掉和下一次投出之间改文章经常又要花几个月。这两年，好几篇实验做得并不如我们的文章登上了Science或Genome Research这样的杂志，我们文章的新颖性也越来越差。</p>
<p>最终为了避免文章中的发现变得一钱不值，我出于促进知识传播和对我的青春负责的理念，决定还是先把文章公开到arXiv上。这个数据库是没有同行评审的，也就是说只有靠读者来衡量文章的价值。但这上面的文章能被引用。有同行评审的杂志我也还在投着，就算能发出去，分数也没多少了。从考核体系角度看，这四年的我和同事的工作和花的研究经费就算喂狗了，我的稳定教职也没戏了，只能继续做一个二站的博后。（话说，有时候很明显从编辑和审稿人打回的意见里能感觉到对中国或东方人的歧视。这篇文章的作者全都是中国人，复旦大学或者中科院计算生物所的成员。因为发表时间拖久了，文章本来的亮点一个个被别人的文章抢了去，也只得把题目从一个全球性的时间计算改成关于中国人祖先扩张的，导致文章更难发表。如果是关于犹太人或者欧洲人的文章，经常是随便一点儿数据都能发到高分杂志。之前曹操后代那篇文章也只投到了日本的Journal of Human Genetics杂志。）</p>
<p>这期间我如果做错了什么，或者什么原因造成的文章难以发表，有什么更好的信息发布方案，都可以帮忙指出，如果有办法能同时兼顾知识传播和实验室利益，我会很感激的。</p>
<p>首發於2013.10.18，新浪博客<br> 修改於2014.01.30</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-杂记</tag>
      </tags>
  </entry>
  <entry>
    <title>信息熵</title>
    <url>/post/4c350e9d.html</url>
    <content><![CDATA[<p>我们简单介绍了<a href="https://aichn.cn/post/6375c8f0.html">香农信息量</a>的概念，由香农信息量我们可以知道对于一个已知概率的事件，我们需要多少的数据量能完整地把它表达清楚，不与外界产生歧义。但对于整个系统而言，其实我们更加关心的是表达系统整体所需要的信息量。比如我们上面举例的aaBaaaVaaaaa这段字母，虽然B和V的香农信息量比较大，但他们出现的次数明显要比a少很多，因此我们需要有一个方法来评估整体系统的信息量。</p>
<p>相信你可以很容易想到利用期望这个东西，因此评估的方法可以是：“事件香农信息量×事件概率”的累加。这也正是信息熵的概念。</p>
<p>如aaBaaaVaaaaa这段字母，信息熵为：<br>$$<br>-\frac{5}{6}log_2\frac{5}{6}-2×\frac{1}{12}log_2\frac{1}{12}=0.817<br>$$<br>abBcdeVfhgim这段字母，信息熵为：<br>$$<br>-12×\frac{1}{12}log_2\frac{1}{12}=3.585<br>$$<br>从数值上可以很直观地看出，第二段字母信息量大，和观察相一致。</p>
<p>对于连续型随机变量，信息熵公式变为积分的形式，如下：</p>
<p>$$<br>H ( p ) = H ( X ) = \mathrm { E } _ { x \sim p ( x ) } [ - \log p ( x ) ] = - \int p ( x ) \log p ( x ) d x<br>$$</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>共轭函数</title>
    <url>/post/e66f8853.html</url>
    <content><![CDATA[<p>共轭函数在最近火的不行的Gan生成对抗神经网络进阶版本的数学推理中有着神奇的作用，因此在这边记录下。</p>
<p>共轭函数的定义为：<br>$$<br>f ^ { * } ( t ) = \max _ { x \in \operatorname { dom } ( f ) } { x t - f ( x ) }<br>$$<br>当然如果去百度它不是这么写的，但这么写和一般的写法等价。</p>
<p>这个公式的<br>$$<br>x \in \operatorname { dom } ( f )<br>$$<br>表示x要在f的定义域内取值，这个蛮好理解的，不在定义域内就算不了。</p>
<p>那它具体在干一件什么事情呢？</p>
<p>可以看到式子的自变量是t，而当t定住后，式子希望在定义域内找到一个x使得右边大括号内的式子取得最大值。</p>
<p>它的物理意义是什么呢？</p>
<p>可以看到当t定住的时候，式子其实变成了y=xt−f(x)，如果高兴也可以再把左右拆开，这样就会发现左边其实是以t为斜率的一根直线，而右边则是x的函数，那么max这货就是要找到原函数f(x)和以t为斜率的直线的最大距离点对应的<br>$$<br>x ^ { * }。<br>$$</p>
<p>说实在的，上面的解释我一看就懂，但完全不知所谓，心中十万只草泥马。最核心的问题在于，这个物理意义一点都不直观，而且这个公式怎么来的也不大清楚，感觉就是数学家随便写出来，然后脑袋一拍发现这东西有奇效！后面百度发现错怪了数学家，是物理学家搞出来的。。。我相信肯定有原因让他们把式子列成这样，但没查到，如果有知道的老哥请告诉我，万分感谢！</p>
<p>那么来看看它有什么性质好了。有两个比较重要的：</p>
<p>1.无论f(t)是不是凸函数，<br>$$<br>f ^ { * } ( t )<br>$$<br>是凸函数。</p>
<p>2.凸函数的共轭函数的共轭函数是它自己。</p>
<p>第一点其实蛮不明显的，尤其是看着<br>$$<br>f ^ { * } ( t )<br>$$<br>的表达式一晚上我也没想到怎么证明，但看到百度百科直接写”很明显能看出它是凸函数”然后半句解释都没有，而有些博客文章直接把这句话就抄了。。。给跪了。</p>
<p>那为什么呢？<br><img src="/../images/%E5%85%B1%E8%BD%AD%E5%87%BD%E6%95%B0/20190108162456372.png" alt="在这里插入图片描述"><br>上面是李宏毅大神的视频给出的图，因为在式子中tt是自变量，因此{xt−f(x)}其实是一堆的直线。而我们取定一个t要使得式子最大，其实就是做t轴的垂线，看看和垂线相交的最上面的点是哪个那就是最大值。<br><img src="/../images/%E5%85%B1%E8%BD%AD%E5%87%BD%E6%95%B0/20190108163002916.png" alt="在这里插入图片描述"></p>
<p>这样当我们跑完整个t之后，就可以得到<br>$$<br>f ^ { * } ( t )<br>$$<br>的表达式。</p>
<p><img src="/../images/%E5%85%B1%E8%BD%AD%E5%87%BD%E6%95%B0/20190108163103218.png" alt="在这里插入图片描述"><br>这个时候通过观察可以直接看出，<br>$$<br>f ^ { * } ( t )<br>$$<br>的斜率一定是不断增大的！那么它就是凸函数。当然从图上看可能会觉得虽然斜率是一直在增大，但在有些地方是不变的，这里无法直接从图上看出它是严格的凸函数，因此在这里存疑。但凸函数这点是一定的。</p>
<p>再来看第二点。假设现在t固定，而我们要求xt−f(x)的最大值其实就是要求式子对x求导后为0的位置。很容易可以算出最大值在f′(x)=t时取得。而因为f(x)是凸函数，因此只有唯一的一个x使得f′(x)=t，也就是说从原函数到其共轭函数x和t是一对一一对应关系。又从性质一我们知道反过来也是成立的。结合两个函数都是凸函数且变量互相一一对应，可以得出凸函数的共轭函数的共轭函数一定是它自己，如下图：<br><img src="/../images/%E5%85%B1%E8%BD%AD%E5%87%BD%E6%95%B0/20190108163723173.png" alt="在这里插入图片描述"><br>假设<br>$$<br>x_?\not=x_1<br>$$<br>则虚线部分将存在无映射的情况，与已知相背。当然这解释有点抽象，但实在是水平有限，不知道怎么从公式本身来证明这件事情。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树中结点的特征选择方法</title>
    <url>/post/e5078155.html</url>
    <content><![CDATA[<h3 id="一、信息增益"><a href="#一、信息增益" class="headerlink" title="一、信息增益"></a>一、信息增益</h3><p> 信息增益用在ID3决策树中，信息增益是依据熵的变化值来决定的值。</p>
<p> 熵：随机变量不确定性大小的度量。熵越大，变量的不确定性就越大。</p>
<p> 熵的公式表示：</p>
<p>​     X的概率分布为P(x=xi) = pi, i=1,2,3…(x可能的取值)，随机变量X熵为<img src="/../images/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E7%BB%93%E7%82%B9%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95/gif.latex" alt="img">，并且0log0=1。</p>
<p>​    条件熵：H(Y|X)表示在随机变量X的条件下随机变量Y的不确定性。<img src="/../images/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E7%BB%93%E7%82%B9%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95/gif.latex" alt="img"></p>
<p>​    在决策树中，Y即是数据集，X即是某个特征，即条件熵就是数据集在特征A划分条件下的熵。</p>
<p>​    信息增益：数据集D的熵H(D)与特征A给定条件下D的条件熵H(D|A)之差。g(D|A)=H(D)-H(D|A)</p>
<p>​    因此根据信息增益决策划分节点时特征选择方法是：对训练数据集D，计算其每隔特征的信息增益，并比较它们的大小，选择信息增益最大的特征。</p>
<h3 id="二、信息增益比"><a href="#二、信息增益比" class="headerlink" title="二、信息增益比"></a>二、信息增益比</h3><p>​    以信息增益作为划分数据集的特征，存在偏向于选择去取值较多的特征的问题，这时候可以使用信息增益比对这一问题进行修正。C4.5决策树正是基于信息增益比进行特征的选择进行结点的分割。</p>
<p>​    信息增益比定义：特征A对于训练集D的信息增益比定义为信息增益g(D|A)与数据集D关于特征A的值得熵之比。</p>
<p>​    公式定义：<img src="/../images/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E7%BB%93%E7%82%B9%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95/gif.latex" alt="img">,其中<img src="/../images/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E7%BB%93%E7%82%B9%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95/gif.latex" alt="img">。</p>
<p>​    关于为什么信息增益比可以修正信息增益存在偏向去选择取值较多的特征的问题，可以认为当一个特征取值特别多时，会分出很多个子结点，当数据集不是很大时，每个子结点只能有很少的数据，大数定律满足条件性更差，不能体现整体数据集的分布，从而使得不确定性减小，比如这个特征有N个取值，且数据集恰好有N个例子，从而每个结点只有一个数据，从而每点的熵均为0，从而加起来也为0，从而信息增益最大。然而，当数据集十分大足够大时，就不会存在这种问题了。</p>
<h3 id="三、基尼指数-Gini"><a href="#三、基尼指数-Gini" class="headerlink" title="三、基尼指数(Gini)"></a>三、基尼指数(Gini)</h3><p>​    CART树分为回归树和分类树，CART分类树结点选择特征进行分裂时选择特征的方法就是基尼指数。</p>
<p>​    分类问题中，假设有K个类，样本点属于第k类的概率为<img src="/../images/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E7%BB%93%E7%82%B9%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95/gif.latex" alt="img">,则概率分布的基尼指数定义为：</p>
<p>​    <img src="/../images/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%AD%E7%BB%93%E7%82%B9%E7%9A%84%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E6%96%B9%E6%B3%95/gif.latex" alt="img">.</p>
<p>​    基尼指数Gini(D)表示集合D的不确定性，基尼指数Gini(D，A)表示经A=a分割后集合D的不确定性，基尼指数越大，样本集合的不确定性也就越大，与熵类似。</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>-大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积与转置卷积</title>
    <url>/post/525002ea.html</url>
    <content><![CDATA[<p>卷积与转置卷积</p>
<p><img src="/../images/%E5%8D%B7%E7%A7%AF%E4%B8%8E%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/20190110171022961.jpg" alt="在这里插入图片描述"><br>得益于神经网络崛起，卷积成为近些年大热的数学词汇，不再只是待在信号处理这门要命的课程之中。</p>
<p>关于卷积在图像处理中的应用，操作部分看上图就明白了：假设输入图像的大小为 5 x 5，局部感受野（或称<strong>卷积核</strong>）的大小为 3 x 3，那么输出层一个神经元所对应的计算过程如上图所示。动态一点的话也可以看下面的动图。<br><img src="/../images/%E5%8D%B7%E7%A7%AF%E4%B8%8E%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/20190110171546140.gif" alt="在这里插入图片描述"><br>而为什么要这么算，如果学过一点图像处理就很好说明，图像处理的经典边缘提取算法如canny，sobel等，或者其他一些经典算法，其实归根结底就是一个卷积过程，只不过里面的卷积核是人为设定的而已。相比于神经网络的全连接层，用卷积层更加能够快速提取到图像的局部信息，也因此更有旋转不变性等的优势，此外需要训练的参数量相比全连接也要少的多。</p>
<p>在实做方面，为了效率，往往会把卷积计算用矩阵来做。</p>
<p>假设一个卷积操作，它的输入是 4x4，卷积核大小是 3x3，步长为 1x1，输出则为 2x2，如下所示：</p>
<p>我们将其从左往右，从上往下以的方式展开，</p>
<ul>
<li>输入矩阵可以展开成维数为 [16, 1] 的矩阵，记作 x</li>
<li>输出矩阵可以展开成维数为 [4, 1] 的矩阵，记作 y</li>
<li>卷积核可以表示为 [4, 16] 的矩阵，记作 C，其中非 0 的值表示卷积对应的第 i 行 j 列的权重。<img src="/../images/%E5%8D%B7%E7%A7%AF%E4%B8%8E%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/20190110171627110.png" alt="在这里插入图片描述"></li>
<li>所以卷积可以用 y = C * x = [4, 16] * [16, 1]=[4, 1]y=C∗x=[4,16]∗[16,1]=[4,1]来表示</li>
</ul>
<p>那卷积就说完了（padding那些并没提及，后面再补吧，比较简单）。</p>
<p>下面看看转置卷积。它火起来应该是从FCN（Fully Convolutional Networks for Semantic Segmentation）这篇论文开始的。该论文提出了一种全卷积神经网络，然后通过转置卷积对最后一层（或者倒数几层）进行上采样，将图像的大小恢复到与输入图像一样，该文章为语义分割指出了一条明路，也使得转置卷积看起来非常高大上。但其实，这个东西并没有什么神奇的。。。</p>
<p>首先再看一下<br><img src="/../images/%E5%8D%B7%E7%A7%AF%E4%B8%8E%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/20190110171717569.png" alt="在这里插入图片描述"><br>卷积的示意图，下面的1只参与生成上面的1，而下面的2参与生成上面的1、2。那么我们能不能反过来，把这一过程逆向呢？答案是可以的，就是下面这张图：<br><img src="/../images/%E5%8D%B7%E7%A7%AF%E4%B8%8E%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/20190110171753705.png" alt="在这里插入图片描述"><br>我们把小图像按照需要扩展一下（下面虚线部分），然后其他部分按照卷积那么算就可以了。它得到的大小会跟卷积前的一样。巧妙的是上面的1只受下面的1影响，而上面的2受到下面的1、2影响，刚刚好就是一对逆向关系。如果把现在的小图像写在右边，卷积核矩阵写在左边，那么该卷积核矩阵写出来刚刚好就是正常卷积的卷积核矩阵的转置。所以这种卷积叫做转置卷积。</p>
<p>这里面有个问题可以稍微看下，那就是对原图做卷积然后再做转置卷积的过程是一个从大到小再到大的过程，那么开始和结束是一样的吗？</p>
<p>答案是不一样的，这个过程会丢失图像信息。至于丢多少主要取决于中间的”小”能保存多少。但这对于语义分割是OK的，因为我们最终要得到的信息会比原图少的多。</p>
<p>另外在本人看来，因为神经网络的权重都是要训练之后得出来的，因此其实转置卷积和正常卷积看起来真的没有多大的不同，不过就是在正常卷积不填充的情况下会把图像变小，而转置卷积一定会填充而把图像变大罢了。</p>
<p>在pytorch中使用转置卷积的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding:utf-8</span><br><span class="line">from PIL import Image</span><br><span class="line">import numpy as np</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line"></span><br><span class="line">x&#x3D;Image.open(&quot;demo.jpg&quot;)</span><br><span class="line">x.show()</span><br><span class="line">x&#x3D;transforms.ToTensor()(x)</span><br><span class="line">x&#x3D;torch.unsqueeze(x,0)#添加一个维度</span><br><span class="line">conv_trans &#x3D; nn.ConvTranspose2d(3, 3,(12,12), 2)# 定义转置卷积</span><br><span class="line">y&#x3D;conv_trans(x)#转置卷积计算</span><br><span class="line">y&#x3D;torch.squeeze(y)#扔掉一个维度</span><br><span class="line">#结果显示</span><br><span class="line">imgout&#x3D;transforms.ToPILImage()(y)</span><br><span class="line">print(x.shape)</span><br><span class="line">print(y.shape)</span><br><span class="line">imgout.show()</span><br></pre></td></tr></table></figure>
<p>原图<br><img src="/../images/%E5%8D%B7%E7%A7%AF%E4%B8%8E%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/20190111094531172.png" alt="在这里插入图片描述"><br>结果：<br><img src="/../images/%E5%8D%B7%E7%A7%AF%E4%B8%8E%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF/2019011109465584.png" alt="在这里插入图片描述"></p>
<p>从图上可以看到，pytorch在初始化的时候应该已经将转置卷积核参数设置成特征提取的形式了。</p>
<p>参考文章：</p>
<p><a href="https://www.jianshu.com/p/09ea4df7a788?utm_source=oschina-app">https://www.jianshu.com/p/09ea4df7a788?utm_source=oschina-app</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1363619">https://cloud.tencent.com/developer/article/1363619</a></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能 -神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>VirtualminWebmin安装与使用强大的VPS服务器和虚拟主机管理系统</title>
    <url>/post/8ff6ed20.html</url>
    <content><![CDATA[<h2 id="在FreeNAS-BSD搭建基于Nginx-FastCGI-MySQL-PHP的WebServer"><a href="#在FreeNAS-BSD搭建基于Nginx-FastCGI-MySQL-PHP的WebServer" class="headerlink" title="在FreeNAS/BSD搭建基于Nginx+FastCGI+MySQL+PHP的WebServer"></a>在FreeNAS/BSD搭建基于Nginx+FastCGI+MySQL+PHP的WebServer</h2><p>使用FreeNAS也快半月月了，在上一篇文章介绍了利用FreeNAS能做的一些事情，其中一项是WebServer。搭建了FreeNAS之后，这项功能也是必不可少的，简单分享一下配置步骤，希望能帮助到同我一样的刚刚接触FreeNAS（同样适用于FreeBSD）的朋友。</p>
<p>在FreeNAS之前，一直都是在Atom上跑Windows，因为作为文件服务器，除了存储文件/共享（Windows的局域网共享做这个确实很方便，但相比FreeNAS内置的SMB，还是稍显复杂，因为还需要通过一些不算简单的设置，才能解决NTFS权限问题，而FreeNAS中，都为你做好了），还有一个更重要的功能就是下载，虽然迅雷的资源共享方式稍显流氓，但其下载速度和资源探索能力也是无需置疑的（之后也会介绍一下如何利用FreeNAS/BSD打造属于自己的全能下载机）。</p>
<p>说实话，相比Windows用了十数年，对于类unix系统，我是相当的不熟悉，也是毕业以后，由于工作需要，才渐渐的接触一些。时至至今，也只会通过apt-get pkg_add等方式来安装软件。在Windows下，一直都是用几年前自己写的一套脚本来安装基于Apache+MySQL+PHP的服务器，初次接触FreeBSD，参考了网上很多资料也终于实现了基于Nginx+FastCGI+MySQL+PHP的WebServer。</p>
<p>以下所有的操作步骤都是在Shell下完成，可以在FreeNAS启动后，通过Console菜单6 Shell或在WebGUI中开启SSH服务登录。</p>
<h3 id="安装PHP"><a href="#安装PHP" class="headerlink" title="安装PHP"></a>安装PHP</h3><p>如果你是在FreeNAS上安装PHP，请特别注意下面的几步，若是在FreeBSD上安装，可以忽略cp，mv的步骤，直接通过pkg_add安装PHP。</p>
<p>因为安装FreeNAS的WebGUI是基于Lighttpd+PHP，重新安装PHP会引起系统崩溃，不仅WebGUI无法启动，连系统都无法引导，因此将PHP的安装放在第一步，如果这一步没有问题，后面的就都简单了。当时我也是经过N次失败才找到这个问题，分享出来，希望大家不要走弯路。</p>
<p>首先，需要备份一个重要的文件，因为在PHP的安装后，会覆盖掉这个文件，而正是这个文件引起系统无法启动和WebGUI不能访问。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usrlocalliblibxml2.so.5 tmplibxml2.so.5</span><br></pre></td></tr></table></figure>
<p>然后开始安装PHP</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pkg_add  php5</span><br><span class="line">pkg_add  php5-extensions</span><br><span class="line">pkg_add  php5-xmlrpc</span><br><span class="line">pkg_add  php5-gettext</span><br><span class="line">pkg_add  php5-mcrypt</span><br><span class="line">pkg_add  php5-mbstring</span><br></pre></td></tr></table></figure>
<p>注意安装完后切忌不要重启，再继续输入下面的命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usrlocalbinphp usrlocalbinphp-cli usrlocalbinphp-cgi usrlocalbinphp usrlocalliblibxml2.so.5 tmplibxml2.so.5 usrlocalliblibxml2.so.5</span><br></pre></td></tr></table></figure>
<p>至此PHP安装完成，请重启你的FreeNAS，如果能够正常访问WebGUI，恭喜你，接下去的步骤就简单多了。</p>
<h3 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pkg_add  mysql50-serverusrlocalbinmysql_install_db  mysql vardbmysqlusrlocalbinmysqld_safe usrlocalbinmysqladmin  root password</span><br></pre></td></tr></table></figure>
<p>修改/etc/rc.conf加入mysql_enable=”YES”，至此MySQL安装完成。</p>
<h3 id="安装Nginx-FastCGI"><a href="#安装Nginx-FastCGI" class="headerlink" title="安装Nginx+FastCGI"></a>安装Nginx+FastCGI</h3><p>由于FreeNAS的WebGUI已占用了80端口，因此建议先通过WebGUI&gt;System&gt;General&gt;WebGUI&gt;Port将WebGUI的端口改为其他，例如88。</p>
<p>参阅了大量网上的Nginx+PHP的配置方案，无一例外都是通过lighttpd的spawn-fcgi来实现，这个脚本找了很久也没找到，虽然FreeNAS自带Lighttpd，我也没在系统内找到……，于是我只好重新安装了一遍Lighttpd。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pkg_add  nginx</span><br><span class="line">pkg_add   lighttpd 0777 usrlocaletcnginxnginx.conf</span><br></pre></td></tr></table></figure>
<p>编辑/usr/local/etc/nginx/nginx.conf，找到以下配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> &#x2F; &#123;</span><br><span class="line">        root   &#x2F;usr&#x2F;local&#x2F;www&#x2F;nginx;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在index最后增加index.php</p>
<p>找到以下配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#location ~ \.php$ &#123;#    root           html;#    fastcgi_pass   127.0.0.1:9000;#    fastcgi_index  index.php;#    fastcgi_param  SCRIPT_FILENAME  &#x2F;scripts$fastcgi_script_name;#    include        fastcgi_params;#&#125;</span><br></pre></td></tr></table></figure>
<p>去掉行首的注释符#，并改为以下内容。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> ~ \.php$ &#123;</span><br><span class="line">        root           html;</span><br><span class="line">        fastcgi_pass   127.0.0.1:;</span><br><span class="line">        fastcgi_index  index.php;</span><br><span class="line">        fastcgi_param  SCRIPT_FILENAME  &#x2F;usr&#x2F;local&#x2F;www&#x2F;nginx$fastcgi_script_name;                fastcgi_params;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至此Nginx安装完成，然后通过下面的脚本分别启动FastCGI和Nginx。此脚本建议加入/etc/rc.local随机启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usrlocalbinspawn-fcgi  127.0.0.1    www  www    usrlocalbinphp-cgiusrlocalsbinnginx</span><br></pre></td></tr></table></figure>
<p>然后在/usr/local/www/nginx目录下新建index.php。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?php echo phpinfo();</span><br></pre></td></tr></table></figure>
<p>输入<a href="http://nas-ip/index.php%EF%BC%8C%E6%98%AF%E4%B8%8D%E6%98%AF%E7%9C%8B%E5%88%B0%E4%BA%86%E4%B9%85%E8%BF%9D%E7%9A%84phpinfo%EF%BC%9F">http://nas-ip/index.php，是不是看到了久违的phpinfo？</a></p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>-linux</tag>
      </tags>
  </entry>
  <entry>
    <title>同时使用gitee和github</title>
    <url>/post/22309.html</url>
    <content><![CDATA[<p>Git共有三个级别的config文件，分别是：</p>
<ul>
<li><strong>system</strong> ：%GitPath%\mingw64\etc\gitconfig文件</li>
<li><strong>global</strong>：$home.gitconfig文件</li>
<li><strong>local</strong>：%RepoPath%.git\config文件</li>
</ul>
<p>其中<code>%GitPath%</code>为Git的安装路径，<code>%RepoPath%</code>为某仓库的本地路径。</p>
<ol>
<li>删掉全局配置</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global --list</span><br><span class="line">$ git config --global --unset user.name &quot;你的名字&quot;</span><br><span class="line">$ git config --global --unset user.email &quot;你的邮箱&quot;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>为不同账户配置ssh秘钥</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd ~&#x2F;.ssh 														# cd到当前用户的.ssh文件夹</span><br><span class="line">ssh-keygen -t rsa -f ~&#x2F;.ssh&#x2F;id_rsa.gitee -C &quot;注册gitee邮箱&quot;		#为不同秘钥指定名称</span><br><span class="line">ssh-keygen -t rsa -f ~&#x2F;.ssh&#x2F;id_rsa.github -C &quot;注册github邮箱&quot;</span><br></pre></td></tr></table></figure>
<p>完成后会在~/.ssh / 目录下生成以下文件：</p>
<ul>
<li>id_rsa.github</li>
<li>id_rsa.github.pub</li>
<li>id_rsa.gitee</li>
<li>id_rsa.gitee.pub</li>
</ul>
<p>复制公钥分别在github和gitee中设置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat id_rsa.github.pub</span><br><span class="line">cat id_rsa.gitee.pub</span><br></pre></td></tr></table></figure>
<p>添加新的私钥</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ ssh-agent bash</span><br><span class="line">$ ssh-add ~&#x2F;.ssh&#x2F;id_rsa.github</span><br><span class="line">$ ssh-add ~&#x2F;.ssh&#x2F;id_rsa.gitee	</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>进行全局配置</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">touch ~&#x2F;.ssh&#x2F;config    </span><br><span class="line"></span><br><span class="line"># gitee</span><br><span class="line">Host gitee.com</span><br><span class="line">HostName gitee.com</span><br><span class="line">PreferredAuthentications publickey</span><br><span class="line">IdentityFile ~&#x2F;.ssh&#x2F;id_rsa.gitee</span><br><span class="line"></span><br><span class="line"># github</span><br><span class="line">Host github.com</span><br><span class="line">HostName github.com</span><br><span class="line">PreferredAuthentications publickey</span><br><span class="line">IdentityFile ~&#x2F;.ssh&#x2F;id_rsa.github</span><br></pre></td></tr></table></figure>
<p>Host 它涵盖了下面一个段的配置，我们可以通过他来替代将要连接的服务器地址。 这里可以使用任意字段或通配符。 当ssh的时候如果服务器地址能匹配上这里Host指定的值，则Host下面指定的HostName将被作为最终的服务器地址使用，并且将使用该Host字段下面配置的所有自定义配置来覆盖默认的/etc/ssh/ssh_config配置信息。</p>
<p>Port 自定义的端口。默认为22，可不配置</p>
<p>User 自定义的用户名，默认为git，可不配置</p>
<p>HostName 真正连接的服务器地址</p>
<p>PreferredAuthentications 指定优先使用哪种方式验证，支持密码和秘钥验证方式</p>
<p>IdentityFile 指定本次连接使用的密钥文件</p>
<ol start="4">
<li>测试连接</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -T git@github.com</span><br><span class="line">Hi yourname! You&#39;ve successfully authenticated, but GitHub does not provide shell access.</span><br><span class="line">ssh -T git@gitee.com</span><br><span class="line">Hi yourname! You&#39;ve successfully authenticated, but GITEE.COM does not provide shell access.</span><br></pre></td></tr></table></figure>
<ol start="5">
<li>hexo博客仓库</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi .depoly_git&#x2F;.git&#x2F;config 增加</span><br><span class="line"></span><br><span class="line">[user]</span><br><span class="line">	name &#x3D; username</span><br><span class="line">	email &#x3D; email</span><br></pre></td></tr></table></figure>
<ol start="6">
<li>针对不同的项目仓库</li>
</ol>
<p>增加本地配置，在每个仓库的<code>.git/config</code>中进行配置不同的用户，以及其他的配置信息</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git config --local user.name &#39;github&#x2F;gitee账号名&#39;</span><br><span class="line">$ git config --local user.email &#39;github&#x2F;gitee账号邮箱&#39;</span><br></pre></td></tr></table></figure>
<p>–global是在全局配置文件中设置</p>
<p>–local 是针对当前仓库的项目进行设置</p>
<p>参考文章：</p>
<p><a href="https://juejin.im/post/6844904180633600007">https://juejin.im/post/6844904180633600007</a></p>
<p><a href="https://www.jianshu.com/p/68578d52470c">https://www.jianshu.com/p/68578d52470c</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-其他</tag>
      </tags>
  </entry>
  <entry>
    <title>在windows环境下让XAMPP使用Nginx作为Web服务器</title>
    <url>/post/a40b0852.html</url>
    <content><![CDATA[<h1 id="windows中下载（xampp）apache后使用nginx作为服务器"><a href="#windows中下载（xampp）apache后使用nginx作为服务器" class="headerlink" title="windows中下载（xampp）apache后使用nginx作为服务器"></a>windows中下载（xampp）apache后使用nginx作为服务器</h1><p>首先去php文件夹那里, 把那个php.ini Copy一份, 命名为php-cli.ini 让nginx使用. 而不会影响Apache 的使用。</p>
<p>打开php-cli.ini，配置下面几个 参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">enable_dl &#x3D; On;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cgi.force_redirect &#x3D; 0;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cgi.fix_pathinfo&#x3D;1;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">fastcgi.impersonate &#x3D; 1;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cgi.rfc2616_headers &#x3D; 1;</span><br></pre></td></tr></table></figure>
<p>然后下载nginx <a href="http://nginx.org/en/download.html%E8%A7%A3%E5%8E%8B">http://nginx.org/en/download.html解压</a></p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/20190424100333193.png" alt="img"></p>
<p>在nginx上部署项目</p>
<p>打开conf文件夹下的nginx.conf文件进行配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        listen       889;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        server_name  www.zch.com;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        #charset koi8-r;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        #access_log  logs&#x2F;host.access.log  main;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		root   C:&#x2F;xampp&#x2F;htdocs&#x2F;phpproject&#x2F;tp5&#x2F;public&#x2F;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        location &#x2F; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            index  index.html index.htm index.php;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            autoindex  on;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">             </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">          if (!-e $request_filename) &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            rewrite  ^(.*)$  &#x2F;index.php?s&#x3D;&#x2F;$1  last;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            break;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">          &#125; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        #error_page  404              &#x2F;404.html;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        # redirect server error pages to the static page &#x2F;50x.html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        #</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        error_page   500 502 503 504  &#x2F;50x.html;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        location &#x3D; &#x2F;50x.html &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            root   html;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	    location ~ \.php$ &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">				fastcgi_pass   127.0.0.1:9001;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                fastcgi_index  index.php;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                fastcgi_split_path_info  ^((?U).+\.php)(&#x2F;?.+)$;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                fastcgi_param  PATH_INFO  $fastcgi_path_info;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                fastcgi_param  PATH_TRANSLATED  $document_root$fastcgi_path_info;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                include        fastcgi_params;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>在C:\Windows\System32\drivers\etc\hosts文件下 ， 配置虚拟目录，即是配置文件中的server name</p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/2019042410140472.png" alt="img"></p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/20190424101422546.png" alt="img"></p>
<p>启动nginx（如果端口号被占用的话就换一个端口号）</p>
<p>切换到php目录，执行 php-cgi.exe -b 127.0.0.1:9001 -c C:\xampp\php\php-cli.ini，</p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/20190424100502412.png" alt="img"></p>
<p>切换到nginx目录，启动nginx</p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/20190424100516752.png" alt="img"></p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/20190424101527533.png" alt="img"></p>
<p>以上结束</p>
<h1 id="参考方法一："><a href="#参考方法一：" class="headerlink" title="参考方法一："></a>参考方法一：</h1><p>说实话, 在windows下使用Nginx 着实有点不太方便, 但因项目需求, 又不想换系统(虽然可以搞个虚拟机玩), 只能用Nginx了</p>
<p>好了, 不多说了. 开始…</p>
<p>首先我用的是xampp包(Apache+Mysql+php+perl) 用的是3.2.2版, 这里各自喜欢…不多说</p>
<p>一般我是把xampp安装在D:\xampp下的…</p>
<p>首先去下载一个Nginx的包.. 戳这-&gt;<a href="http://nginx.org/en/download.html">http://nginx.org/en/download.html</a> 有三个版的(Mainline version / Stable version / Legacy versions )  我是下了个稳定版的 即Stable version ,不要问为什么, 因为稳定!</p>
<p>下完后就可以解压至D:\xampp\nginx 了… 如图:</p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/997515-20161227134916679-1887516644.png" alt="img"></p>
<p>这里得去php文件夹那里, 把那个php.ini Copy一份, 命名为php-cli.ini 这个就是为了给Nginx玩的. 而不会影响Apache 的使用….</p>
<p>好了. 到这里, 就打开php-cli.ini(建议文本器打开)</p>
<p>配置一下下面几个 直接查找就行了::</p>
<p>enable_dl = On;</p>
<p>cgi.force_redirect = 0;</p>
<p>cgi.fix_pathinfo=1;</p>
<p>fastcgi.impersonate = 1;</p>
<p>cgi.rfc2616_headers = 1;</p>
<p>OK 现在就可以打开nginx.exe了 </p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/997515-20161227141543882-949700058.png" alt="img"></p>
<p>(这里的-b 应该是 -a 和 -p 的集合…吧)</p>
<p>然后再开一个cmd 下输 D:\xampp\nginx\nginx</p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/997515-20161227141607054-964655387.png" alt="img"></p>
<p>这里有点麻烦就是, 如果挂了. 就得重新打开一个cmd… D:\xampp\nginx\nginx -s reload</p>
<p>也可以这样处理, 关闭Nginx </p>
<p>taskkill /F /IM nginx.exe &gt; nul</p>
<p>taskkill /F /IM php-cgi.exe &gt; nul</p>
<p>建议如果是改了配置的话, 得先使用 nginx -t 测试看有没有报错. 再reload 或者其它操作</p>
<p>还有我看了下网上说的, 可以借助<a href="https://skydrive.live.com/redir?resid=1E48DF64F8BD957!202">RunHiddenConsole</a> 来管理Nginx (这里我没试过, 有空得搞搞)</p>
<p><strong>注意: nginx不能和apache 同时使用, 因为他们默认都使用同一个端口 所以你开nginx得把apache干掉</strong></p>
<p><strong><em>Nginx 配置\</em></strong>:</p>
<p>打开nginx\conf\nginx.conf</p>
<p>这里我是直接引入了文件夹去找其它的配置</p>
<p>像这样(-^-)</p>
<p>include web/*.conf; </p>
<p><img src="/../images/%E5%9C%A8windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%AE%A9XAMPP%E4%BD%BF%E7%94%A8Nginx%E4%BD%9C%E4%B8%BAWeb%E6%9C%8D%E5%8A%A1%E5%99%A8/997515-20161227140823695-1616046948.png" alt="img"></p>
<p>location / {<br>root D:/xampp/htdocs/;<br>index index.html index.htm index.php;<br>autoindex on;<br>autoindex_exact_size on;<br>autoindex_localtime on;<br>}</p>
<p>location ~* .php$ {<br>root D:/xampp/htdocs/;<br>fastcgi_pass 127.0.0.1:9000;<br>fastcgi_index index.php;<br>include fastcgi.conf;<br>}</p>
<p>配置根站点…</p>
<p>还有配置一下那个phpmyadmin</p>
<p>location = /phpmyadmin/ {</p>
<p>root D:/xampp/;<br>index index.php index.html index.htm;<br>}</p>
<p><strong>location ~* /phpmyadmin/.*.php {</strong></p>
<p><strong>root D:/xampp/;<br>include fastcgi.conf;<br>fastcgi_pass 127.0.0.1:9000;<br>fastcgi_index index.php;<br>#fastcgi_param SCRIPT_FILENAME D:/xampp/$fastcgi_script_name;<br>}</strong></p>
<p> 重新加载配置&gt;&gt;&gt;D:\xampp\nginx\nginx -t &gt;&gt;&gt; D:\xampp\nginx\nginx -s reload</p>
<p>配域名的话这里就不写了. 不会的话,  <a href="http://www.baidu.com/">www.baidu.com</a> 是个好东西.</p>
]]></content>
      <categories>
        <category>建站</category>
      </categories>
      <tags>
        <tag>-win7</tag>
      </tags>
  </entry>
  <entry>
    <title>基于TensorFlow框架搭建一个最简单的CNN框架</title>
    <url>/post/85ca40.html</url>
    <content><![CDATA[<h2 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h2><p>本文将使用python，并借助TensorFlow框架搭建一个最简单的CNN框架，来实现对手写数字的识别。</p>
<h2 id="本文搭建的CNN框架结构"><a href="#本文搭建的CNN框架结构" class="headerlink" title="本文搭建的CNN框架结构"></a>本文搭建的CNN框架结构</h2><p>【1】输入层（本文的输入是一个28<em>28且为单通道的图片，所以输入层有784个节点）<br>【2】第一个卷积层（该卷积层包含了32个不同的5</em>5的卷积核，即该卷积层提取了32种不同图形特征，【5,5,1,32】表示卷积核尺寸为5<em>5,1个颜色通道，32个不同的卷积核）<br>【3】第一个卷积层后的最大池化层<br>【4】第二个卷积层（该卷积层包含了64个不同的5</em>5的卷积核，即该卷积层提取了32种不同图形特征，【5,5,32,64】表示卷积核尺寸为5*5，64个不同的卷积核）<br>【5】第二个卷积层后的最大池化层<br>【6】全连接层<br>【7】一个Dropout层（为了减轻过拟合，在训练时，我们随机丢弃一部分节点的数据来减轻过拟合，预测是则保留全部数据来追求最好的预测性能）<br>【8】Softmax层，得到最后的概率输出。<br>【9】定义损失函数为交叉熵（cross entropy），优化器使用Adam<br>【10】得到模型的预测精度</p>
<h2 id="项目代码"><a href="#项目代码" class="headerlink" title="项目代码"></a>项目代码</h2><h1 id="导入相应的库"><a href="#导入相应的库" class="headerlink" title="导入相应的库"></a>导入相应的库</h1><p>from tensorflow.examples.tutorials.mnist import input_data<br>import tensorflow as tf</p>
<h1 id="导入手写数字数据集"><a href="#导入手写数字数据集" class="headerlink" title="导入手写数字数据集"></a>导入手写数字数据集</h1><p>mnist = input_data.read_data_sets(“MNIST_data/“,one_hot = True)<br>sess = tf.InteractiveSession()</p>
<h1 id="定义生成权重的函数"><a href="#定义生成权重的函数" class="headerlink" title="定义生成权重的函数"></a>定义生成权重的函数</h1><p>def weight_variabel(shape):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">initial &#x3D; tf.truncated_normal(shape,stddev &#x3D; 0.1)return tf.Variable(initial)</span><br></pre></td></tr></table></figure>
<h1 id="定义生成偏重的函数"><a href="#定义生成偏重的函数" class="headerlink" title="定义生成偏重的函数"></a>定义生成偏重的函数</h1><p>def bias_variable(shape):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">initial &#x3D; tf.constant(0.1,shape &#x3D; shape)return tf.Variable(initial)</span><br></pre></td></tr></table></figure>
<h1 id="定义生成卷积层的函数"><a href="#定义生成卷积层的函数" class="headerlink" title="定义生成卷积层的函数"></a>定义生成卷积层的函数</h1><h1 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h1><p>def conv2d(x,W):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">return tf.nn.conv2d(x,W,strides&#x3D;[1,1,1,1],padding&#x3D;&#39;SAME&#39;)</span><br></pre></td></tr></table></figure>
<h1 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h1><h1 id="定义生成最大池化层函数"><a href="#定义生成最大池化层函数" class="headerlink" title="定义生成最大池化层函数"></a>定义生成最大池化层函数</h1><p>def max_pool_2x2(x):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">return tf.nn.max_pool(x,ksize&#x3D;[1,2,2,1],strides&#x3D;[1,2,2,1],</span><br><span class="line">                     padding&#x3D;&#39;SAME&#39;)</span><br></pre></td></tr></table></figure>
<h1 id="传入输入的变量"><a href="#传入输入的变量" class="headerlink" title="传入输入的变量"></a>传入输入的变量</h1><p>x = tf.placeholder(tf.float32,[None,784])</p>
<h1 id="传入标签的变量"><a href="#传入标签的变量" class="headerlink" title="传入标签的变量"></a>传入标签的变量</h1><p>y_ = tf.placeholder(tf.float32,[None,10])</p>
<h1 id="将1D的图片转为28-28的2D照片"><a href="#将1D的图片转为28-28的2D照片" class="headerlink" title="将1D的图片转为28*28的2D照片"></a>将1D的图片转为28*28的2D照片</h1><p>x_image = tf.reshape(x,[-1,28,28,1])</p>
<h1 id="我们定义第一个卷积层"><a href="#我们定义第一个卷积层" class="headerlink" title="我们定义第一个卷积层"></a>我们定义第一个卷积层</h1><h1 id="权重"><a href="#权重" class="headerlink" title="权重"></a>权重</h1><p>W_conv1 = weight_variabel([5,5,1,32])</p>
<h1 id="偏置"><a href="#偏置" class="headerlink" title="偏置"></a>偏置</h1><p>b_conv1 = bias_variable([32])</p>
<h1 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h1><p>h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)</p>
<h1 id="最大池化层"><a href="#最大池化层" class="headerlink" title="最大池化层"></a>最大池化层</h1><p>h_pool1 = max_pool_2x2(h_conv1)</p>
<h1 id="定义第二个卷积层"><a href="#定义第二个卷积层" class="headerlink" title="定义第二个卷积层"></a>定义第二个卷积层</h1><h1 id="权重-1"><a href="#权重-1" class="headerlink" title="权重"></a>权重</h1><p>W_conv2 = weight_variabel([5,5,32,64])</p>
<h1 id="偏置-1"><a href="#偏置-1" class="headerlink" title="偏置"></a>偏置</h1><p>b_conv2 = bias_variable([64])</p>
<h1 id="卷积核-1"><a href="#卷积核-1" class="headerlink" title="卷积核"></a>卷积核</h1><p>h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)</p>
<h1 id="最大池化层-1"><a href="#最大池化层-1" class="headerlink" title="最大池化层"></a>最大池化层</h1><p>h_pool2 = max_pool_2x2(h_conv2)</p>
<h1 id="定义一个全连接层，隐含节点数为1024，并使用ReLU激活函数"><a href="#定义一个全连接层，隐含节点数为1024，并使用ReLU激活函数" class="headerlink" title="定义一个全连接层，隐含节点数为1024，并使用ReLU激活函数"></a>定义一个全连接层，隐含节点数为1024，并使用ReLU激活函数</h1><p>W_fc1 = weight_variabel([7<em>7</em>64,1024])<br>b_fc1 = bias_variable([1024])<br>h_pool2_flat = tf.reshape(h_pool2,[-1,7<em>7</em>64])<br>h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)</p>
<h1 id="为了减轻过拟合，下面使用一个Dropout层，是通过一个placeholder的传输keepr-prob比率来控制的。在训练时，"><a href="#为了减轻过拟合，下面使用一个Dropout层，是通过一个placeholder的传输keepr-prob比率来控制的。在训练时，" class="headerlink" title="为了减轻过拟合，下面使用一个Dropout层，是通过一个placeholder的传输keepr_prob比率来控制的。在训练时，"></a>为了减轻过拟合，下面使用一个Dropout层，是通过一个placeholder的传输keepr_prob比率来控制的。在训练时，</h1><h1 id="我们随机丢弃一部分节点数据来减轻过拟合，预测时我们保留全部数据来追求最好的预测性能"><a href="#我们随机丢弃一部分节点数据来减轻过拟合，预测时我们保留全部数据来追求最好的预测性能" class="headerlink" title="我们随机丢弃一部分节点数据来减轻过拟合，预测时我们保留全部数据来追求最好的预测性能"></a>我们随机丢弃一部分节点数据来减轻过拟合，预测时我们保留全部数据来追求最好的预测性能</h1><p>keep_prob = tf.placeholder(tf.float32)<br>h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)</p>
<h1 id="最后我们将Dropout层的输出连接一个Softmax层，得到最后的概率输出"><a href="#最后我们将Dropout层的输出连接一个Softmax层，得到最后的概率输出" class="headerlink" title="最后我们将Dropout层的输出连接一个Softmax层，得到最后的概率输出"></a>最后我们将Dropout层的输出连接一个Softmax层，得到最后的概率输出</h1><p>W_fc2 = weight_variabel([1024,10])<br>b_fc2 = bias_variable([10])<br>y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)</p>
<h2 id="我们定义损失函数cross-entropy-和之前一样，但是优化器使用Adam，并给予一个小的学习速率1e-4"><a href="#我们定义损失函数cross-entropy-和之前一样，但是优化器使用Adam，并给予一个小的学习速率1e-4" class="headerlink" title="我们定义损失函数cross entropy ,和之前一样，但是优化器使用Adam，并给予一个小的学习速率1e-4"></a>我们定义损失函数cross entropy ,和之前一样，但是优化器使用Adam，并给予一个小的学习速率1e-4</h2><p>cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reduction_indices &#x3D; [1]))</span><br></pre></td></tr></table></figure>
<p>train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</p>
<p>correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))<br>accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</p>
<h1 id="下面开始训练过程，首先是初始化所有参数"><a href="#下面开始训练过程，首先是初始化所有参数" class="headerlink" title="下面开始训练过程，首先是初始化所有参数"></a>下面开始训练过程，首先是初始化所有参数</h1><p>tf.global_variables_initializer().run()<br>for i in range(20000):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">batch &#x3D; mnist.train.next_batch(50)if i % 100 &#x3D;&#x3D; 0:</span><br><span class="line">    train_accuracy &#x3D; accuracy.eval(feed_dict&#x3D; &#123;x:batch[0],y_:batch[1],</span><br><span class="line">                                              keep_prob:1.0&#125;)</span><br><span class="line">    print(&quot;step %d,trainning accuracy %g&quot;%(i,train_accuracy))train_step.run(feed_dict&#x3D;&#123;x:batch[0],y_:batch[1],keep_prob:0.5&#125;)</span><br></pre></td></tr></table></figure>
<p>print(“test accuracy %g”%accuracy.eval(feed_dict={x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0}))</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>如何让Win7开机不输入密码直接登录的方法</title>
    <url>/post/65be3812.html</url>
    <content><![CDATA[<p>电脑是win7的系统，然而也很少别人来玩，但是为了安全还是设置了一个密码，但是每次开机后都需要在本地登录的时候填写密码，那么该如何让Win7开机不输入密码直接登录呢？</p>
<h2 id="方法-步骤"><a href="#方法-步骤" class="headerlink" title="方法/步骤"></a>方法/步骤</h2><ol>
<li><p>点击屏幕左下角开始菜单</p>
<p> 点击运行，若没有运行，那么按win+R键也可以</p>
<p> 在运行的“打开”一行中输入“netplwiz” 点击”确定“</p>
<p> 在弹出的窗口中点中你需要输入密码的那个账号，默认是Administrator 点中之后该帐户背景会变为蓝色</p>
<p> 去掉”要使用本机，用户必须输入用户名和密码“前面框框中的勾。</p>
<p> 最后点击”应用“–在弹出的窗口中输入你电脑的登录密码   最后点击”确定“—“确定” 重启后生效。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>win7</category>
      </categories>
      <tags>
        <tag>-win7</tag>
      </tags>
  </entry>
  <entry>
    <title>安装 - LNMP一键安装包</title>
    <url>/post/398958a0.html</url>
    <content><![CDATA[<p> <a href="https://lnmp.org/install.html">https://lnmp.org/install.html</a></p>
<p><strong>系统需求:</strong></p>
<ul>
<li>CentOS/RHEL/Fedora/Debian/Ubuntu/Raspbian Linux系统</li>
<li>需要5GB以上硬盘剩余空间</li>
<li>需要128MB以上内存(如果为128MB的小内存VPS,Xen的需要有SWAP,OpenVZ的至少要有128MB以上的vSWAP或突发内存)，注意小内存请勿使用64位系统！</li>
<li>**安装MySQL 5.6或5.7及MariaDB 10必须1G以上内存!**。</li>
<li>VPS或服务器必须已经联网，且必须设置的是网络源不能是光盘源，同时VPS/服务器 DNS要正常！</li>
<li>Linux下区分大小写，输入命令时请注意！</li>
</ul>
<p>LNMP一键安装包 V1.3 已经在<a href="https://www.vpser.net/go/photonvps">PhotonVPS</a>、<a href="https://www.vpser.net/go/vultr">Vultr</a>、<a href="https://www.vpser.net/go/aoyohost">遨游主机</a>、<a href="https://www.vpser.net/go/oneasiahost">OneAsiahost新加坡VPS</a>、<a href="https://www.vpser.net/go/bandwagonhost">搬瓦工</a>、<a href="https://www.vpser.net/go/budgetvm">BudgetVM</a>、、<a href="https://www.vpser.net/go/digitalocean">DigitalOcean</a>、<a href="https://www.vpser.net/go/locvps">LocVPS</a>、<a href="https://www.vpser.net/go/linode">Linode</a>、<a href="https://www.vpser.net/go/diahosting">DiaHosting</a>、<a href="https://www.vpser.net/go/rashost">瑞豪开源</a>、<a href="https://www.vpser.net/go/kvmla">KVMLA</a>、<a href="https://www.vpser.net/go/jwdns">景文互联</a>、<a href="https://www.vpser.net/go/ramnode">RamNode</a>、<a href="https://www.vpser.net/go/hostigation">Hostigation</a>、<a href="https://www.vpser.net/go/buyvm">BuyVM</a>、<a href="https://www.vpser.net/go/80vps">80VPS</a>、<a href="https://www.vpser.net/go/xsvps">XSVPS</a>、<a href="https://www.vpser.net/go/hostus">HostUS</a>、<a href="https://www.vpser.net/go/kiiyi">快易互联</a>、<a href="https://www.vpser.net/go/aliyun">阿里云</a>等众多VPS的CentOS 5-7、RHEL 6-7、Fedora 21-23、Debian 7-8、Ubuntu 10.04-16.04的32位和64位系统上测试通过。</p>
<p><strong>安装步骤:</strong><br><strong>1、使用<a href="https://www.vpser.net/other/putty-ssh-linux-vps.html">putty</a>或类似的SSH工具登陆VPS或服务器；</strong></p>
<p>登陆后运行：<strong>screen -S lnmp</strong></p>
<p>如果提示screen: command not found 命令不存在可以执行：yum install screen 或 apt-get install screen安装，详细内容参考<a href="https://www.vpser.net/manage/run-screen-lnmp.html">screen教程</a>。</p>
<p><strong>2、下载并安装LNMP一键安装包：</strong></p>
<p>您可以选择使用下载版(推荐美国及海外VPS或空间较小用户使用)或者完整版(推荐国内VPS使用，国内用户可用在<a href="https://lnmp.org/download.html">下载</a>中找国内下载地址替换)，两者没什么区别，只是完整版把一些需要的源码文件预先放到安装包里。</p>
<p>安装LNMP<br><strong>wget -c <a href="http://soft.vpser.net/lnmp/lnmp1.3.tar.gz">http://soft.vpser.net/lnmp/lnmp1.3.tar.gz</a> &amp;&amp; tar zxf lnmp1.3.tar.gz &amp;&amp; cd lnmp1.3 &amp;&amp; ./install.shlnmp</strong></p>
<p>默认安装lnmp可不写，如需要安装LNMPA或LAMP，将./install.sh 后面的参数替换为lnmpa或lamp即可。如需更改网站和数据库目录先修改 lnmp.conf 文件。</p>
<p>如下载速度慢请更换其他下载节点，详情请看<a href="https://lnmp.org/download.html">下载页面</a>。<a href="https://lnmp.org/faq/lnmp-download-source.html">LNMP下载节点具体替换方法</a>。</p>
<p>按上述命令执行后，会出现如下提示：<br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-1.png)<br>需要设置MySQL的root密码（不输入直接回车将会设置为root）如果输入有错误需要删除时，可以按住Ctrl再按Backspace键进行删除。输入后回车进入下一步，如下图所示：<br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-2.png)<br>询问是否需要启用MySQL InnoDB，InnoDB引擎默认为开启，一般建议开启，直接回车或输入 y ，如果确定确实不需要该引擎可以输入 n，输入完成，回车进入下一步<br>选择MySQL版本，目前提供了较多版本的MySQL和MariaDB，需要注意的是MySQL 5.6,5.7及MariaDB 10必须在1G以上内存的更高配置上才能选择：<br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-3.png)<br>输入对应MySQL或MariaDB版本前面的序号，回车进入下一步，选择PHP版本：<br>注意：选择PHP7等高版本时需要自行确认是否与自己的程序兼容。<br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-4.png)<br>输入要选择的PHP版本的序号，回车进入下一步，选择是否安装内存优化：<br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-5.png)<br>可以选择不安装、Jemalloc或TCmalloc，输入对应序号回车，直接回车为默认为不安装。</p>
<p>如果是LNMPA或LAMP的话还会提示“Please enter Administrator Email Address:”，需要设置管理员邮箱，该邮箱会在报错时显示在错误页面上。<br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-6.png)<br>再选择Apache版本<br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-7.png)<br>按提示输入对应版本前面的数字序号，回车。</p>
<p>提示”Press any key to install…or Press Ctrl+c to cancel”后，按回车键确认开始安装。<br>LNMP脚本就会自动安装编译Nginx、MySQL、PHP、phpMyAdmin、Zend Optimizer这几个软件。</p>
<p>安装时间可能会几十分钟到几个小时不等，主要是机器的配置网速等原因会造成影响。</p>
<p><strong>3、安装完成</strong><br>如果显示Nginx: OK，MySQL: OK，PHP: OK<br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-sucess.png)<br>并且Nginx、MySQL、PHP都是running，80和3306端口都存在，并提示Install lnmp V1.3 completed! enjoy it.的话，说明已经安装成功。<br>接下来按<a href="https://lnmp.org/faq/lnmp-vhost-add-howto.html"><strong>添加虚拟主机教程</strong></a>，添加虚拟主机后上传网站代码，可以使用<a href="https://lnmp.org/faq/sftp.html">sftp</a>或<a href="https://lnmp.org/faq/ftpserver.html">ftp服务器</a>上传网站，将域名解析到VPS或服务器的IP上，解析生效即可使用。</p>
<p><strong>4、安装失败</strong><br>![img](../images/安装 - LNMP一键安装包/lnmp-1.3-install-failed.png)<br>如果出现类似上图的提示，则表明安装失败，说明没有安装成功！！需要用<a href="http://www.vpser.net/manage/winscp.html">winscp</a>或其他类似工具，将/root目录下面的lnmp-install.log下载下来，到<a href="http://bbs.vpser.net/forum-25-1.html">LNMP支持论坛</a>发帖注明你的系统发行版名称及版本号、32位还是64位等信息，并将lnmp-install.log压缩以附件形式上传到论坛，我们会通过日志查找错误，并给予相应的解决方法。</p>
<p><strong>默认LNMP是不安装FTP服务器的，如需要FTP服务器：<a href="https://lnmp.org/faq/ftpserver.html">https://lnmp.org/faq/ftpserver.html</a></strong></p>
<p><strong>5、添加、删除虚拟主机及伪静态管理</strong><br><a href="https://lnmp.org/faq/lnmp-vhost-add-howto.html">https://lnmp.org/faq/lnmp-vhost-add-howto.html</a></p>
<p><strong>6、eAccelerator、xcache、memcached、imageMagick、ionCube、redis、opcache的安装</strong><br><a href="https://lnmp.org/faq/addons.html">https://lnmp.org/faq/addons.html</a></p>
<p><strong>7、LNMP相关软件目录及文件位置</strong><br><a href="https://lnmp.org/faq/lnmp-software-list.html">https://lnmp.org/faq/lnmp-software-list.html</a></p>
<p><strong>8、LNMP状态管理命令</strong><br><a href="https://lnmp.org/faq/lnmp-status-manager.html">https://lnmp.org/faq/lnmp-status-manager.html</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>对《切韵》一书成书的思考</title>
    <url>/post/3c99c8d7.html</url>
    <content><![CDATA[<p><strong>对《切韵》一书成书的思考</strong></p>
<p>​                     <strong>李 沣</strong></p>
<p><strong>《切韵》是我国最早的具有完整意义的韵书。是陆法言参考了前人的韵书文献，集中了多人的智慧，以萧该、颜之推的意见为主，将南北音韵系统综合研究的结果。</strong></p>
<p><strong>陆法言《切韵•序》中说：“欲广文路，自可清浊皆通；若赏知音，即须轻重有异。吕静《韵集》，夏侯该《韵略》，阳休之《韵略》，周思言《音韵》，李季节《音谱》，杜台卿《韵略》等，各有乖互。”说明陆法言博览了各种韵书，但发觉这些韵书都有偏颇，都不完整，甚至互相矛盾。当刘臻、颜之推、卢思道、李若、萧该、辛德源、薛道衡、魏彦渊这八位当时的著名学者到陆法言家饮酒论韵时，对音韵之学，各抒高见，进行了热烈地讨论。“欲更捃选精切，除削疏缓，萧（该）颜（之推）多所决定。”在这中， 萧该、颜之推的言论和意见也更为丰富、完整和准确。“魏著作（渊）谓法言曰：「向来论难，疑处悉尽，何不随口记之。我辈数人，定则定矣。」”陆法言在魏彦渊的建议下，于是在灯下提笔粗略地记录了这次讨论的结果。后来陆法言又请教了许多懂音韵的人，得到了音韵学的精华。陆法言获罪免官为民后，隐居山野，私训弟子，“遂取诸家音韵， 古今字书，以前所记者定之，为《切韵》五卷。”编辑成了五卷本《切韵》。</strong></p>
<p><strong>学界普遍认同，《切韵》反映了当时汉语的语音。这一语音系统完整的保存在后来的《广韵》，甚而《集韵》等书中。作为中古汉语的代表，颜之推在《音辞》中说：“共以帝王都邑，参校方俗，考核古今，为之折衷。**</strong>搉**<strong>而量之，独金陵与洛下耳。”颜之推的这席话，是他对音韵学整理的见解，也是他的同辈尤其也是陆法言编辑《切韵》的原则。</strong> <strong>要制订一种权威的、标准的、能为各地接受的语音体系，必须以帝王都邑的音韵为主，参校各地的方言俗语，考核古音今音的变化规律，为之“折中”。所谓“折中”，既不是对这些语音要素全盘接受，也不是全盘否定，而是广收精华，融为一体。在当时要更准确地把握音韵规律，就是要着重研究和把握金陵和洛阳这两地的音韵特点和构成。因为这两地的音韵系统，已经是各个不同时代众多语音的折中或综合。</strong></p>
<p><strong>因为《切韵》对后世影响很大，学界对《切韵》的性质、源头、构成等问题，曾进行过多次讨论，尽管讨论中有争论，理解有差异甚至有矛盾，但对《切韵》性质等问题的总体认知基本一致。</strong></p>
<p><strong>王力先生在其《汉语史稿》中说：</strong></p>
<p><strong>“陆法言的《切韵》是现在能见到的最早的一般韵书。它在汉语史上占有重要的地位。根据《切韵》的语音系统，可以上推古音，下推今音，现代汉语普通话和各地方言的语音系统，基本上可以从《切韵》系统上得到解释。中古汉语的语音，以《切韵》系统为标准。《切韵》的系统并不代表当时（隋代）的首都长安的实际语音，它只代表一种被认为文学语言的语音系统。”</strong></p>
<p><strong>“依南北朝的韵文观察，《切韵》所包括的字，适与南北朝韵文所表现的系统相当。可见《切韵》大致仍以南北朝的实际语言为标准。”⑴</strong></p>
<p><strong>王力先生的意见是《切韵》包涵了古音、今音、各地方言，它虽然产生于隋的首都长安，但它与长安的实际语音无关，而与南北朝的韵文相当。</strong></p>
<p><strong>周祖谟说：“《切韵》分韵不仅与齐、梁、陈之间诗文押韵的情况基本一致，而且与梁代吴郡顾野王《玉篇》的韵类几乎全部相同。⑵</strong></p>
<p><strong>周祖谟的意见是，《切韵》与齐、梁、陈的诗文押韵基本一致，而且与梁代顾野王的《玉篇》韵类几乎全部相同。强调了《切韵》与南朝的诗文和《玉篇》的承继关系。</strong></p>
<p><strong>黄淬伯说：“《切音》音系既是当时南北方音的复杂组合，又经过萧该、颜之推的规划，颜之推所推的金陵与洛下的音系一定蕴藏在《切韵》之中，假若全面的研究六朝韵语或其它相关资料，我想当时民语的基础方言即金陵与洛下的音系是可以从《切韵》中发现的。”⑶</strong></p>
<p><strong>邵荣芬说：“《切韵》音系大体上是一个活方言的音系，只是部分地集中了一些方音的特点。具体地说，当时洛阳一带的语音是它的基础，金陵一带的语音是它的主要参考对象。”⑷</strong></p>
<p><strong>黄、邵的意见都说《切韵》的基础是各地民间的方言，而洛阳和金陵的方言音系，对其影响更为直接，但认为两者对《切韵》的作用不完全一样。</strong></p>
<p><strong>赵振铎说：“以洛阳为中心的中原一带方言是有资格作为这个基础的。”“洛阳是我国的古都之一，是古代的政治、经济、文化中心”⑸</strong></p>
<p><strong>周祖谟说：“《切韵》音系的基础，应当是公元六世纪南北土人通用的雅言。”这种雅言就是“当时应用的书音和官于金陵的士大夫通用的语言。”⑹</strong></p>
<p><strong>赵强调了洛语对《切韵》的基础作用，而周祖谟强调了对《切韵》产生直接影响的讲的，是当时南北应用的书音和官于金陵的士大夫通用的语言。因此要真正理解《切韵》成书的基础和要义，就要深入研究六朝时期官于金陵的士大夫的通用语言。</strong></p>
<p><strong>陆法言的《切韵》成书于大隋仁寿元年，即公元601年。他们那次对声韵学的讨论是在20年前，大致是公元580年左右。而隋灭南朝的陈是在公元589年。也就是说，《切韵》虽成书于隋，但基础在六朝即魏晋南北朝时期。例如对《切韵》影响最大的是萧该、颜之推二人，因为他们俩对韵学都有很深的研究造诣，都是音韵大家，萧该著有《汉书音义》、《文选音义》和《后汉书音义》，颜之推著有《颜氏家训•音辞篇》。而对萧该、颜之推的语音影响最大、最直接的，是萧、颜的父辈、祖辈等人，而萧、颜的父、祖辈，以至于曾祖以上，他们都是南迁的北方士家豪族，都是南朝的宋、齐、梁、陈时代的士族官僚之家。金陵官音，与南迁士族和侨郡、侨县制度有重要关系，因此弄懂“金陵之音”，就需要把南朝的政治、经济、文化大背景弄清楚。</strong></p>
<p><strong>西晋末年“八王之乱”的直接的政治后果，就是形成了中国历史上第二次大规模的北人南迁浪潮。</strong></p>
<p> <strong>《晋书•王导传》载：“洛京倾复，中州士女避乱江左者十六七。”就是说十分之六七的北方豪族、士族男女都逃到江南去了。</strong></p>
<p><strong>《晋书•地理志》载：“永嘉之乱……幽、冀、青、并、兖五州及徐州之一淮北流人，相率过江淮。” “及胡寇南侵，淮南百姓皆渡江。”</strong></p>
<p><strong>《晋书•郗鉴传》载：鲁人郗鉴初率乡里“千余家，避难于鲁之峄山，三年间，众至数万。”，后又率众屯晋陵（今江苏常州）。</strong></p>
<p><strong>黄河流域的士家豪族和自由民的大规模、集体南迁，前后延续了160多年，是几代人前后相继的行动。学者统计，西晋末和南朝时，南迁北人大约有90多万，占了整个北方人口的八分之一。⑺</strong></p>
<p><strong>北人南迁地，主要是长江流域，即当时的益、荆、扬三州。而扬州地区，即东晋的政治中心，聚集的南迁汉人最多，大约有26万。而这26万北人主要是山东人和与之相邻的苏北人。这26万山东、苏北人主要迁居在长江南岸的建邺（南京）、京口（镇江）、晋陵（常州）及长江北岸的广陵（扬州）等地。⑻</strong></p>
<p><strong>晋元帝司马睿是司马懿的曾孙，琅**</strong>玡**<strong>王司马由的孙子，嗣琅**</strong>玡**<strong>王司马觐的儿子。琅**</strong>玡**<strong>王氏自王祥以来，一直是冠冕盛门。晋司马氏与琅**</strong>玡**<strong>王氏“素相亲善”。</strong> <strong>元帝渡江，就是听从了王导的建议，即“永嘉初，用王导计，始镇建邺。”司马氏要在江南建邺做皇帝，其主要靠山就是琅琊王氏。</strong></p>
<p><strong>晋元帝政治上完全依靠王导，军事上完全依靠王敦，因此民间有“王与马，共天下”之说。</strong></p>
<p><strong>元帝渡江时，跟随大量琅琊国人，“晋乱，琅琊国人随元帝过江千余户。”</strong></p>
<p><strong>元帝过江后，身边参赞机务的也多为琅琊国人，如琅琊王氏、颜氏、诸葛氏、刘氏等，《晋书•诸葛恢传》载：“时王氏为将军，而恢兄弟及颜含并居显要。”说明晋元帝时，琅**</strong>玡**<strong>颜氏的颜含和诸葛氏的恢兄弟，“并居显要”。颜之推乃颜含的八世孙。琅琊颜氏的显赫地位，是从颜含开始东渡江左，辅佐晋元帝在建邺做皇帝开始的。</strong></p>
<p><strong>跟随元帝渡江的琅琊人可用万计。为使这些以氏族、家族为纽带，世家与宾客、部曲结为一体的庞大人群扎根江南，在江南能安居乐业，元帝于太兴三年（公元320年），侨立怀德县于建康，以安置这些琅琊侨民。成帝司马衍又于咸康元年（公元335年），在江乘县（今江苏句容县北60里）境内侨立琅琊郡。东晋政权并根据王导的提议实行了“侨寄法”。所谓“侨寄”，就是把迁到长江流域的北方人，按照在北方时的州、郡、县名，重新命名新地，保持了原来 族群、乡里的稳定性。根据《侨寄法》，在建康周围 江乘（今南京栖霞）、晋陵（今常州）设置了南琅**</strong>玡**<strong>、南东莞、南兰陵等郡县，在武进设立南彭城、南临淮等三郡**</strong>,<strong>**在与建康相对的江北丹徒（今镇江）设南徐州。</strong>                                             </p>
<p><strong>《侨寄法》的另一功能就是设立官位，安置南迁士人。南迁后王导劝元帝选取北方名士百余人做属官。用官位来安抚南迁士家豪族。颜之推在《观我生赋》自注中说：中原士族随晋元帝渡江的有百家，因此江东有《百家谱》，东晋政权要依靠这百家，就必须给这百家官职和特权。范文澜先生说：“东晋政权主要是这一百家的政权”⑼</strong></p>
<p><strong>从洛阳南迁的司马氏政权，身边除王导兄弟外，还有一大批来自琅**</strong>玡**<strong>、兰陵、彭城的青徐士家豪族，他们在建业（建康或曰金陵）周围聚族而居。因此，金陵的语言、语音系统，实际是洛语和青徐方音的杂处或者说结合，而琅**</strong>玡**<strong>、兰陵、彭城的方音在这里占有重要的地位。侨居江南的北方政权**</strong>，要能在江南立住脚，必须与江南的地方势力，即江南的士家豪族，结合起来，以取得他们的配合和支持。因此王导的重要策略就是以北方士族做骨干，用南方士族做辅助。为此，王导在大庭广众下，常有意地讲吴语，来安抚南方士族，这还引起一些北方士族的不满。在北人占主导地位的政治格局下，无论怎么样提倡说吴语，洛语甚至青徐方音在南朝依然占有重要地位，由于聚族而居，青徐方音仍会代代口耳相传。**</p>
<p><strong>周祖谟说：金陵雅言，就是“当时应用的书音和官于金陵的士大夫通用的语言。”</strong></p>
<p><strong>继东晋政权后的江南，是彭城（徐州）刘裕的宋、宋后是萧道成（刘裕的继母是萧氏，萧氏是刘宋的外戚）的齐、齐后是同为萧氏的梁。萧该，又名子宝，祖父萧恢是梁武帝萧衍之弟。而梁武帝萧衍是齐武帝（萧道成之子萧赜）的族弟。南齐皇帝萧道成虽然生在江南，但祖籍是兰陵（今山东省枣庄市峄城镇）。萧道成的高祖萧整，是东晋初年南迁江南的。这样无论南朝宋、齐、梁的皇帝，还是周围的臣僚，都有挥之不去的青徐之根和青徐方音。</strong></p>
<p><strong>在这种背景下，金陵音系，绝对不是单纯的吴音，也不是单纯的洛下之音，而是洛下之音、金陵之音和青徐方音的融合物，是个复合之音。青徐之音，是不可忽视的音韵要素。</strong></p>
<p><strong>参考资料：</strong></p>
<p><strong>⑴王力：《南北朝诗人用韵考》，清华学报1936（11）</strong></p>
<p><strong>⑵、⑹周祖谟：《〈切韵〉的性质和它的音系基础》，中华书局1966年版。</strong></p>
<p><strong>⑶黄淬伯：《论〈切韵〉音系并批判高本汉的论点》，南京大学学报1957年（2）。</strong></p>
<p><strong>⑷邵荣芬：《〈切韵〉音系的性质和它在汉语语音史上的地位》，《中国语文》1961年。</strong></p>
<p><strong>⑸赵振铎：《从〈切韵•序〉论〈切韵〉》，《中国语文》1962年（10）。</strong></p>
<p><strong>⑺谭其骧：《晋永嘉乱后之民族迁徙》，载《燕京学报》十五期。</strong></p>
<p><strong>⑻田余庆：《秦汉魏晋史探微》第341页，中华书局1993年版。</strong></p>
<p><strong>⑼范文澜：《中国通史》第二册第457页，人民出版社1949年版。</strong></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-杂记</tag>
      </tags>
  </entry>
  <entry>
    <title>教你如何修改win7旗舰版系统远程桌面端口</title>
    <url>/post/6e092dae.html</url>
    <content><![CDATA[<p>**<a href="http://www.windows7en.com/">win7旗舰版</a>**系统中的远程终端服务是一项功能非常强大的服务，同时也成了入侵者长驻主机的通道，入侵者可以利用一些手段得到管理员账号和密码并入侵主机。下面，墨染暖心教你如何通过修改win7旗舰版远程桌面默认端口，防范黑客入侵。</p>
<p>　　远程终端服务基于端口3389。入侵者一般先扫描主机开放端口，一旦发现其开放了3389端口，就会进行下一步的入侵，所以我们只需要修改该务默认端口就可以避开大多数入侵者的耳目。</p>
<p>　　<strong>具体操作步骤：</strong></p>
<p>　　1、打开“开始“→”运行”，输入“regedit”，按下回车键，打开注册表，依次点开：[HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\Wds\rdpwd\Tds\tcp]，可以看到PortNumber的默认值是3389，修改成所希望的端口即可，例如此处墨染暖心用的是8080，同时，要注意点选“十进制”。见下图：</p>
<p><img src="/../images/%E6%95%99%E4%BD%A0%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9win7%E6%97%97%E8%88%B0%E7%89%88%E7%B3%BB%E7%BB%9F%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E7%AB%AF%E5%8F%A3/4-140923161S0V8.jpg" alt="修改成所希望的端口"></p>
<p>　　2、打开[HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Terminal Server\WinStations\RDP-Tcp]，将PortNumber的值(默认是3389)修改成端口8080，注意使用十进制。</p>
<p>　　PS：网上很多教程到此就结束了。的确，如果是XP或2003系统，这样客户端就可以通过8080端口进行远程桌面连接。但是，在win7旗舰版系统下，光修改以上两处的端口为8080，客户端是无法进行远程桌面连接的。究其原因，原来<a href="http://www.windows7en.com/">win7旗舰版</a> 加强了自带防火墙的功能。下面是一张已经将远程桌面的本地端口修改为8080后的截图，原本默认本地端口为3389：</p>
<p><img src="/../images/%E6%95%99%E4%BD%A0%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9win7%E6%97%97%E8%88%B0%E7%89%88%E7%B3%BB%E7%BB%9F%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E7%AB%AF%E5%8F%A3/4-14092316194EV.jpg" alt="远程桌面的本地端口修改为8080后"></p>
<p>　　再PS：从入站规则里的防火墙策略里，如果不手动修改防火墙策略的端口为8080，是不能发现有任何一条防火墙策略的本地端口为8080的。也就是说，在入站规则里，如果不开启对8080端口的放行，防火墙会默认拒绝外界访问8080端口，这也是客户端不能成功进行远程桌面连接的原因。</p>
<p>　　3、只有通过修改注册表的方式来修改防火墙策略。在注册表中依次打开[HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\services\SharedAccess\Defaults\FirewallPolicy\FirewallRules]，将RemoteDesktop-In-TCP的值中包含3389的数据改成8080，并保存。</p>
<p>　　4、接着依次点开[HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\services\SharedAccess\Parameters\FirewallPolicy\FirewallRules]，将RemoteDesktop-In-TCP的值中包含3389的数据改成8080，并保存。</p>
<p>　　5、修改完毕，重新启动电脑，那么以后远程登录的时候使用端口8080就可以了。</p>
<p>　　具体的访问的方法是IP:端口号，如192.168.100.100：8080，如下图：</p>
<p><img src="/../images/%E6%95%99%E4%BD%A0%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9win7%E6%97%97%E8%88%B0%E7%89%88%E7%B3%BB%E7%BB%9F%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E7%AB%AF%E5%8F%A3/4-140923162049633.jpg" alt="端口号，如192.168.100.100：8080"></p>
]]></content>
      <categories>
        <category>win7</category>
      </categories>
      <tags>
        <tag>-win7</tag>
      </tags>
  </entry>
  <entry>
    <title>拷贝网页上的公式到本地</title>
    <url>/post/d1234036.html</url>
    <content><![CDATA[<h3 id="有时在写文章或者搞别的东西的时候需要用到别人的公式，然而一般这些公式都是复制不了的，如果这个时候一个个去打可以说相当要命。然而我们可以通过：mathpix这个神器轻轻松松解决这个问题。有了它之后，在哪看到公式直接截图就可以帮我们翻译成latex公式。"><a href="#有时在写文章或者搞别的东西的时候需要用到别人的公式，然而一般这些公式都是复制不了的，如果这个时候一个个去打可以说相当要命。然而我们可以通过：mathpix这个神器轻轻松松解决这个问题。有了它之后，在哪看到公式直接截图就可以帮我们翻译成latex公式。" class="headerlink" title="有时在写文章或者搞别的东西的时候需要用到别人的公式，然而一般这些公式都是复制不了的，如果这个时候一个个去打可以说相当要命。然而我们可以通过：mathpix这个神器轻轻松松解决这个问题。有了它之后，在哪看到公式直接截图就可以帮我们翻译成latex公式。"></a>有时在写文章或者搞别的东西的时候需要用到别人的公式，然而一般这些公式都是复制不了的，如果这个时候一个个去打可以说相当要命。然而我们可以通过：mathpix这个神器轻轻松松解决这个问题。有了它之后，在哪看到公式直接截图就可以帮我们翻译成latex公式。<img src="/../images/%E6%8B%B7%E8%B4%9D%E7%BD%91%E9%A1%B5%E4%B8%8A%E7%9A%84%E5%85%AC%E5%BC%8F%E5%88%B0%E6%9C%AC%E5%9C%B0/20190227174410743.png" alt="img"></h3><h3 id="就像上面这个，一截就变成了下面的这一串latex公式描述"><a href="#就像上面这个，一截就变成了下面的这一串latex公式描述" class="headerlink" title="就像上面这个，一截就变成了下面的这一串latex公式描述"></a>就像上面这个，一截就变成了下面的这一串latex公式描述</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\alpha &#x3D; - \arctan \left( \frac &#123; z _ &#123; 2 &#125; \sin \vartheta _ &#123; 2 &#125; - z _ &#123; 1 &#125; \sin \vartheta _ &#123; 1 &#125; &#125; &#123; z _ &#123; 2 &#125; \cos \vartheta _ &#123; 2 &#125; - z _ &#123; 1 &#125; \cos \vartheta _ &#123; 1 &#125; &#125; \right)</span><br></pre></td></tr></table></figure>
<h3 id="接着，我们可以把这段描述放到Typora等markdown工具中，公式又将美好的出现在我们面前。"><a href="#接着，我们可以把这段描述放到Typora等markdown工具中，公式又将美好的出现在我们面前。" class="headerlink" title="接着，我们可以把这段描述放到Typora等markdown工具中，公式又将美好的出现在我们面前。"></a>接着，我们可以把这段描述放到Typora等markdown工具中，公式又将美好的出现在我们面前。</h3><h3 id="当然到这里其实是不完整的。因为word虽然也可以支持latex公式，但还是比较麻烦。有没有方法能直接将上面的代码转成word直接能识别的格式呢？"><a href="#当然到这里其实是不完整的。因为word虽然也可以支持latex公式，但还是比较麻烦。有没有方法能直接将上面的代码转成word直接能识别的格式呢？" class="headerlink" title="当然到这里其实是不完整的。因为word虽然也可以支持latex公式，但还是比较麻烦。有没有方法能直接将上面的代码转成word直接能识别的格式呢？"></a>当然到这里其实是不完整的。因为word虽然也可以支持latex公式，但还是比较麻烦。有没有方法能直接将上面的代码转成word直接能识别的格式呢？</h3><h3 id="有。还是以Typora为例，如下图所示选择“复制到-MS-Word”"><a href="#有。还是以Typora为例，如下图所示选择“复制到-MS-Word”" class="headerlink" title="有。还是以Typora为例，如下图所示选择“复制到 MS Word”"></a>有。还是以Typora为例，如下图所示选择“复制到 MS Word”</h3><p><img src="/../images/%E6%8B%B7%E8%B4%9D%E7%BD%91%E9%A1%B5%E4%B8%8A%E7%9A%84%E5%85%AC%E5%BC%8F%E5%88%B0%E6%9C%AC%E5%9C%B0/20190227174837162.png" alt="img"></p>
<h3 id="在word或者PowerPoint中右键选择"><a href="#在word或者PowerPoint中右键选择" class="headerlink" title="在word或者PowerPoint中右键选择"></a>在word或者PowerPoint中右键选择</h3><p><img src="/../images/%E6%8B%B7%E8%B4%9D%E7%BD%91%E9%A1%B5%E4%B8%8A%E7%9A%84%E5%85%AC%E5%BC%8F%E5%88%B0%E6%9C%AC%E5%9C%B0/20190227175130769.png" alt="img"></p>
<h3 id="公式就优雅的过来啦！！！"><a href="#公式就优雅的过来啦！！！" class="headerlink" title="公式就优雅的过来啦！！！"></a>公式就优雅的过来啦！！！</h3><p><img src="/../images/%E6%8B%B7%E8%B4%9D%E7%BD%91%E9%A1%B5%E4%B8%8A%E7%9A%84%E5%85%AC%E5%BC%8F%E5%88%B0%E6%9C%AC%E5%9C%B0/20190227175214295.png" alt="img"></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>整套1208-20160109_免费高速下载百度云 斐讯PSG1208刷机大合集</title>
    <url>/post/fb16d405.html</url>
    <content><![CDATA[<p>整套1208-20160109_免费高速下载|百度云 网盘-分享无限制</p>
<p><a href="http://pan.baidu.com/s/1ges68Jx#path=%2F%E6%95%B4%E5%A5%971208-20160109">http://pan.baidu.com/s/1ges68Jx#path=%252F%25E6%2595%25B4%25E5%25A5%25971208-20160109</a></p>
<p>斐讯PSG1208刷机教程<br><a href="http://pan.baidu.com/s/1bpXKlS%E9%87%8C%E9%9D%A2%E6%9C%89%E8%A7%86%E9%A2%91%E9%87%8C%E7%9A%84%E5%85%A8%E9%83%A8%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84%E5%B7%A5%E5%85%B7%E5%92%8Cbreed%E8%BF%98%E6%9C%89%E4%B8%80%E4%B8%AA%E5%8D%8E%E7%A1%95%E8%80%81%E6%AF%9B%E5%AD%90%E5%9B%BA%E4%BB%B6">http://pan.baidu.com/s/1bpXKlS里面有视频里的全部所需要的工具和breed还有一个华硕老毛子固件</a><br>原帖  <a href="http://forum.anywlan.com/forum.php?mod=viewthread&tid=384522&extra=page=1&filter=author&orderby=dateline">http://forum.anywlan.com/forum.p … 6orderby%3Ddateline</a><br>刷完潘多拉后</p>
<p>在浏览器中输入192.168.1.1 密码admin 点击登入 OK 进入到路由页面<br>1 进入路由管理界面后点击左侧的“接口”，选择“WAN”。<br>2 点击“协议”选项栏里的“DHCP客户端”改为“PPPoE”,点击“切换协议”。<br>3 在“PAP/CHAP用户名”输入你宽带的用户名，“PAP/CHAP密码”输入你宽带的密码。<br>4 在当前页面点击“高级设置”,“使用网关跃点”输入“40”，点击右下角的“保存并应用”。<br>上面的是潘多拉固件普通拨号方法，接下来才是怎么多播。如果不需要多播，到此步即可结束操作。<br>5 点击左侧的”虚拟WAN接口“，“启用”前面打对钩，“虚拟接口”数量建议输入“10”，“断线自动重连”打对钩，最低在线数输入“1”，“保存并应用”。<br>6 等待15S后，点击“重新并发拨号”。<br>7 检查多拨状态，点左侧“负载均衡”，等1分钟，看看你下图的接口绿了几个就是成功多拨了几个。<br>原帖  <a href="http://www.52pojie.cn/thread-409698-1-1.html">http://www.52pojie.cn/thread-409698-1-1.html</a><br>不需要多拨的，可以刷华硕的，感觉比原厂固件好<br>地址 <a href="http://www.right.com.cn/forum/thread-161324-1-1.html">http://www.right.com.cn/forum/thread-161324-1-1.html</a><br>更新更多斐讯k1 斐讯1208固件  <a href="http://www.right.com.cn/forum/forum.php?mod=viewthread&tid=181006&highlight=1208">http://www.right.com.cn/forum/fo … &amp;highlight=1208</a><br> 下载地址 <a href="http://pan.baidu.com/s/1skl0VIP">http://pan.baidu.com/s/1skl0VIP</a></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>斐讯PSG1208 K1 免拆机刷breed恢复控制台</title>
    <url>/post/cf81e54b.html</url>
    <content><![CDATA[<p>Breed，不是 U-Boot，也不是 U-Boot 的改进版，是全新、独立的、跟 U-Boot 平级的 Bootloader。</p>
<p>进入breed恢复控制台的方法:路由断电,按住复位键不放,路由通电,5秒后放开复位键,等一会,在浏览器上打开192.168.1.1,进入breed恢复控制台.</p>
<p>今天有人找我要潘多拉的设置方法,这里发教程,需要的朋友去安装吧.</p>
<p>看这么多人路由器刷了潘多拉，发个多拨教程</p>
<p>首先本文是介绍breed恢复控制台的,不是介绍刷固件的,刷完breed恢复控制台,不刷固件的话,是正常使用原版固件的,没任何影响的,刷了breed恢复控制台后,可以轻松的备份固件(也就是路由器的系统),更新固件,刷第三方固件,超频等,具体介绍和功能看注释.至于刷第三方固件有什么用,本文不作介绍.</p>
<p>刷breed恢复控制台步骤:<br>1.先接好路由,设置好,让路由能连网;<br>2.查看自己的电脑ip地址,这里假设电脑的ip是192.168.2.100;<br>3.在浏览器上登陆路由器,192.168.2.1,账号:admin,密码:admin;<br>4.浏览器地址栏打开 <a href="http://192.168.2.1/goform/Diagnosis?pingAddr=192.168.2.100%7Cecho&quot;&quot;%7Ctelnetd">http://192.168.2.1/goform/Diagnosis?pingAddr=192.168.2.100|echo&quot;&quot;|telnetd</a> (红色部分是本机ip,如果你的电脑ip不是192.168.2.100,请改成你电脑的ip);<br>5.点击 <a href="http://www.cr173.com/k/kscd/">开始菜单</a>-&gt;运行,输入cmd,打开控制台;<br>6.telnet 192.168.2.1,账号:admin,密码:admin;<br>7.cd /tmp;<br>8.wget <a href="http://breed.hackpascal.net/breed-mt7620-reset1.bin">http://breed.hackpascal.net/breed-mt7620-reset1.bin</a>;</p>
<p>9.mtd_write write breed-mt7620-reset1.bin Bootloader;</p>
<p>10.重启路由,按住复位键(大概3-5秒左右),如果看到路由器的部分或全部LED连闪4次，或 ping 通即表明进入 Web 刷机模式(路由地址为:192.168.1.1).<br>如果不按住复位键则正常启动路由(路由地址为:192.168.2.1).</p>
<p>这时你就可以刷入你想要使用的固件了,建议刷固件前先备份固件,如果刷的新的固件不能用,可以重新刷备份的固件就可以了.</p>
<p>潘多拉固件下载地址:<br><a href="http://downloads.openwrt.org.cn/PandoraBox/Xiaomi-Mini-R1CM/stable/PandoraBox-ralink-mt7620-xiaomi-mini-squashfs-sysupgrade-r1024-20150608.bin">http://downloads.openwrt.org.cn/PandoraBox/Xiaomi-Mini-R1CM/stable/PandoraBox-ralink-mt7620-xiaomi-mini-squashfs-sysupgrade-r1024-20150608.bin</a></p>
<p>老毛子Padavan固件:<a href="http://www.right.com.cn/forum/thread-161324-1-1.html">http://www.right.com.cn/forum/thread-161324-1-1.html</a></p>
<p>注释:<br>breed恢复控制台作用功能:<br>Breed，不是 U-Boot，也不是 U-Boot 的改进版，是全新、独立的、跟 U-Boot 平级的 Bootloader。<br>[功能介绍]<br>Breed 拥有不死 U-Boot 的全部功能，并且还有以下特性：<br>真正多线程<br>实时刷机进度，进度条能准确反映刷机进度<br>Web 页面快速响应<br>最大固件备份速度，依 Flash 而定，一般能达到 1MB/s<br>免按复位键进入 Web 刷机模式<br>telnet 功能，免 TTL 进入 Breed 命令控制台<br>复位键定义测试功能<br>固件启动失败自动进入 Web 刷机模式</p>
<p>Web 界面跟不死 U-Boot 基本一致</p>
<p>[U-Boot功能介绍]<br>能够启动 TP-LINK 原厂固件、OpenWrt 固件 (包含石像鬼固件)、DD-WRT 固件、UBNT 固件<br>支持大量 Flash，支持型号识别，能自动识别未知 FLASH 的大小 (4M / 8M / 16M / 32M)。<br>支持 TP-LINK 固件头和 U-Boot 固件头。<br>带 Web 刷机界面。支持开机按 RESET/W<a href="http://www.cr173.com/k/photoshopcs5/">PS</a> 按钮进入刷机界面。<br>开启交换机 LED，以便检查 U-Boot 更新固件时网络连接是否正常<br>所有版本均有不死超频功能</p>
<p>[Web 刷机界面功能]<br>兼容大部分主流浏览器<br>自动分配 IP 地址，不用手动修改计算机 IP 地址<br>显示 FLASH 型号和大小、CPU 型号、内存容量、系统频率<br>固件更新，U-Boot、固件、ART均可更新；支持直刷编程器固件<br>自动去除 TP-LINK 官方固件的 U-Boot 部分<br>自动补充 ART，解决刷官方固件丢失无线的问题<br>刷机前文件大小、MD5值确认<br>恢复出厂设置<br>不死超频/降频<br>修改特定设备的相关信息，包括修改 MAC 地址和 PIN 码、修改 UBNT 无线 MAC 地址等<br>编程器固件备份<br>网络控制台 (UDP 协议)<br>支持 Web 界面重启路由<br>详细的失败信息<br>全中文版界面</p>
<h1 id="PSG1208-K1固件下载地址"><a href="#PSG1208-K1固件下载地址" class="headerlink" title="PSG1208 K1固件下载地址"></a>PSG1208 K1固件下载地址</h1><p>Breed控制台：<a href="http://breed.hackpascal.net/breed-mt7620-reset1.bin">http://breed.hackpascal.net/breed-mt7620-reset1.bin</a></p>
<p>小米潘多拉（多拨）：<a href="http://downloads.openwrt.org.cn/PandoraBox/Xiaomi-Mini-R1CM/">http://downloads.openwrt.org.cn/PandoraBox/Xiaomi-Mini-R1CM/</a></p>
<p>老毛子改（华硕稳定版本）：<a href="http://pan.baidu.com/s/1qWr367y">http://pan.baidu.com/s/1qWr367y</a></p>
<h1 id="斐讯PSG1208刷机大合集"><a href="#斐讯PSG1208刷机大合集" class="headerlink" title="斐讯PSG1208刷机大合集"></a>斐讯PSG1208刷机大合集</h1><p>斐讯PSG1208刷机教程  <a href="http://pan.baidu.com/s/1bpXKlS%E9%87%8C%E9%9D%A2%E6%9C%89%E8%A7%86%E9%A2%91%E9%87%8C%E7%9A%84%E5%85%A8%E9%83%A8%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84%E5%B7%A5%E5%85%B7%E5%92%8Cbreed">http://pan.baidu.com/s/1bpXKlS里面有视频里的全部所需要的工具和breed</a></p>
<p>还有一个华硕老毛子固件 原帖  <a href="http://forum.anywlan.com/forum.p">http://forum.anywlan.com/forum.p</a> … 6orderby%3Ddateline </p>
<p>刷完潘多拉后 在浏览器中输入192.168.1.1 密码admin 点击登入 OK 进入到路由页面 </p>
<p>1 进入路由管理界面后点击左侧的“接口”，选择“WAN”。 </p>
<p>2 点击“协议”选项栏里的“DHCP客户端”改为“PPPoE”,点击“切换协议”。 </p>
<p>3 在“PAP/CHAP用户名”输入你宽带的用户名，“PAP/CHAP密码”输入你宽带的密码。</p>
<p> 4 在当前页面点击“高级设置”,“使用网关跃点”输入“40”，点击右下角的“保存并应用”。 上面的是潘多拉固件普通拨号方法，接下来才是怎么多播。如果不需要多播，到此步即可结束操作。</p>
<p> 5 点击左侧的”虚拟WAN接口“，“启用”前面打对钩，“虚拟接口”数量建议输入“10”，“断线自动重连”打对钩，最低在线数输入“1”，“保存并应用”。 </p>
<p>6 等待15S后，点击“重新并发拨号”。 </p>
<p>7 检查多拨状态，点左侧“负载均衡”，等1分钟，看看你下图的接口绿了几个就是成功多拨了几个。 </p>
<p>原帖  <a href="http://www.52pojie.cn/thread-409698-1-1.html">http://www.52pojie.cn/thread-409698-1-1.html</a> </p>
<p>不需要多拨的，可以刷华硕的，感觉比原厂固件好 地址  <a href="http://www.right.com.cn/forum/thread-161324-1-1.html">http://www.right.com.cn/forum/thread-161324-1-1.html</a></p>
<p> 更新更多斐讯k1 斐讯1208固件  <a href="http://www.right.com.cn/forum/fo">http://www.right.com.cn/forum/fo</a> … &amp;highlight=1208  </p>
<p>下载地址  <a href="http://pan.baidu.com/s/1skl0VIP">http://pan.baidu.com/s/1skl0VIP</a></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>-斐讯 -技术</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习10个最佳人工智能开发框架和AI库（优缺点总结）</title>
    <url>/post/d0f5fd4f.html</url>
    <content><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>通过本文我们来一起看一些用于人工智能的高质量AI库，它们的优点和缺点，以及它们的一些特点。</p>
<p><strong>人工智能（AI）</strong>已经存在很长时间了。然而，由于这一领域的巨大进步，近年来它已成为一个流行语。人工智能曾经被称为一个完整的书呆子和天才的领域，但由于各种开发库和框架的发展，它已经成为一个友好的IT领域，并有很多人正走进它。</p>
<p>在这篇文章中，我们将研究用于人工智能的优质库，它们的优缺点以及它们的一些特征。让我们深入并探索这些<strong>人工智能库</strong>的世界！</p>
<h2 id="1-TensorFlow"><a href="#1-TensorFlow" class="headerlink" title="1. TensorFlow"></a><strong>1. TensorFlow</strong></h2><h4 id="“使用数据流图表的可伸缩机器学习的计算”"><a href="#“使用数据流图表的可伸缩机器学习的计算”" class="headerlink" title="“使用数据流图表的可伸缩机器学习的计算”"></a>“使用数据流图表的可伸缩机器学习的计算”</h4><p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/1528726843672650.png" alt="img"></p>
<p><strong>语言：</strong>C ++或Python。</p>
<p>当进入AI时，你会听到的第一个框架之一就是Google的TensorFlow。</p>
<p>TensorFlow是一个使用数据流图表进行数值计算的开源软件。这个框架被称为具有允许在任何CPU或GPU上进行计算的架构，无论是台式机、服务器还是移动设备。这个框架在Python编程语言中是可用的。</p>
<p>TensorFlow对称为节点的数据层进行排序，并根据所获得的任何信息做出决定。</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/1528726844586861.png" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>使用易于学习的语言（Python）。</li>
<li>使用计算图表抽象。</li>
<li>用于TensorBoard的可用性的可视化。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>这很慢，因为Python不是语言中最快的。</li>
<li>缺乏许多预先训练的模型。</li>
<li>不完全开源。</li>
</ul>
<h2 id="2-Microsoft-CNTK"><a href="#2-Microsoft-CNTK" class="headerlink" title="2. Microsoft CNTK"></a><strong>2. Microsoft CNTK</strong></h2><h4 id="“开源深度学习工具包”"><a href="#“开源深度学习工具包”" class="headerlink" title="“开源深度学习工具包”"></a>“开源深度学习工具包”</h4><p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/1528726844730194.png" alt="img"></p>
<p><strong>语言：</strong>C ++。</p>
<p>我们可以称之为微软对Google的TensorFlow的回应。</p>
<p>微软的计算网络工具包是一个增强分离计算网络模块化和维护的库，提供学习算法和模型描述。</p>
<p>在需要大量服务器进行操作的情况下，CNTK可以同时利用多台服务器。</p>
<p>据说它的功能与Google的TensorFlow相近；但是，它会更快。</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/1528726844668687.png" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>这是非常灵活的。</li>
<li>允许分布式训练。</li>
<li>支持C ++、C＃、Java和Python。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>它以一种新的语言――网络描述语言（Network Description Language , NDL）来实现。</li>
<li>缺乏可视化。</li>
</ul>
<h2 id="3-Theano"><a href="#3-Theano" class="headerlink" title="3. Theano"></a><strong>3. Theano</strong></h2><h4 id="“数值计算库”"><a href="#“数值计算库”" class="headerlink" title="“数值计算库”"></a>“数值计算库”</h4><p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/1528726845929886.png" alt="img"></p>
<p><strong>语言：</strong>Python。</p>
<p>Theano是TensorFlow的强有力竞争者，是一个功能强大的Python库，允许以高效率的方式进行涉及多维数组的数值操作。</p>
<p>Theano库透明地使用GPU来执行数据密集型计算而不是CPU，因此操作效率很高。</p>
<p>出于这个原因，Theano已经被用于为大规模的计算密集型操作提供动力大约十年。</p>
<p>然而，在2017年9月，宣布Theano的主要开发将于2017年11月发布的1.0版本后停止。</p>
<p>这并不意味着它是一个不够强大的库。你仍然可以随时进行深入的学习研究。</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/1528726845589168.png" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>正确优化CPU和GPU。</li>
<li>有效的数字任务。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>与其他库相比，原生Theano有点低级。</li>
<li>需要与其他库一起使用以获得高度的抽象化。</li>
<li>AWS上有点bug。</li>
</ul>
<h2 id="4-Caffe"><a href="#4-Caffe" class="headerlink" title="4. Caffe"></a><strong>4. Caffe</strong></h2><h4 id="“快速、开源的深度学习框架”"><a href="#“快速、开源的深度学习框架”" class="headerlink" title="“快速、开源的深度学习框架”"></a>“快速、开源的深度学习框架”</h4><p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/1528726846426756.png" alt="img"></p>
<p><strong>语言：</strong>C ++。</p>
<p>Caffe是一个强大的深度学习框架。</p>
<p>像这个清单上的其他框架一样，深度学习的研究速度非常快。</p>
<p>借助Caffe，您可以非常轻松地构建用于图像分类的卷积神经网络（CNN）。Caffe在GPU上运行良好，这有助于在运行期间提高速度。</p>
<p>Caffe主要的类有：</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/1528726846867003.png" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>Python和MATLAB的绑定可用。</li>
<li>性能表现良好。</li>
<li>无需编写代码即可进行模型的训练。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>对于经常性网络不太好。</li>
<li>新体系结构不太好。</li>
</ul>
<h2 id="5-Keras"><a href="#5-Keras" class="headerlink" title="5. Keras"></a><strong>5. Keras</strong></h2><h4 id="“人类的深度学习”"><a href="#“人类的深度学习”" class="headerlink" title="“人类的深度学习”"></a>“人类的深度学习”</h4><blockquote>
</blockquote>
<p><strong>语言：</strong>Python。</p>
<p>Keras是一个用Python编写的开源的神经网络库。</p>
<p>与TensorFlow、CNTK和Theano不同，Keras不是一个端到端的机器学习框架。</p>
<p>相反，它作为一个接口，提供了一个高层次的抽象化，这使得无论它坐落在哪个框架上，神经网络的配置都会变得容易。</p>
<p>谷歌的TensorFlow目前支持Keras作为后端，而微软的CNTK也会在很短的时间内做到这一点。</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/71f35ef9c4f49cd2dfa051dbdf6c47a2.jpg" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>它是用户友好的。</li>
<li>它很容易扩展。</li>
<li>在CPU和GPU上无缝运行。</li>
<li>与Theano和TensorFlow无缝工作。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不能有效地用作独立的框架。</li>
</ul>
<h2 id="6-Torch"><a href="#6-Torch" class="headerlink" title="6. Torch"></a><strong>6. Torch</strong></h2><h4 id="“一个开源的机器学习库”"><a href="#“一个开源的机器学习库”" class="headerlink" title="“一个开源的机器学习库”"></a>“一个开源的机器学习库”</h4><blockquote>
</blockquote>
<p><strong>语言：</strong>C。</p>
<p>Torch是一个用于科学和数字操作的开源机器学习库。</p>
<p>这是一个基于Lua编程语言而非Python的库。</p>
<p>Torch通过提供大量的算法，使得深度学习研究更容易，并且提高了效率和速度。它有一个强大的N维数组，这有助于切片和索引等操作。它还提供了线性代数程序和神经网络模型。<a href="http://torch.ch/">
</a></p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/46a202b7e2595403f3df336e8736d4f5.jpg" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>非常灵活。</li>
<li>高水平的速度和效率。</li>
<li>大量的预训练模型可用。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不清楚的文献记录。</li>
<li>缺乏即时使用的即插即用代码。</li>
<li>它基于一种不那么流行的语言――Lua。</li>
</ul>
<h2 id="7-Accord-NET"><a href="#7-Accord-NET" class="headerlink" title="7. Accord.NET"></a><strong>7. Accord.NET</strong></h2><h4 id="“机器学习、计算机视觉、统计和-NET通用科学计算”"><a href="#“机器学习、计算机视觉、统计和-NET通用科学计算”" class="headerlink" title="“机器学习、计算机视觉、统计和.NET通用科学计算”"></a>“机器学习、计算机视觉、统计和.NET通用科学计算”</h4><p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/97742ad082554ea8c7a12a6c20923c01.png" alt="img"></p>
<p><strong>语言：</strong>C＃。</p>
<p>这是专为C＃程序员设计的。</p>
<p>Accord.NET框架是一个.NET机器学习框架，使音频和图像处理变得简单。</p>
<p>这个框架可以有效地处理数值优化、人工神经网络，甚至可视化。除此之外，Accord.NET对计算机视觉和信号处理的功能非常强大，同时也使得算法的实现变得简单。</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/bcb92c9f748b469c96cff329f8f3b804.jpg" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>它有一个强大而积极的开发团队。</li>
<li>非常有据可查的框架。</li>
<li>质量可视化。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不是一个非常流行的框架。</li>
<li>比TensorFlow慢。</li>
</ul>
<h2 id="8-Spark-MLlib"><a href="#8-Spark-MLlib" class="headerlink" title="8. Spark MLlib"></a><strong>8. Spark MLlib</strong></h2><h4 id="“可扩展的机器学习库”"><a href="#“可扩展的机器学习库”" class="headerlink" title="“可扩展的机器学习库”"></a>“可扩展的机器学习库”</h4><blockquote>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/eb3a3a6644854728d920ae1c1622425b.png" alt="img"></p>
</blockquote>
<p><strong>语言：</strong>Scala。</p>
<p>Apache的Spark MLlib是一个非常可扩展的机器学习库。</p>
<p>它非常适用于诸如Java、Scala、Python，甚至R等语言。它非常高效，因为它可以与Python库和R库中的numpy进行互操作。</p>
<p>MLlib可以轻松插入到Hadoop工作流程中。它提供了机器学习算法，如分类、回归和聚类。</p>
<p>这个强大的库在处理大型数据时非常快速。</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/19a2dc5b2a510cbfa8e085cd4becc9d8.jpg" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>对于大规模数据处理非常快速。</li>
<li>提供多种语言。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>陡峭的学习曲线。</li>
<li>即插即用仅适用于Hadoop。</li>
</ul>
<h2 id="9-Sci-kit-Learn"><a href="#9-Sci-kit-Learn" class="headerlink" title="9. Sci-kit Learn"></a><strong>9. Sci-kit Learn</strong></h2><h4 id="“用Python的机器学习”"><a href="#“用Python的机器学习”" class="headerlink" title="“用Python的机器学习”"></a>“用Python的机器学习”</h4><p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/fa3129d1a5c4d32652c43ee5bfefc44e.jpg" alt="img"></p>
<p><strong>语言：</strong>Python。</p>
<p>Sci-kit learn是一个非常强大的机器学习Python库，主要用于构建模型。</p>
<p>使用numpy、SciPy和matplotlib等其他库构建，对统计建模技术（如分类、回归和聚类）非常有效。</p>
<p>Sci-kit learn带有监督学习算法、无监督学习算法和交叉验证等功能。</p>
<p><strong>优点：</strong></p>
<ul>
<li>许多主要算法的可用性。</li>
<li>有效的数据挖掘。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不是构建模型的最佳选择。</li>
<li>GPU效率不高。</li>
</ul>
<h2 id="10-MLPack"><a href="#10-MLPack" class="headerlink" title="10. MLPack"></a><strong>10. MLPack</strong></h2><h4 id="“可扩展的C-机器学习库”"><a href="#“可扩展的C-机器学习库”" class="headerlink" title="“可扩展的C ++机器学习库”"></a>“可扩展的C ++机器学习库”</h4><p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/7547e8233eeaacfaa9dafe699537df27.png" alt="img"></p>
<p><strong>语言：</strong>C ++。</p>
<p>MLPack是一个用C ++实现的可扩展的机器学习库。因为它是用C ++编写的，所以你可以猜测它对于内存管理是非常好的。</p>
<p>MLPack以极高的速度运行，因为高质量的机器学习算法与库一起出现。这个库是对新手友好的，并提供了一个简单的API使用。</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010%E4%B8%AA%E6%9C%80%E4%BD%B3%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6%E5%92%8CAI%E5%BA%93%EF%BC%88%E4%BC%98%E7%BC%BA%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%89/a6801074bf4cc841424d99d786c6537b.png" alt="img"></p>
<p><strong>优点：</strong></p>
<ul>
<li>非常可扩展。</li>
<li>Python和C ++绑定可用。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不是最好的文献记录。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>本文讨论的库非常有效，并且随着时间的推移已经证明都是高质量的。像Facebook、谷歌、雅虎、苹果和微软这样的大公司都利用其中的一些库来进行深度学习和机器学习项目，那么你为什么不呢？</p>
<p>你能想到你经常使用的但并不在这个列表中的其他库吗？</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能 -机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习经典算法之-----最小二乘法</title>
    <url>/post/46e20187.html</url>
    <content><![CDATA[<p>最小二乘法</p>
<p>  我们以最简单的一元线性模型来解释最小二乘法。什么是一元线性模型呢？ 监督学习中，如果预测的变量是离散的，我们称其为分类（如决策树，支持向量机等），如果预测的变量是连续的，我们称其为回归。回归分析中，如果只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。对于二维空间线性是一条直线；对于三维空间线性是一个平面，对于多维空间线性是一个超平面…</p>
<p>  对于一元线性回归模型, 假设从总体中获取了n组观察值（X1，Y1），（X2，Y2）， …，（Xn，Yn）。对于平面中的这n个点，可以使用无数条曲线来拟合。要求样本回归函数尽可能好地拟合这组值。综合起来看，这条直线处于样本数据的中心位置最合理。 选择最佳拟合曲线的标准可以确定为：使总的拟合误差（即总残差）达到最小。有以下三个标准可以选择：</p>
<p>​    （1）用“残差和最小”确定直线位置是一个途径。但很快发现计算“残差和”存在相互抵消的问题。<br>​    （2）用“残差绝对值和最小”确定直线位置也是一个途径。但绝对值的计算比较麻烦。<br>​    （3）最小二乘法的原则是以“残差平方和最小”确定直线位置。用最小二乘法除了计算比较方便外，得到的估计量还具有优良特性。这种方法对异常值非常敏感。</p>
<p>　 最常用的是普通最小二乘法（ Ordinary  Least Square，OLS）：所选择的回归模型应该使所有观察值的残差平方和达到最小。（Q为残差平方和）- 即采用平方损失函数。</p>
<p> 样本回归模型：</p>
<p>​         <img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8B-----%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/1354428434_7303.jpg" alt="img">          其中ei为样本（Xi, Yi）的误差</p>
<p>  平方损失函数：</p>
<p>​           <img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8B-----%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/1354428515_1582.jpg" alt="img"></p>
<p>  则通过Q最小确定这条直线，即确定<img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8B-----%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/1354428590_9906.jpg" alt="img">，以<img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8B-----%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/1354428601_4150.jpg" alt="img">为变量，把它们看作是Q的函数，就变成了一个求极值的问题，可以通过求导数得到。求Q对两个待估参数的偏导数：</p>
<p>​          <img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8B-----%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/1354428700_9699.jpg" alt="img">  </p>
<p>  根据数学知识我们知道，函数的极值点为偏导为0的点。</p>
<p>  解得：</p>
<p>​          <img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8B-----%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/1354428824_3244.jpg" alt="img"></p>
<p>这就是最小二乘法的解法，就是求得平方损失函数的极值点。</p>
<p>下面通过一个例子来说明最小二乘法：</p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8B-----%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/20160926100546115" alt="img"></p>
<p><img src="/../images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E4%B9%8B-----%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/20160926100605037" alt="img"></p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>-大数据 -机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>无监督学习</title>
    <url>/post/f54fd71a.html</url>
    <content><![CDATA[<p><strong>目录</strong></p>
<ul>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label0">1 关于机器学习</a></li>
<li>2 sklearn库中的标准数据集及基本功能<ul>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label1_0">2.1 标准数据集</a></li>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label1_1">2.2 sklearn库的基本功能</a></li>
</ul>
</li>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label2">3 关于无监督学习</a></li>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label3">4 K-means方法及应用</a></li>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label4">5 DBSCAN方法及应用</a></li>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label5">6  PCA方法及其应用</a></li>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label6">7 NMF方法及其实例</a></li>
<li><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_label7">8 基于聚类的“图像分割”</a></li>
</ul>
<p><strong>正文</strong></p>
<h1 id="1-关于机器学习"><a href="#1-关于机器学习" class="headerlink" title="1 关于机器学习"></a>1 关于机器学习</h1><p>　　机器学习是实现人工智能的手段, 其主要研究内容是如何利用数据或经验进行学习, 改善具体算法的性能 </p>
<p>　　　　多领域交叉, 涉及概率论、统计学, 算法复杂度理论等多门学科</p>
<p>　　　　广泛应用于网络搜索、垃圾邮件过滤、推荐系统、广告投放、信用评价、欺诈检测、股票交易和医疗诊断等应用<br>　　机器学习的分类</p>
<p>　　　　<strong>监督学习</strong> （Supervised Learning）</p>
<p>　　　　　　从给定的数据集中学习出一个函数, 当新的数据到来时, 可以根据这个函数预测结果, 训练集通常由人工标注</p>
<p>　　　　<strong>无监督学习</strong> （Unsupervised Learning）</p>
<p>　　　　　　相较于监督学习, 没有人工标注</p>
<p>　　　　<strong>强化学习</strong>（Reinforcement Learning，增强学习）</p>
<p>　　　　　　通过观察通过什么样的动作获得最好的回报, 每个动作都会对环境有所影响, 学习对象通过观察周围的环境进行判断</p>
<p>　　　　<strong>半监督学习</strong>（Semi-supervised Learning）</p>
<p>　　　　　　介于监督学习和无监督学习</p>
<p>　　　　<strong>深度学习</strong> (Deep Learning)</p>
<p>　　　　　　利用深层网络神经模型, 抽象数据表示特征</p>
<p>　　在Python中使用**Scikit-learn(简化为sklearn)**这一模块来处理机器学习</p>
<p>　　　　<a href="http://scikit-learn.org/stable/">官网</a></p>
<p>　　　　主要是依赖于numpy, scipy和matplotlib库</p>
<p>　　　　开源可复用</p>
<p>　　sklearn中机器学习模型十分丰富, 需要根据问题的类型来选择适当的模型</p>
<p>　　sklearn常用的函数</p>
<p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518151628182-1057765599.png" alt="img"></p>
<p>　　关于sklearn库</p>
<p>　　　　sklearn是scikit-learn的简称，是一个基于Python的第三方模块。sklearn库集成了一些常用的机器学习方法，在进行机器学习任务时，并不需要实现算法，只需要简单的调用sklearn库中提供的模块就能完成大多数的机器学习任务。</p>
<p>　　　　安装sklearn库需要安装numpy, scipy(sklearn的基础, 集成了多种数学算法和函数), matplotlib(数据绘图工具)</p>
<p>　　　　<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/">安装地址</a></p>
<p>　　　　注意安装有顺序: numpy -&gt; scipy -&gt; matplotlib -&gt; sklearn</p>
<p><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_labelTop">回到顶部</a></p>
<h1 id="2-sklearn库中的标准数据集及基本功能"><a href="#2-sklearn库中的标准数据集及基本功能" class="headerlink" title="2 sklearn库中的标准数据集及基本功能"></a>2 sklearn库中的标准数据集及基本功能</h1><h2 id="2-1-标准数据集"><a href="#2-1-标准数据集" class="headerlink" title="2.1 标准数据集"></a>2.1 标准数据集</h2><p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518162319478-267092604.png" alt="img"></p>
<p>　　1) 波士顿房价数据集</p>
<p>　　　　波士顿房价数据集包含506组数据，每条数据包含房屋以及房屋周围的详细信息。其中包括城镇犯罪率、一氧化氮浓度、住宅平均房间数、到中心区域的加距离以及自住房平均房价等。因此，波士顿房价数据集能够应用到回归问题上。</p>
<p>　　　　加载数据集</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sklearn.datasets.load_boston()</span><br></pre></td></tr></table></figure>
<p>　　　　其中有参数return_X_y, 设置为True是会返回(data, target)两个数据, <strong>默认为False</strong>, 只返回data(包含了data和target两个部分的内容)</p>
<p>　　　　具体使用</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518163922713-1506268480.png" alt="img"></p>
<p>　　2) 鸢尾花数据集</p>
<p>　　　　鸢尾花数据集采集的是鸢尾花的测量数据以及其所属的类别</p>
<p>　　　　测量数据包括: 萼片长度、萼片宽度、花瓣长度、花瓣宽度</p>
<p>　　　　类别共分为三类: Iris Setosa，Iris Versicolour，Iris Virginica, 该数据集可用于多分类问题</p>
<p>　　　　加载数据集</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sklearn.datasets. load_iris()</span><br></pre></td></tr></table></figure>
<p>　　　　同样有参数return_X_y, 使用方法雷同</p>
<p>　　　　具体实例</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518164919900-1535707821.png" alt="img"></p>
<p>　　3) 手写数字数据集</p>
<p>　　　　手写数字数据集包括1797个0-9的手写数字数据，每个数字由8*8大小的矩阵构成，矩阵中值的范围是0-16，代表颜色的深度。</p>
<p>　　　　加载数据集</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sklearn.datasets.load_digits()</span><br></pre></td></tr></table></figure>
<p>　　　　return_X_y: 效果依旧, True返回(data, target), 默认False直接返回全部内容</p>
<p>　　　　n_class: 设置数据类别, 返回数据的类别比设置类别低的数据样本, 设置为5就会返回0~4的数据 </p>
<p>　　　　基本使用<br>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518165720525-228666888.png" alt="img"></p>
<h2 id="2-2-sklearn库的基本功能"><a href="#2-2-sklearn库的基本功能" class="headerlink" title="2.2 sklearn库的基本功能"></a>2.2 sklearn库的基本功能</h2><p>　　sklearn库的共分为6大部分，分别用于完成分类任务、回归任务、聚类任务、降维任务、 模型选择以及数据的预处理</p>
<p>　　1) <strong>分类</strong>任务</p>
<p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518170108494-1242465797.png" alt="img"></p>
<p>　　2) <strong>回归</strong>任务</p>
<p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518170135635-1624450024.png" alt="img"></p>
<p>　　3) <strong>聚类</strong>任务</p>
<p> 　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518170203385-816326160.png" alt="img"></p>
<p>　　4) <strong>降维</strong>任务</p>
<p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518170219666-1472992565.png" alt="img"></p>
<p><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_labelTop">回到顶部</a></p>
<h1 id="3-关于无监督学习"><a href="#3-关于无监督学习" class="headerlink" title="3 关于无监督学习"></a>3 关于无监督学习</h1><p>　　无监督学习的目标</p>
<p>　　　　利用无标签的数据学习数据的分布或数据与数据之间的关系被称作无监督学习</p>
<p>　　　　有监督学习和无监督学习的最大区别在于数据是否有标签</p>
<p>　　　　无监督学习最常应用的场景是<strong>聚类(clustering)**和</strong>降维(DimensionReduction)**</p>
<p>　　<strong>聚类</strong></p>
<p>　　　　聚类(clustering)，就是根据数据的“相似性”将数据分为多类的过程</p>
<p>　　　　评估两个不同样本之间的“相似性” ，通常使用的方法就是计算两个样本之间的“距离”。使用不同的方法计算样本间的距离会关系到聚类结果的好坏</p>
<p>　　1) <strong>欧氏距离</strong></p>
<p>　　　　欧氏距离是最常用的一种距离度量方法，源于欧式空间中<strong>两点的距离</strong>。</p>
<p>　　　　计算公式</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518170709135-1532917790.png" alt="img"></p>
<p>　　　　直观表示</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518170832182-886281143.png" alt="img"></p>
<p>　　2) <strong>曼哈顿距离</strong></p>
<p>　　　　曼哈顿距离也称作“城市街区距离”，类似于在城市之中驾车行驶，<strong>从一个十字路口到另外一个十字楼口的距离(x与y两个方向的距离之和)</strong></p>
<p>　　　　计算公式</p>
<p> 　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518170923869-2101076582.png" alt="img"></p>
<p>　　　　直观表示</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518170948603-1805810447.png" alt="img"></p>
<p>　　3) <strong>马氏距离</strong></p>
<p>　　　　马氏距离表示数据的协方差距离，是一种尺度无关的度量方式。也就是说马氏距离会先将样本点的各个属性标准化，再计算样本间的距离。</p>
<p>　　　　计算公式, 其中s是协方差矩阵</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518171114385-1175330249.png" alt="img"></p>
<p>　　　　马氏空间的距离</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518171159057-1051433700.png" alt="img"></p>
<p>　　4) <strong>夹角余弦</strong></p>
<p>　　　　余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个样本差异的大小。余弦值越接近1，说明两个向量夹角越接近0度，表明两个向量越相似</p>
<p>　　　　计算公式</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518171255244-1619807957.png" alt="img"></p>
<p>　　　　二维空间显示</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518171312307-1211754309.png" alt="img"></p>
<p>　　sklearn提供的常用聚类算法函数包含在<strong>sklearn.cluster</strong>这个模块中</p>
<p>　　以同样的数据集应用于不同的算法，可能会得到不同的结果，算法所耗费的时间也不尽相同，这是由算法的特性决定的</p>
<p>　　sklearn.cluster</p>
<p>　　　　sklearn.cluster模块提供的各聚类算法函数可以使用不同的数据形式作为输入</p>
<p>　　　　标准数据输入格式:<strong>[**</strong>样本个数，特征个数****]**定义的矩阵形式</p>
<p>　　　　相似性矩阵输入格式：即由**[样本数目，样本数目]**定义的矩阵形式，矩阵中的每一个元素为两个样本的相似度，如DBSCAN，AffinityPropagation(近邻传播算法)接受这种输入。如果以余弦相似度为例，则对角线元素全为1. 矩阵中每个元素的取值范围为[0,1]</p>
<p>　　具有代表性的聚类函数</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518172253010-1621085682.png" alt="img"></p>
<p>　　<strong>降维</strong></p>
<p>　　　　降维就是在保证数据所具有的代表性特征或分布的情况下, 将<strong>高维数据转化为低维数据</strong>的过程</p>
<p>　　　　作用:</p>
<p>　　　　　　数据可视化</p>
<p>　　　　　　作为中间过程, 起到精简数据, 提高其他机器学习算法效率的作用</p>
<p>　　分类和降维</p>
<p>　　　　聚类和分类都是无监督学习的典型任务，任务之间存在关联，比如某些高纬数据的分类可以通过降维处理更好的获得，另外学界研究也表明代表性的分类算法如k-means与降维算法如NMF之间存在等价性</p>
<p>　　sklearn和降维</p>
<p>　　　　降维是机器学习领域的一个重要研究内容，有很多被工业界和学术界接受的典型算法，截止到目前sklearn库提供7种降维算法</p>
<p>　　　　降维过程也可以被理解为对<strong>数据集的组成成份进行分解（decomposition）</strong>的过程，因此sklearn为降维模块命名为decomposition, 在对降维算法调用需要使用sklearn.decomposition模块</p>
<p>　　　　sklearn.decomposition的常用算法</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518173946947-1840266132.png" alt="img"></p>
<p><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_labelTop">回到顶部</a></p>
<h1 id="4-K-means方法及应用"><a href="#4-K-means方法及应用" class="headerlink" title="4 K-means方法及应用"></a>4 K-means方法及应用</h1><p>　　k-means算法也就是<strong>k均值算法</strong></p>
<p>　　k-means算法以k为参数，把n个对象分成k个簇, 使簇内具有较高的相似度, 而簇间的相似度较低</p>
<p>　　处理结果如下</p>
<p>　　　　1 随机选择k个点作为初始的聚类中心；</p>
<p>　　　　2 对于剩下的点，根据其与聚类中心的距离，将其归入最近的簇</p>
<p>　　　　3 对每个簇，计算所有点的均值作为新的聚类中心</p>
<p>　　　　4 重复2、 3直到聚类中心不再发生改变</p>
<p>　　k-meams方法的处理过程如下</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518184141416-532536277.png" alt="img"></p>
<p>　　创建k-means实例</p>
<p>　　　　创建实例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sklearn.cluster.Kmeans()</span><br></pre></td></tr></table></figure>
<p>　　　　n_clusters: 用于指定聚类中心的个数, 一般设定此参数, 别的参数使用默认值</p>
<p>　　　　init: 初始聚类中心的初始化方法, 默认值是k-means++</p>
<p>　　　　max_iter: 最大的跌打次数, 默认值是30</p>
<p>　　创建实例后, 可以通过实例对象调用<strong>fit_predict()**计算</strong>簇中心以及为簇分配序号**</p>
<p>　　　　其中会传入参数data, 用于传入需要加载的数据</p>
<p>　　　　返回的结果是一个label, 是聚类后各个数据所属的标签</p>
<p>　　k-means实例还有一个参数 <strong>cluster_centers_</strong>, 可以通过处理该参数的值来得到更进一步的处理数据　　</p>
<p>　　k-means的应用</p>
<p>　　处理中国1999年各省份的消费水平</p>
<p>　　　　处理的技术路线: sklearn.cluster.Kmeans</p>
<p>　　　　数据模型为</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170525123220341-1430445217.png" alt="img"></p>
<p>　　　　具体实例代码如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">def loadData(filePath):</span><br><span class="line">    fr &#x3D; open(filePath,&#39;r+&#39;)</span><br><span class="line">    lines &#x3D; fr.readlines()</span><br><span class="line">    retData &#x3D; []</span><br><span class="line">    retCityName &#x3D; []</span><br><span class="line">    for line in lines:</span><br><span class="line">        items &#x3D; line.strip().split(&quot;,&quot;)</span><br><span class="line">        retCityName.append(items[0])</span><br><span class="line">        retData.append([float(items[i]) for i in range(1,len(items))])</span><br><span class="line">    return retData,retCityName</span><br><span class="line">  </span><br><span class="line">      </span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    data,cityName &#x3D; loadData(&#39;31省市居民家庭消费水平-city.txt&#39;)</span><br><span class="line">    km &#x3D; KMeans(n_clusters&#x3D;4)</span><br><span class="line">    label &#x3D; km.fit_predict(data)</span><br><span class="line">    expenses &#x3D; np.sum(km.cluster_centers_,axis&#x3D;1)</span><br><span class="line">    #print(expenses)</span><br><span class="line">    CityCluster &#x3D; [[],[],[],[]]</span><br><span class="line">    for i in range(len(cityName)):</span><br><span class="line">        CityCluster[label[i]].append(cityName[i])</span><br><span class="line">    for i in range(len(CityCluster)):</span><br><span class="line">        print(&quot;Expenses:%.2f&quot; % expenses[i])</span><br><span class="line">        print(CityCluster[i])</span><br></pre></td></tr></table></figure>
<p>　　　　程序结果</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170525122740950-2018421250.png" alt="img"></p>
<p>　　深入程序解释</p>
<p>　　　　label是一个列表类型, 具体的值是 对应的数据被分成哪一类的索引</p>
<p>　　　　也就是说, 遍历cityname的时候同步取得label的值, 就可以对应的把城市名字放到合适的分类中, 这就是下面这句话的来源</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CityCluster[label[i]].append(cityName[i])</span><br></pre></td></tr></table></figure>
<p>　　　　生成的cluster_centers_是一个二维数据, 是一个列表里面套列表, 里面列表存储的是一个分类中, 每个城市的值对应处理得到的结果</p>
<p>　　　　所以对这个值在1维上相加得到的就是每一个聚类的综合的值, 这就是这句话的来源</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">expenses &#x3D; np.sum(km.cluster_centers_,axis&#x3D;1)</span><br></pre></td></tr></table></figure>
<p>　　深入k-means</p>
<p>　　　　k-means在计算两条数据相似性时, <strong>默认是使用欧式距离</strong>, 且没有给对应的参数来修改这个默认的计算距离的方法</p>
<p>　　　　如果需要修改这个默认的距离方式, 需要修改源代码</p>
<p>　　　　源码位置为C:\Python36\Lib\site-packages\sklearn\metrics\pairwise.py</p>
<p>　　　　162行的euclidean_distances()函数</p>
<p>　　　　建议使用scipy.spatial.distance.cdist方法</p>
<p><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_labelTop">回到顶部</a></p>
<h1 id="5-DBSCAN方法及应用"><a href="#5-DBSCAN方法及应用" class="headerlink" title="5 DBSCAN方法及应用"></a>5 DBSCAN方法及应用</h1><p>　　DBSCAN算法是一种<strong>基于密度</strong>的聚类算法</p>
<p>　　　　DBSCAN算法聚类的时候不要预先指定簇的个数</p>
<p>　　　　因而最终的簇的个数不确定</p>
<p>　　DBSCAN算法将数据点分为三类</p>
<p>　　　　<strong>核心点</strong>: 在半径Eps内含有超过MinPts数据的点</p>
<p>　　　　<strong>边界点</strong>: 在半径Eps内点的数量小于MinPts, 但是落在核心点的邻域内</p>
<p>　　　　<strong>噪音点</strong>: 既不是核心点也不是边界点的点</p>
<p>　　DBSCAN的算法流程</p>
<p>　　　　1.将所有点标记为核心点、边界点或噪声点;</p>
<p>　　　　2.删除噪声点;</p>
<p>　　　　3.为距离在Eps之内的所有核心点之间赋予一条边;</p>
<p>　　　　4.每组连通的核心点形成一个簇;</p>
<p>　　　　5.将每个边界点指派到一个与之关联的核心点的簇中(哪一个核心点的半径范围之内)</p>
<p>　　获得密度聚类的实例</p>
<p>　　　　设Eps=3, MinPts=3, 采用曼哈顿距离聚类</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518192449353-152727134.png" alt="img"></p>
<p>　　　　处理核心点, 边界点, 噪声点</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518192532416-1288859775.png" alt="img"></p>
<p>　　　　将不超过Eps=3的点相互圈起来形成一个簇, 核心点邻域内的点都会被加入到这个簇当中</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518192641525-2103156938.png" alt="img"></p>
<p>　　创建DBSCAN的实例</p>
<p>　　　　使用代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sklearn.cluster.DBSCAN()</span><br></pre></td></tr></table></figure>
<p>　　　　其中有几个参数</p>
<p>　　　　eps: 两个样本被看做邻居节点的最大距离</p>
<p>　　　　min_samples: 簇的样本数</p>
<p>　　　　metric: 距离的计算方式</p>
<p>　　　　<a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN">详细介绍</a></p>
<p>　　创建完毕DBSCAN的对象之后</p>
<p>　　　　可以后 DBSCAN对象.fix(数据) 来生成一个结果, 这个结果有一个属性是<strong>labels_</strong></p>
<p>　　　　这个就是我们需要的标签</p>
<p> 　　　其中标签中值为-1表示噪声</p>
<p>　　实例处理, 学生上网时间分布</p>
<p>　　数据</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170525160322966-58968362.png" alt="img"></p>
<p>　　　　分别是 记录编号, 学生编号, MAC地址, IP地址, 开始上网时间, 结束上网时间, 上网时长(秒), …</p>
<p>　　具体代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import sklearn.cluster as skc</span><br><span class="line">from sklearn import metrics</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"> </span><br><span class="line">onlinetimes &#x3D; &#123;&#125;</span><br><span class="line">with open(&quot;学生月上网时间分布-TestData.txt&quot;, encoding&#x3D;&quot;utf8&quot;) as f:</span><br><span class="line">    for line in f:</span><br><span class="line">        info_list &#x3D; line.strip().split(&#39;,&#39;)</span><br><span class="line">        mac &#x3D; info_list[2]</span><br><span class="line">        onlinetime &#x3D; int(info_list[6])</span><br><span class="line">        # 获取上网的起始时候的小时 &quot;2014-07-21 08:14:29.287000000&quot; 这个的08</span><br><span class="line">        starttime &#x3D; int(info_list[4].split(&#39; &#39;)[1].split(&#39;:&#39;)[0])</span><br><span class="line">        onlinetimes[mac] &#x3D; (starttime, onlinetime)</span><br><span class="line">real_X &#x3D; np.array([onlinetimes[key] for key in onlinetimes]).reshape((-1, 2))</span><br><span class="line"># 只获取上网的时间点</span><br><span class="line">X &#x3D; real_X[:, 0:1]</span><br><span class="line"> </span><br><span class="line">db &#x3D; skc.DBSCAN(eps&#x3D;0.01, min_samples&#x3D;20).fit(X)</span><br><span class="line">labels &#x3D; db.labels_</span><br><span class="line"> </span><br><span class="line"># 获得噪声点比例</span><br><span class="line">raito &#x3D; len(labels[labels[:] &#x3D;&#x3D; -1]) &#x2F; len(labels)</span><br><span class="line">print(&#39;Noise raito:&#39;, format(raito, &#39;.2%&#39;))</span><br><span class="line"> </span><br><span class="line"># 显示算法性能</span><br><span class="line">n_clusters_ &#x3D; len(set(labels)) - (1 if -1 in labels else 0)</span><br><span class="line">print(&#39;Estimated number of clusters: %d&#39; % n_clusters_)</span><br><span class="line">print(&quot;Silhouette Coefficient: %0.3f&quot; % metrics.silhouette_score(X, labels))</span><br><span class="line"> </span><br><span class="line">for i in range(n_clusters_):</span><br><span class="line">    print(&#39;Cluster &#39;, i, &#39;:&#39;)</span><br><span class="line">    print(list(X[labels &#x3D;&#x3D; i].flatten()))</span><br><span class="line"> </span><br><span class="line">plt.hist(X, 24)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>　　实验结果</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170525172657138-68858036.png" alt="img"></p>
<p>　　处理数据的技巧</p>
<p>　　　　如果原始数据不协调, 不利于数据处理, 可以对原始数据进行无损变化来使得数据大小更加合适处理</p>
<p>　　　　具体的处理办法就是取对数变换</p>
<p><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_labelTop">回到顶部</a></p>
<h1 id="6-PCA方法及其应用"><a href="#6-PCA方法及其应用" class="headerlink" title="6  PCA方法及其应用"></a>6  PCA方法及其应用</h1><p>　　PCA(Principal Component Analysis), 主成分分析, 是最常用的一种降维方法, 通常用于高维数据集的探索与可视化, 还可以用作数据压缩和预处理等</p>
<p>　　PCA可以把具有相关性的高维变量<strong>合成</strong>为线性无关的低维变量，称为主成分。主成分能够尽可能保留原始数据的信息</p>
<p>　　相关术语</p>
<p>　　1) 方差</p>
<p>　　　　是各个样本和样本均值的差的平方和的均值，用来度量一组数据的分散程度</p>
<p>　　　　公式</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518200233775-1681892894.png" alt="img"></p>
<p>　　2) 协方差</p>
<p>　　　　用于度量两个变量之间的线性相关性程度，若两个变量的协方差为0，则可认为二者线性无关。协方差矩阵则是由变量的协方差值构成的矩阵（对称阵）</p>
<p>　　　　公式</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518200343869-905360614.png" alt="img"></p>
<p>　　3) 特征向量</p>
<p>　　　　矩阵的特征向量是描述数据集结构的非零向量</p>
<p>　　　　公式</p>
<p>　　　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170518200807557-1259352640.png" alt="img"></p>
<p>　　主成分分析的原理</p>
<p>　　　　矩阵的主成分就是其协方差矩阵对应的特征向量，按照对应的特征值大小进行排序，最大的特征值就是第一主成分，其次是第二主成分，以此类推</p>
<p>　　使用PCA</p>
<p>　　　　创建PCA对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sklearn.decomposition.PCA()</span><br></pre></td></tr></table></figure>
<p>　　　　主要有两个参数</p>
<p>　　　　n_components: 指定主要成分的个数</p>
<p>　　　　svd_solver: 设置特征值分解的方法, 默认为auto, 其他可选的还有full, arpack, randomized</p>
<p>　　创建PCA对象之后, 可以通过调用**fit_transform(data)**函数传入需要降维的数据, 返回的数据就是降维之后处理完毕的数据</p>
<p>　　实例, 处理鸢尾花数据集</p>
<p>　　　　鸢尾花数据集是(150, 4)</p>
<p>　　　　可以利用PCA将数据集处理成(150, 2)的数据</p>
<p>　　　　处理鸢尾花数据让其从4维数据编程2位平面数据, 具体代码如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">  </span><br><span class="line">data &#x3D; load_iris()</span><br><span class="line">y &#x3D; data.target</span><br><span class="line">X &#x3D; data.data</span><br><span class="line">pca &#x3D; PCA(n_components&#x3D;2)</span><br><span class="line">reduced_X &#x3D; pca.fit_transform(X)</span><br><span class="line">  </span><br><span class="line">red_x, red_y &#x3D; [], []</span><br><span class="line">blue_x, blue_y &#x3D; [], []</span><br><span class="line">green_x, green_y &#x3D; [], []</span><br><span class="line">  </span><br><span class="line">for i in range(len(reduced_X)):</span><br><span class="line">    if y[i] &#x3D;&#x3D; 0:</span><br><span class="line">        red_x.append(reduced_X[i][0])</span><br><span class="line">        red_y.append(reduced_X[i][1])</span><br><span class="line">    elif y[i] &#x3D;&#x3D; 1:</span><br><span class="line">        blue_x.append(reduced_X[i][0])</span><br><span class="line">        blue_y.append(reduced_X[i][1])</span><br><span class="line">    else:</span><br><span class="line">        green_x.append(reduced_X[i][0])</span><br><span class="line">        green_y.append(reduced_X[i][1])</span><br><span class="line">  </span><br><span class="line">plt.scatter(red_x, red_y, c&#x3D;&#39;r&#39;, marker&#x3D;&#39;x&#39;)</span><br><span class="line">plt.scatter(blue_x, blue_y, c&#x3D;&#39;b&#39;, marker&#x3D;&#39;D&#39;)</span><br><span class="line">plt.scatter(green_x, green_y, c&#x3D;&#39;g&#39;, marker&#x3D;&#39;.&#39;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>　　具体结果</p>
<p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170525184342372-23230586.png" alt="img"></p>
<p><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_labelTop">回到顶部</a></p>
<h1 id="7-NMF方法及其实例"><a href="#7-NMF方法及其实例" class="headerlink" title="7 NMF方法及其实例"></a>7 NMF方法及其实例</h1><p>　　NMF(Non-negative Matrix Factorization, 非负矩阵分解), 是在矩阵中所有元素均为<strong>非负数</strong>约束条件之下的矩阵分解方法</p>
<p>　　基本思想：给定一个非负矩阵V，NMF能够找到一个非负矩阵W和一个非负矩阵H，使得矩阵W和H的乘积近似等于矩阵V中的值</p>
<p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170519085203932-1800063375.png" alt="img"></p>
<p>　　W矩阵：基础图像矩阵, 相当于从原矩阵V中抽取出来的特征</p>
<p>　　H矩阵：系数矩阵</p>
<p>　　NMF能够广泛应用于图像分析、文本挖掘和语音处理等领域</p>
<p>　　</p>
<p>　　矩阵分解优化目标: 最小化W矩阵H矩阵的乘积和原始矩阵之间的差别，目标函数如下</p>
<p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170519085903728-2129321519.png" alt="img"></p>
<p>　　基于KL散度的优化目标, 损失函数如下</p>
<p>　　<img src="/../images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/1003577-20170519091244353-1606654133.png" alt="img"></p>
<p>　　<a href="http://blog.csdn.net/acdreamers/article/details/44663421/">公式的推导</a></p>
<p>　　在sklearn库中，可以使用sklearn.decomposition.NMF加载NMF算法，主要参数有</p>
<p>　　生成NMF对象</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sklearn.decomposition.NMF()</span><br></pre></td></tr></table></figure>
<p>　　　　n_components：用于指定分解后矩阵的单个维度k</p>
<p>　　　　init：W矩阵和H矩阵的初始化方式，默认为‘ nndsvdar’</p>
<p>　　使用NMF对人脸数据进行特征提取</p>
<p>　　　　使用 <strong>NMF对象.fit(数据)</strong> 来处理数据, 生成的内容还是在NMF对象中</p>
<p>　　　　获取处理数据 <strong>NMF对象.components_</strong> 获取得到的数据</p>
<p>　　具体使用PCA和NMF处理人脸数据并且对比展示的代码如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from numpy.random import RandomState</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.datasets import fetch_olivetti_faces</span><br><span class="line">from sklearn import decomposition</span><br><span class="line">  </span><br><span class="line">n_row, n_col &#x3D; 2, 3</span><br><span class="line">n_components &#x3D; n_row * n_col</span><br><span class="line">image_shape &#x3D; (64, 64)</span><br><span class="line">  </span><br><span class="line"># Load faces data</span><br><span class="line">dataset &#x3D; fetch_olivetti_faces(shuffle&#x3D;True, random_state&#x3D;RandomState(0))</span><br><span class="line">faces &#x3D; dataset.data</span><br><span class="line">  </span><br><span class="line">def plot_gallery(title, images, n_col&#x3D;n_col, n_row&#x3D;n_row):</span><br><span class="line">    plt.figure(figsize&#x3D;(2. * n_col, 2.26 * n_row))</span><br><span class="line">    plt.suptitle(title, size&#x3D;16)</span><br><span class="line">    for i, comp in enumerate(images):</span><br><span class="line">        plt.subplot(n_row, n_col, i + 1)</span><br><span class="line">        vmax &#x3D; max(comp.max(), -comp.min())</span><br><span class="line">  </span><br><span class="line">        plt.imshow(comp.reshape(image_shape), cmap&#x3D;plt.cm.gray,</span><br><span class="line">                   interpolation&#x3D;&#39;nearest&#39;, vmin&#x3D;-vmax, vmax&#x3D;vmax)</span><br><span class="line">        plt.xticks(())</span><br><span class="line">        plt.yticks(())</span><br><span class="line">    plt.subplots_adjust(0.01, 0.05, 0.99, 0.94, 0.04, 0.)</span><br><span class="line">  </span><br><span class="line">      </span><br><span class="line">plot_gallery(&quot;First centered Olivetti faces&quot;, faces[:n_components])</span><br><span class="line"> </span><br><span class="line">estimators &#x3D; [</span><br><span class="line">    (&#39;Eigenfaces - PCA using randomized SVD&#39;,</span><br><span class="line">         decomposition.PCA(n_components&#x3D;6,whiten&#x3D;True)),</span><br><span class="line">  </span><br><span class="line">    (&#39;Non-negative components - NMF&#39;,</span><br><span class="line">         decomposition.NMF(n_components&#x3D;6, init&#x3D;&#39;nndsvda&#39;, tol&#x3D;5e-3))</span><br><span class="line">]</span><br><span class="line">  </span><br><span class="line">for name, estimator in estimators:</span><br><span class="line">    print(&quot;Extracting the top %d %s...&quot; % (n_components, name))</span><br><span class="line">    print(faces.shape)</span><br><span class="line">    estimator.fit(faces)</span><br><span class="line">    components_ &#x3D; estimator.components_</span><br><span class="line">    plot_gallery(name, components_[:n_components])</span><br><span class="line">  </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><a href="https://www.cnblogs.com/weihuchao/p/6874683.html#_labelTop">回到顶部</a></p>
<h1 id="8-基于聚类的“图像分割”"><a href="#8-基于聚类的“图像分割”" class="headerlink" title="8 基于聚类的“图像分割”"></a>8 基于聚类的“图像分割”</h1><p>　　图像分割：利用图像的灰度、颜色、纹理、形状等特征，把图像分成若干个互不重叠的区域，并使这些特征在同一区域内呈现相似性，在不同的区域之间存在明显的差异性。 然后就可以将分割的图像中具有独特性质的区域提取出来用于不同的研究</p>
<p>　　图像分割技术已在实际生活中得到广泛的应用。例如：在机车检验领域，可以应用到轮毂裂纹图像的分割，及时发现裂纹，保证行车安全；在生物医学工程方面，对肝脏CT图像进行分割，为临床治疗和病理学研究提供帮助</p>
<p>　　图像分割常用方法：</p>
<p>　　　　1 阈值分割：对图像灰度值进行度量，设置不同类别的阈值，达到分割的目的</p>
<p>　　　　2 边缘分割：对图像边缘进行检测，即检测图像中灰度值发生跳变的地方，则为一片区域的边缘</p>
<p>　　　　3 直方图法：对图像的颜色建立直方图，而直方图的波峰波谷能够表示一块区域的颜色值的范围，来达到分割的目的</p>
<p>　　　　4 特定理论：基于聚类分析、小波变换等理论完成图像分割</p>
<p>　　实例描述</p>
<p>　　　　目标: 利用K-means聚类算法对图像像素点颜色进行聚类实现简单的图像分割 </p>
<p>　　　　输出: 同一聚类中的点使用相同颜色标记，不同聚类颜色不同</p>
<p>　　　　技术路线: sklearn.cluster.KMeans</p>
<p>　　具体代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import PIL.Image as image</span><br><span class="line">from sklearn.cluster import KMeans</span><br><span class="line">  </span><br><span class="line">def loadData(filePath):</span><br><span class="line">    f &#x3D; open(filePath,&#39;rb&#39;)</span><br><span class="line">    data &#x3D; []</span><br><span class="line">    img &#x3D; image.open(f)</span><br><span class="line">    m,n &#x3D; img.size</span><br><span class="line">    for i in range(m):</span><br><span class="line">        for j in range(n):</span><br><span class="line">            x,y,z &#x3D; img.getpixel((i,j))</span><br><span class="line">            data.append([x&#x2F;256.0,y&#x2F;256.0,z&#x2F;256.0])</span><br><span class="line">    f.close()</span><br><span class="line">    return np.mat(data),m,n</span><br><span class="line">  </span><br><span class="line">imgData,row,col &#x3D; loadData(&#39;kmeans&#x2F;bull.jpg&#39;)</span><br><span class="line">label &#x3D; KMeans(n_clusters&#x3D;4).fit_predict(imgData)</span><br><span class="line">  </span><br><span class="line">label &#x3D; label.reshape([row,col])</span><br><span class="line">pic_new &#x3D; image.new(&quot;L&quot;, (row, col))</span><br><span class="line">for i in range(row):</span><br><span class="line">    for j in range(col):</span><br><span class="line">        pic_new.putpixel((i,j), int(256&#x2F;(label[i][j]+1)))</span><br><span class="line">pic_new.save(&quot;result-bull-4.jpg&quot;, &quot;JPEG&quot;)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>-大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>极大似然估计（MLE）</title>
    <url>/post/107224d5.html</url>
    <content><![CDATA[<p>我们已经了解了似然函数是什么，但怎么去把里面的θ给求出来是个更加关键的问题。这篇我们将来探讨下这个问题。</p>
<p>还是先举一个例子，假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为θ）各是多少？</p>
<p>这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！</p>
<p>于是我们拿这枚硬币抛了10次，得到的数据x_0x0是：反正正正正反正正正反。我们想求的正面概率θ是模型参数，而抛硬币模型是二项分布(除非硬币立起来，那么这个时候要马上去买彩票，还搞什么算法)。</p>
<p>那么，出现实验结果x0（即反正正正正反正正正反）的似然函数是多少呢？我们是这样列式的：<br>$$<br>f \left( x _ { 0 } , \theta \right) = ( 1 - \theta ) \times \theta \times \theta \times \theta \times \theta \times ( 1 - \theta ) \times \theta \times \theta \times \theta \times ( 1 - \theta ) = \theta ^ { 7 } ( 1 - \theta ) ^ { 3 } = f ( \theta )<br>$$<br>求出来函数的最大值是θ=0.7时取得的。这样，我们已经完成了对θ的极大似然估计。即抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。</p>
<p>看完上面的公式相信很多人跟我一样是一脸懵逼的。懵逼的点就在于这他妈公式是哪里来的？为什么这样列式然后求其最大值时θ的取值就是极大似然估计的值，也就是根据给出样本的情况模型参数最有可能的取值？Why?</p>
<p>这里需要另外一个例子来告诉我们：</p>
<p>假设有一批产品，根据以往的经验知道它的次品率可能是0.1或0.3。生产这批产品的厂家认为该批产品很好，次品率大约为0.1，而收购产品的商业部门表示产品质量有问题，次品率可能为0.3。现在从这批产品中随机抽取15件，发现其中有5件是次品。问：生产厂家与收购部分谁的估计更加可靠？</p>
<p>解：记次品数为X，则<br>$$<br>X \sim B ( n , p )<br>$$<br>(这式子的意思是X服从二项分布)</p>
<p>若次品率<br>$$<br>p _ { 1 } = 0.1，<br>$$<br>则15件产品中有5件是次品的概率为：<br>$$<br>P ( X = 5 ) = C _ { 15 } ^ { 5 } 0.1 ^ { 5 } 0.9 ^ { 10 } = 0.0105<br>$$<br>若次品率<br>$$<br>p _ { 2 } = 0.3，<br>$$<br>则15件产品中有5件是次品的概率为：<br>$$<br>P ( X = 5 ) = C _ { 15 } ^ { 5 } 0.3 ^ { 5 } 0.7 ^ { 10 } = 0.2061<br>$$<br>后面的概率显然高于前面的，因此用0.3作为次品率的估计值更为可靠一些。</p>
<p>OK，解题结束，到这里相信你已经恍然大悟了。为什么极大似然估计公式是连乘。那不就是上面两道公式<br>$$<br>C _ { 15 } ^ { 5 }的右边部分吗？仔细看来，对比上下两道公式，可以发现C _ { 15 } ^ { 5 }这个部分是一样的，不同的就是C _ { 15 } ^ { 5 }的右边部分。<br>$$<br>而我们要让评估更正确，其实是要求让<br>$$<br>P ( X = 5 )这道公式取最大值的pp的值。又因为C _ { 15 } ^ { 5 }<br>$$<br>这部分写不写都不影响求解结果，它相当于一个常数，因此忽略掉那部分后，就得到了极大似然估计公式。</p>
<p>我们用更加严谨的公式把似然函数和极大似然估计都用数学表达出来如下（其中argmaxθ表示当右边函数取得最大值时θ的取值）：<br>似然函数：<br>$$<br>l ( \theta ) = P ( x | \theta ) = p \left( x _ { 1 } , x _ { 2 } , \cdots , x _ { N } | \theta \right) = \prod _ { i = 1 } ^ { N } p \left( x _ { i } | \theta \right)<br>$$</p>
<p>极大似然估计：<br>$$<br>\hat { \theta } = \arg \max _ { \theta } l ( \theta ) = \arg \max _ { \theta } \prod _ { i = 1 } ^ { N } p \left( x _ { i } | \theta \right)<br>$$</p>
<p>当然这个公式看起来虽好，但有个问题，算起来比较要命，因为是连乘啊！这求个导能把人求哭。怎么办？两边取对数（因为lnx是随着x增大而单调增大的，也就是说当lnx取得最大值的时候x也取得最大值），这个时候极大似然估计变成这样：<br>$$<br>\hat { \theta } = \arg \max _ { \theta } H ( \theta ) = \arg \max _ { \theta } \ln l ( \theta ) = \arg \max _ { \theta } \sum _ { i = 1 } ^ { N } \ln p \left( x _ { i } | \theta \right)<br>$$<br>连乘变成累加，世界瞬间清净了！</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>深入浅出--梯度下降法及其实现</title>
    <url>/post/e85f0a87.html</url>
    <content><![CDATA[<blockquote>
<ul>
<li>梯度下降的场景假设</li>
<li>梯度</li>
<li>梯度下降算法的数学解释</li>
<li>梯度下降算法的实例</li>
<li>梯度下降算法的实现</li>
<li>Further reading</li>
</ul>
</blockquote>
<p>本文将从一个下山的场景开始，先提出梯度下降算法的基本思想，进而从数学上解释梯度下降算法的原理，最后实现一个简单的梯度下降算法的实例！</p>
<h1 id="梯度下降的场景假设"><a href="#梯度下降的场景假设" class="headerlink" title="梯度下降的场景假设"></a>梯度下降的场景假设</h1><blockquote>
<p>梯度下降法的基本思想可以类比为一个下山的过程。假设这样一个场景：一个人被困在山上，需要从山上下来(i.e. 找到山的最低点，也就是山谷)。但此时山上的浓雾很大，导致可视度很低。因此，下山的路径就无法确定，他必须利用自己周围的信息去找到下山的路径。这个时候，他就可以利用梯度下降算法来帮助自己下山。具体来说就是，以他当前的所处的位置为基准，寻找这个位置最陡峭的地方，然后朝着山的高度下降的地方走，同理，如果我们的目标是上山，也就是爬到山顶，那么此时应该是朝着最陡峭的方向往上走。然后每走一段距离，都反复采用同一个方法，最后就能成功的抵达山谷。</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-6ae594f795406b8b.png" alt="img"></p>
<p>image.png</p>
<p>我们同时可以假设这座山最陡峭的地方是无法通过肉眼立马观察出来的，而是需要一个复杂的工具来测量，同时，这个人此时正好拥有测量出最陡峭方向的能力。所以，此人每走一段距离，都需要一段时间来测量所在位置最陡峭的方向，这是比较耗时的。那么为了在太阳下山之前到达山底，就要尽可能的减少测量方向的次数。这是一个两难的选择，如果测量的频繁，可以保证下山的方向是绝对正确的，但又非常耗时，如果测量的过少，又有偏离轨道的风险。所以需要找到一个合适的测量方向的频率，来确保下山的方向不错误，同时又不至于耗时太多！</p>
</blockquote>
<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>梯度下降的基本过程就和下山的场景很类似。</p>
<hr>
<p>首先，我们有一个可<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Differentiable_function"><em>微分</em></a>的函数。这个函数就代表着一座山。我们的目标就是找到这个函数的最小值，也就是山底。根据之前的场景假设，最快的下山的方式就是找到当前位置最陡峭的方向，然后沿着此方向向下走，对应到函数中，就是找到给定点的<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Gradient"><em>梯度</em></a> ，然后朝着梯度相反的方向，就能让函数值下降的最快！因为梯度的方向就是函数之变化最快的方向(在后面会详细解释)<br>所以，我们重复利用这个方法，反复求取梯度，最后就能到达局部的最小值，这就类似于我们下山的过程。而求取梯度就确定了最陡峭的方向，也就是场景中测量方向的手段。那么为什么梯度的方向就是最陡峭的方向呢？接下来，我们从微分开始讲起</p>
<h1 id="微分"><a href="#微分" class="headerlink" title="微分"></a>微分</h1><p>看待微分的意义，可以有不同的角度，最常用的两种是：</p>
<ul>
<li><p>函数图像中，某点的切线的斜率</p>
</li>
<li><p>函数的变化率</p>
<p>几个微分的例子：</p>
</li>
</ul>
<p>  <img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-0eb0f1bfd7de705b.png" alt="img"></p>
<p>  image.png</p>
<p>上面的例子都是单变量的微分，当一个函数有多个变量的时候，就有了多变量的微分，即分别对每个变量进行求微分</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-4029977524e3b365.png" alt="img"></p>
<p>image.png</p>
<h1 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h1><p>梯度实际上就是多变量微分的一般化。<br>下面这个例子：</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-570afdfc6fabf3b6.png" alt="img"></p>
<p>image.png</p>
<p>我们可以看到，梯度就是分别对每个变量进行微分，然后用逗号分割开，梯度是用&lt;&gt;包括起来，说明梯度其实一个向量。</p>
<p>梯度是微积分中一个很重要的概念，之前提到过梯度的意义</p>
<ul>
<li>在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率</li>
<li>在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向</li>
</ul>
<p>这也就说明了为什么我们需要千方百计的求取梯度！我们需要到达山底，就需要在每一步观测到此时最陡峭的地方，梯度就恰巧告诉了我们这个方向。梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向，这正是我们所需要的。所以我们只要沿着梯度的方向一直走，就能走到局部的最低点！</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-13d969531284a9f9.png" alt="img"></p>
<p>image.png</p>
<h1 id="梯度下降算法的数学解释"><a href="#梯度下降算法的数学解释" class="headerlink" title="梯度下降算法的数学解释"></a>梯度下降算法的数学解释</h1><p>上面我们花了大量的篇幅介绍梯度下降算法的基本思想和场景假设，以及梯度的概念和思想。下面我们就开始从数学上解释梯度下降算法的计算过程和思想！</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-f20521a962005299.png" alt="img"></p>
<p>image.png</p>
<p>此公式的意义是：J是关于Θ的一个函数，我们当前所处的位置为Θ0点，要从这个点走到J的最小值点，也就是山底。首先我们先确定前进的方向，也就是梯度的反向，然后走一段距离的步长，也就是α，走完这个段步长，就到达了Θ1这个点！</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-af8dd9722c762c13.png" alt="img"></p>
<p>image.png</p>
<p>下面就这个公式的几个常见的疑问：</p>
<ul>
<li>α是什么含义？<br>α在梯度下降算法中被称作为<strong>学习率</strong>或者<strong>步长</strong>，意味着我们可以通过α来控制每一步走的距离，以保证不要步子跨的太大扯着蛋，哈哈，其实就是不要走太快，错过了最低点。同时也要保证不要走的太慢，导致太阳下山了，还没有走到山下。所以α的选择在梯度下降法中往往是很重要的！α不能太大也不能太小，太小的话，可能导致迟迟走不到最低点，太大的话，会导致错过最低点！</li>
</ul>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-ba3da0b06da97ddb.png" alt="img"></p>
<p>image.png</p>
<ul>
<li>为什么要梯度要乘以一个负号？<br>梯度前加一个负号，就意味着朝着梯度相反的方向前进！我们在前文提到，梯度的方向实际就是函数在此点上升最快的方向！而我们需要朝着下降最快的方向走，自然就是负的梯度的方向，所以此处需要加上负号</li>
</ul>
<h1 id="梯度下降算法的实例"><a href="#梯度下降算法的实例" class="headerlink" title="梯度下降算法的实例"></a>梯度下降算法的实例</h1><p>我们已经基本了解了梯度下降算法的计算过程，那么我们就来看几个梯度下降算法的小实例，首先从单变量的函数开始</p>
<h2 id="单变量函数的梯度下降"><a href="#单变量函数的梯度下降" class="headerlink" title="单变量函数的梯度下降"></a>单变量函数的梯度下降</h2><p>我们假设有一个单变量的函数</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-abb73822fb6d2a2c.png" alt="img"></p>
<p>image.png</p>
<p>函数的微分</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-66ce0cdcef5e2686.png" alt="img"></p>
<p>image.png</p>
<p>初始化，起点为</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-8ee36cc5ce832b17.png" alt="img"></p>
<p>image.png</p>
<p>学习率为</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-798b134107b6593d.png" alt="img"></p>
<p>image.png</p>
<p>根据梯度下降的计算公式</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-f20521a962005299.png" alt="img"></p>
<p>image.png</p>
<p>我们开始进行梯度下降的迭代计算过程：</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-57538d21dbb34e65.png" alt="img"></p>
<p>image.png</p>
<p>如图，经过四次的运算，也就是走了四步，基本就抵达了函数的最低点，也就是山底</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-bb7fa36d116fcadc.png" alt="img"></p>
<p>image.png</p>
<h2 id="多变量函数的梯度下降"><a href="#多变量函数的梯度下降" class="headerlink" title="多变量函数的梯度下降"></a>多变量函数的梯度下降</h2><p>我们假设有一个目标函数</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-a56cfde25c688859.png" alt="img"></p>
<p>image.png</p>
<p>现在要通过梯度下降法计算这个函数的最小值。我们通过观察就能发现最小值其实就是 (0，0)点。但是接下来，我们会从梯度下降算法开始一步步计算到这个最小值！<br>我们假设初始的起点为：</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-8b1b6f1b200fd7b5.png" alt="img"></p>
<p>image.png</p>
<p>初始的学习率为：</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-ccc1493848871074.png" alt="img"></p>
<p>image.png</p>
<p>函数的梯度为：</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-3d744d9364a4ba40.png" alt="img"></p>
<p>image.png</p>
<p>进行多次迭代：</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-b21bf64600c4e32f.png" alt="img"></p>
<p>image.png</p>
<p>我们发现，已经基本靠近函数的最小值点</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-becdcdfdefb4eab7.png" alt="img"></p>
<p>image.png</p>
<h1 id="梯度下降算法的实现"><a href="#梯度下降算法的实现" class="headerlink" title="梯度下降算法的实现"></a>梯度下降算法的实现</h1><p>下面我们将用python实现一个简单的梯度下降算法。场景是一个简单的<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Linear_regression"><em>线性回归</em></a>的例子：假设现在我们有一系列的点，如下图所示</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-333f16d34874c230.png" alt="img"></p>
<p>image.png</p>
<p>我们将用梯度下降法来拟合出这条直线！</p>
<p>首先，我们需要定义一个代价函数，在此我们选用<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Least_squares"><em>均方误差代价函数</em></a></p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-4e4000e69f05af7b.png" alt="img"></p>
<p>image.png</p>
<p>此公示中</p>
<ul>
<li><p>m是数据集中点的个数</p>
</li>
<li><p>½是一个常量，这样是为了在求梯度的时候，二次方乘下来就和这里的½抵消了，自然就没有多余的常数系数，方便后续的计算，同时对结果不会有影响</p>
</li>
<li><p>y 是数据集中每个点的真实y坐标的值</p>
</li>
<li><p>h 是我们的预测函数，根据每一个输入x，根据Θ 计算得到预测的y值，即</p>
</li>
</ul>
<p>  <img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-acea37db1e02004d.png" alt="img"></p>
<p>  image.png</p>
<p>我们可以根据代价函数看到，代价函数中的变量有两个，所以是一个多变量的梯度下降问题，求解出代价函数的梯度，也就是分别对两个变量进行微分</p>
<p><img src="/" alt="img"></p>
<p>image.png</p>
<p>明确了代价函数和梯度，以及预测的函数形式。我们就可以开始编写代码了。但在这之前，需要说明一点，就是为了方便代码的编写，我们会将所有的公式都转换为矩阵的形式，python中计算矩阵是非常方便的，同时代码也会变得非常的简洁。</p>
<p>为了转换为矩阵的计算，我们观察到预测函数的形式</p>
<p><img src="/" alt="img"></p>
<p>image.png</p>
<p>我们有两个变量，为了对这个公式进行矩阵化，我们可以给每一个点x增加一维，这一维的值固定为1，这一维将会乘到Θ0上。这样就方便我们统一矩阵化的计算</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-a54d53411f945d95.png" alt="img"></p>
<p>image.png</p>
<p>然后我们将代价函数和梯度转化为矩阵向量相乘的形式</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-66b04086dd1f8ba9.png" alt="img"></p>
<p>image.png</p>
<h2 id="coding-time"><a href="#coding-time" class="headerlink" title="coding time"></a>coding time</h2><p>首先，我们需要定义数据集和学习率</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np# Size of the points dataset.m &#x3D; 20# Points x-coordinate and dummy value (x0, x1).X0 &#x3D; np.ones((m, 1))</span><br><span class="line">X1 &#x3D; np.arange(1, m+1).reshape(m, 1)</span><br><span class="line">X &#x3D; np.hstack((X0, X1))# Points y-coordinatey &#x3D; np.array([    3, 4, 5, 5, 2, 4, 7, 8, 11, 8, 12,    11, 13, 13, 16, 17, 18, 17, 19, 21]).reshape(m, 1)# The Learning Rate alpha.alpha &#x3D; 0.01</span><br></pre></td></tr></table></figure>
<p>接下来我们以矩阵向量的形式定义代价函数和代价函数的梯度</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def error_function(theta, X, y):</span><br><span class="line">    &#39;&#39;&#39;Error function J definition.&#39;&#39;&#39;</span><br><span class="line">    diff &#x3D; np.dot(X, theta) - y    return (1.&#x2F;2*m) * np.dot(np.transpose(diff), diff)def gradient_function(theta, X, y):</span><br><span class="line">    &#39;&#39;&#39;Gradient of the function J definition.&#39;&#39;&#39;</span><br><span class="line">    diff &#x3D; np.dot(X, theta) - y    return (1.&#x2F;m) * np.dot(np.transpose(X), diff)</span><br></pre></td></tr></table></figure>
<p>最后就是算法的核心部分，梯度下降迭代计算</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def gradient_descent(X, y, alpha):</span><br><span class="line">    &#39;&#39;&#39;Perform gradient descent.&#39;&#39;&#39;</span><br><span class="line">    theta &#x3D; np.array([1, 1]).reshape(2, 1)</span><br><span class="line">    gradient &#x3D; gradient_function(theta, X, y)    while not np.all(np.absolute(gradient) &lt;&#x3D; 1e-5):</span><br><span class="line">        theta &#x3D; theta - alpha * gradient</span><br><span class="line">        gradient &#x3D; gradient_function(theta, X, y)    return theta</span><br></pre></td></tr></table></figure>
<p>当梯度小于1e-5时，说明已经进入了比较平滑的状态，类似于山谷的状态，这时候再继续迭代效果也不大了，所以这个时候可以退出循环！</p>
<p>完整的代码如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np# Size of the points dataset.m &#x3D; 20# Points x-coordinate and dummy value (x0, x1).X0 &#x3D; np.ones((m, 1))</span><br><span class="line">X1 &#x3D; np.arange(1, m+1).reshape(m, 1)</span><br><span class="line">X &#x3D; np.hstack((X0, X1))# Points y-coordinatey &#x3D; np.array([    3, 4, 5, 5, 2, 4, 7, 8, 11, 8, 12,    11, 13, 13, 16, 17, 18, 17, 19, 21]).reshape(m, 1)# The Learning Rate alpha.alpha &#x3D; 0.01def error_function(theta, X, y):</span><br><span class="line">    &#39;&#39;&#39;Error function J definition.&#39;&#39;&#39;</span><br><span class="line">    diff &#x3D; np.dot(X, theta) - y    return (1.&#x2F;2*m) * np.dot(np.transpose(diff), diff)def gradient_function(theta, X, y):</span><br><span class="line">    &#39;&#39;&#39;Gradient of the function J definition.&#39;&#39;&#39;</span><br><span class="line">    diff &#x3D; np.dot(X, theta) - y    return (1.&#x2F;m) * np.dot(np.transpose(X), diff)def gradient_descent(X, y, alpha):</span><br><span class="line">    &#39;&#39;&#39;Perform gradient descent.&#39;&#39;&#39;</span><br><span class="line">    theta &#x3D; np.array([1, 1]).reshape(2, 1)</span><br><span class="line">    gradient &#x3D; gradient_function(theta, X, y)    while not np.all(np.absolute(gradient) &lt;&#x3D; 1e-5):</span><br><span class="line">        theta &#x3D; theta - alpha * gradient</span><br><span class="line">        gradient &#x3D; gradient_function(theta, X, y)    return theta</span><br><span class="line"></span><br><span class="line">optimal &#x3D; gradient_descent(X, y, alpha)</span><br><span class="line">print(&#39;optimal:&#39;, optimal)</span><br><span class="line">print(&#39;error function:&#39;, error_function(optimal, X, y)[0,0])</span><br></pre></td></tr></table></figure>
<p>运行代码，计算得到的结果如下</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-af64f7e8e5fb3dfb.png" alt="img"></p>
<p>image.png</p>
<p>所拟合出的直线如下</p>
<p><img src="/../images/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/1234352-27806efbd53ced41.png" alt="img"></p>
<p>image.png</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>至此，我们就基本介绍完了梯度下降法的基本思想和算法流程，并且用python实现了一个简单的梯度下降算法拟合直线的案例！<br>最后，我们回到文章开头所提出的场景假设:<br><strong>这个下山的人实际上就代表了<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Backpropagation">反向传播算法</a>，下山的路径其实就代表着算法中一直在寻找的参数Θ，山上当前点的最陡峭的方向实际上就是代价函数在这一点的梯度方向，场景中观测最陡峭方向所用的工具就是<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Derivative">微分</a> 。在下一次观测之前的时间就是有我们算法中的学习率α所定义的。</strong><br>可以看到场景假设和梯度下降算法很好的完成了对应！</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>-大数据 -人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习2---任意结点数的三层全连接神经网络</title>
    <url>/post/ee239b41.html</url>
    <content><![CDATA[<p>上一篇文章：<a href="https://aichn.cn/post/74e51a6a.html">深度学习1—最简单的全连接神经网络</a>　<br>　　我们完成了一个三层（输入+隐含+输出）且每层都具有两个节点的全连接神经网络的原理分析和代码编写。本篇文章将进一步探讨如何把每层固定的两个节点变成任意个节点，以方便我们下一篇文章用本篇文章完成的网络来训练手写字符集“mnist”。<br>　　对于前向传播，基本上没有什么变化，就不用说了。主要看看后向传播的梯度下降公式。先放上上篇文章的网络图。<br><img src="/../images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02---%E4%BB%BB%E6%84%8F%E7%BB%93%E7%82%B9%E6%95%B0%E7%9A%84%E4%B8%89%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20180928134419558" alt="在这里插入图片描述"><br>　　上篇文章我们推知，含有两个节点的隐含层到输出层的权值对误差的偏导数，公式如下：<br>　<br>$$<br>　\frac{\partial E_{总}}{\partial W_{11}^{(２)}}=(O_{1}-T_{1})*O_{1}(1-O_{1})*Y_{1}<br>$$<br>　　而含有两个节点的输入层到隐含层的权值对于误差梯度的偏导数公式如下：<br>　　<br>$$<br>\frac{\partial E_{总}}{\partial W_{11}^{(1)}}=((O_{1}-T_{1})*O_{1}(1-O_{1})*W_{11}^{(2)}+(O_{2}-T_{2})*O_{2}(1-O_{2})*W_{21}^{(2)})*Y_{1}(1-Y_{1})*X_{1}<br>$$<br>　　现在我们来总结规律，先看第一道公式：<br>　　<br>$$<br>W_{11}^{(2)}<br>$$<br>位于输出层第一个结点的后方，与隐含层第一个结点相连接，其对总误差求偏导的式子结果也只与这两个节点的相关参数有关，与输入层、隐含层的第二个节点、输出层的第二个节点均无关。因此，也可以说，无论各层的节点数怎么样变化，隐含层到输出层的权值只与它连接的两个节点的参数相关。上式可以写成：<br>　　<br>$$<br>\frac{\partial E_{总}}{\partial W_{xy}^{(2)}}=(O_{x}-T_{x})*O_{x}(1-O_{x})*Y_{y}<br>$$<br>　　再看第二道公式：<br>　　<br>$$<br>W_{11}^{(1)}<br>$$<br>位于隐含层第一个节点的后方，与输入层第一个节点相连接，第一个隐含层节点又与输出层所有节点相连接。公式中出现的项与上面描述到的节点相关，因此如果输出层节点增加，则表达式需要增加对增加节点的计算。而隐含层和输入层增加则无所谓。因此表达式可以写成：<br>　　<br>$$<br>\frac{\partial E_{总}}{\partial W_{xy}^{(1)}}=[\sum_{k=1}^{n}(O_{k}-T_{k})*O_{k}(1-O_{k})*W_{kx}^{(2)}]*Y_{x}(1-Y_{x})*X_{y}<br>$$<br>　　大功告成！规律总结完了，下面就只剩下写代码了。不得不承认，这一篇原理部分蛮少的，应该只能算是上一篇文章的补充。但从固定到任意还是挺重要的，因此独立出来写。<br>　　下面我们用代码来实现一个任意节点数（代码中取的输入层、隐含层、输出层分别为5、10、5个节点，当然你高兴的话可以随意改动）的三层全连接神经网络。</p>
<h2 id="C-实现"><a href="#C-实现" class="headerlink" title="C++实现"></a><strong>C++实现</strong></h2><hr>
<p>直接上代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;cmath&gt;</span><br><span class="line">#include&lt;ctime&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">#define IPNNUM 5     &#x2F;&#x2F;输入层节点数</span><br><span class="line">#define HDNNUM 10    &#x2F;&#x2F;隐含层节点数</span><br><span class="line">#define OPNNUM 5     &#x2F;&#x2F;输出层节点数</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;结点类，用以构成网络</span><br><span class="line">class node </span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">	double value; &#x2F;&#x2F;数值，存储结点最后的状态</span><br><span class="line">	double *W&#x3D;NULL;    &#x2F;&#x2F;结点到下一层的权值</span><br><span class="line"></span><br><span class="line">	void initNode(int num);&#x2F;&#x2F;初始化函数，必须调用以初始化权值个数</span><br><span class="line">	~node();	  &#x2F;&#x2F;析构函数，释放掉权值占用内存</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">void node::initNode(int num)</span><br><span class="line">&#123;</span><br><span class="line">	W &#x3D; new double[num];</span><br><span class="line">	srand((unsigned)time(NULL));</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; num; i++)&#x2F;&#x2F;给权值赋一个随机值</span><br><span class="line">	&#123;</span><br><span class="line">		W[i]&#x3D; (rand() % 100)&#x2F;(double)100;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">node::~node()</span><br><span class="line">&#123;</span><br><span class="line">	if (W!&#x3D;NULL)</span><br><span class="line">	&#123;</span><br><span class="line">		delete[]W;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;网络类，描述神经网络的结构并实现前向传播以及后向传播</span><br><span class="line">class net </span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">	node inlayer[IPNNUM]; &#x2F;&#x2F;输入层</span><br><span class="line">	node hidlayer[HDNNUM];&#x2F;&#x2F;隐含层</span><br><span class="line">	node outlayer[OPNNUM];&#x2F;&#x2F;输出层</span><br><span class="line"></span><br><span class="line">	double yita &#x3D; 0.1;&#x2F;&#x2F;学习率η</span><br><span class="line">	double k1;&#x2F;&#x2F;输入层偏置项权重</span><br><span class="line">	double k2;&#x2F;&#x2F;隐含层偏置项权重</span><br><span class="line">	double Tg[OPNNUM];&#x2F;&#x2F;训练目标</span><br><span class="line">	double O[OPNNUM];&#x2F;&#x2F;网络实际输出</span><br><span class="line"></span><br><span class="line">	net();&#x2F;&#x2F;构造函数，用于初始化各层和偏置项权重</span><br><span class="line">	double sigmoid(double z);&#x2F;&#x2F;激活函数</span><br><span class="line">	double getLoss();&#x2F;&#x2F;损失函数，输入为目标值</span><br><span class="line">	void forwardPropagation(double *input);&#x2F;&#x2F;前向传播,输入为输入层节点的值</span><br><span class="line">	void backPropagation(double *T);&#x2F;&#x2F;反向传播，输入为目标输出值</span><br><span class="line">	void printresual(int trainingTimes);&#x2F;&#x2F;打印信息</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">net::net()</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F;初始化输入层和隐含层偏置项权值，给一个随机值</span><br><span class="line">	srand((unsigned)time(NULL));</span><br><span class="line">	k1&#x3D; (rand() % 100) &#x2F; (double)100;</span><br><span class="line">	k2 &#x3D; (rand() % 100) &#x2F; (double)100;</span><br><span class="line">	&#x2F;&#x2F;初始化输入层到隐含层节点个数</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; IPNNUM; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		inlayer[i].initNode(HDNNUM);</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;初始化隐含层到输出层节点个数</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; HDNNUM; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		hidlayer[i].initNode(OPNNUM);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;激活函数</span><br><span class="line">double net::sigmoid(double z)</span><br><span class="line">&#123;</span><br><span class="line">	return 1&#x2F;(1+ exp(-z));</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;损失函数</span><br><span class="line">double net::getLoss()</span><br><span class="line">&#123;</span><br><span class="line">	double mloss &#x3D; 0;</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; OPNNUM; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		mloss +&#x3D; pow(O[i] - Tg[i], 2);</span><br><span class="line">	&#125;</span><br><span class="line">	return mloss &#x2F; OPNNUM;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;前向传播</span><br><span class="line">void net::forwardPropagation(double *input)</span><br><span class="line">&#123;</span><br><span class="line">	for (size_t iNNum &#x3D; 0; iNNum &lt; IPNNUM; iNNum++)&#x2F;&#x2F;输入层节点赋值</span><br><span class="line">	&#123;</span><br><span class="line">		inlayer[iNNum].value &#x3D; input[iNNum];</span><br><span class="line">	&#125;</span><br><span class="line">	for (size_t hNNum &#x3D; 0; hNNum &lt; HDNNUM; hNNum++)&#x2F;&#x2F;算出隐含层结点的值</span><br><span class="line">	&#123;</span><br><span class="line">		double z &#x3D; 0;</span><br><span class="line">		for (size_t iNNum &#x3D; 0; iNNum &lt; IPNNUM; iNNum++)</span><br><span class="line">		&#123;</span><br><span class="line">			z+&#x3D; inlayer[iNNum].value*inlayer[iNNum].W[hNNum];</span><br><span class="line">		&#125;</span><br><span class="line">		z+&#x3D; k1;&#x2F;&#x2F;加上偏置项</span><br><span class="line">		hidlayer[hNNum].value &#x3D; sigmoid(z);</span><br><span class="line">	&#125;</span><br><span class="line">	for (size_t oNNum &#x3D; 0; oNNum &lt; OPNNUM; oNNum++)&#x2F;&#x2F;算出输出层结点的值</span><br><span class="line">	&#123;</span><br><span class="line">		double z &#x3D; 0;</span><br><span class="line">		for (size_t hNNum &#x3D; 0; hNNum &lt; HDNNUM; hNNum++)</span><br><span class="line">		&#123;</span><br><span class="line">			z +&#x3D; hidlayer[hNNum].value*hidlayer[hNNum].W[oNNum];</span><br><span class="line">		&#125;</span><br><span class="line">		z +&#x3D; k2;&#x2F;&#x2F;加上偏置项</span><br><span class="line">		O[oNNum] &#x3D; outlayer[oNNum].value &#x3D; sigmoid(z);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;反向传播，这里为了公式好看一点多写了一些变量作为中间值</span><br><span class="line">&#x2F;&#x2F;计算过程用到的公式在博文中已经推导过了，如果代码没看明白请看看博文</span><br><span class="line">void net::backPropagation(double *T)</span><br><span class="line">&#123;	</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; OPNNUM; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		Tg[i] &#x3D; T[i];</span><br><span class="line">	&#125;</span><br><span class="line">	for (size_t iNNum &#x3D; 0; iNNum &lt; IPNNUM; iNNum++)&#x2F;&#x2F;更新输入层权重</span><br><span class="line">	&#123;</span><br><span class="line">		for (size_t hNNum &#x3D; 0; hNNum &lt; HDNNUM; hNNum++)</span><br><span class="line">		&#123;</span><br><span class="line">			double y &#x3D; hidlayer[hNNum].value;</span><br><span class="line">			double loss &#x3D; 0;</span><br><span class="line">			for (size_t oNNum &#x3D; 0; oNNum &lt; OPNNUM; oNNum++)</span><br><span class="line">			&#123;</span><br><span class="line">				loss +&#x3D; (O[oNNum] - Tg[oNNum])*O[oNNum] * (1 - O[oNNum])*hidlayer[hNNum].W[oNNum];</span><br><span class="line">			&#125;</span><br><span class="line">			inlayer[iNNum].W[hNNum] -&#x3D; yita*loss*y*(1 - y)*inlayer[iNNum].value;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	for (size_t hNNum &#x3D; 0; hNNum &lt; HDNNUM; hNNum++)&#x2F;&#x2F;更新隐含层权重</span><br><span class="line">	&#123;</span><br><span class="line">		for (size_t oNNum &#x3D; 0; oNNum &lt; OPNNUM; oNNum++)</span><br><span class="line">		&#123;</span><br><span class="line">			hidlayer[hNNum].W[oNNum]-&#x3D; yita*(O[oNNum] - Tg[oNNum])*</span><br><span class="line">				O[oNNum] *(1- O[oNNum])*hidlayer[hNNum].value;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void net::printresual(int trainingTimes)</span><br><span class="line">&#123;</span><br><span class="line">	double loss &#x3D; getLoss();</span><br><span class="line">	cout &lt;&lt; &quot;训练次数：&quot; &lt;&lt; trainingTimes &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; &quot;loss：&quot; &lt;&lt; loss &lt;&lt; endl;</span><br><span class="line">	for (size_t oNNum &#x3D; 0; oNNum &lt; OPNNUM; oNNum++)</span><br><span class="line">	&#123;</span><br><span class="line">		cout &lt;&lt; &quot;输出&quot; &lt;&lt; oNNum+1&lt;&lt; &quot;：&quot; &lt;&lt; O[oNNum] &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">	net mnet;</span><br><span class="line">	double minput[IPNNUM] &#x3D; &#123; 0.1, 0.2, 0.3, 0.4, 0.5 &#125;;</span><br><span class="line">	double mtarget[IPNNUM] &#x3D; &#123; 0.2, 0.4, 0.6, 0.8, 1 &#125;;</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; 10000; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		mnet.forwardPropagation(minput);&#x2F;&#x2F;前向传播</span><br><span class="line">		mnet.backPropagation(mtarget);&#x2F;&#x2F;反向传播</span><br><span class="line">		if (i%1000&#x3D;&#x3D;0)</span><br><span class="line">		&#123;</span><br><span class="line">			mnet.printresual(i);&#x2F;&#x2F;信息打印</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a><strong>python实现</strong></h2><hr>
<p>直接上代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import math</span><br><span class="line">import random</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">IPNNUM&#x3D;5     #输入层节点数</span><br><span class="line">HDNNUM&#x3D;10    #隐含层节点数</span><br><span class="line">OPNNUM&#x3D;3     #输出层节点数</span><br><span class="line"></span><br><span class="line">class node:</span><br><span class="line">    #结点类，用以构成网络</span><br><span class="line">    def __init__(self,connectNum&#x3D;0):</span><br><span class="line">        self.value&#x3D;0 #数值，存储结点最后的状态，对应到文章示例为X1，Y1等值</span><br><span class="line">        self.W &#x3D; (2*np.random.random_sample(connectNum)-1)*0.01</span><br><span class="line"></span><br><span class="line">class net:</span><br><span class="line">    #网络类，描述神经网络的结构并实现前向传播以及后向传播</span><br><span class="line">    def __init__(self):</span><br><span class="line">        #初始化函数，用于初始化各层间节点和偏置项权重</span><br><span class="line">        #输入层结点</span><br><span class="line">        self.inlayer&#x3D;[node(HDNNUM)];</span><br><span class="line">        for obj in range(1, IPNNUM):</span><br><span class="line">            self.inlayer.append(node(HDNNUM)) </span><br><span class="line">        #隐含层结点</span><br><span class="line">        self.hidlayer&#x3D;[node(OPNNUM)];</span><br><span class="line">        for obj in range(1, HDNNUM):</span><br><span class="line">            self.hidlayer.append(node(OPNNUM))             </span><br><span class="line">        #输出层结点</span><br><span class="line">        self.outlayer&#x3D;[node(0)];</span><br><span class="line">        for obj in range(1, OPNNUM):</span><br><span class="line">            self.outlayer&#x3D;[node(0)]                 </span><br><span class="line"></span><br><span class="line">        self.yita &#x3D; 0.1                                           #学习率η</span><br><span class="line">        self.k1&#x3D;random.random()                       #输入层偏置项权重</span><br><span class="line">        self.k2&#x3D;random.random()                       #隐含层偏置项权重</span><br><span class="line">        self.Tg&#x3D;np.zeros(OPNNUM)                   #训练目标</span><br><span class="line">        self.O&#x3D;np.zeros(OPNNUM)                     #网络实际输出</span><br><span class="line"></span><br><span class="line">    def sigmoid(self,z):</span><br><span class="line">        #激活函数</span><br><span class="line">        return 1 &#x2F; (1 + math.exp(-z))</span><br><span class="line"></span><br><span class="line">    def getLoss(self):</span><br><span class="line">        #损失函数</span><br><span class="line">        loss&#x3D;0</span><br><span class="line">        for num in range(0, OPNNUM):</span><br><span class="line">            loss+&#x3D;pow(self.O[num] -self.Tg[num],2)</span><br><span class="line">        return loss&#x2F;OPNNUM</span><br><span class="line"></span><br><span class="line">    def forwardPropagation(self,input):</span><br><span class="line">        #前向传播</span><br><span class="line">        for i in range(0, IPNNUM):</span><br><span class="line">            #输入层节点赋值</span><br><span class="line">            self.inlayer[i].value &#x3D; input[i]</span><br><span class="line">        for hNNum in range(0,HDNNUM):</span><br><span class="line">             #算出隐含层结点的值</span><br><span class="line">            z &#x3D; 0</span><br><span class="line">            for iNNum in range(0,IPNNUM):</span><br><span class="line">                z+&#x3D;self.inlayer[iNNum].value*self.inlayer[iNNum].W[hNNum]</span><br><span class="line">            #加上偏置项</span><br><span class="line">            z+&#x3D; self.k1</span><br><span class="line">            self.hidlayer[hNNum].value &#x3D; self.sigmoid(z)</span><br><span class="line">        for oNNum in range(0,OPNNUM):</span><br><span class="line">            #算出输出层结点的值</span><br><span class="line">            z &#x3D; 0</span><br><span class="line">            for hNNum in range(0,HDNNUM):</span><br><span class="line">                z +&#x3D; self.hidlayer[hNNum].value* self.hidlayer[hNNum].W[oNNum]</span><br><span class="line">            z +&#x3D; self.k2</span><br><span class="line">            self.O[oNNum] &#x3D; self.sigmoid(z)</span><br><span class="line"></span><br><span class="line">    def backPropagation(self,T):</span><br><span class="line">        #反向传播，这里为了公式好看一点多写了一些变量作为中间值</span><br><span class="line">        for num in range(0, OPNNUM):</span><br><span class="line">            self.Tg[num] &#x3D; T[num]</span><br><span class="line">        for iNNum in range(0,IPNNUM):</span><br><span class="line">            #更新输入层权重</span><br><span class="line">            for hNNum in range(0,HDNNUM):</span><br><span class="line">                y &#x3D; self.hidlayer[hNNum].value</span><br><span class="line">                loss &#x3D; 0</span><br><span class="line">                for oNNum in range(0, OPNNUM):</span><br><span class="line">                    loss+&#x3D;(self.O[oNNum] - self.Tg[oNNum])*self.O[oNNum] * (1 - self.O[oNNum])*self.hidlayer[hNNum].W[oNNum]</span><br><span class="line">                self.inlayer[iNNum].W[hNNum] -&#x3D; self.yita*loss*y*(1- y)*self.inlayer[iNNum].value</span><br><span class="line">        for hNNum in range(0,HDNNUM):</span><br><span class="line">            #更新隐含层权重</span><br><span class="line">            for oNNum in range(0,OPNNUM):</span><br><span class="line">                self.hidlayer[hNNum].W[oNNum]-&#x3D; self.yita*(self.O[oNNum] - self.Tg[oNNum])*self.O[oNNum]*\</span><br><span class="line">                    (1- self.O[oNNum])*self.hidlayer[hNNum].value</span><br><span class="line"></span><br><span class="line">    def printresual(self,trainingTimes):</span><br><span class="line">        #信息打印</span><br><span class="line">        loss &#x3D; self.getLoss()</span><br><span class="line">        print(&quot;训练次数：&quot;, trainingTimes)</span><br><span class="line">        print(&quot;loss&quot;,loss)</span><br><span class="line">        for oNNum in range(0,OPNNUM):</span><br><span class="line">            print(&quot;输出&quot;,oNNum,&quot;:&quot;,self.O[oNNum])</span><br><span class="line"></span><br><span class="line">#主程序</span><br><span class="line">mnet&#x3D;net()</span><br><span class="line">input&#x3D;np.array([0.1,0.2,0.3,0.4,0.5])</span><br><span class="line">target&#x3D;np.array([0.1,0.4,0.5])</span><br><span class="line"></span><br><span class="line">for n in range(0,1000):   </span><br><span class="line">    mnet.forwardPropagation(input)</span><br><span class="line">    mnet.backPropagation(target)</span><br><span class="line">    if (n%200&#x3D;&#x3D;0):</span><br><span class="line">        mnet.printresual(n)</span><br></pre></td></tr></table></figure>
<h2 id="pytorch的CPU实现"><a href="#pytorch的CPU实现" class="headerlink" title="pytorch的CPU实现"></a><strong>pytorch的CPU实现</strong></h2><hr>
<p>其实pytorch本身就已经支持任意节点数，所以这里只是随意的改了下上一篇文章中代码的参数部分。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding&#x3D;UTF-8</span><br><span class="line">import time</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        #定义Net的初始化函数，这个函数定义了该神经网络的基本结构</span><br><span class="line">        super(Net, self).__init__() #复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数</span><br><span class="line">        self.intohid_layer &#x3D; nn.Linear(5, 10) #定义输入层到隐含层的连结关系函数</span><br><span class="line">        self.hidtoout_layer &#x3D; nn.Linear(10, 5)#定义隐含层到输出层的连结关系函数</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        #定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成</span><br><span class="line">        x &#x3D; torch.nn.functional.sigmoid(self.intohid_layer(input))    #输入input在输入层经过经过加权和与激活函数后到达隐含层</span><br><span class="line">        x &#x3D; torch.nn.functional.sigmoid(self.hidtoout_layer(x))       #类似上面</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">mnet &#x3D; Net()</span><br><span class="line">target&#x3D;Variable(torch.FloatTensor([0.2, 0.4, 0.6, 0.8, 1]))   #目标输出</span><br><span class="line">input&#x3D;Variable(torch.FloatTensor([0.1, 0.2, 0.3, 0.4, 0.5]))    #输入</span><br><span class="line"></span><br><span class="line">loss_fn &#x3D; torch.nn.MSELoss()                       #损失函数定义，可修改</span><br><span class="line">optimizer &#x3D; torch.optim.SGD(mnet.parameters(), lr&#x3D;0.5, momentum&#x3D;0.9);</span><br><span class="line"></span><br><span class="line">start &#x3D; time.time()</span><br><span class="line"></span><br><span class="line">for t in range(0,5000):</span><br><span class="line">    optimizer.zero_grad()      #清空节点值</span><br><span class="line">    out&#x3D;mnet(input)            #前向传播</span><br><span class="line">    loss &#x3D; loss_fn(out,target) #损失计算</span><br><span class="line">    loss.backward()            #后向传播</span><br><span class="line">    optimizer.step()           #更新权值</span><br><span class="line">    if (t%1000&#x3D;&#x3D;0):</span><br><span class="line">        print(out)</span><br><span class="line"></span><br><span class="line">end &#x3D; time.time()</span><br><span class="line">print(end - start)</span><br></pre></td></tr></table></figure>
<h2 id="pytorch的GPU实现"><a href="#pytorch的GPU实现" class="headerlink" title="pytorch的GPU实现"></a><strong>pytorch的GPU实现</strong></h2><hr>
<p>直接上代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding&#x3D;UTF-8</span><br><span class="line">import time</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        #定义Net的初始化函数，这个函数定义了该神经网络的基本结构</span><br><span class="line">        super(Net, self).__init__() #复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数</span><br><span class="line">        self.intohid_layer &#x3D; nn.Linear(5, 10) #定义输入层到隐含层的连结关系函数</span><br><span class="line">        self.hidtoout_layer &#x3D; nn.Linear(10, 5)#定义隐含层到输出层的连结关系函数</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        #定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成</span><br><span class="line">        x &#x3D; torch.nn.functional.sigmoid(self.intohid_layer(input))    #输入input在输入层经过经过加权和与激活函数后到达隐含层</span><br><span class="line">        x &#x3D; torch.nn.functional.sigmoid(self.hidtoout_layer(x))       #类似上面</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">mnet &#x3D; Net().cuda()</span><br><span class="line">target&#x3D;Variable(torch.cuda.FloatTensor([0.2, 0.4, 0.6, 0.8, 1]))   #目标输出</span><br><span class="line">input&#x3D;Variable(torch.cuda.FloatTensor([0.1, 0.2, 0.3, 0.4, 0.5]))    #输入</span><br><span class="line"></span><br><span class="line">loss_fn &#x3D; torch.nn.MSELoss()                       #损失函数定义，可修改</span><br><span class="line">optimizer &#x3D; torch.optim.SGD(mnet.parameters(), lr&#x3D;0.5, momentum&#x3D;0.9);</span><br><span class="line"></span><br><span class="line">start &#x3D; time.time()</span><br><span class="line"></span><br><span class="line">for t in range(0,5000):</span><br><span class="line">    optimizer.zero_grad()      #清空节点值</span><br><span class="line">    out&#x3D;mnet(input)            #前向传播</span><br><span class="line">    loss &#x3D; loss_fn(out,target) #损失计算</span><br><span class="line">    loss.backward()            #后向传播</span><br><span class="line">    optimizer.step()           #更新权值</span><br><span class="line">    if (t%1000&#x3D;&#x3D;0):</span><br><span class="line">        print(out)</span><br><span class="line"></span><br><span class="line">end &#x3D; time.time()</span><br><span class="line">print(end - start)</span><br></pre></td></tr></table></figure>
<p>到此就用代码实现了任意结点数的三层全连接神经网络，代码运行的结果都是对的，但相对来说pytorch收敛的快一些，可能跟其默认初始化的参数有关(自己写的代码都是用随机数初始化的)。<br>　　下一篇文章我们将用一个输入层、隐含层、输出层分别为784、100、10的三层全连接神经网络来训练闻名已久的MNIST手写数字字符集，然后自己手写一个数字来看看网络是否能比较给力的工作。<br>　　最后再预告下篇文章，<a href="https://aichn.cn/post/abc0fd31.html">深度学习3—用三层全连接神经网络训练MNIST手写数字字符集</a><br>　　另外写文章累人，写代码掉头发，如果觉得文章有帮助，哈哈哈</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-神经网络 -人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习1---最简单的全连接神经网络</title>
    <url>/post/74e51a6a.html</url>
    <content><![CDATA[<p>本文有一部分内容参考以下两篇文章：<br>　　<a href="https://www.cnblogs.com/charlotte77/p/5629865.html">一文弄懂神经网络中的反向传播法——BackPropagation</a><br>　　<a href="http://ufldl.stanford.edu/wiki/index.php/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">神经网络</a><br>　　<br>　　最简单的全连接神经网络如下图所示(这张图极其重要，本文所有的推导都参照的这张图，如果有兴趣看推导，建议保存下来跟推导一起看)：</p>
<p><img src="/../images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01---%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20180210030918240" alt="这里写图片描述"></p>
<p>　　它的前向传播计算过程非常简单，这里先讲一下：</p>
<h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a><strong>前向传播</strong></h2><hr>
<p>$$<br>\begin{aligned}<br>Y_{1} &amp;=f\left(W_{11}^{(1)} X_{1}+W_{12}^{(1)} X_{2}+K_{1}\right) \<br>Y_{2} &amp;=f\left(W_{21}^{(1)} X_{1}+W_{22}^{(1)} X_{2}+K_{1}\right) \<br>O_{1} &amp;=f\left(W_{11}^{(2)} Y_{1}+W_{12}^{(2)} Y_{2}+K_{2}\right) \<br>O_{2} &amp;=f\left(W_{21}^{(2)} Y_{1}+W_{22}^{(2)} Y_{2}+K_{2}\right)<br>\end{aligned}<br>$$<br>　　具体的，如果代入实际数值，取<br>$$<br>\begin{array}{lc}<br>X_{1}=0.05 &amp; X_{2}=0.10 \<br>K_{1}=0.35 &amp; K_{2}=0.60 \<br>W_{11}^{(1)}=0.15 &amp; W_{12}^{(1)}=0.20 \<br>W_{21}^{(1)}=0.25 &amp; W_{22}^{(1)}=0.30 \<br>W_{11}^{(2)}=0.40 &amp; W_{12}^{(2)}=0.45 \<br>W_{21}^{(2)}=0.50 &amp; W_{22}^{(2)}=0.55<br>\end{array}<br>$$</p>
<p>　　激活函数为：<br>$$<br>\frac{1}{1+e^{-z}}<br>$$<br>　　则有：<br>$$<br>\begin{array}{l}<br>z_{1}^{(1)}=0.15 * 0.05+0.20 * 0.10+0.35=0.3775 \<br>Y_{1}=\frac{1}{1+e^{-z_{1}^{(1)}}}=\frac{1}{1+e^{-0.3775}}=0.5932699921 \<br>z_{2}^{(1)}=0.25 * 0.05+0.30 * 0.10+0.35=0.3925 \<br>Y_{2}=\frac{1}{1+e^{-z_{2}^{(1)}}}=\frac{1}{1+e^{-0.3925}}=0.5968843783 \<br>z_{1}^{(2)}=0.40 * 0.5932699921+0.45 * 0.5968843783+0.60=1.1059059671 \<br>O_{1}=\frac{1}{1+e^{-z_{2}^{(2)}}}=\frac{1}{1+e^{-1.1059059671}}=0.7513650696 \<br>z_{2}^{(2)}=0.50 * 0.5932699921+0.55 * 0.5968843783+0.60=1.2249214041 \<br>O_{2}=\frac{1}{1+e^{-z_{2}^{(2)}}}=f(1.2249214041)=\frac{1}{1+e^{-1.2249210041}}=0.7729284653<br>\end{array}<br>$$</p>
<p>　　经过上面的过程，我们就完成了一次神经网络从输入到输出的计算。虽然公式代入数值看起来比较要命，但实际上对于计算机来说并没有什么。<br>　　那它有什么用呢？单看上面的例子可以说是完全没用的，因为它的输出跟输入的关系还非常的模糊。我们需要做的是训练这个网络中的参数，使得输出和输入存在某种对应关系（比如输入1、1，输出1、0来实现一个类似于加法器这样的东西），当上面网络的参数训练好了，我们工程中就只需要将数据输入这个网络，然后看看输出结果就行。从这里也大致可以看到，神经网络在实际应用中计算量大归大（可能网络本身就很复杂），但其实也还可以接受，最要命的地方是在于训练(每训练一次都要做一次前向传播计算，一般训练的次数又是以万为单位的)！<br>　　以上面的网络为例，通常我们说的训练参数就是训练公式中跟W相关的那8个数。在具体展开讲之前先补充下上面用到的神经网络的两个知识点：</p>
<ul>
<li><p><strong>激活函数</strong>，也就是上面例子中的<br>　　$$<br>  \frac{1}{1+e^{-z}}<br>  $$<br>  （事实上只要满足一定的规范，激活函数可以有无数种形态，不一定就用这个），其大体有两个作用：<br>  1.将数据归一化，因为前一层网络的计算结果很有可能不在0~1之间，而数据的范围需要统一，因此用激活函数把数据范围给限定住。<br>  　　2.打破网络的线性映射关系，如果网络只存在线性关系，则无论网络多深多复杂，最后都可以用单层网络替换，这样也就跟深度学习没什么关系了。另外更重要的一点是，如果只有线性，对于非线性的数据要分类是无能为力的。</p>
</li>
<li><p><strong>偏置项</strong>，也就是本篇最开始的网络图中最底层的那个“+1”<br>　　对这个东西有什么用，有些解释如下：<br>  　　Y=WX+b  （1）<br>  　　假设没有b，则公式退化成<br>  　　Y=WX   （2）<br>  　　假设现在要把(1,1)、(2,2)这两个点分成不同的类，则公式（2）直接就跪了，而公式（1）可以做到。<br>  　　但，本人不同意这个说法，因为这样的话(1,b)、(2,b)这两个点就分不出来了。也就是说按照这样的解释方法加入偏置项虽然能解决一部分问题，但会带入另外的问题，并没有什么卵用。<br>  　　本人对偏置项作用的看法是，偏置项要结合激活函数来看，每一层网络虽然共享一个偏置项，然而因为前面计算的结果有所差异（如例子中<br>  $$<br>  W_{11}^{(1)} X_{1}+W_{12}^{(1)} X_{2}与 W_{21}^{(1)} X_{1}+W_{22}^{(1)} X_{2}<br>  $$<br>  )，而激活函数又非线性函数，因而可以将神经元较快的分化出来。</p>
</li>
</ul>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a><strong>反向传播</strong></h2><hr>
<p>　　承接上面，我们来讲最重要的参数训练问题，深度学习一般用反向传播法更新权重(甚至可以说反向传播是神经网络的灵魂)。它的作用其实很好理解，下面结合着上面举的例子解释一下。</p>
<p>​        上面我们的输入是：<br>$$<br>X_{1}=0.05 \quad X_{2}=0.10<br>$$</p>
<p>　　对应的输出是：<br>　　<br>$$<br>O_{1}=0.7513650696 \quad O_{2}=0.7729284653<br>$$<br>　　假设我们希望输入对应的输出为：<br>$$<br>O_{1}=0.01 \quad O_{2}=0.99<br>$$<br>　　我们就需要改变Ｗ的取值，而具体要改变多少，我们一般会用<strong>梯度下降</strong>的方法去评估。在讲梯度下降之前，先来看看评价误差大小的“损失函数”。<br>　　 <strong>损失函数</strong>，也叫做“代价函数”，损失函数越小，就代表模型拟合的越好。最常用的损失函数是均方误差：<br>　　<br>$$<br>E_{\text {总 }}=\frac{\sum_{i=1}^{n}\left(T_{i}-O_{i}\right)^{2}}{n}(其中T_{i}为期望网络输出的结果，T_{i}为实际网络输出的结果)<br>$$<br>　　代入上面例子的期望输出和实际输出数值则可以求得<br>　　<br>$$<br>E_{\text {总 }}=\frac{\sum_{i=1}^{n}\left(T_{i}-O_{i}\right)^{2}}{n}=E_{O_{1}}+E_{O_{2}}=\frac{(0.01-0.7513650696)^{2}}{2}+\frac{(0.99-0.7729284653)^{2}}{2}<br>$$<br>　　通过损失函数算出误差大小之后我们就可以大概知道网络训练的怎么样了，是不是已经大致能工作之类的。<br>　　OK，下面进入梯度下降法：<br>　　<strong>梯度下降法</strong><br>　　要求单个的W对于总体误差起到多大的影响。在数学上，就是求总体误差对相应W的偏导数。以示例中隐含层到输出层的<br>$$<br>W_{11}^{(2)} 为例, 就是求 \frac{\partial E_{总}}{\partial W_{11}^{(2)}} 。<br>$$<br>要直接求基本是不可能的，我们可以先分析下<br>$$<br>W_{11}^{(2)} 到 E_{\text {总 }}<br>$$<br>间到底经历了什么。<br>$$</p>
<ol>
<li>W_{11}^{(2)} 先与 Y_{1} 相乘<br>$$</li>
</ol>
<ol>
<li><p><em>W</em>(2)11W11(2)先与<em>Y</em>1Y1相乘</p>
</li>
<li><p>经过激活函数</p>
</li>
</ol>
<p>　　3. 经过误差计算公式，也就是损失函数</p>
<p>因此我们可以把<br>$$<br>\frac{\partial E_{总}}{\partial W_{11}^{(2)}}<br>$$<br>拆开来（链式法则，高数学的不好的同学回去翻书），如下：<br>$$<br>\frac{\partial E_{兄}}{\partial W_{11}^{(2)}}=\frac{\partial E_{兄}}{\partial O_{1}} * \frac{\partial O_{1}}{\partial z_{1}^{(2)}} * \frac{\partial z_{1}^{(2)}}{\partial W_{11}^{(2)}} \quad\left(z_{1}^{(2)} \text { 为经过激活函数前的状态 }\right)<br>$$<br>　　这样，只要能分别求出这三个部分，整体也就求出来了。<br>　　下面先列出被微分的这几项<br>$$<br>\begin{array}{l}<br>E_{\text {总 }}=E_{O_{1}}+E_{O_{2}}=\frac{\left(T_{1}-O_{1}\right)^{2}}{2}+\frac{\left(T_{2}-O_{2}\right)^{2}}{2} \<br>O_{1}=\frac{1}{1+e^{-z_{1}^{(2)}}} \<br>z_{1}^{(2)}=W_{11}^{(2)} Y_{1}+W_{12}^{(2)} Y_{2}+K_{2}<br>\end{array}<br>$$</p>
<p>　　分别做偏微分得到<br>$$<br>\begin{aligned}<br>\frac{\partial E_{\text {兄 }}}{\partial O_{1}}=\frac{\partial\left[\frac{\left(T_{1}-O_{1}\right)^{2}}{2}+\frac{\left(T_{2}-O_{2}\right)^{2}}{2}\right]}{\partial O_{1}}=-\left(T_{1}-O_{1}\right)=O_{1}-T_{1} \<br>\frac{\partial O_{1}}{\partial z_{1}^{(2)}}=\frac{\partial \frac{1}{1+e^{-z_{1}^{(2)}}}}{\partial z_{1}^{(2)}}=\frac{e^{-z_{1}^{(2)}}}{\left(1+e^{-z_{1}^{(2)}}\right)^{2}} &amp;=\frac{1+e^{-z_{1}^{(2)}-1}}{\left(1+e^{-z_{1}^{(2)}}\right)^{2}}=\frac{1}{1+e^{-z_{1}^{(2)}}}\left(1-\frac{1}{1+e^{-z_{1}^{(2)}}}\right)=O_{1}\left(1-O_{1}\right) \<br>\frac{\partial z_{1}^{(2)}}{\partial W_{11}^{(2)}} &amp;=\frac{\partial\left(W_{11}^{(2)} Y_{1}+W_{12}^{(2)} Y_{2}+K_{2}\right)}{\partial W_{11}^{(2)}}=Y_{1}<br>\end{aligned}<br>$$</p>
<p>　　代入具体数值得到<br>$$<br>\begin{array}{l}<br>\frac{\partial E_{\text {总 }}}{\partial O_{1}}=O_{1}-T_{1}=0.7513650696-0.01=0.7413650696 \<br>\frac{\partial O_{1}}{\partial z_{1}^{(2)}}=O_{1}\left(1-O_{1}\right)=0.7513650695(1-0.7513650695)=0.1868156018 \<br>\frac{\partial z_{1}^{(2)}}{\partial W_{11}^{(2)}}=Y_{1}=0.5932699921 \<br>\text { 则 } \frac{\partial E_{\text {总 }}}{\partial W_{11}^{(2)}}=\frac{\partial E_{\text {总 }}}{\partial O_{1}} * \frac{\partial O_{1}}{\partial z_{1}^{(2)}} * \frac{\partial z_{1}^{(2)}}{\partial W_{11}^{(2)}}=\left(O_{1}-T_{1}\right) * O_{1}\left(1-O_{1}\right) * Y_{1}=0.7413650696 \<br>\quad * 0.1868156018 * 0.5932699921=0.0821670406<br>\end{array}<br>$$</p>
<p>　　到此，我们求出了总体误差对相应隐含层的权重W的偏导数。他的含义是在当前位置上，如果权重W移动一小段距离，会引起总体误差的变化的大小。很容易可以想到，如果求出来的值比较大，证明该权重对误差的影响大，那么我们需要对它调整的步伐也就大。反之，则稍微调整一下就可以了。调整的公式如下：<br>$$<br>W_{n e w 11}^{(2)}=W_{11}^{(2)}-\eta * \frac{\partial E_{总}}{\partial W_{11}^{(2)}}<br>$$<br>　　公式中的η为<strong>学习速率</strong>，这哥们比较关键，如果取得太大有可能怎么训练都无法取得最优值，取得太小训练速度又非常的慢，且很容易就会陷入局部最优而出不来，关于这块的解释可以参考机器学习的书籍，如果有必要后面会专门出一篇文章来探讨这个问题，本文在示例中取η=0.5。<br>　　那么，代入数值：<br>$$<br>W_{n e w 11}^{(2)}=W_{11}^{(2)}-\eta * \frac{\partial E_{\underline{g}}}{\partial W_{11}^{(2)}}=0.40-0.5 * 0.0821670406=0.3589164797<br>$$</p>
<p>　　　　有了上面的推导，更新隐含层剩下的三个权重可以说易如反掌：<br>$$<br>　　\begin{array}{l}<br>　　W_{\text {new} 12}^{(2)}=0.45-0.5 *\left(O_{1}-T_{1}\right) * O_{1}\left(1-O_{1}\right) * Y_{2}=0.4086661861 \<br>　　W_{\text {new} 21}^{(2)}=0.50-0.5 *\left(O_{2}-T_{2}\right) * O_{2}\left(1-O_{2}\right) * Y_{1}=0.5113012703 \<br>　　W_{\text {new} 22}^{(2)}=0.55-0.5 *\left(O_{2}-T_{2}\right) * O_{2}\left(1-O_{2}\right) * Y_{2}=0.5613701211<br>　　\end{array}<br>$$</p>
<p>　　　　接下来还有输入层到隐含层的权重，基本原理是一样的，但因为所处位置比较前，所有改变这个位置的一个权重会影响两个输出的值，求偏导也要考虑两个输出的影响。<br>$$<br>　　\frac{\partial E_{\text {总 }}}{\partial W_{11}^{(1)}}=\frac{\partial E_{\text {总 }}}{\partial Y_{1}} * \frac{\partial Y_{1}}{\partial z_{1}^{(1)}} * \frac{\partial z_{1}^{(1)}}{\partial W_{11}^{(1)}}<br>$$</p>
<p>　　　　可以看到，后面两项跟隐含层到输出层的偏导几乎一模一样，可以套用其结论，公式变为：<br>$$<br>　　\frac{\partial E_{\text {总 }}}{\partial W_{11}^{(1)}}=\frac{\partial E_{\text {总 }}}{\partial Y_{1}} * Y_{1}\left(1-Y_{1}\right) * X_{1}<br>$$</p>
<p>　　　　现在主要就要求<br>$$<br>　　\frac{\partial E_{\text {总 }}}{\partial Y_{1}}，<br>$$<br>　　回头看本文一开始的图片，可以看到<em>E</em>总和<em>Y</em>1的距离是比较远的，无法直接求偏导，因而需要通过链式法则再展开一下。<br>　　　　<br>$$<br>　　\frac{\partial E_{\text {总 }}}{\partial Y_{1}}=\frac{\partial\left(E_{O_{1}}+E_{O_{2}}\right)}{\partial Y_{1}}=\frac{\partial E_{O_{1}}}{\partial Y_{1}}+\frac{\partial E_{O_{2}}}{\partial Y_{1}}<br>$$</p>
<p>　　　　因为<br>$$<br>　　\frac{\partial E_{O_{1}}}{\partial Y_{1}}与\frac{\partial E_{O_{2}}}{\partial Y_{1}}<br>$$<br>　　形式相同，因而先看前者。<br>　　　　<br>$$<br>　　\frac{\partial E_{O_{1}}}{\partial Y_{1}}=\frac{\partial E_{O_{1}}}{\partial O_{1}} * \frac{\partial O_{1}}{\partial z_{1}^{(2)}} * \frac{\partial z_{1}^{(2)}}{\partial Y_{1}}<br>$$</p>
<p>　　　　前面两项之前求过，因此上式变成：<br>$$<br>　　\frac{\partial E_{O_{1}}}{\partial Y_{1}}=\frac{\partial E_{O_{1}}}{\partial O_{1}} * \frac{\partial O_{1}}{\partial z_{1}^{(2)}} * \frac{\partial z_{1}^{(2)}}{\partial Y_{1}}=\left(O_{1}-T_{1}\right) * O_{1}\left(1-O_{1}\right) * \frac{\partial z_{1}^{(2)}}{\partial Y_{1}}<br>$$<br>　　​        又<br>$$<br>　　\frac{\partial z_{1}^{(2)}}{\partial Y_{1}}=\frac{\partial\left(W_{11}^{(2)} Y_{1}+W_{12}^{(2)} Y_{2}+K_{2}\right)}{\partial Y_{1}}=W_{11}^{(2)}<br>$$</p>
<p>　　　　故<br>$$<br>　　\frac{\partial E_{O_{1}}}{\partial z_{1}^{(1)}}=\left(O_{1}-T_{1}\right) * O_{1}\left(1-O_{1}\right) * W_{11}^{(2)}<br>$$</p>
<p>　　　　同理<br>$$<br>　　\frac{\partial E_{O_{2}}}{\partial z_{1}^{(1)}}=\left(O_{2}-T_{2}\right) * O_{2}\left(1-O_{2}\right) * W_{21}^{(2)}<br>$$</p>
<p>　　　　则<br>$$<br>　　\frac{\partial E_{总}}{\partial W_{11}^{(1)}}=\left(\left(O_{1}-T_{1}\right) * O_{1}\left(1-O_{1}\right) * W_{11}^{(2)}+\left(O_{2}-T_{2}\right) * O_{2}\left(1-O_{2}\right) * W_{21}^{(2)}\right)* Y_{1}\left(1-Y_{1}\right) * X_{1}<br>$$</p>
<p>　　　　代入数值可求得<br>　　　　<br>$$<br>　　\frac{\partial E_{总}}{\partial W_{11}^{(1)}}=0.000438568<br>$$</p>
<p>　　　　则参数更新为<br>　　　　<br>$$<br>　　\begin{aligned}<br>　　&amp;W_{n e w 11}^{(1)}=W_{11}^{(1)}-\eta * \frac{\partial E_{总}}{\partial W_{11}^{(1)}}=0.149781\<br>　　&amp;\text { 同理可求得： }\<br>　　&amp;W_{n e w 12}^{(1)}=W_{12}^{(1)}-\eta * \frac{\partial E_{总}}{\partial W_{12}^{(1)}}=0.199561\<br>　　&amp;W_{n e w 21}^{(1)}=W_{21}^{(1)}-\eta * \frac{\partial E_{总}^{(1)}}{\partial W_{21}^{(1)}}=0.249751\<br>　　&amp;W_{n e w 22}^{(1)}=W_{22}^{(1)}-\eta * \frac{\partial E_{总}^{(1)}}{\partial W_{22}^{(1)}}=0.299502<br>　　\end{aligned}<br>$$</p>
<p>　　　　到此，理论部分就都讲完了，万岁！！！</p>
<p>　　在这里在此说明下，本文主要参考<a href="https://www.cnblogs.com/charlotte77/p/5629865.html">一文弄懂神经网络中的反向传播法——BackPropagation</a>这篇文章，里面有些论证直接是按照作者的思路来的，而且代入数据也直接抄的作者的数据，因为这样做本人在写的过程中可以通过比较结果是不是跟它一样来验证推导出的公式正确与否。如果觉得本人写的还不是太清楚可以看看该文章，作者用了比较多的图片辅助解释可能会比较易懂(本人都集中到一张图中了)。<br>　　在这里顺便推荐一下该作者的博客，写的很好！一看作者说自己只是本科生，我觉得我研究生白读了，额。。。</p>
<h2 id="C-实现"><a href="#C-实现" class="headerlink" title="C++实现"></a><strong>C++实现</strong></h2><hr>
<p>　　直接上代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;#include &lt;cmath&gt;using namespace std;&#x2F;&#x2F;结点类，用以构成网络class node </span><br><span class="line">&#123;public:    double value; &#x2F;&#x2F;数值，存储结点最后的状态，对应到文章示例为X1，Y1等值    double W[2];  &#x2F;&#x2F;结点到下一层的权值&#125;;&#x2F;&#x2F;网络类，描述神经网络的结构并实现前向传播以及后向传播&#x2F;&#x2F;这里为文章示例中的三层网络，每层结点均为两个class net </span><br><span class="line">&#123;public:</span><br><span class="line">    node input_layer[2];&#x2F;&#x2F;输入层结点</span><br><span class="line">    node hidden_layer[2];&#x2F;&#x2F;隐含层结点</span><br><span class="line">    node output_layer[2];&#x2F;&#x2F;输出层结点,这里只是两个数，但这样做方便后面的扩展    double yita &#x3D; 0.5;&#x2F;&#x2F;学习率η    double k1;&#x2F;&#x2F;输入层偏置项权重    double k2;&#x2F;&#x2F;隐含层偏置项权重    double Tg[2];&#x2F;&#x2F;训练目标    double O[2];&#x2F;&#x2F;网络实际输出</span><br><span class="line"></span><br><span class="line">    net();&#x2F;&#x2F;构造函数，用于初始化权重，一般可以随机初始化    double sigmoid(double z);&#x2F;&#x2F;激活函数    double getLoss();&#x2F;&#x2F;损失函数，输入为目标值    void forwardPropagation(double input1,double input2);&#x2F;&#x2F;前向传播    void backPropagation(double T1, double T2);&#x2F;&#x2F;反向传播，更新权值    void printresual();&#x2F;&#x2F;打印信息&#125;;</span><br><span class="line"></span><br><span class="line">net::net()</span><br><span class="line">&#123;</span><br><span class="line">    k1 &#x3D; 0.35;</span><br><span class="line">    k2 &#x3D; 0.60;</span><br><span class="line">    input_layer[0].W[0] &#x3D; 0.15;</span><br><span class="line">    input_layer[0].W[1] &#x3D; 0.25;</span><br><span class="line">    input_layer[1].W[0] &#x3D; 0.20;</span><br><span class="line">    input_layer[1].W[1] &#x3D; 0.30;</span><br><span class="line">    hidden_layer[0].W[0] &#x3D; 0.40;</span><br><span class="line">    hidden_layer[0].W[1] &#x3D; 0.50;</span><br><span class="line">    hidden_layer[1].W[0] &#x3D; 0.45;</span><br><span class="line">    hidden_layer[1].W[1] &#x3D; 0.55;</span><br><span class="line">&#125;&#x2F;&#x2F;激活函数double net::sigmoid(double z)</span><br><span class="line">&#123;    return 1&#x2F;(1+ exp(-z));</span><br><span class="line">&#125;&#x2F;&#x2F;损失函数double net::getLoss()</span><br><span class="line">&#123;    return (pow(O[0] -Tg[0],2)+ pow(O[1] - Tg[1],2))&#x2F;2;</span><br><span class="line">&#125;&#x2F;&#x2F;前向传播void net::forwardPropagation(double input1, double input2)</span><br><span class="line">&#123;</span><br><span class="line">    input_layer[0].value &#x3D; input1;</span><br><span class="line">    input_layer[1].value &#x3D; input2;    for (size_t hNNum &#x3D; 0; hNNum &lt; 2; hNNum++)&#x2F;&#x2F;算出隐含层结点的值</span><br><span class="line">    &#123;        double z &#x3D; 0;        for (size_t iNNum &#x3D; 0; iNNum &lt; 2; iNNum++)</span><br><span class="line">        &#123;</span><br><span class="line">            z+&#x3D; input_layer[iNNum].value*input_layer[iNNum].W[hNNum];</span><br><span class="line">        &#125;</span><br><span class="line">        z+&#x3D; k1;&#x2F;&#x2F;加上偏置项</span><br><span class="line">        hidden_layer[hNNum].value &#x3D; sigmoid(z);</span><br><span class="line">    &#125;    for (size_t outputNodeNum &#x3D; 0; outputNodeNum &lt; 2; outputNodeNum++)&#x2F;&#x2F;算出输出层结点的值</span><br><span class="line">    &#123;        double z &#x3D; 0;        for (size_t hNNum &#x3D; 0; hNNum &lt; 2; hNNum++)</span><br><span class="line">        &#123;</span><br><span class="line">            z +&#x3D; hidden_layer[hNNum].value*hidden_layer[hNNum].W[outputNodeNum];</span><br><span class="line">        &#125;</span><br><span class="line">        z +&#x3D; k2;&#x2F;&#x2F;加上偏置项</span><br><span class="line">        O[outputNodeNum] &#x3D; output_layer[outputNodeNum].value &#x3D; sigmoid(z);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&#x2F;&#x2F;反向传播，这里为了公式好看一点多写了一些变量作为中间值&#x2F;&#x2F;计算过程用到的公式在博文中已经推导过了，如果代码没看明白请看看博文void net::backPropagation(double T1, double T2)</span><br><span class="line">&#123;   </span><br><span class="line">    Tg[0] &#x3D; T1;</span><br><span class="line">    Tg[1] &#x3D; T2;    for (size_t iNNum &#x3D; 0; iNNum &lt; 2; iNNum++)&#x2F;&#x2F;更新输入层权重</span><br><span class="line">    &#123;        for (size_t wnum &#x3D; 0; wnum &lt; 2; wnum++)</span><br><span class="line">        &#123;            double y &#x3D; hidden_layer[wnum].value;</span><br><span class="line">            input_layer[iNNum].W[wnum] -&#x3D; yita*((O[0] - T1)*O[0] *(1- O[0])*</span><br><span class="line">                hidden_layer[wnum].W[0] +(O[1] - T2)*O[1] *(1 - O[1])*hidden_layer[wnum].W[1])*</span><br><span class="line">                y*(1- y)*input_layer[iNNum].value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;    for (size_t hNNum &#x3D; 0; hNNum &lt; 2; hNNum++)&#x2F;&#x2F;更新隐含层权重</span><br><span class="line">    &#123;        for (size_t wnum &#x3D; 0; wnum &lt; 2; wnum++)</span><br><span class="line">        &#123;</span><br><span class="line">            hidden_layer[hNNum].W[wnum]-&#x3D; yita*(O[wnum] - Tg[wnum])*</span><br><span class="line">                O[wnum] *(1- O[wnum])*hidden_layer[hNNum].value;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;void net::printresual()</span><br><span class="line">&#123;    double loss &#x3D; getLoss();</span><br><span class="line">    cout &lt;&lt; &quot;loss：&quot; &lt;&lt; loss &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;输出1：&quot; &lt;&lt; O[0] &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;输出2：&quot; &lt;&lt; O[1] &lt;&lt; endl;</span><br><span class="line">&#125;void main()</span><br><span class="line">&#123;</span><br><span class="line">    net mnet;    for (size_t i &#x3D; 0; i &lt; 10000; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        mnet.forwardPropagation(0.05, 0.1);&#x2F;&#x2F;前向传播</span><br><span class="line">        mnet.backPropagation(0.01, 0.99);&#x2F;&#x2F;反向传播        if (i%1000&#x3D;&#x3D;0)</span><br><span class="line">        &#123;</span><br><span class="line">            mnet.printresual();&#x2F;&#x2F;反向传播</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a><strong>python实现</strong></h2><hr>
<p>　　这里本人将贴出自己写的代码，但因为python是初学的，还不太行，所以如有错误和不够简练的地方望请见谅。另外推荐一个网站可以学习各种编程语言的：<a href="http://www.runoob.com/python/python-tutorial.html">http://www.runoob.com/python/python-tutorial.html</a><br>　　哦哦，上面提到的博文也贴出了博主自行实现的python代码，本人因为初学无法评价，如有兴趣可以去看看。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import mathclass node:    #结点类，用以构成网络    def __init__(self,w1&#x3D;None,w2&#x3D;None):</span><br><span class="line">        self.value&#x3D;0; #数值，存储结点最后的状态，对应到文章示例为X1，Y1等值</span><br><span class="line">        self.W&#x3D;[w1,w2]; #结点到下一层的权值class net:    #网络类，描述神经网络的结构并实现前向传播以及后向传播    #这里为文章示例中的三层网络，每层结点均为两个    def __init__(self):        #初始化函数，将权重，偏置等值全部初始化为博文示例的数值</span><br><span class="line">        self.inlayer &#x3D;[node(0.15,0.25),node(0.20,0.30)]; #输入层结点</span><br><span class="line">        self.hidlayer&#x3D;[node(0.40,0.50),node(0.45,0.55)]; #隐含层结点</span><br><span class="line">        self.outlayer&#x3D;[node(),node()];                   #输出层结点</span><br><span class="line"></span><br><span class="line">        self.yita &#x3D; 0.5;                                 #学习率η</span><br><span class="line">        self.k1&#x3D;0.35;                                    #输入层偏置项权重</span><br><span class="line">        self.k2&#x3D;0.60;                                    #隐含层偏置项权重</span><br><span class="line">        self.Tg&#x3D;[0,0];                                   #训练目标</span><br><span class="line">        self.O&#x3D;[0,0];                                    #网络实际输出    def sigmoid(self,z):        #激活函数        return 1 &#x2F; (1 + math.exp(-z)) </span><br><span class="line"></span><br><span class="line">    def getLoss(self):        #损失函数        return ((self.O[0] -self.Tg[0])**2+ (self.O[1] - self.Tg[1])**2)&#x2F;2;    def forwardPropagation(self,input1,input2):        #前向传播</span><br><span class="line">        self.inlayer[0].value &#x3D; input1;</span><br><span class="line">        self.inlayer[1].value &#x3D; input2;        for hNNum in range(0,2):             #算出隐含层结点的值</span><br><span class="line">            z &#x3D; 0;            for iNNum in range(0,2):</span><br><span class="line">                z+&#x3D;self.inlayer[iNNum].value*self.inlayer[iNNum].W[hNNum];            #加上偏置项</span><br><span class="line">            z+&#x3D; self.k1;</span><br><span class="line">            self.hidlayer[hNNum].value &#x3D; self.sigmoid(z);        for oNNum in range(0,2):            #算出输出层结点的值</span><br><span class="line">            z &#x3D; 0;            for hNNum in range(0,2):</span><br><span class="line">                z +&#x3D; self.hidlayer[hNNum].value* self.hidlayer[hNNum].W[oNNum];</span><br><span class="line">            z +&#x3D; self.k2;</span><br><span class="line">            self.outlayer[oNNum].value &#x3D; self.sigmoid(z);</span><br><span class="line">            self.O[oNNum] &#x3D; self.sigmoid(z);    def backPropagation(self,T1,T2):        #反向传播，这里为了公式好看一点多写了一些变量作为中间值        #计算过程用到的公式在博文中已经推导过了，如果代码没看明白请看看博文 </span><br><span class="line">        self.Tg[0] &#x3D; T1;</span><br><span class="line">        self.Tg[1] &#x3D; T2;        for iNNum in range(0,2):            #更新输入层权重            for wnum in range(0,2):</span><br><span class="line">                y &#x3D; self.hidlayer[wnum].value;</span><br><span class="line">                self.inlayer[iNNum].W[wnum] -&#x3D; self.yita*((self.O[0] - self.Tg[0])*self.O[0] *(1- self.O[0])*\</span><br><span class="line">                    self.hidlayer[wnum].W[0] +(self.O[1] - self.Tg[1])*self.O[1] *(1 - self.O[1])*\</span><br><span class="line">                    self.hidlayer[wnum].W[1])*y*(1- y)*self.inlayer[iNNum].value;        for hNNum in range(0,2):            #更新隐含层权重            for wnum in range(0,2):</span><br><span class="line">                self.hidlayer[hNNum].W[wnum]-&#x3D; self.yita*(self.O[wnum] - self.Tg[wnum])*self.O[wnum]*\</span><br><span class="line">                    (1- self.O[wnum])*self.hidlayer[hNNum].value;    def printresual(self):        #信息打印</span><br><span class="line">        loss &#x3D; self.getLoss();</span><br><span class="line">        print(&quot;loss&quot;,loss);</span><br><span class="line">        print(&quot;输出1&quot;,self.O[0]);</span><br><span class="line">        print(&quot;输出2&quot;,self.O[1]);#主程序mnet&#x3D;net();for n in range(0,20000):</span><br><span class="line">    mnet.forwardPropagation(0.05, 0.1);</span><br><span class="line">    mnet.backPropagation(0.01, 0.99);    if (n%1000&#x3D;&#x3D;0):</span><br><span class="line">        mnet.printresual();</span><br></pre></td></tr></table></figure>
<h2 id="pytorch的CPU实现"><a href="#pytorch的CPU实现" class="headerlink" title="pytorch的CPU实现"></a><strong>pytorch的CPU实现</strong></h2><hr>
<p>　　用pytorch实现的时候并没有用文章示例中给的参数进行初始化，因为那样很麻烦，而且也并不重要，因此用自带函数初始化了参数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import timeimport torchimport torch.nn as nnfrom torch.autograd import Variableclass Net(nn.Module):    def __init__(self):        #定义Net的初始化函数，这个函数定义了该神经网络的基本结构</span><br><span class="line">        super(Net, self).__init__() #复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数</span><br><span class="line">        self.intohid_layer &#x3D; nn.Linear(2, 2); #定义输入层到隐含层的连结关系函数</span><br><span class="line">        self.hidtoout_layer &#x3D; nn.Linear(2, 2);#定义隐含层到输出层的连结关系函数    def forward(self, input):        #定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成</span><br><span class="line">        x &#x3D; torch.nn.functional.sigmoid(self.intohid_layer(input))    #输入input在输入层经过经过加权和与激活函数后到达隐含层</span><br><span class="line">        x &#x3D; torch.nn.functional.sigmoid(self.hidtoout_layer(x))       #类似上面        return x</span><br><span class="line"></span><br><span class="line">mnet &#x3D; Net()</span><br><span class="line">target&#x3D;Variable(torch.FloatTensor([0.01, 0.99]));   #目标输出input&#x3D;Variable(torch.FloatTensor([0.05, 0.01]));    #输入loss_fn &#x3D; torch.nn.MSELoss();                       #损失函数定义，可修改optimizer &#x3D; torch.optim.SGD(mnet.parameters(), lr&#x3D;0.5, momentum&#x3D;0.9);</span><br><span class="line"></span><br><span class="line">start &#x3D; time.time()for t in range(0,5000):</span><br><span class="line">    optimizer.zero_grad();      #清空节点值</span><br><span class="line">    out&#x3D;mnet(input);            #前向传播</span><br><span class="line">    loss &#x3D; loss_fn(out,target); #损失计算</span><br><span class="line">    loss.backward();            #后向传播</span><br><span class="line">    optimizer.step();           #更新权值    if (t%1000&#x3D;&#x3D;0):</span><br><span class="line">        print(out);</span><br><span class="line"></span><br><span class="line">end &#x3D; time.time()</span><br><span class="line">print(end - start)</span><br></pre></td></tr></table></figure>
<p>　　现成的架构实现起来就是简单，代码量呈指数下降，上面的代码运行要8s左右，下面试试看用GPU的要多久。</p>
<h2 id="pytorch的GPU实现"><a href="#pytorch的GPU实现" class="headerlink" title="pytorch的GPU实现"></a><strong>pytorch的GPU实现</strong></h2><hr>
<p>　　看现有的资料pytorch使用GPU非常简单，只需要在数据和模型后面加上“.cuda()”即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import timeimport torchimport torch.nn as nnfrom torch.autograd import Variableclass Net(nn.Module):    def __init__(self):        #定义Net的初始化函数，这个函数定义了该神经网络的基本结构</span><br><span class="line">        super(Net, self).__init__() #复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数</span><br><span class="line">        self.intohid_layer &#x3D; nn.Linear(2, 2); #定义输入层到隐含层的连结关系函数</span><br><span class="line">        self.hidtoout_layer &#x3D; nn.Linear(2, 2);#定义隐含层到输出层的连结关系函数    def forward(self, input):        #定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成</span><br><span class="line">        x &#x3D; torch.nn.functional.sigmoid(self.intohid_layer(input))    #输入input在输入层经过经过加权和与激活函数后到达隐含层</span><br><span class="line">        x &#x3D; torch.nn.functional.sigmoid(self.hidtoout_layer(x))       #类似上面        return x</span><br><span class="line"></span><br><span class="line">mnet &#x3D; Net().cuda()</span><br><span class="line">target&#x3D;Variable(torch.cuda.FloatTensor([0.01, 0.99]));   #目标输出input&#x3D;Variable(torch.cuda.FloatTensor([0.05, 0.01]));    #输入loss_fn &#x3D; torch.nn.MSELoss();                            #损失函数定义，可修改optimizer &#x3D; torch.optim.SGD(mnet.parameters(), lr&#x3D;0.5, momentum&#x3D;0.9);</span><br><span class="line"></span><br><span class="line">start &#x3D; time.time()for t in range(0,5000):</span><br><span class="line">    optimizer.zero_grad();      #清空节点值</span><br><span class="line">    out&#x3D;mnet(input);            #前向传播</span><br><span class="line">    loss &#x3D; loss_fn(out,target); #损失计算</span><br><span class="line">    loss.backward();            #后向传播</span><br><span class="line">    optimizer.step();           #更新权值print(out.cpu());</span><br><span class="line">end &#x3D; time.time()</span><br><span class="line">print(end - start)</span><br></pre></td></tr></table></figure>
<p>　　上面的代码运行时间是11s左右，比CPU版本的慢，这个比较合理，因为网络比较小，GPU单线程性能又不如CPU，因此有此结果，随着网络不断的复杂，可以想想这个情况会逐渐不一样。</p>
<p>　　最后再预告下下篇文章，<a href="https://aichn.cn/post/ee239b41.html">深度学习2—任意结点数的三层全连接神经网络</a><br>　　<br>　　另外写文章累人，写代码掉头发，写这篇就大概写了两个星期。。。加个打赏好啦，如果觉得文章有帮助，哈哈哈</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-神经网络 -人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>海淘新手入门必看——2018最新美国亚马逊海淘攻略！含海淘转运攻略海淘教程</title>
    <url>/post/1176dd62.html</url>
    <content><![CDATA[<p>海淘是什么相信大家应该都了解，在蒸蒸日上的海淘大军里，很多人在海淘购物之前担心很多问题，因此在海淘大门前徘徊许久。在没开始海淘钱我一是其中的一分子 。下面和朋友们说说亚马逊的攻略希望可以帮助那些徘徊在海淘门前的你们。</p>
<p>详细介绍一下在美国亚马逊购物的攻略！先给大家说一下，海淘一点都不复杂，这个教程虽然写了很长，但其实真正操作起来就几个步骤，大家不要看到这么长的教程就犹豫了！最关键的是第一次需要注册，填各种信息，所以第一次有点麻烦，有了第一次，以后海淘，就剩下爽了！（一）首先你需要准备一张信用卡,美国亚马逊支持双币信用卡、单币银联卡，都无手续费，直接以实时汇率转换成人民币结算！ (帮主现在用的最多的是浦发信用卡，海淘最高有25%的返现，平时看电影、吃饭也经常会有浦发信用卡的折扣，网上申请也非常方便 ) （二）其次对于英语不太好的亲来说，一个翻译软件是很有必要的，不过现在都有网页版的在线翻译，把要翻译的句子粘贴过去，基本解决问题。然后是换算。美国的重量采取的是磅，一磅等于454克，这样心里就有个谱了，因为运费牵扯到重量的。（三）由于大部分美国网站都不能直运回中国（美国亚马逊部分商品可直邮，直邮攻略请：点击这里 用手机也可以在美亚下单了），所以需要通过转运公司，什么是转运公司呢？就是帮你把东东寄回国的公司。比如你在一个美国网站上购物，在你下单时，把地址栏填写转运公司给你的地址（这个地址是你在转运公司网站上注册时获得的专属地址），然后美网就把东东寄到转运公司了，转运公司收到，就帮你再寄回国内。我现在用的比较多的是爱淘转运：点击这里注册直达关于转运，我用过的还有八达网转运、爱淘转运、铭宣海淘等，这几个个转运公司除了美国线路，还有日本、德国、澳洲等线路，这样在其他国家海淘的话，也比较方便。（一个靠谱的转运公司对我们海淘族相当关键， 建议：如果经常海淘，可以注册2到3家转运，都走一单，这样时效、价格自己就心里有谱了，别人说的再好，不如自己亲自试一下！也是试出来的~~~）</p>
<p>注册完毕，就可以看见你的美国专属地址了。（一般会有有2个地址，一个加州 一个免税州。如果没有看到，也可以联系首页上的客服，让他帮你马上开通）</p>
<p>以上部分，是海淘大部分网站需要做的准备工作，下面开始说说亚马逊。点击注册地址：<a href="http://www.amazon.com/">http://www.amazon.com</a> 在输入你的注册邮箱后，请点击sign in.</p>
<p><img src="https://zhuanlan.zhihu.com/p/data:image/svg+xml;utf8,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='271'%20height='162'%3E%3C/svg%3E" alt="img"></p>
<p>点击sign in 出现以下页面：依次输入你的邮箱地址，接着你设定密码，点击create your Aamzon account</p>
<p><img src="https://zhuanlan.zhihu.com/p/data:image/svg+xml;utf8,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='364'%20height='394'%3E%3C/svg%3E" alt="img"></p>
<p>然后填写你的名字（你的昵称，和收货人无关），再次输入邮箱地址，再次输入一次密码，点击create your Aamzon account出现下面的页面：</p>
<p><img src="https://zhuanlan.zhihu.com/p/data:image/svg+xml;utf8,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='376'%20height='513'%3E%3C/svg%3E" alt="img"></p>
<p>然后出现以下界面：恭喜你！你已经创建成功啦！</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-6bde93ca6930cb74a590771c1b10d692_r.jpg" alt="img"></p>
<p>哈哈，接下来我们可以购买自己喜欢的东东了。为了进一步验证大家注册是否成功，可以关闭所有的亚马逊页面，点击亚马逊搜索页</p>
<p>如果右上角出现你的名（hello ****)，例如:</p>
<p><img src="https://zhuanlan.zhihu.com/p/data:image/svg+xml;utf8,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='242'%20height='90'%3E%3C/svg%3E" alt="img"></p>
<p>说明注册成功。给大家总结了个亚马逊的导航网站：涵盖了适合海淘的所有商品，大家可以把这个网站保存在收藏夹里，以后想找自己喜欢的商品，直接进入导航找就可以了。比如我们要买大热的Vulli Sophie苏菲小鹿，请在搜索栏输入：Vulli Sophie</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-b4c418ad403bbd1c131cf1ce5b1e0a10_r.jpg" alt="img"></p>
<p>点击搜索就出现很多款如下：</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-01c4d88e612aa8cb3b54bb99072035c2_r.jpg" alt="img"></p>
<p>出来的是各种型号的苏菲小鹿，我们选择第一种，一只装的。点击进去:</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-65d042048466cff467ed9450194b8268_r.jpg" alt="img"></p>
<p>可以看见原价和折后的价格。绿色的”In Stock”表示目前有现货。需要注意的是，Amazon不止自己卖东西，也有类似“店中店”的概念。”Ships from and sold by”后面如果跟的是”Amazon”打头的文字，即表示是Amazon自己销售的产品，如果是 “shipped from and sold by <strong>“ ：”</strong>“不是”amazon”，那就是说这不是amazon自家的，而且可能还需要你另付邮费，请一定要看清楚。选择购买的数量，然后点击ADD TO CART放入购物车，看看购物车里的情况：</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-ef96523b8f4d8287f4c689b348bb7a74_r.jpg" alt="img"></p>
<p>点击右边的结账：Proceed to Cheakout</p>
<p>接着开始填写转运公司地址，如果还没有注册转运公司的，点击这里 <a href="http://t.cn/R3L4Lsl">http://t.cn/R3L4Lsl</a></p>
<p>依次写好你的专属地址（后面会有填写示例），此处请对照你注册转运公司时给你的地址，一般会有2个地址，至于选哪个地址，请参考下面的说明：</p>
<p>在亚马逊购物，送到CA（加州）地址都是有消费税的（食品饮品类没有消费税，加州税率9%），可以选择or（免税州）免交消费税。</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-f6e28038bc7bd8a4c9dddd1157260d43_r.jpg" alt="img"></p>
<p>特别注意：最后一项“IS this address also your billing address(the address that appears on your credit card or bank statement)? 是问你上面的地址是否是你的信用卡账单地址.严格来说，这里应该填写”NO”,因为您的账单地址是你办信用卡的时候所填写的账单地址，肯定不可能和转运地址相同。但根据帮主的经验，如果你买的商品价值不大，比如没超过1000美元以上，为了省事，选“yes”也是没问题的。如果你一次性买了大额的商品，为了不被亚马逊冻结你账号，您这里要选择“NO”，然后填写自己在国内的账单地址（不确定自己的账单地址可以打信用卡客服电话，电子账单也会有一个账单地址。然后用英文填写，不会翻译的可以在网上搜索一下地址翻译. 另外中国的邮编是6位，填上去会多出来1位，这个不要紧，删除一位就行了，邮编不影响）。等你下单的商品发货后，您就无需再担心账单地址问题了，发货成功就OK了！</p>
<p>常用地址英语：室/房Room，村（乡）Village，号No.，宿舍Dormitory，楼/层F，住宅区/小区Residential Quarter，甲/乙/丙/丁A/B/C/D，巷/弄Lane，单元Unit，号楼/幢Building，厂Factory，酒楼/酒店Hotel，路Road，花园Garden，街Street，县County，镇Town，市City，区District，信箱Mailbox，省Province</p>
<p>比如转运给我的地址是：</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-6e3eca351a41e331ce0d27f613316b4b_r.jpg" alt="img"></p>
<p>接着开始选择运输方式。前面带了FREE的，都是免费的。购买亚马逊自营的东西，买满49美元免运费（免美国境内运费）。推荐大家加入一个亚马逊的特有服务——“亚马逊家庭计划”（如何加入，下面会有介绍），这样就可以免费试用1个月的PRIME服务（这个服务可以不用买满49美元也可以免运费，更可以选择免费的2天送达，也就是下图中的第三个选项，因为帮主写教程时已经加入妈妈计划，所以会出现下图第三项的2日免费送达，如果没有加入这个家庭计划，那亚马逊的免费送货时间就会是5到8天），加入家庭计划后，如果你不想交年费，快到一个月的时候取消就行（如何取消，下面会有说明，忘记取消也没关系，下面告诉您方法），同时注意再次确认一下你的订单，货物和地址是否正确。</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-1ca9aa973acf4b33c261f881c82356f4_r.jpg" alt="img"></p>
<p>下面这步是输入信用卡的号码ADD A NEW CARD，依次输入：你的信用卡持卡人的名字（用拼音，就是你信用卡上的名字）信用卡号码和有效期。然后再次点击继续。</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/v2-b7950d4f782d2a243a3eda9154a2521a_r.jpg" alt="img"></p>
<p><img src="https://zhuanlan.zhihu.com/p/data:image/svg+xml;utf8,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='403'%20height='328'%3E%3C/svg%3E" alt="img"></p>
<p><img src="https://zhuanlan.zhihu.com/p/data:image/svg+xml;utf8,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20width='275'%20height='342'%3E%3C/svg%3E" alt="img"></p>
<p>如果你有优惠码，请在gift cards&amp;promotional codes里面输入，然后点击apply。价格会重新显示为优惠后的价格,请仔细检查你的订单，若没有问题的话，请点击PLACE Your Order,你就完成了本次订单!</p>
<p>有时亚马逊会先扣你信用卡1美元，这一美元是预授权，验证你信用卡的真实性，过几天发货后就退回了。亚马逊不是即时扣款的，是”发货后”或者”准备发货”才扣款，如果一单有多件商品，而亚马逊的仓库又不在同一个地方，所以基本都是分开发货，这样就会出现零散扣款，而不是一次扣除整个订单费用的情况。</p>
<p>恭喜，到现在为止，我们的第一单终于成功了！</p>
<p>下面给大家讲海淘的第二大部分：转运。</p>
<p><strong><a href="http://www.haitaobang.cn/glDetail?id=11">转运操作流程及常见问题解决方法</a></strong></p>
<p><strong>如何判断商品究竟是不是Amazon自家的？</strong></p>
<p>目前amazon上的商品主要有三种：</p>
<p>  （1）如果是 “shipped from and sold by amazon.com”,那就是amazon自家。</p>
<p>  （2）如果是 “sold by** and fullfilled by amzon”,那就是说这是amazon上的商家在卖，但是运费政策和amazon履行一致，也就是说比如amazon说满25刀包邮，这个商品虽然不是亚马逊自家的商品，但是也算在内，amazon prime享受的政策和优惠，这件商品和这家店铺都可以提供；</p>
<p> （3）如果是 “shipped from and sold by <strong>“ ：”</strong>“不是”amazon”，那就是说这不是amazon自家的，而且可能还需要你另付邮费，请一定要看清楚。</p>
<p><strong>超级省钱之两大法宝！</strong></p>
<p>  <strong>首先介绍一下，超级省钱，亚马逊独有的**</strong>Subscribe &amp; Save服务。<strong>Amazon在以下4个分类中都有Subscribe &amp; Save服务：化妆美容，食品，健康及办公用品和个人护理。使用Subscribe &amp; Save功能，可以有15个点的折扣，而且免运费。先是选择S&amp;S服务，然后选择定时发货的时间段和购买数量，从1-6个月不等，意思是Amazon每间隔多长时间自动下单，发货。如何取消呢？在本次购买Amazon发货后，点击“</strong>Your Account<strong>”，然后选择“</strong>Orders–&gt;manage subscribe &amp; save items**”，就可以把自动下单取消了。可以8.5折，而且全免运费，只有亚马逊才有哦！</p>
<p><strong>关于Subscribe &amp; Save的几个注意事项</strong></p>
<p><strong>1.只有右上角显示Subscribe &amp; Save的选项，才是可以SS的，不是所有的产品都有的。</strong></p>
<p><strong>2.选择SS的产品，无论多少金额，都是免运费的，运输时间5-7天。</strong></p>
<p><strong>3.一件SS的商品需要下单一次，多个SS商品需要下单多次，而且不能和非SS的商品一起下单，好在现在大部分的转运公司都是免费合箱的，可以把东西发到转运那免费合箱。</strong></p>
<p><strong>关于Subscribe&amp;Save**</strong>更多新政策介绍，可参考**<strong>：</strong></p>
<h1 id="美国亚马逊（S-amp-S）最新政策介绍：Amazon-Subscribe-amp-Save"><a href="#美国亚马逊（S-amp-S）最新政策介绍：Amazon-Subscribe-amp-Save" class="headerlink" title="美国亚马逊（S&amp;S）最新政策介绍：Amazon Subscribe &amp; Save"></a><a href="http://www.haitaobang.cn/glDetail?id=18"><strong>美国亚马逊（S&amp;S）最新政策介绍：Amazon Subscribe &amp; Save</strong></a></h1><p><strong>省钱第2大法宝–<strong>*<strong>\</strong>***************************<a href="https://www.amazon.com/gp/family/signup/welcome/?ref_=assoc_tag_ph_1457104784749&ie=UTF8&*Version*=1&*entries*=0&camp=1789&creative=9325&linkCode=pf4&tag=toplive-20&linkId=LJZYLD2YWF7WL2NH">********************************加入Amazon Family家庭计划********************************</a>****************************\</strong></strong> (之前的亚马逊妈妈计划Amazon Mom）<strong>，享受免费**</strong>Prime会员资格及额外折扣**</p>
<p>Amazon Family的前身是Amazon Mom计划，虽然名称换了，但内容和福利有增无减：（1）*<strong>\</strong>***********加入Amazon Family*************<strong><em>是免费的，而且可以随时取消<strong>。</strong> （2） 加入后的第一个月可免费享受Amazon Prime资格，也就是发货后免费2天送达，<strong>如果在1个月内取消，取消后也可继续享受完1个月的**</strong>Prime会员资格,但不建议加入后马上取消，因为这样有些特殊优惠就没法享受，一般快到1个月的某一天取消就行（如何取消，下面有方法；忘记取消也没关系，即使过了1个月被扣款了也能分分钟要回！下面有介绍）。** （3）Amazon还提供很多优惠給Amazon Family会员，像是尿片、湿巾有额外20%折扣等，或是其他某些婴儿用品有额外的优惠。</em></strong>*<em>\</em>**********************************************************加入Amazon Family****************************************************************只需要填写宝宝的名字和出生年月就可以了，非常的简单.</p>
<p>​                           <strong><em>*</em>***********<a href="https://www.amazon.com/gp/family/signup/welcome/?ref_=assoc_tag_ph_1457104784749&ie=UTF8&*Version*=1&*entries*=0&camp=1789&creative=9325&linkCode=pf4&tag=toplive-20&linkId=LJZYLD2YWF7WL2NH">****************亚马逊Amazon Family计划加入链接****************</a>**************</strong></p>
<p><a href="https://www.amazon.com/gp/family/signup/welcome/?ref_=assoc_tag_ph_1457104784749&ie=UTF8&*Version*=1&*entries*=0&camp=1789&creative=9325&linkCode=pf4&tag=toplive-20&linkId=LJZYLD2YWF7WL2NH"><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/002nUHNIzy6XLFSBs1x27&690" alt="海淘新手入门必看——2018最新美国亚马逊海淘攻略！含海淘转运攻略海淘教程"></a></p>
<p>   进入后点击<strong>Start Your 30-Day Free Trial of Prime</strong>，页面跳转至信息填写页面。最上面是填写宝宝的一些相关信息（名字、生日、性别），这里可以乱填的，因为不做审核。</p>
<p>   页面下方是输入您的信用卡信息，右侧是账单地址( 帮主实测目前只支持双币信用卡，也就是卡面上有VISA或MasterCard 或者JBC等标志)，，账单地址可以选择已有的地址或者添加一个新地址<strong>（\</strong>原则上应该是信用卡的国内账单地址，但根据帮主的测试和粉丝的反馈，填写转运地址也没问题。）****</p>
<p> 然后选择下方的按钮，提交即可，非常的简单。 </p>
<p>加入后的第一个月可免费享受Amazon Prime资格，但一个月免费期结束后如果不取消family计划，将自动从你的信用卡里扣107.91美元的年费。（<strong>最好是快到30天的时候再取消，因为有些妈妈计划的优惠，必须在没取消之前有效！如果忘记取消也没关系，帮主实测即使过了1个月信用卡被扣了107.91，通过在线联系客服，百分百能要回来！大家放心！</strong>）！ </p>
<p>想在一个月内自己取消的，只要取消Prime会员就可以，这样1个月到期后就不会扣费了！方法：点击<a href="https://www.amazon.com/gp/subs/primeclub/account/homepage.html/?ie=UTF8&tag=toplive-20&linkCode=ur2&camp=1789&creative=390957"><strong>取消Prime链接</strong></a>，登录后，点击Do not continue 按钮,在出现的界面中点击Do not continue 即可！</p>
<p><strong>如果忘记取消试用，被扣了107.91美元(或者是99美元)美金怎么办？</strong>别急，可以申诉拿回我的107.91美金，取消我的Prime资格。 点击：<a href="https://www.amazon.com/gp/help/contact-us/general-questions.html/?ie=UTF8&camp=1789&creative=390957&linkCode=ur2&nodeId=508510&tag=toplive-20&token=&type="><strong>亚马逊客服页面</strong></a></p>
<p>1） what can we help you with?那一栏选择“Prime or Something else ”<br>2 ）Tell us more about your issue<br>    Select an issue那一栏 选择“Prime Support”<br>    Select issue details 那一栏 选择“Cancel Prime Membership” ,然后点击“More help options”<br>3） How would you like to contact us? 选择 E-mail电子邮件，Phone电话，Chat在线对话。选择电子邮件或者在线对话都可以，就说:<strong>I want cancel my Prime membership,please refund me</strong>（我想取消妈妈计划资格，请退款）即可，一般107.91美元会在3-5天退回信用卡（帮主一般选择Chat，亚马逊客服都是24小时在线，一般分分钟就帮你取消，并退款给您了！）。 </p>
<p><strong>注意：免费试用家庭计划一个月的前提是之前没有加入过Prime服务，不然就没有这1个月的免费试用了。</strong></p>
<p><strong>关于家庭计划的更多详细解读，请参考帮主最新心血总结：\</strong><a href="http://www.haitaobang.cn/glDetail?id=27">**亚马逊家庭计划详细解读**</a>****</p>
<p><strong>省钱第**</strong>3大法宝–<strong><strong>亚马逊</strong></strong>Baby registry婴儿注册表！**用此方法，母婴用品、化妆品、保健品都可以有15%的优惠！</p>
<p><strong><em>\</em>因为篇幅限制，关于如何注册Baby registry及使用，请参考帮主详细教程：<a href="http://blog.sina.com.cn/s/blog_824629260102uwpc.html">**点击这里**</a>**</strong> </p>
<p><strong><em>*</em>*省钱第4大法宝–亚马逊****Wedding Registry注册表！**用此方法，电子产品、厨房用品、箱包等都有10%的优惠，注册一个月后，邮箱会收到一个10%的折扣码，结账时候输入即可。关于详细的步骤，帮主正在撰写，大家可以参考Baby registry婴儿注册表自己先研究。注册链接：<a href="http://www.amazon.com/gp/wedding/homepage/?ref=assoc_tag_ph_1402131587292&ie=UTF8&camp=1789&creative=9325&linkCode=pf4&tag=toplive-20&linkId=MYO5FOQOGMFI525M">**点击这里**</a> （先注册好，然后在你要买的商品页面右侧就会出现：”Add to Wedding Registry” ，点这个按钮就可添加到Wedding 注册表，等一个月后，邮箱收到折扣码就可以购买这些商品了。关于细节大家可先参考：<a href="http://www.amazon.com/b?ie=UTF8?t=toplive-20&node=8021049011&pf_rd_p=1877078722&pf_rd_s=center-5&pf_rd_t=601&pf_rd_i=wedding-homepage&pf_rd_m=ATVPDKIKX0DER&pf_rd_r=09FS17BGQKHRP1KGXQ0H&ref_=acs_ux_hsb_5s_5_m_WR-HP?t=toplive-20">Wedding 注册表折扣使用规则</a>）**</strong>  </p>
<p><strong>亚马逊上的东西浩如烟海，怎样才能一下子直达我们想要找的东东，没关系，帮主为你总结了亚马逊的中文分类导航：<a href="http://www.haitaobang.cn/amazon_nav">*<em>Amazon中文导航*</em></a> ，还列出了亚马逊自营商品的分类，怎么样？幸福吧！哈哈，快快收藏吧，以后此页就是你的海淘首页，再也不用浪费时间大海捞针啦，COME ON！</strong> </p>
<p>  <strong>初次海淘，怎么知道哪些东西是最值得海淘的呢？哪些东西性价比最高评价最好呢？帮主总结了海淘路上大家的使用心得，大家可以做个参考，这里的东西，帮主都是千挑万选，只要你用的着，买回来肯定不会后悔就是了。来看看吧！帮主总结在这里</strong>：</p>
<p><strong><a href="http://www.haitaobang.cn/glDetail?id=5">*<em>最值得海淘的商品推荐——“化妆品”篇*</em></a></strong></p>
<p><strong><a href="http://www.haitaobang.cn/glDetail?id=15">*<em>最值得海淘的商品推荐——“保健品”篇*</em></a></strong></p>
<p><strong><a href="http://www.haitaobang.cn/glDetail?id=19">*<em>最值得海淘的商品推荐——“母婴产品”篇*</em></a></strong></p>
<p><strong>我们怎么才能知道亚马逊哪些东西在特价呢？记得经常来这里看看：</strong></p>
<p><strong><a href="http://www.haitaobang.cn/zhekoulist?mall=%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A">亚马逊最新折扣频道</a></strong></p>
<p>可以把这个帖子收藏起来，经常看看优惠信息，避免错过优惠。另外遇到海淘问题或者一些海淘省钱攻略等帮主也做了个索引，方便很多：</p>
<p><a href="http://blog.sina.com.cn/s/blog_824629260102uxqs.html"><strong>帮主所有海淘教程、省钱攻略汇总索引</strong></a></p>
<p>最后感谢您花了时间耐心阅读帮主准备的教程，希望我的教程能够对您有帮助。也欢迎你通过微博或微信联系帮主，给我多提宝贵意见和反馈。另外很多人问帮主是否代购，是否有淘宝店铺？在这里帮主告诉大家，帮主希望大家都学会海淘，自己来，尽量不要找代购，既节约成本又降低被骗的风险。因为帮主精力有限，目前只给大家福利代购一些推车和儿童安全座椅之类的大件，基本上和自己淘的价格是一样的。在淘宝搜索“<a href="http://haitaobang.taobao.com/">海淘帮帮主</a>”即可找到帮主店铺：<a href="http://haitaobang.taobao.com/">haitaobang.taobao.com</a></p>
<p> <strong>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</strong></p>
<p><strong>帮主补充的几点注意事项：</strong></p>
<h1 id="（一）Amazon-Prime-完整试用、取消方法（建议不用开通这个，按上面方法开通Amazon-Family，也就是亚马逊家庭计划即可，开通后包含免费1个月的Prime-，帮主写在这里是因为有些粉丝在提交订单的时候，在选择运输方式的阶段，亚马逊会提示你是否开通Prime的2日送达，很多粉丝没看清楚就直接稀里糊涂加入了！因为加入这个只能享受免费试用1个月的Prime的服务，而加入Amazon-Family除了包含免费试用1个月的Prime，还有一些其他的优惠，详见：-亚马逊家庭计划详细解读-）"><a href="#（一）Amazon-Prime-完整试用、取消方法（建议不用开通这个，按上面方法开通Amazon-Family，也就是亚马逊家庭计划即可，开通后包含免费1个月的Prime-，帮主写在这里是因为有些粉丝在提交订单的时候，在选择运输方式的阶段，亚马逊会提示你是否开通Prime的2日送达，很多粉丝没看清楚就直接稀里糊涂加入了！因为加入这个只能享受免费试用1个月的Prime的服务，而加入Amazon-Family除了包含免费试用1个月的Prime，还有一些其他的优惠，详见：-亚马逊家庭计划详细解读-）" class="headerlink" title="（一）Amazon Prime 完整试用、取消方法（建议不用开通这个，按上面方法开通Amazon Family，也就是亚马逊家庭计划即可，开通后包含免费1个月的Prime ，帮主写在这里是因为有些粉丝在提交订单的时候，在选择运输方式的阶段，亚马逊会提示你是否开通Prime的2日送达，很多粉丝没看清楚就直接稀里糊涂加入了！因为加入这个只能享受免费试用1个月的Prime的服务，而加入Amazon Family除了包含免费试用1个月的Prime，还有一些其他的优惠，详见： 亚马逊家庭计划详细解读 ）"></a>（一）Amazon Prime 完整试用、取消方法（建议不用开通这个，按上面方法开通<a href="https://www.amazon.com/gp/family/signup/welcome/?ref_=assoc_tag_ph_1457104784749&ie=UTF8&*Version*=1&*entries*=0&camp=1789&creative=9325&linkCode=pf4&tag=toplive-20&linkId=LJZYLD2YWF7WL2NH">Amazon Family，也就是亚马逊家庭计划即可</a>，开通后包含免费1个月的Prime ，帮主写在这里是因为有些粉丝在提交订单的时候，在选择运输方式的阶段，亚马逊会提示你是否开通Prime的2日送达，很多粉丝没看清楚就直接稀里糊涂加入了！因为加入这个只能享受免费试用1个月的Prime的服务，而加入<a href="https://www.amazon.com/gp/family/signup/welcome/?ref_=assoc_tag_ph_1457104784749&ie=UTF8&*Version*=1&*entries*=0&camp=1789&creative=9325&linkCode=pf4&tag=toplive-20&linkId=LJZYLD2YWF7WL2NH">Amazon Family</a>除了包含免费试用1个月的Prime，还有一些其他的优惠，详见： <a href="http://www.haitaobang.cn/glDetail?id=27">亚马逊家庭计划详细解读</a> ）</h1><p><strong>Prime服务有两大优势：</strong></p>
<blockquote>
<p><strong>享受任意金额免美国境内运费，以及免费的2个工作日送达服务。</strong></p>
</blockquote>
<p><strong>开通方法:（1）开通链接：<a href="http://www.amazon.com/tryprimefree/?ref_=assoc_tag_ph_1427739975520&_encoding=UTF8&camp=1789&creative=9325&linkCode=pf4&tag=toplive-20&linkId=FIBRZORNH4WOMVN4">点击这里</a></strong> </p>
<p>​    <strong>（2）在出现的页面中点击：<a href="http://www.amazon.com/tryprimefree/?ref_=assoc_tag_ph_1427739975520&_encoding=UTF8&camp=1789&creative=9325&linkCode=pf4&tag=toplive-20&linkId=FIBRZORNH4WOMVN4"><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/82462926tx6DfmKTVlMd2&690" alt="海淘新手入门必看——2018最新美国亚马逊海淘攻略！含海淘转运攻略海淘教程"></a></strong></p>
<p>​       （3）之后输入输入信用卡号，已经输过的无需输入，点击”<strong>start my free trial</strong>“ </p>
<p>之后出现如下界面就表示试用成功。在此一个月内，你都能享受免费的2个工作日送达，和任意金额免运费。</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/745a8c23gw1dnqz5uqwazj.jpg" alt="海淘新手入门必看——2018最新美国亚马逊海淘攻略！含海淘转运攻略海淘教程"></p>
<blockquote>
<p>Prime服务会自动续费，一个月之后会扣除99美元，因此我们需要关掉自动续费。这样到期就结束，而不会扣款。关闭的方法是：</p>
</blockquote>
<p>1,点击<a href="https://www.amazon.com/gp/subs/primeclub/account/homepage.html/?ie=UTF8&tag=toplive-20&linkCode=ur2&camp=1789&creative=390957"><strong>这个链接</strong></a>，登录后，进入管理，点击Do not upgrade按钮，出现如下字符will <strong>not</strong> upgrade，即表示自动关闭。建议开通后立即去取消自动续费。（这里的立即是完成第一笔购物后取消的意思）</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/745a8c23gw1dnqz6b2cqsj.jpg" alt="海淘新手入门必看——2018最新美国亚马逊海淘攻略！含海淘转运攻略海淘教程"></p>
<p>另外，如果真的忘记取消，被扣费了，也没关系，只要没有试用过Prime，按照上面妈妈计划要求退款的方法给客服写一个邮件，要求refund，Amazon也会把99美元(有消费税是107.91美元）退给你。</p>
<p>（二）：如何看商品的重量？</p>
<p>A：比如这件1150的剃须刀：<a href="http://www.amazon.com/gp/product/B006W2SYF8/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=B006W2SYF8&linkCode=as2&tag=toplive-20"><strong>亚马逊剃须刀购买页面</strong></a> 在商品下面会有一个：</p>
<p><a href="http://s15.sinaimg.cn/orignal/82462926gcac0949ddd4e"><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/82462926gcac0949ddd4e&690" alt="海淘新手入门必看——2018最新美国亚马逊海淘攻略！含海淘转运攻略海淘教程"></a></p>
<p>其中：</p>
<h2 id="“Shipping-Weight-”就是运输重量，“Product-Dimensions-”是产品不含包装的尺寸和重量。我们运回国内，当然要看运输重量，也就是带包装的-Shipping-Weight。（有些显示为-ounces，可以自己算一下1磅-16盎司）"><a href="#“Shipping-Weight-”就是运输重量，“Product-Dimensions-”是产品不含包装的尺寸和重量。我们运回国内，当然要看运输重量，也就是带包装的-Shipping-Weight。（有些显示为-ounces，可以自己算一下1磅-16盎司）" class="headerlink" title="“Shipping Weight: ”就是运输重量，“Product Dimensions:”是产品不含包装的尺寸和重量。我们运回国内，当然要看运输重量，也就是带包装的**Shipping Weight。（有些显示为**ounces，可以自己算一下1磅=16盎司）"></a>“<strong>Shipping Weight:</strong> ”就是运输重量，“<strong>Product Dimensions:”是产品不含包装的尺寸和重量。我们运回国内，当然要看运输重量，也就是带包装的**</strong>Shipping Weight。（有些显示为**ounces，可以自己算一下1磅=16盎司）</h2><p><strong>但是转运公司最后的重量会和亚马逊标注的稍微有点差别，有时轻，有时重一点。</strong></p>
<p><strong>帮主心血总结：</strong><a href="http://www.haitaobang.cn/amazonnav/"><strong>美国亚马逊中文导航</strong></a></p>
<p><strong>更多海淘攻略：</strong></p>
<p><strong><em>\</em><a href="http://www.haitaobang.cn/glDetail?id=125">**海淘攻略全集|用支付宝就能海淘**</a>**</strong></p>
<p><a href="http://www.haitaobang.cn/gonglue/43.html"><strong><em>\</em>美国亚马逊直邮教程（电脑端）**</strong></a></p>
<h2 id="美国亚马逊直邮购物攻略（手机端）"><a href="#美国亚马逊直邮购物攻略（手机端）" class="headerlink" title="\美国亚马逊直邮购物攻略（手机端）**"></a><a href="http://www.haitaobang.cn/gonglue/99.html"><strong><em>\</em>美国亚马逊直邮购物攻略（手机端）**</strong></a></h2><h2 id="iHerb海淘攻略、最新优惠码"><a href="#iHerb海淘攻略、最新优惠码" class="headerlink" title="\iHerb海淘攻略、最新优惠码**"></a><a href="http://www.haitaobang.cn/gonglue/21.html"><strong><em>\</em>iHerb海淘攻略、最新优惠码**</strong></a></h2><h2 id="日本亚马逊海淘攻略"><a href="#日本亚马逊海淘攻略" class="headerlink" title="\日本亚马逊海淘攻略**"></a><a href="http://www.haitaobang.cn/gonglue/64.html"><strong><em>\</em>日本亚马逊海淘攻略**</strong></a></h2><h2 id="6PM手把手海淘攻略"><a href="#6PM手把手海淘攻略" class="headerlink" title="\6PM手把手海淘攻略**"></a><a href="http://www.haitaobang.cn/gonglue/69.html"><strong><em>\</em>6PM手把手海淘攻略**</strong></a></h2><h2 id="德淘安全座椅的好去处Kidsroom网站攻略"><a href="#德淘安全座椅的好去处Kidsroom网站攻略" class="headerlink" title="\德淘安全座椅的好去处Kidsroom网站攻略**"></a><a href="http://www.haitaobang.cn/gonglue/92.html"><strong><em>\</em>德淘安全座椅的好去处Kidsroom网站攻略**</strong></a></h2><h2 id="shopbop（烧包网）海淘直邮购物攻略"><a href="#shopbop（烧包网）海淘直邮购物攻略" class="headerlink" title="\shopbop（烧包网）海淘直邮购物攻略**"></a><a href="http://www.haitaobang.cn/gonglue/70.html"><strong><em>\</em>shopbop（烧包网）海淘直邮购物攻略**</strong></a></h2><h2 id="英国海淘攻略：Lookfantastic、THE-HUT、mybag-海淘下单图文教程"><a href="#英国海淘攻略：Lookfantastic、THE-HUT、mybag-海淘下单图文教程" class="headerlink" title="\英国海淘攻略：Lookfantastic、THE HUT、mybag 海淘下单图文教程**"></a><a href="http://www.haitaobang.cn/gonglue/103.html"><strong><em>\</em>英国海淘攻略：Lookfantastic、THE HUT、mybag 海淘下单图文教程**</strong></a></h2><h2 id="日本乐天国际市场海淘攻略"><a href="#日本乐天国际市场海淘攻略" class="headerlink" title="\日本乐天国际市场海淘攻略**"></a><a href="http://www.haitaobang.cn/gonglue/63.html"><strong><em>\</em>日本乐天国际市场海淘攻略**</strong></a></h2><h2 id="澳洲首家折扣药房——Roy-Young-Chemist海淘攻略"><a href="#澳洲首家折扣药房——Roy-Young-Chemist海淘攻略" class="headerlink" title="\澳洲首家折扣药房——Roy Young Chemist海淘攻略**"></a><a href="http://www.haitaobang.cn/gonglue/108.html"><strong><em>\</em>澳洲首家折扣药房——Roy Young Chemist海淘攻略**</strong></a></h2><h2 id="澳洲最大在线-Pharmacy-Online-药房购物攻略"><a href="#澳洲最大在线-Pharmacy-Online-药房购物攻略" class="headerlink" title="\澳洲最大在线 Pharmacy Online 药房购物攻略**"></a><a href="http://www.haitaobang.cn/gonglue/111.html"><strong><em>\</em>澳洲最大在线 Pharmacy Online 药房购物攻略**</strong></a></h2><p><strong><a href="http://www.haitaobang.cn/gonglue/11.html">*<em>海淘转运教程—转运操作流程及常见问题解决方法*</em></a></strong></p>
<h2 id="亚马逊Baby-registry注册及使用攻略-图文教程-超详细！-母婴用品、化妆品都可有15-优惠"><a href="#亚马逊Baby-registry注册及使用攻略-图文教程-超详细！-母婴用品、化妆品都可有15-优惠" class="headerlink" title="\亚马逊Baby registry注册及使用攻略( 图文教程 超详细！) 母婴用品、化妆品都可有15%优惠**"></a><a href="http://www.haitaobang.cn/gonglue/33.html"><strong><em>\</em>亚马逊Baby registry注册及使用攻略( 图文教程 超详细！) 母婴用品、化妆品都可有15%优惠**</strong></a></h2><h2 id="亚马逊Amazon-Family家庭计划使用攻略详细解读图文教程"><a href="#亚马逊Amazon-Family家庭计划使用攻略详细解读图文教程" class="headerlink" title="\亚马逊Amazon Family家庭计划使用攻略详细解读图文教程**"></a><a href="http://www.haitaobang.cn/gonglue/27.html"><strong><em>\</em>亚马逊Amazon Family家庭计划使用攻略详细解读图文教程**</strong></a></h2><h2 id="美国亚马逊（S-amp-S）最新政策介绍：Amazon-Subscribe-amp-Save-1"><a href="#美国亚马逊（S-amp-S）最新政策介绍：Amazon-Subscribe-amp-Save-1" class="headerlink" title="\美国亚马逊（S&amp;S）最新政策介绍：Amazon Subscribe &amp; Save**"></a><a href="http://www.haitaobang.cn/gonglue/18.html"><strong><em>\</em>美国亚马逊（S&amp;S）最新政策介绍：Amazon Subscribe &amp; Save**</strong></a></h2><h2 id="如何加入美亚Prime会员？帮主送上Prime会员免费试用教程！"><a href="#如何加入美亚Prime会员？帮主送上Prime会员免费试用教程！" class="headerlink" title="\如何加入美亚Prime会员？帮主送上Prime会员免费试用教程！**"></a><a href="http://www.haitaobang.cn/gonglue/65.html"><strong><em>\</em>如何加入美亚Prime会员？帮主送上Prime会员免费试用教程！**</strong></a></h2><h2 id="美亚购物，帮主教你玩转Prime-Pantry"><a href="#美亚购物，帮主教你玩转Prime-Pantry" class="headerlink" title="*美亚购物，帮主教你玩转Prime Pantry*"></a><strong><a href="http://www.haitaobang.cn/gonglue/66.html">*<em>美亚购物，帮主教你玩转Prime Pantry*</em></a></strong></h2><h2 id><a href="#" class="headerlink" title></a></h2><h2 id="美国亚马逊礼品卡买赠方法图文详解"><a href="#美国亚马逊礼品卡买赠方法图文详解" class="headerlink" title="\美国亚马逊礼品卡买赠方法图文详解**"></a><a href="http://www.haitaobang.cn/gonglue/97.html"><strong><em>\</em>美国亚马逊礼品卡买赠方法图文详解**</strong></a></h2><h2 id="日本亚马逊官网中文-日亚官网中文版来啦！"><a href="#日本亚马逊官网中文-日亚官网中文版来啦！" class="headerlink" title="\日本亚马逊官网中文_日亚官网中文版来啦！**"></a><a href="http://www.haitaobang.cn/gonglue/104.html"><strong><em>\</em>日本亚马逊官网中文_日亚官网中文版来啦！**</strong></a></h2><h2 id="鞋、女包、眼镜满-150免费直邮中国"><a href="#鞋、女包、眼镜满-150免费直邮中国" class="headerlink" title="\鞋、女包、眼镜满$150免费直邮中国**"></a><a href="http://www.haitaobang.cn/gonglue/45.html"><strong><em>\</em>鞋、女包、眼镜满$150免费直邮中国**</strong></a></h2><h2 id="联系美国亚马逊客服、日本亚马逊的方法亚马逊中文客服解答"><a href="#联系美国亚马逊客服、日本亚马逊的方法亚马逊中文客服解答" class="headerlink" title="\联系美国亚马逊客服、日本亚马逊的方法亚马逊中文客服解答**"></a><a href="http://www.haitaobang.cn/gonglue/100.html"><strong><em>\</em>联系美国亚马逊客服、日本亚马逊的方法亚马逊中文客服解答**</strong></a></h2><p><strong><em>\</em>更多海淘推荐：**</strong></p>
<p><strong><a href="http://www.haitaobang.cn/gonglue/19.html">*<em>最值得海淘的商品推荐—“母婴产品”*</em></a></strong></p>
<p><strong><a href="http://www.haitaobang.cn/gonglue/20.html">*<em>海淘清单1：从怀孕到育儿必备的用品*</em></a></strong></p>
<p><strong><em>\</em>夏日特辑——海淘推荐30款宝宝防护产品**</strong></p>
<p><strong><a href="http://www.haitaobang.cn/gonglue/15.html">*<em>最值得海淘的商品推荐——“保健品”篇*</em></a></strong></p>
<p><strong><em>\</em>最\</strong><a href="http://www.haitaobang.cn/gonglue/5.html">*<em>值得海淘的商品推荐——“化妆品”篇*</em></a>**</p>
<h2 id="美亚最值得淘的保健品分类推荐"><a href="#美亚最值得淘的保健品分类推荐" class="headerlink" title="*美亚最值得淘的保健品分类推荐*"></a><strong><a href="http://www.haitaobang.cn/gonglue/113.html">*<em>美亚最值得淘的保健品分类推荐*</em></a></strong></h2><p> <strong><a href="http://www.haitaobang.cn/gonglue/118.html">*<em>美亚十大热门洗发护发产品*</em></a></strong></p>
<p> <strong><a href="http://www.haitaobang.cn/gonglue/124.html">*<em>拒绝跟风那些低调好用的天然护肤品牌*</em></a></strong></p>
<p> <strong><a href="http://www.haitaobang.cn/gonglue/35.html">*<em>iHerb畅销产品排名榜*</em></a></strong></p>
<p> <strong><a href="http://www.haitaobang.cn/gonglue/17.html">*<em>iHerb超值明星产品介绍*</em></a></strong></p>
<p> <strong><a href="http://www.haitaobang.cn/gonglue/107.html">*<em>Lookfantastic必败20件好物*</em></a></strong></p>
<p> <strong><em>\</em><a href="http://www.haitaobang.cn/gonglue/112.html">德淘买什么？推荐20款德国儿童必备药</a>**</strong></p>
<h2 id="-1"><a href="#-1" class="headerlink" title></a></h2><h2 id="——————————"><a href="#——————————" class="headerlink" title="——————————-"></a>——————————-</h2><p><strong>海淘过程中遇到问题怎么办？</strong></p>
<p>海淘过程中的任何问题，可咨询帮主公众号客服，微信公众号：<strong>海淘帮帮主</strong></p>
<p>可扫描下方二维码关注：</p>
<p><img src="/../images/%E6%B5%B7%E6%B7%98%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8%E5%BF%85%E7%9C%8B%E2%80%94%E2%80%942018%E6%9C%80%E6%96%B0%E7%BE%8E%E5%9B%BD%E4%BA%9A%E9%A9%AC%E9%80%8A%E6%B5%B7%E6%B7%98%E6%94%BB%E7%95%A5%EF%BC%81%E5%90%AB%E6%B5%B7%E6%B7%98%E8%BD%AC%E8%BF%90%E6%94%BB%E7%95%A5%E6%B5%B7%E6%B7%98%E6%95%99%E7%A8%8B/6362390296578843715873968.png" alt="海淘新手入门必看——2018最新美国亚马逊海淘攻略！含海淘转运攻略海淘教程"></p>
<p><strong>强烈推荐通过以下方式，实时获取折扣信息：</strong></p>
<p>【<strong>微信</strong>】添加微信号：<strong>haitaobang555</strong> 添加后进海淘微信群（群名额有限，手快有）</p>
<p>【<strong>微博</strong>】：@海淘帮帮主（<a href="http://weibo.com/haitaobang">点此看微博精彩</a>） </p>
<p><strong>【QQ群】： 678266923</strong>（ <a href="https://jq.qq.com/?_wv=1027&k=57mTCWx">点此直接加入</a> ）</p>
<p>【<strong>网站</strong>】：<a href="http://www.haitaobang.cn/">点此进入海淘帮官网</a>（每日更新，分类详细）</p>
<p>【<strong>全国各地QQ/微信交流群</strong>】： <a href="http://www.haitaobang.cn/gonglue/245.html">点此加入</a></p>
<p>【海淘帮 <strong>微信公众号</strong>】：</p>
<p>美国海淘折扣+问题解答，关注微信公众号：<strong>美国海淘帮</strong></p>
<p>日本海淘折扣+问题解答，关注微信公众号：<strong>日本海淘帮</strong></p>
<p>欧洲海淘折扣+问题解答，关注微信公众号：<strong>欧洲海淘帮</strong></p>
<p>澳洲海淘折扣+问题解答，关注微信公众号：<strong>澳洲海淘帮</strong></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-其他</tag>
      </tags>
  </entry>
  <entry>
    <title>源码分享</title>
    <url>/post/8461f8ca.html</url>
    <content><![CDATA[<p>老外做的中国汉字网站：<a href="https://hanziyuan.net/">https://hanziyuan.net/</a></p>
<p>LNMP一键安装包：<a href="https://lnmp.org/install.html">https://lnmp.org/install.html</a></p>
<p>斐讯PSG1208刷机大合集：<a href="https://pan.baidu.com/s/1ges68Jx#list/path=%2F">https://pan.baidu.com/s/1ges68Jx#list/path=%2F</a></p>
<p>蓝天主板BIOS下载更新：<a href="https://repo.palkeo.com/clevo-mirror/">https://repo.palkeo.com/clevo-mirror/</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-其他</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习3—用三层全连接神经网络训练MNIST手写数字字符集</title>
    <url>/post/abc0fd31.html</url>
    <content><![CDATA[<p>上一篇文章：<a href="https://aichn.cn/post/ee239b41.html">深度学习2—任意结点数的三层全连接神经网络</a><br>　　距离上篇文章过去了快四个月了，真是时光飞逝，之前因为要考试所以耽误了更新，谁知道考完试之前落下的接近半个学期的工作是如此之多，以至于弄到现在才算基本填完坑，实在是疲惫至极。<br>　　另外在这段期间，发现了一本非常好的神经网络入门书籍，本篇的很多细节问题本人就是在这本书上找到的答案，强烈推荐一下：
　　</p>
<p><img src="/../images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03%E2%80%94%E7%94%A8%E4%B8%89%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%AD%97%E7%AC%A6%E9%9B%86/20180629031044540" alt="这里写图片描述"></p>
<p>　　上篇文章介绍了如何实现一个任意结点数的三层全连接神经网络。本篇，我们将利用已经写好的代码，搭建一个输入层、隐含层、输出层分别为784、100、10的三层全连接神经网络来训练闻名已久的mnist手写数字字符集，然后自己手写一个数字来看看网络是否能比较给力的工作。<br>　　在正式做之前，还是按照惯例讲几个会用到的知识点。</p>
<ol>
<li>mnist数字字符集的结构解析，这个我单独写了一篇文章来做介绍了，如有需要了解请先移步：<a href="http://blog.csdn.net/weixinhum/article/details/74908042">深度学习3番外篇—mnist数据集格式及转换</a></li>
<li>我们之前都是直接放入几个数作为输入，然后给网络几个数作为目标来训练网络的，而mnist手写字符集给我们的是一堆手写的28<em>28像素的图片还有图片对应的手写数字标签，我们怎么对它进行转换？<br>　　转换是这样的，我们把图片的所有像素当做输入，也就是28</em>28=784个像素直接作为输入，然后用0~9总共十个数作为输出目标的指引(当标签是“5”，则目标输出为0.01、0.01、0.01、0.01、0.01、0.99、0.01、0.01、0.01、0.01，依次类推)。<br>   　　这里有一点比较有意思，为什么要用0.01而不是0，用0.99而不是1？<br>   　　答案是我们用的激活函数永远不能输出0，1这两个数，因此如果取了这两个数则网络永远无法达到预期，会有训练过度的可能。<br>   　　另外，细心的你可能也想到了，我们之前输入的数都是在01的范围内的，而像素的灰度取值范围在0255，因此我们需要先对灰度值做一个归一化处理然后再放入网络中。<br>   　　这里归一化处理的方式也比较有意思，假设X为输入，我们的处理公式如下：<br>   　　$X÷255×0.99+0.01 $<br>   　　为什么要乘0.99再加0.01？<br>   　　答案是我们不希望输入取到0值，因为0有个小学生都知道的特点，任何数乘以它都等于0，因此无论输入层到隐含层的权值是多少，在输入等于0的时候都是一样的，这会影响权值的更新。</li>
<li>我们前面只确定了输入和输出层的节点个数，隐含层的节点个数还不知道，那我们怎么选取呢？答案可能让人难过，没有绝对正确的公式，只有几个经验公式(似乎有优化算法可以确定隐含层节点个数，后面如有需要开一篇专门讨论)：<br>m=\sqrt{n+l}+\alpham=n+l+αm=log_{2}nm=log2nm=\sqrt{nl}m=nl<br>　　其中，mm是隐含层节点数，nn是输入层节点数，ll是输出层节点数，\alphaα是00~1010之间的常数<br>　　本篇取第三个，最后因为比较接近100，就直接取了100(怎么感觉好随意。。。)。</li>
<li>因为这次的输入节点有784个，算是比较多的，要十分注意在初始化网络参数的时候要避免参数与输入节点的积之和过大的情况出现。因为我们用的是sigmod函数作为激活函数，它的波形如下图所示：<br>　　<img src="/../images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03%E2%80%94%E7%94%A8%E4%B8%89%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%AD%97%E7%AC%A6%E9%9B%86/20180626011108241" alt="这里写图片描述"><br>   　　可以看到，如果输入的数值过大或过小，波形会趋于平缓，也就是通常所说的“梯度消失”，我们要避免这种情况的出现。当然这也是用sigmod函数作为激活函数的问题。<br>   　　那么究竟权值取多少合适呢，一般的做法是取-1~1中间的随机数，而数学家得到的经验规则告诉我们，可以在一个节点传入链接数量平方根倒数的大致范围内随机采样，初始化权值。以我们隐含层到输出层权重为例，输出层节点有100条传入链接，则其权重范围在-1/\sqrt{100}−1/100至1/\sqrt{100}1/100之间。</li>
<li>最后，我们要判断输出的是否准确，则先做前向传播，得到10个输出之后，找到最大的一个跟标签对比，如果相同则网络预测正确。</li>
</ol>
<hr>
<p>那么，原理介绍完了，我们先对下图所示的第一、二张图像和相应的标签进行训练，主要代码如下（整个工程的代码会在最后面给出）：
　　</p>
<p><img src="/../images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03%E2%80%94%E7%94%A8%E4%B8%89%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%AD%97%E7%AC%A6%E9%9B%86/20180626013655589" alt="这里写图片描述"></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for (size_t count &#x3D; 0; count &lt; 3000; count++)</span><br><span class="line">&#123;</span><br><span class="line">	mnet.forwardPropagation(mNumImg[0].inputdata);&#x2F;&#x2F;前向传播</span><br><span class="line">	mnet.backPropagation(mNumImg[0].outputdata);&#x2F;&#x2F;反向传播</span><br><span class="line">	mnet.forwardPropagation(mNumImg[1].inputdata);&#x2F;&#x2F;前向传播</span><br><span class="line">	mnet.backPropagation(mNumImg[1].outputdata);&#x2F;&#x2F;反向传播</span><br><span class="line">&#125;</span><br><span class="line">mnet.forwardPropagation(mNumImg[0].inputdata);</span><br><span class="line">mnet.printresual(0);&#x2F;&#x2F;输出结果</span><br><span class="line">mnet.forwardPropagation(mNumImg[1].inputdata);</span><br><span class="line">mnet.printresual(0);</span><br></pre></td></tr></table></figure>
<p>运行结果如下：<br><img src="/../images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03%E2%80%94%E7%94%A8%E4%B8%89%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%AD%97%E7%AC%A6%E9%9B%86/20180704012927910" alt="这里写图片描述"><br>　　可以看到训练了3000次之后该网络可以分类之前输入的两个数字了（10个数字中最大的为预测结果，为了方便后面的正确率统计，一般会写一个函数将最大的数选出来和标签进行对比，看看网络的判断是不是正确的）。<br><img src="/../images/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A03%E2%80%94%E7%94%A8%E4%B8%89%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%AD%97%E7%AC%A6%E9%9B%86/20180704020745652" alt="这里写图片描述"><br>　　可以看到，该网络基本能达到96%的准确率，而且还有上升的趋势，因为训练时间感人，所以这里就不再接着训练了，据网上查询到的结果，该网络基本精确率基本到96%多一些，不到97%就到头了。</p>
<h2 id="C-实现"><a href="#C-实现" class="headerlink" title="C++实现"></a><strong>C++实现</strong></h2><hr>
<p>因为网络结构都没有改，改的只是各层节点的个数，前面提到的一些注意点，因此如果对整套代码有不明白的地方可以移步前两篇文章或看看本篇前面提到的5个注意点。<br>　　因为代码量变得比较多了，因此为了方便管理将工程分成了四个文件。</p>
<h3 id="setting-h"><a href="#setting-h" class="headerlink" title="setting.h"></a>setting.h</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#pragma once</span><br><span class="line">#include &quot;time.h&quot;</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line">#define IPNNUM 784</span><br><span class="line">#define HDNNUM 100</span><br><span class="line">#define OPNNUM 10</span><br></pre></td></tr></table></figure>
<h3 id="net-hpp"><a href="#net-hpp" class="headerlink" title="net.hpp"></a>net.hpp</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#pragma once</span><br><span class="line">#include &quot;setting.h&quot;</span><br><span class="line"></span><br><span class="line">class node</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">	double value; &#x2F;&#x2F;数值，存储结点最后的状态</span><br><span class="line">	double *W &#x3D; NULL;    &#x2F;&#x2F;结点到下一层的权值</span><br><span class="line"></span><br><span class="line">	void initNode(int num);&#x2F;&#x2F;初始化函数，必须调用以初始化权值个数</span><br><span class="line">	~node();     &#x2F;&#x2F;析构函数，释放掉权值占用内存</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">void node::initNode(int num)</span><br><span class="line">&#123;</span><br><span class="line">	W &#x3D; new double[num];</span><br><span class="line">	srand((unsigned)time(NULL));</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; num; i++)&#x2F;&#x2F;给权值赋一个随机值</span><br><span class="line">	&#123;</span><br><span class="line">		W[i] &#x3D; rand() % 100 &#x2F; double(100)*0.1;</span><br><span class="line">		if (rand() % 2)</span><br><span class="line">		&#123;</span><br><span class="line">			W[i] &#x3D; -W[i];</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">node::~node()</span><br><span class="line">&#123;</span><br><span class="line">	if (W !&#x3D; NULL)</span><br><span class="line">	&#123;</span><br><span class="line">		delete[]W;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;网络类，描述神经网络的结构并实现前向传播以及后向传播</span><br><span class="line">class net</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">	node inlayer[IPNNUM]; &#x2F;&#x2F;输入层</span><br><span class="line">	node hidlayer[HDNNUM];&#x2F;&#x2F;隐含层</span><br><span class="line">	node outlayer[OPNNUM];&#x2F;&#x2F;输出层</span><br><span class="line"></span><br><span class="line">	double yita &#x3D; 0.1;&#x2F;&#x2F;学习率η</span><br><span class="line">	double k1;&#x2F;&#x2F;输入层偏置项权重</span><br><span class="line">	double k2;&#x2F;&#x2F;隐含层偏置项权重</span><br><span class="line">	double Tg[OPNNUM];&#x2F;&#x2F;训练目标</span><br><span class="line">	double O[OPNNUM];&#x2F;&#x2F;网络实际输出</span><br><span class="line"></span><br><span class="line">	net();&#x2F;&#x2F;构造函数，用于初始化各层和偏置项权重</span><br><span class="line">	double sigmoid(double z);&#x2F;&#x2F;激活函数</span><br><span class="line">	double getLoss();&#x2F;&#x2F;损失函数，输入为目标值</span><br><span class="line">	void forwardPropagation(double *input);&#x2F;&#x2F;前向传播,输入为输入层节点的值</span><br><span class="line">	void backPropagation(double *T);&#x2F;&#x2F;反向传播，输入为目标输出值</span><br><span class="line">	void printresual(int trainingTimes);&#x2F;&#x2F;打印信息</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">net::net()</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;&#x2F;初始化输入层和隐含层偏置项权值，给一个随机值</span><br><span class="line">	srand((unsigned)time(NULL));</span><br><span class="line">	k1 &#x3D; rand() % 100 &#x2F; double(100);</span><br><span class="line">	k2 &#x3D; rand() % 100 &#x2F; double(100);</span><br><span class="line">	&#x2F;&#x2F;初始化输入层到隐含层节点权重</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; IPNNUM; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		inlayer[i].initNode(HDNNUM);</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;初始化隐含层到输出层节点权重</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; HDNNUM; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		hidlayer[i].initNode(OPNNUM);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;激活函数</span><br><span class="line">double net::sigmoid(double z)</span><br><span class="line">&#123;</span><br><span class="line">	return 1 &#x2F; (1 + exp(-z));</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;损失函数</span><br><span class="line">double net::getLoss()</span><br><span class="line">&#123;</span><br><span class="line">	double mloss &#x3D; 0;</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; OPNNUM; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		mloss +&#x3D; pow(O[i] - Tg[i], 2);</span><br><span class="line">	&#125;</span><br><span class="line">	return mloss &#x2F; OPNNUM;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;前向传播</span><br><span class="line">void net::forwardPropagation(double *input)</span><br><span class="line">&#123;</span><br><span class="line">	for (size_t iNNum &#x3D; 0; iNNum &lt; IPNNUM; iNNum++)&#x2F;&#x2F;输入层节点赋值</span><br><span class="line">	&#123;</span><br><span class="line">		inlayer[iNNum].value &#x3D; input[iNNum];</span><br><span class="line">	&#125;</span><br><span class="line">	for (size_t hNNum &#x3D; 0; hNNum &lt; HDNNUM; hNNum++)&#x2F;&#x2F;算出隐含层结点的值</span><br><span class="line">	&#123;</span><br><span class="line">		double z &#x3D; 0;</span><br><span class="line">		for (size_t iNNum &#x3D; 0; iNNum &lt; IPNNUM; iNNum++)</span><br><span class="line">		&#123;</span><br><span class="line">			z +&#x3D; inlayer[iNNum].value*inlayer[iNNum].W[hNNum];</span><br><span class="line">		&#125;</span><br><span class="line">		z +&#x3D; k1;&#x2F;&#x2F;加上偏置项</span><br><span class="line">		hidlayer[hNNum].value &#x3D; sigmoid(z);</span><br><span class="line">	&#125;</span><br><span class="line">	for (size_t oNNum &#x3D; 0; oNNum &lt; OPNNUM; oNNum++)&#x2F;&#x2F;算出输出层结点的值</span><br><span class="line">	&#123;</span><br><span class="line">		double z &#x3D; 0;</span><br><span class="line">		for (size_t hNNum &#x3D; 0; hNNum &lt; HDNNUM; hNNum++)</span><br><span class="line">		&#123;</span><br><span class="line">			z +&#x3D; hidlayer[hNNum].value*hidlayer[hNNum].W[oNNum];</span><br><span class="line">		&#125;</span><br><span class="line">		z +&#x3D; k2;&#x2F;&#x2F;加上偏置项</span><br><span class="line">		O[oNNum] &#x3D; outlayer[oNNum].value &#x3D; sigmoid(z);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;&#x2F;反向传播，这里为了公式好看一点多写了一些变量作为中间值</span><br><span class="line">&#x2F;&#x2F;计算过程用到的公式在博文中已经推导过了，如果代码没看明白请看看博文</span><br><span class="line">void net::backPropagation(double *T)</span><br><span class="line">&#123;</span><br><span class="line">	for (size_t i &#x3D; 0; i &lt; OPNNUM; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		Tg[i] &#x3D; T[i];</span><br><span class="line">	&#125;</span><br><span class="line">	for (size_t iNNum &#x3D; 0; iNNum &lt; IPNNUM; iNNum++)&#x2F;&#x2F;更新输入层权重</span><br><span class="line">	&#123;</span><br><span class="line">		for (size_t hNNum &#x3D; 0; hNNum &lt; HDNNUM; hNNum++)</span><br><span class="line">		&#123;</span><br><span class="line">			double y &#x3D; hidlayer[hNNum].value;</span><br><span class="line">			double loss &#x3D; 0;</span><br><span class="line">			for (size_t oNNum &#x3D; 0; oNNum &lt; OPNNUM; oNNum++)</span><br><span class="line">			&#123;</span><br><span class="line">				loss +&#x3D; (O[oNNum] - Tg[oNNum])*O[oNNum] * (1 - O[oNNum])*hidlayer[hNNum].W[oNNum];</span><br><span class="line">			&#125;</span><br><span class="line">			inlayer[iNNum].W[hNNum] -&#x3D; yita * loss*y*(1 - y)*inlayer[iNNum].value;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	for (size_t hNNum &#x3D; 0; hNNum &lt; HDNNUM; hNNum++)&#x2F;&#x2F;更新隐含层权重</span><br><span class="line">	&#123;</span><br><span class="line">		for (size_t oNNum &#x3D; 0; oNNum &lt; OPNNUM; oNNum++)</span><br><span class="line">		&#123;</span><br><span class="line">			hidlayer[hNNum].W[oNNum] -&#x3D; yita * (O[oNNum] - Tg[oNNum])*</span><br><span class="line">				O[oNNum] * (1 - O[oNNum])*hidlayer[hNNum].value;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void net::printresual(int trainingTimes)</span><br><span class="line">&#123;</span><br><span class="line">	double loss &#x3D; getLoss();</span><br><span class="line">	cout &lt;&lt; &quot;训练次数：&quot; &lt;&lt; trainingTimes &lt;&lt; endl;</span><br><span class="line">	cout &lt;&lt; &quot;loss：&quot; &lt;&lt; loss &lt;&lt; endl;</span><br><span class="line">	for (size_t oNNum &#x3D; 0; oNNum &lt; OPNNUM; oNNum++)</span><br><span class="line">	&#123;</span><br><span class="line">		cout &lt;&lt; &quot;输出&quot; &lt;&lt; oNNum + 1 &lt;&lt; &quot;：&quot; &lt;&lt; O[oNNum] &lt;&lt; endl;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="getImg-hpp"><a href="#getImg-hpp" class="headerlink" title="getImg.hpp"></a>getImg.hpp</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#pragma once</span><br><span class="line">#include &quot;setting.h&quot;</span><br><span class="line"></span><br><span class="line">class ImgData&#x2F;&#x2F;单张图像</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">	unsigned char tag;</span><br><span class="line">	double data[IPNNUM];</span><br><span class="line">	double label[OPNNUM];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class getImg</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">	ImgData* mImgData;</span><br><span class="line">	void imgTrainDataRead(const char *datapath, const char *labelpath);</span><br><span class="line">	~getImg();</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">void getImg::imgTrainDataRead(const char *datapath, const char *labelpath)</span><br><span class="line">&#123;</span><br><span class="line">	&#x2F;***********读取图片数据***********&#x2F;</span><br><span class="line">	unsigned char readbuf[4];&#x2F;&#x2F;信息数据读取空间</span><br><span class="line">	FILE *f;</span><br><span class="line">	fopen_s(&amp;f, datapath, &quot;rb&quot;);</span><br><span class="line">	fread_s(readbuf, 4, 1, 4, f);&#x2F;&#x2F;读取魔数，即文件标志位</span><br><span class="line">	fread_s(readbuf, 4, 1, 4, f);&#x2F;&#x2F;读取数据集图像个数</span><br><span class="line">	int sumOfImg &#x3D; (readbuf[0] &lt;&lt; 24) + (readbuf[1] &lt;&lt; 16) + (readbuf[2] &lt;&lt; 8) + readbuf[3];&#x2F;&#x2F;图像个数</span><br><span class="line">	fread_s(readbuf, 4, 1, 4, f);&#x2F;&#x2F;读取数据集图像行数</span><br><span class="line">	int imgheight &#x3D; (readbuf[0] &lt;&lt; 24) + (readbuf[1] &lt;&lt; 16) + (readbuf[2] &lt;&lt; 8) + readbuf[3];&#x2F;&#x2F;图像行数</span><br><span class="line">	fread_s(readbuf, 4, 1, 4, f);&#x2F;&#x2F;读取数据集图像列数</span><br><span class="line">	int imgwidth &#x3D; (readbuf[0] &lt;&lt; 24) + (readbuf[1] &lt;&lt; 16) + (readbuf[2] &lt;&lt; 8) + readbuf[3];&#x2F;&#x2F;图像列数</span><br><span class="line">	mImgData &#x3D; new ImgData[sumOfImg];</span><br><span class="line">	unsigned char *data &#x3D; new unsigned char[IPNNUM];</span><br><span class="line">	for (int i &#x3D; 0; i &lt; sumOfImg; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		fread_s(data, IPNNUM, 1, IPNNUM, f);&#x2F;&#x2F;读取数据集图像列数</span><br><span class="line">		for (size_t px &#x3D; 0; px &lt; IPNNUM; px++)&#x2F;&#x2F;图像数据归一化</span><br><span class="line">		&#123;</span><br><span class="line">			mImgData[i].data[px] &#x3D; data[px]&#x2F;(double)255*0.99+0.01;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	delete[]data;</span><br><span class="line">	fclose(f);</span><br><span class="line">	&#x2F;**********************************&#x2F;</span><br><span class="line">   &#x2F;***********读取标签数据***********&#x2F;</span><br><span class="line">   &#x2F;**********************************&#x2F;</span><br><span class="line">	fopen_s(&amp;f, labelpath, &quot;rb&quot;);</span><br><span class="line">	fread_s(readbuf, 4, 1, 4, f);&#x2F;&#x2F;读取魔数，即文件标志位</span><br><span class="line">	fread_s(readbuf, 4, 1, 4, f);&#x2F;&#x2F;读取数据集图像个数</span><br><span class="line">	sumOfImg &#x3D; (readbuf[0] &lt;&lt; 24) + (readbuf[1] &lt;&lt; 16) + (readbuf[2] &lt;&lt; 8) + readbuf[3];&#x2F;&#x2F;图像个数</span><br><span class="line">	for (int i &#x3D; 0; i &lt; sumOfImg; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		fread_s(&amp;mImgData[i].tag, 1, 1, 1, f);&#x2F;&#x2F;读取数据集图像列数</span><br><span class="line">		for (size_t j &#x3D; 0; j &lt; 10; j++)</span><br><span class="line">		&#123;</span><br><span class="line">			mImgData[i].label[j] &#x3D; 0.01;</span><br><span class="line">		&#125;</span><br><span class="line">		mImgData[i].label[mImgData[i].tag] &#x3D; 0.99;</span><br><span class="line">	&#125;</span><br><span class="line">	fclose(f);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">getImg::~getImg()</span><br><span class="line">&#123;</span><br><span class="line">	delete[]mImgData;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="BPNetC-cpp"><a href="#BPNetC-cpp" class="headerlink" title="BPNetC.cpp"></a>BPNetC.cpp</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;setting.h&quot;</span><br><span class="line">#include &quot;net.hpp&quot;&#x2F;&#x2F;神经网络</span><br><span class="line">#include &quot;getImg.hpp&quot;&#x2F;&#x2F;训练数据</span><br><span class="line"></span><br><span class="line">void AccuracyRate(int time, net *mnet, getImg *mImg)&#x2F;&#x2F;精确率评估</span><br><span class="line">&#123;</span><br><span class="line">	double tagright &#x3D; 0;&#x2F;&#x2F;正确个数统计</span><br><span class="line">	for (size_t count &#x3D; 0; count &lt; 10000; count++)</span><br><span class="line">	&#123;</span><br><span class="line">		mnet-&gt;forwardPropagation(mImg-&gt;mImgData[count].data);&#x2F;&#x2F;前向传播</span><br><span class="line">		double value &#x3D; -100;</span><br><span class="line">		int gettag &#x3D; -100;</span><br><span class="line">		for (size_t i &#x3D; 0; i &lt; 10; i++)</span><br><span class="line">		&#123;</span><br><span class="line">			if (mnet-&gt;outlayer[i].value &gt; value)</span><br><span class="line">			&#123;</span><br><span class="line">				value &#x3D; mnet-&gt;outlayer[i].value;</span><br><span class="line">				gettag &#x3D; i;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		if (mImg-&gt;mImgData[count].tag &#x3D;&#x3D; gettag)</span><br><span class="line">		&#123;</span><br><span class="line">			tagright++;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	&#x2F;&#x2F;mnet.printresual(0);&#x2F;&#x2F;信息打印</span><br><span class="line">	cout &lt;&lt; &quot;第&quot; &lt;&lt; time + 1 &lt;&lt; &quot;轮:  &quot;;</span><br><span class="line">	cout &lt;&lt; &quot;正确率为:&quot; &lt;&lt; tagright &#x2F; 10000 &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">	getImg mGetTrainImg;</span><br><span class="line">	mGetTrainImg.imgTrainDataRead(&quot;train-images.idx3-ubyte&quot;, &quot;train-labels.idx1-ubyte&quot;);</span><br><span class="line">	getImg mGetTestImg;</span><br><span class="line">	mGetTestImg.imgTrainDataRead(&quot;t10k-images.idx3-ubyte&quot;, &quot;t10k-labels.idx1-ubyte&quot;);</span><br><span class="line">	net mnet;&#x2F;&#x2F;神经网络对象</span><br><span class="line">	for (size_t j &#x3D; 0; j &lt; 10; j++)</span><br><span class="line">	&#123;</span><br><span class="line">		for (size_t i &#x3D; 0; i &lt; 60000; i++)</span><br><span class="line">		&#123;</span><br><span class="line">			mnet.forwardPropagation(mGetTrainImg.mImgData[i].data);&#x2F;&#x2F;前向传播</span><br><span class="line">			mnet.backPropagation(mGetTrainImg.mImgData[i].label);&#x2F;&#x2F;反向传播</span><br><span class="line">		&#125;</span><br><span class="line">		AccuracyRate(j,&amp;mnet, &amp;mGetTestImg);</span><br><span class="line">	&#125;</span><br><span class="line">	std::cout &lt;&lt; &quot;搞完收工!\n&quot;; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a><strong>python实现</strong></h2><p>距离C++第一个版本完成过去了有半年多了，因为入学后各种事情搞得分身乏术，剩下一点时间也用来打游戏调解了哈哈哈。<br>最近因为<strong>研究需要！！！</strong> 又开始看神经网络，因此顺便修改了C++的第一个版本，并且把python版本也做了出来。万万没想到之前写的版本有bug，调了一天才调通了，看了之前文章python代码的同志们实在是抱歉！<br>另外，虽然完美的跑通了代码（其实也就是把C++版本翻译了一下），但python的运行速度之低实在是让人想哭（这里有极大部分是本人水平不够的关系，但本人一点都不想去学怎么提高其效率，因为不需要）。因此，在这篇过后将直接取消python实现这一块，哈哈哈哈哈！那么就用该块最后一份代码送它上路吧！</p>
<h3 id="ReadData-py"><a href="#ReadData-py" class="headerlink" title="ReadData.py"></a><a href="http://readdata.py/">ReadData.py</a></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import struct</span><br><span class="line"></span><br><span class="line">def loadImageSet(filename):</span><br><span class="line">	print (&quot;load image set&quot;,filename)</span><br><span class="line">	binfile&#x3D; open(filename, &#39;rb&#39;)</span><br><span class="line">	buffers &#x3D; binfile.read()</span><br><span class="line">	head &#x3D; struct.unpack_from(&#39;&gt;IIII&#39; , buffers ,0)</span><br><span class="line">	print (&quot;head,&quot;,head)</span><br><span class="line">	offset &#x3D; struct.calcsize(&#39;&gt;IIII&#39;)</span><br><span class="line">	imgNum &#x3D; head[1]</span><br><span class="line">	width &#x3D; head[2]</span><br><span class="line">	height &#x3D; head[3]</span><br><span class="line">	#[60000]*28*28</span><br><span class="line">	bits &#x3D; imgNum * width * height</span><br><span class="line">	bitsString &#x3D; &#39;&gt;&#39; + str(bits) + &#39;B&#39; #读取定长数据段，即字符集图片总和</span><br><span class="line">	imgs &#x3D; struct.unpack_from(bitsString,buffers,offset)</span><br><span class="line">	binfile.close()</span><br><span class="line">	imgs &#x3D; np.reshape(imgs,[imgNum,1,width*height])#将字符集图片分隔为单张图片</span><br><span class="line">	print (&quot;load imgs finished&quot;)</span><br><span class="line">	return imgs</span><br><span class="line"></span><br><span class="line">def loadLabelSet(filename):</span><br><span class="line">	print (&quot;load label set&quot;,filename)</span><br><span class="line">	binfile &#x3D; open(filename, &#39;rb&#39;)</span><br><span class="line">	buffers &#x3D; binfile.read()</span><br><span class="line">	head &#x3D; struct.unpack_from(&#39;&gt;II&#39; , buffers ,0)</span><br><span class="line">	print (&quot;head,&quot;,head)</span><br><span class="line">	imgNum&#x3D;head[1]</span><br><span class="line">	offset &#x3D; struct.calcsize(&#39;&gt;II&#39;)</span><br><span class="line">	numString &#x3D; &#39;&gt;&#39;+str(imgNum)+&quot;B&quot;</span><br><span class="line">	labels &#x3D; struct.unpack_from(numString , buffers , offset)</span><br><span class="line">	binfile.close()</span><br><span class="line">	labels &#x3D; np.reshape(labels,[imgNum,1])</span><br><span class="line">	print (&#39;load label finished&#39;)</span><br><span class="line">	return labels</span><br></pre></td></tr></table></figure>
<h3 id="BPNetPy-py"><a href="#BPNetPy-py" class="headerlink" title="BPNetPy.py"></a><a href="http://bpnetpy.py/">BPNetPy.py</a></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import ReadData as rd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import math</span><br><span class="line">import random</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">IPNNUM&#x3D;784     #输入层节点数</span><br><span class="line">HDNNUM&#x3D;100    #隐含层节点数</span><br><span class="line">OPNNUM&#x3D;10     #输出层节点数</span><br><span class="line"></span><br><span class="line">class node:</span><br><span class="line">    #结点类，用以构成网络</span><br><span class="line">    def __init__(self,connectNum&#x3D;0):</span><br><span class="line">        self.value&#x3D;0 #数值，存储结点最后的状态，对应到文章示例为X1，Y1等值</span><br><span class="line">        self.W &#x3D; (2*np.random.random_sample(connectNum)-1)*0.01</span><br><span class="line"></span><br><span class="line">class net:</span><br><span class="line">    #网络类，描述神经网络的结构并实现前向传播以及后向传播</span><br><span class="line">    def __init__(self):</span><br><span class="line">        #初始化函数，用于初始化各层间节点和偏置项权重</span><br><span class="line">        #输入层结点</span><br><span class="line">        self.inlayer&#x3D;[node(HDNNUM)];</span><br><span class="line">        for obj in range(1, IPNNUM):</span><br><span class="line">            self.inlayer.append(node(HDNNUM)) </span><br><span class="line">        #隐含层结点</span><br><span class="line">        self.hidlayer&#x3D;[node(OPNNUM)];</span><br><span class="line">        for obj in range(1, HDNNUM):</span><br><span class="line">            self.hidlayer.append(node(OPNNUM))             </span><br><span class="line">        #输出层结点</span><br><span class="line">        self.outlayer&#x3D;[node(0)];</span><br><span class="line">        for obj in range(1, OPNNUM):</span><br><span class="line">            self.outlayer&#x3D;[node(0)]                 </span><br><span class="line"></span><br><span class="line">        self.yita &#x3D; 0.1                                            #学习率η</span><br><span class="line">        self.k1&#x3D;random.random()                       #输入层偏置项权重</span><br><span class="line">        self.k2&#x3D;random.random()                       #隐含层偏置项权重</span><br><span class="line">        self.Tg&#x3D;np.zeros(OPNNUM)                   #训练目标</span><br><span class="line">        self.O&#x3D;np.zeros(OPNNUM)                     #网络实际输出</span><br><span class="line"></span><br><span class="line">    def sigmoid(self,z):</span><br><span class="line">        #激活函数</span><br><span class="line">        return 1 &#x2F; (1 + math.exp(-z))</span><br><span class="line"></span><br><span class="line">    def getLoss(self):</span><br><span class="line">        #损失函数</span><br><span class="line">        loss&#x3D;0</span><br><span class="line">        for num in range(0, OPNNUM):</span><br><span class="line">            loss+&#x3D;pow(self.O[num] -self.Tg[num],2)</span><br><span class="line">        return loss&#x2F;OPNNUM</span><br><span class="line"></span><br><span class="line">    def forwardPropagation(self,input):</span><br><span class="line">        #前向传播</span><br><span class="line">        for i in range(0, IPNNUM):</span><br><span class="line">            #输入层节点赋值</span><br><span class="line">            self.inlayer[i].value &#x3D; input[i]</span><br><span class="line">        for hNNum in range(0,HDNNUM):</span><br><span class="line">             #算出隐含层结点的值</span><br><span class="line">            z &#x3D; 0</span><br><span class="line">            for iNNum in range(0,IPNNUM):</span><br><span class="line">                z+&#x3D;self.inlayer[iNNum].value*self.inlayer[iNNum].W[hNNum]</span><br><span class="line">            #加上偏置项</span><br><span class="line">            z+&#x3D; self.k1</span><br><span class="line">            self.hidlayer[hNNum].value &#x3D; self.sigmoid(z)</span><br><span class="line">        for oNNum in range(0,OPNNUM):</span><br><span class="line">            #算出输出层结点的值</span><br><span class="line">            z &#x3D; 0</span><br><span class="line">            for hNNum in range(0,HDNNUM):</span><br><span class="line">                z +&#x3D; self.hidlayer[hNNum].value* self.hidlayer[hNNum].W[oNNum]</span><br><span class="line">            z +&#x3D; self.k2</span><br><span class="line">            self.O[oNNum] &#x3D; self.sigmoid(z)</span><br><span class="line"></span><br><span class="line">    def backPropagation(self,T):</span><br><span class="line">        #反向传播，这里为了公式好看一点多写了一些变量作为中间值</span><br><span class="line">        for num in range(0, OPNNUM):</span><br><span class="line">            self.Tg[num] &#x3D; T[num]</span><br><span class="line">        for iNNum in range(0,IPNNUM):</span><br><span class="line">            #更新输入层权重</span><br><span class="line">            for hNNum in range(0,HDNNUM):</span><br><span class="line">                y &#x3D; self.hidlayer[hNNum].value</span><br><span class="line">                loss &#x3D; 0</span><br><span class="line">                for oNNum in range(0, OPNNUM):</span><br><span class="line">                    loss+&#x3D;(self.O[oNNum] - self.Tg[oNNum])*self.O[oNNum] * (1 - self.O[oNNum])*self.hidlayer[hNNum].W[oNNum]</span><br><span class="line">                self.inlayer[iNNum].W[hNNum] -&#x3D; self.yita*loss*y*(1- y)*self.inlayer[iNNum].value</span><br><span class="line">        for hNNum in range(0,HDNNUM):</span><br><span class="line">            #更新隐含层权重</span><br><span class="line">            for oNNum in range(0,OPNNUM):</span><br><span class="line">                self.hidlayer[hNNum].W[oNNum]-&#x3D; self.yita*(self.O[oNNum] - self.Tg[oNNum])*self.O[oNNum]*\</span><br><span class="line">                    (1- self.O[oNNum])*self.hidlayer[hNNum].value</span><br><span class="line"></span><br><span class="line">    def printresual(self,trainingTimes):</span><br><span class="line">        #信息打印</span><br><span class="line">        loss &#x3D; self.getLoss()</span><br><span class="line">        print(&quot;训练次数：&quot;, trainingTimes)</span><br><span class="line">        print(&quot;loss&quot;,loss)</span><br><span class="line">        for oNNum in range(0,OPNNUM):</span><br><span class="line">            print(&quot;输出&quot;,oNNum,&quot;:&quot;,self.O[oNNum])</span><br><span class="line"></span><br><span class="line">#主程序</span><br><span class="line">mnet&#x3D;net()</span><br><span class="line">imgs&#x3D;rd.loadImageSet(&quot;train-images.idx3-ubyte&quot;);</span><br><span class="line">labels&#x3D;rd.loadLabelSet(&quot;train-labels.idx1-ubyte&quot;);</span><br><span class="line">##显示图像</span><br><span class="line">#im&#x3D;np.array(input)</span><br><span class="line">#im &#x3D; im.reshape(28,28)</span><br><span class="line">#fig &#x3D; plt.figure()</span><br><span class="line">#plotwindow &#x3D; fig.add_subplot(111)</span><br><span class="line">#plt.imshow(im , cmap&#x3D;&#39;gray&#39;)</span><br><span class="line">#plt.show()</span><br><span class="line">for n in range(0,1000):</span><br><span class="line">    print(n)</span><br><span class="line">    for x in range(0,3):</span><br><span class="line">        input&#x3D;(imgs[x,:]&#x2F;255*0.99+0.01).ravel() #ravel多维转1维</span><br><span class="line">        target&#x3D;np.ones(10)*0.01</span><br><span class="line">        target[labels[x]]&#x3D;0.99</span><br><span class="line">        mnet.forwardPropagation(input)</span><br><span class="line">        mnet.backPropagation(target)</span><br><span class="line">        if (n%200&#x3D;&#x3D;0):</span><br><span class="line">            mnet.printresual(n)</span><br></pre></td></tr></table></figure>
<h2 id="pytorch的CPU实现"><a href="#pytorch的CPU实现" class="headerlink" title="pytorch的CPU实现"></a><strong>pytorch的CPU实现</strong></h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding&#x3D;utf-8</span><br><span class="line">import time</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line">import torchvision.datasets as dsets</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line"></span><br><span class="line">#网络模型</span><br><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        #定义Net的初始化函数，这个函数定义了该神经网络的基本结构</span><br><span class="line">        super(Net, self).__init__() #复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数</span><br><span class="line">        self.intohid_layer &#x3D; nn.Linear(784, 100) #定义输入层到隐含层的连结关系函数</span><br><span class="line">        self.hidtoout_layer &#x3D; nn.Linear(100, 10)#定义隐含层到输出层的连结关系函数</span><br><span class="line">    def forward(self, input):</span><br><span class="line">        #定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成</span><br><span class="line">        x &#x3D; torch.sigmoid(self.intohid_layer(input))   #输入input在输入层经过经过加权和与激活函数后到达隐含层</span><br><span class="line">        x &#x3D; torch.sigmoid(self.hidtoout_layer(x))       #类似上面</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">mnet &#x3D; Net()</span><br><span class="line">#数据集</span><br><span class="line">train_dataset &#x3D; dsets.MNIST(root &#x3D; &#39;..&#x2F;mnist&#x2F;&#39;, #选择数据的根目录</span><br><span class="line">                           train &#x3D; True, # 选择训练集</span><br><span class="line">                           transform &#x3D; transforms.ToTensor(), # 转换成tensor变量</span><br><span class="line">                           download &#x3D; False) # 不从网络上download图片</span><br><span class="line">test_dataset &#x3D; dsets.MNIST(root &#x3D; &#39;..&#x2F;mnist&#x2F;&#39;, # 选择数据的根目录</span><br><span class="line">                           train &#x3D; False, # 选择训练集</span><br><span class="line">                           transform &#x3D; transforms.ToTensor(),# 转换成tensor变量</span><br><span class="line">                           download &#x3D; False) # 不从网络上download图片</span><br><span class="line"># 加载数据</span><br><span class="line">train_loader &#x3D; torch.utils.data.DataLoader(dataset &#x3D; train_dataset, </span><br><span class="line">                                           batch_size &#x3D; 1,#每一次训练选用的数据个数</span><br><span class="line">                                           shuffle &#x3D; False)#将数据打乱</span><br><span class="line">test_loader &#x3D; torch.utils.data.DataLoader(dataset &#x3D; test_dataset,</span><br><span class="line">                                          batch_size &#x3D; 1000,#每一次训练选用的数据个数</span><br><span class="line">                                          shuffle &#x3D; False)</span><br><span class="line"></span><br><span class="line">loss_fn &#x3D; torch.nn.MSELoss()#损失函数定义，可修改</span><br><span class="line">optimizer &#x3D; torch.optim.SGD(mnet.parameters(), lr &#x3D; 0.1, momentum&#x3D;0.9)</span><br><span class="line"></span><br><span class="line">start &#x3D; time.time()</span><br><span class="line"></span><br><span class="line">for epoch in range(1):#训练次数</span><br><span class="line">    print(&#39;current epoch &#x3D; %d&#39; % epoch)</span><br><span class="line">    for i, (images, labels) in enumerate(train_loader): #利用enumerate取出一个可迭代对象的内容</span><br><span class="line">        images &#x3D; Variable(images.view(-1, 28 * 28))</span><br><span class="line">        labels &#x3D; Variable(labels)</span><br><span class="line">        labels &#x3D; torch.LongTensor(labels).view(-1,1)#将标签转为单列矩阵</span><br><span class="line">        target&#x3D; torch.zeros(1, 10).scatter_(dim &#x3D; 1, index &#x3D; labels, value &#x3D; 0.98)#将标签转为onehot形式</span><br><span class="line">        target+&#x3D;0.01</span><br><span class="line">        optimizer.zero_grad()               #清空节点值</span><br><span class="line">        outputs &#x3D; mnet(images)          #前向传播</span><br><span class="line">        loss &#x3D; loss_fn(outputs, target)  #损失计算</span><br><span class="line">        loss.backward()                         #后向传播</span><br><span class="line">        optimizer.step()                         #更新权值</span><br><span class="line">        if i % 10000 &#x3D;&#x3D; 0:</span><br><span class="line">            print(i)</span><br><span class="line">            total &#x3D; 0</span><br><span class="line">            correct &#x3D; 0.0</span><br><span class="line">            for images, labels in test_loader:</span><br><span class="line">                images &#x3D; Variable(images.view(-1, 28 * 28))</span><br><span class="line">                outputs &#x3D; mnet(images)                                        #前向传播</span><br><span class="line">                _, predicts &#x3D; torch.max(outputs.data, 1)                #返回预测结果</span><br><span class="line">                total +&#x3D; labels.size(0)</span><br><span class="line">                correct +&#x3D; (predicts &#x3D;&#x3D; labels).sum()</span><br><span class="line">            print(&#39;Accuracy &#x3D; %.2f&#39; % (100 * float(correct) &#x2F; total))</span><br><span class="line"></span><br><span class="line">end &#x3D; time.time()</span><br><span class="line">print(&#39;花费时间%.2f&#39; % (end - start))</span><br></pre></td></tr></table></figure>
<p>上面的代码在频率为3.40GHz的电脑上，训练10遍，每次都遍历一整个训练集要花费1000s左右，也就是16.7分钟左右，因全连接神经网络的过拟合问题，正确率基本到了97.5%之后就再也升不上去了。</p>
<h2 id="pytorch的GPU实现"><a href="#pytorch的GPU实现" class="headerlink" title="pytorch的GPU实现"></a><strong>pytorch的GPU实现</strong></h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coding&#x3D;utf-8</span><br><span class="line">import time</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line">import torchvision.datasets as dsets</span><br><span class="line">import torchvision.transforms as transforms</span><br><span class="line"></span><br><span class="line">#网络模型</span><br><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        #定义Net的初始化函数，这个函数定义了该神经网络的基本结构</span><br><span class="line">        super(Net, self).__init__() #复制并使用Net的父类的初始化方法，即先运行nn.Module的初始化函数</span><br><span class="line">        self.intohid_layer &#x3D; nn.Linear(784, 100) #定义输入层到隐含层的连结关系函数</span><br><span class="line">        self.hidtoout_layer &#x3D; nn.Linear(100, 10)#定义隐含层到输出层的连结关系函数</span><br><span class="line">    def forward(self, input):</span><br><span class="line">        #定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成</span><br><span class="line">        x &#x3D; torch.sigmoid(self.intohid_layer(input))   #输入input在输入层经过经过加权和与激活函数后到达隐含层</span><br><span class="line">        x &#x3D; torch.sigmoid(self.hidtoout_layer(x))       #类似上面</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">mnet &#x3D; Net().cuda()</span><br><span class="line">#数据集</span><br><span class="line">train_dataset &#x3D; dsets.MNIST(root &#x3D; &#39;..&#x2F;mnist&#x2F;&#39;, #选择数据的根目录</span><br><span class="line">                           train &#x3D; True, # 选择训练集</span><br><span class="line">                           transform &#x3D; transforms.ToTensor(), # 转换成tensor变量</span><br><span class="line">                           download &#x3D; False) # 不从网络上download图片</span><br><span class="line">test_dataset &#x3D; dsets.MNIST(root &#x3D; &#39;..&#x2F;mnist&#x2F;&#39;, # 选择数据的根目录</span><br><span class="line">                           train &#x3D; False, # 选择训练集</span><br><span class="line">                           transform &#x3D; transforms.ToTensor(),# 转换成tensor变量</span><br><span class="line">                           download &#x3D; False) # 不从网络上download图片</span><br><span class="line"># 加载数据</span><br><span class="line">train_loader &#x3D; torch.utils.data.DataLoader(dataset &#x3D; train_dataset, </span><br><span class="line">                                           batch_size &#x3D; 1,#每一次训练选用的数据个数</span><br><span class="line">                                           shuffle &#x3D; False)#将数据打乱</span><br><span class="line">test_loader &#x3D; torch.utils.data.DataLoader(dataset &#x3D; test_dataset,</span><br><span class="line">                                          batch_size &#x3D; 1000,#每一次训练选用的数据个数</span><br><span class="line">                                          shuffle &#x3D; False)</span><br><span class="line"></span><br><span class="line">loss_fn &#x3D; torch.nn.MSELoss()#损失函数定义，可修改</span><br><span class="line">optimizer &#x3D; torch.optim.SGD(mnet.parameters(), lr &#x3D; 0.1, momentum&#x3D;0.9)</span><br><span class="line"></span><br><span class="line">start &#x3D; time.time()</span><br><span class="line"></span><br><span class="line">for epoch in range(1):#训练次数</span><br><span class="line">    print(&#39;current epoch &#x3D; %d&#39; % epoch)</span><br><span class="line">    for i, (images, labels) in enumerate(train_loader): #利用enumerate取出一个可迭代对象的内容</span><br><span class="line">        images &#x3D; Variable(images.view(-1, 28 * 28).cuda())</span><br><span class="line">        labels &#x3D; Variable(labels.cuda())</span><br><span class="line">        labels &#x3D; torch.cuda.LongTensor(labels).view(-1,1)#将标签转为单列矩阵</span><br><span class="line">        target&#x3D; torch.zeros(1, 10).cuda().scatter_(dim &#x3D; 1, index &#x3D; labels, value &#x3D; 0.98)#将标签转为onehot形式</span><br><span class="line">        target+&#x3D;0.01</span><br><span class="line">        optimizer.zero_grad()               #清空节点值</span><br><span class="line">        outputs &#x3D; mnet(images)           #前向传播</span><br><span class="line">        loss &#x3D; loss_fn(outputs, target)  #损失计算</span><br><span class="line">        loss.backward()                          #后向传播</span><br><span class="line">        optimizer.step()                         #更新权值</span><br><span class="line">        if i % 10000 &#x3D;&#x3D; 0:</span><br><span class="line">            print(i)</span><br><span class="line">            total &#x3D; 0</span><br><span class="line">            correct &#x3D; 0.0</span><br><span class="line">            for images, labels in test_loader:</span><br><span class="line">                images &#x3D; Variable(images.view(-1, 28 * 28).cuda())</span><br><span class="line">                outputs &#x3D; mnet(images)                                        #前向传播</span><br><span class="line">                _, predicts &#x3D; torch.max(outputs.data, 1)                #返回预测结果</span><br><span class="line">                total +&#x3D; labels.size(0)</span><br><span class="line">                correct +&#x3D; (predicts &#x3D;&#x3D; labels.cuda()).sum()</span><br><span class="line">            print(&#39;Accuracy &#x3D; %.2f&#39; % (100 * float(correct) &#x2F; total))</span><br><span class="line"></span><br><span class="line">end &#x3D; time.time()</span><br><span class="line">print(&#39;花费时间%.2f&#39; % (end - start))</span><br></pre></td></tr></table></figure>
<p>另外写文章累人，写代码掉头发，如果觉得文章有帮助，哈哈哈</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-神经网络 -人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>琴生(jensen)不等式</title>
    <url>/post/96895f36.html</url>
    <content><![CDATA[<p>在Gan生成对抗神经网络中会用到Jensen不等式，因此做下记录。</p>
<p>Jensen不等式告诉我们：如果f是在区间[a,b]上的凸函数（就是导数一直增长的函数，或者说是导数的导数大于0的函数），<em>x</em>是随机变量，那么有：<br>$$<br>E(f(x))≥f(E(x))<br>$$<br>也就是说函数f f<em>f</em>的期望大于等于期望的函数。</p>
<p>下面来看看怎么证明，我们假设<br>$$<br>x_{1}, x_{2}, \ldots \ldots x_{n}<br>$$<br>都是区间[a,b]内的数，且<br>$$<br>x_{1} \leq x_{2} \leq, \ldots \ldots x_{n}<br>$$<br>，则上式可以写成下面这个形式：<br>$$<br>a_{1} f\left(x_{1}\right)+a_{2} f\left(x_{2}\right)+\ldots \ldots+a_{n} f\left(x_{n}\right) \geq f\left(a_{1} x_{1}+a_{2} x_{2}+\ldots \ldots+a_{n} x_{n}\right)<br>$$<br>其中<br>$$<br>\sum_{i=1}^{n} a_{i}=1 \text { 且 } a_{i}&gt;0<br>$$<br>当n = 1时，式子显然成立。</p>
<p>当n = 2时，可以构造一个式子如下：<br>$$<br>F(x)=a_{1} f\left(x_{1}\right)+\left(1-a_{1}\right) f(x)-f\left(a_{1} x_{1}+\left(1-a_{1}\right) x\right)<br>$$<br>显然<br>$$<br>F(x_{1})=a_{1} f\left(x_{1}\right)+\left(1-a_{1}\right) f(x_{1})-f\left(a_{1} x_{1}+\left(1-a_{1}\right) x_{1}\right)=0<br>$$</p>
<p>$$<br>F^{\prime}(x)=\left(1-a_{1}\right) f^{\prime}(x)-f^{\prime}\left[a_{1} x_{1}+\left(1-a_{1}\right) x\right]\left(1-a_{1}\right)<br>$$</p>
<p>$$<br>=\left(1-a_{1}\right)\left(f^{\prime}(x)-f^{\prime}\left(a_{1}\left(x_{1}-x\right)+x\right)\right.<br>$$</p>
<p>由于是凸函数，当x&gt;x1的时候，a 1 ( x 1 − x ) + x ， 故F ′ ( x ) &gt; 0 </p>
<p>等式成立。</p>
<p>假设n = k 的时候等式成立，即<br>$$<br>a_{1} f\left(x_{1}\right)+a_{2} f\left(x_{2}\right)+\ldots \ldots+a_{k} f\left(x_{k}\right) \geq f\left(a_{1} x_{1}+a_{2} x_{2}+\ldots \ldots+a_{k} x_{k}\right) \sum_{i=1}^{n} a_{i}=1 且 a_{i}&gt;0<br>$$</p>
<p>那么当n = k + 1 时，有<br>$$<br>\begin{array}{c}<br>a_{1} f\left(x_{1}\right)+a_{2} f\left(x_{2}\right)+\ldots \ldots+a_{k} f\left(x_{k}\right)+a_{k+1} f\left(x_{k+1}\right) \<br>=\left(1-a_{k+1}\right) \frac{1}{\left(1-a_{k+1}\right)}\left[a_{1} f\left(x_{1}\right)+a_{2} f\left(x_{2}\right)+\ldots \ldots+a_{k} f\left(x_{k}\right)\right]+a_{k+1} f\left(x_{k+1}\right)<br>\end{array}<br>$$<br>这里有<br>$$<br>\frac{1}{\left(1-a_{k+1}\right)} \sum_{i=1}^{n} a_{i}=1<br>$$<br>故上式<br>$$<br>\geq\left(1-a_{k+1}\right) f\left(\frac{a_{1} x_{1}+\ldots a_{k} x_{k}}{1-a_{k+1}}\right)+a_{k+1} f\left(x_{k+1}\right)<br>$$<br>刚刚好满足n = 2时的情况，有<br>$$<br>\geq f\left(a_{1} x_{1}+a_{2} x_{2}+\ldots \ldots+a_{k} x_{k}+a_{k+1} x_{k+1}\right)<br>$$<br>等式成立！而且从证明的过程我们也可以看出，等于号只有在<br>$$<br>x_{1}, x_{2}, \ldots \ldots x_{n}<br>$$<br>都相等的情况下才能取得。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>相对熵（KL散度）</title>
    <url>/post/66caae23.html</url>
    <content><![CDATA[<p>我们简单介绍了信息熵的概念，知道了信息熵可以表达数据的信息量大小，是信息处理一个非常重要的概念。</p>
<p>对于离散型随机变量，信息熵公式如下：<br>$$<br>H ( p ) = H ( X ) = \mathrm { E } _ { x \sim p ( x ) } [ - \log p ( x ) ] = -\sum_{i=1}^n  p ( x )\log p ( x )<br>$$<br>对于连续型随机变量，信息熵公式如下：<br>$$<br>H ( p ) = H ( X ) = \mathrm { E } _ { x \sim p ( x ) } [ - \log p ( x ) ] = - \int p ( x ) \log p ( x ) d x<br>$$<br>注意，我们前面在说明的时候log是以2为底的，但是一般情况下在神经网络中，默认以e为底，这样算出来的香农信息量虽然不是最小的可用于完整表示事件的比特数，但对于信息熵的含义来说是区别不大的。其实只要这个底数是大于1的，都能用来表达信息熵的大小。</p>
<p>本篇我们来看看机器学习中比较重要的一个概念—相对熵。相对熵，又被称为KL散度或信息散度，是两个概率分布间差异的非对称性度量 。在信息论中，相对熵等价于两个概率分布的信息熵的差值，若其中一个概率分布为真实分布，另一个为理论（拟合）分布，则此时相对熵等于交叉熵与真实分布的信息熵之差，表示使用理论分布拟合真实分布时产生的信息损耗 。</p>
<p>看完上面的解释，我相信你跟我开始看的时候一模一样，一脸懵逼。下面我们直接看公式，然后慢慢理解：<br>$$<br>D _ { K L } ( p | q ) = \sum _ { i = 1 } ^ { N } \left[ p \left( x _ { i } \right)\log p \left( x _ { i } \right) - p \left( x _ { i } \right)\log q \left( x _ { i } \right)\right]<br>$$<br>上面的<br>$$<br>p ( x _i)<br>$$<br>为真实事件的概率分布，<br>$$<br>q ( x _i)<br>$$<br>为理论拟合出来的该事件的概率分布。</p>
<p>因此该公式的字面上含义就是真实事件的信息熵与理论拟合的事件的香农信息量与真实事件的概率的乘积的差的累加。比较难懂的是<br>$$<br>-\sum _ { i = 1 } ^ { N } p \left( x _ { i } \right) \log q \left( x _ { i } \right)<br>$$<br>这玩意，到底是什么鬼。经过我看了又看，我发现好像很难做出含义解释，估计这东西是前人凑出来的好用的东西（以后有新的理解会更新上来）。那么退而求其次看看它有什么用吧。</p>
<p>假设理论拟合出来的事件概率分布跟真实的一模一样，那么这玩意就等于真实事件的信息熵，这一点显而易见。</p>
<p>假设拟合的不是特别好，那么这个玩意会比真实事件的信息熵大（稍后证明）。</p>
<p>也就是在理论拟合出来的事件概率分布跟真实的一模一样的时候，相对熵等于0。而拟合出来不太一样的时候，相对熵大于0。这个性质很关键，因为它正是深度学习梯度下降法需要的特性。假设神经网络拟合完美了，那么它就不再梯度下降，而不完美则因为它大于0而继续下降。</p>
<p>但它有不好的地方，就是它是不对称的。举个例子，比如随机变量X∼P取值为1,2,3时的概率分别为[0.1,0.4,0.5]，随机变量Y∼Q取值为1,2,3时的概率分别为[0.4,0.2,0.4]，则：<br>$$<br>D ( P | Q ) = 0.1 \times \log \left( \frac { 0.1 } { 0.4 } \right) + 0.4 \times \log \left( \frac { 0.4 } { 0.2 } \right) + 0.5 \times \log \left( \frac { 0.5 } { 0.4 } \right)=0.250<br>$$</p>
<p>$$<br>D ( Q | P ) = 0.4 \times \log \left( \frac { 0.4 } { 0.1 } \right) + 0.2 \times \log \left( \frac { 0.2 } { 0.4 } \right) + 0.4 \times \log \left( \frac { 0.4 } { 0.5 } \right)=0.327<br>$$</p>
<p>也就是用P来拟合Q和用Q来拟合P的相对熵居然不一样，而他们的距离是一样的。这也就是说，相对熵的大小并不跟距离有一一对应的关系。这点蛮头疼的，因为一般我们希望距离越远下降越快，而相对熵取哪个为参考在同等距离情况下下降的速度都不一样，这就非常尴尬了。</p>
<p>推导到这相信很多人会想，既然如此，那为什么现在还是很多人用相对熵衍生出来的交叉熵作为损失函数来训练神经网络而不直接用距离相关的均方差呢？<br>以下面的例子稍作解释：<br>假设神经网络的最后一层激活函数为sigmoid，它长这样：<br><img src="/../images/%E7%9B%B8%E5%AF%B9%E7%86%B5%EF%BC%88KL%E6%95%A3%E5%BA%A6%EF%BC%89/201812181413501.png" alt="在这里插入图片描述"><br>可以看到它的两头异常的平，也就是说在那些地方的导数接近于0。而反向传播是需要求导的，用了均方差损失函数之后求导结果包含y(y−1)（可参考<a href="https://aichn.cn/post/74e51a6a.html">这篇文章深度学习1—最简单的全连接神经网络</a>），这在y接近于0或者1的时候都趋于0，会导致梯度消失，网络训练不下去。但如果用相对熵衍生出来的交叉熵作为损失函数则没有这个问题。详细的分析可见<a href="https://aichn.cn/post/7c5ef9ec.html">这篇文章为什么交叉熵能作为损失函数及其弥补了平方差损失什么缺陷</a>。因此虽然相对熵的距离特性不是特别好，但总归好过直接梯度消失玩不下去，因此很多用sigmoid作为激活函数的神经网络还是选择了用相对熵衍生出来的交叉熵作为损失函数。<br>当然如果你选用的不是sigmoid激活函数，则不需要考虑这些，这个是外话了。</p>
<p>最后来证明下相对熵公式只有在<br>$$<br>p(x_i)等于q(x_i)<br>$$<br>的时候等于0，其他时候大于0。<br>要证：<br>$$<br>D _ { K L } ( p | q ) = \sum _ { i = 1 } ^ { N } \left[ p \left( x _ { i } \right)\log p \left( x _ { i } \right) - p \left( x _ { i } \right)\log q \left( x _ { i } \right)\right]\geq0<br>$$<br>即证<br>$$<br>\sum _ { i = 1 } ^ { N } p (x_ { i }) \log \ \frac { q (x_ { i }) } { p (x_ { i }) }  \leq0<br>$$<br>又<br>$$<br>\ln ( x ) \leq x - 1<br>$$<br>，当且仅当x=1时等号成立又ln(x)≤x−1，当且仅当x=1时等号成立</p>
<p>故<br>$$<br>\sum _ { i = 1 } ^ { N } p (x_ { i }) \log \ \frac { q (x_ { i }) } { p (x_ { i }) }  \leq\sum _ { i = 1 } ^ { N } p (x_ { i }) (\frac { q (x_ { i }) } { p (x_ { i }) }-1)=\sum _ { i = 1 } ^ { N } [p (x_ { i })-q (x_ { i })]=0<br>$$<br>上面式子中≤的等于号只在<br>$$<br>p (x_ { i })=q (x_ { i })<br>$$<br>时成立。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>老外做的中国汉字的网站</title>
    <url>/post/11261dbb.html</url>
    <content><![CDATA[<p><a href="http://www.chineseetymology.org/CharacterEtymology.aspx?characterInput=%E8%BB%8A&amp;submitButton1=Etymology">http://www.chineseetymology.org/CharacterEtymology.aspx?characterInput=車&amp;submitButton1=Etymology</a></p>
<p><a href="http://hanziyuan.net/">http://hanziyuan.net/</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-其他</tag>
      </tags>
  </entry>
  <entry>
    <title>蓝天官方各机型BIOS下载20161219更新</title>
    <url>/post/3a715a7a.html</url>
    <content><![CDATA[<h1 id="Index-of-CLEVO-BIOS"><a href="#Index-of-CLEVO-BIOS" class="headerlink" title="Index of /CLEVO BIOS"></a>Index of /CLEVO BIOS</h1><table>
<thead>
<tr>
<th align="left">[Name](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/?C=N;O=D)</th>
<th align="left">[Last modified](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/?C=M;O=A)</th>
<th align="left">[Size](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/?C=S;O=A)</th>
<th align="left">[Description](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/?C=D;O=A)</th>
</tr>
</thead>
<tbody><tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><a href="http://blacky.bestmail.ws/">Parent Directory</a></td>
<td align="left"></td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P6xxRx/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P6xxRx/)</td>
<td align="left">2016-04-17 11:15</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P6xxSE/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P6xxSE/)</td>
<td align="left">2016-04-17 10:13</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P6xxSG/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P6xxSG/)</td>
<td align="left">2016-04-17 10:18</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P7x0DM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P7x0DM/)</td>
<td align="left">2016-04-17 11:19</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P18xHM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P18xHM/)</td>
<td align="left">2011-12-01 19:06</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P150EM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P150EM/)</td>
<td align="left">2013-06-23 21:18</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P150HM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P150HM/)</td>
<td align="left">2012-09-14 10:59</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P150SM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P150SM/)</td>
<td align="left">2015-05-16 12:26</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P151EM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P151EM/)</td>
<td align="left">2013-06-23 22:38</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P170EM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P170EM/)</td>
<td align="left">2014-01-24 17:56</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P170HM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P170HM/)</td>
<td align="left">2012-07-04 17:01</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P170SM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P170SM/)</td>
<td align="left">2015-05-16 12:22</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P370SM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P370SM/)</td>
<td align="left">2015-07-25 11:40</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P570WM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P570WM/)</td>
<td align="left">2014-10-04 17:31</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P750ZM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P750ZM/)</td>
<td align="left">2015-09-19 11:24</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P770ZM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P770ZM/)</td>
<td align="left">2015-09-19 11:27</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P775DM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P775DM/)</td>
<td align="left">2016-04-17 11:18</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[P870DM/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/P870DM/)</td>
<td align="left">2016-04-17 10:37</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[W1xER/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/W1xER/)</td>
<td align="left">2013-12-18 10:49</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[W35xST/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/W35xST/)</td>
<td align="left">2014-01-31 14:37</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[W110ER/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/W110ER/)</td>
<td align="left">2013-12-18 10:41</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[W230SS/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/W230SS/)</td>
<td align="left">2015-05-16 12:37</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[W230ST/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/W230ST/)</td>
<td align="left">2014-10-04 18:05</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">[other/](<a href="http://blacky.bestmail.ws/CLEVO">http://blacky.bestmail.ws/CLEVO</a> BIOS/other/)</td>
<td align="left">2015-07-17 22:43</td>
<td align="left">-</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
<p><a href="https://repo.palkeo.com/clevo-mirror/">https://repo.palkeo.com/clevo-mirror/</a></p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-其他</tag>
      </tags>
  </entry>
  <entry>
    <title>西部数据 NAS 红盘 WD20EFRX 假货识别</title>
    <url>/post/36149d23.html</url>
    <content><![CDATA[<p>电脑外设鱼龙混杂，尤其像网上购买硬件，很多不懂得消费者很容易被JS得小伎俩欺骗。下面介绍简单的购买技巧来识别买到的硬盘是否为假货。</p>
<p>西部数据红盘和黑盘的价格比普通绿盘高出近三分之一。某些无良商家便用绿盘来以次充好。欺骗消费者。西部数据官网查询保修只是凭借序列号，而这个序列号的标签纸很容易就可以伪造出来。卖家只要准备一批在质保内的序列号，就可以瞒天过海。</p>
<p>惯用伎俩大致有3条：</p>
<p>1.更换正面标签，将绿盘的标签换成红盘或黑盘；</p>
<p>2.谎称水货或散装，保修只给店铺保修，不支持全国联保，而从官网查到的保修期都不足三年；</p>
<p>3.将绿盘固件刷成红盘或黑盘，重置S.M.A.R.T参数，这样即使用专业软件如HDTune等也无法立即识别；</p>
<h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><ol>
<li><p>1</p>
<p>以下图示，左边为真货，右边为假货</p>
<p>1.真盘的外形突出部分与假盘完全不同。</p>
<p>2.真盘的黑色螺丝孔的布局也与假盘不一致。</p>
<p>![西部数据 NAS 红盘 WD20EFRX 假货识别](../images/西部数据 NAS 红盘 WD20EFRX 假货识别/586bfdefe0781431ecc14dd8dc6699cf035362cf.jpg)</p>
</li>
<li><p>2</p>
<p>以下图示，左边为真货，右边为假货</p>
<p>1.真盘的马达部分有胶水，假盘没有</p>
<p>2.真盘的PCBA码为二维码，而假盘则为条形码</p>
<p>3.PCB布线外观等不同。商家会以硬盘生产批次不同来误导买家。而作为一个合格的硬件生产厂商，电路板对于产品来说是至关重要的。不可能因为生产批次的而导致电路板完全不一致。就如一瓶饮料，不会因为生产批次不同而直接把原料给换掉，最多换换包装。除非是这饮料有问题，这是重大生产事故。而这类事故通常百度新闻等都会有报道。</p>
<p>4.接口形状不一致</p>
<p>![西部数据 NAS 红盘 WD20EFRX 假货识别](../images/西部数据 NAS 红盘 WD20EFRX 假货识别/2e223d85e036e2917b9f4c54b2723d03baea5bcf.jpg)</p>
</li>
<li><p>3</p>
<p>另外，有些商家会将硬盘S.M.A.R.T中通电次数刷为零，标榜为全新未使用。</p>
<p>而电子产品在出厂时都会经过质检，在质检过程中需要通电测试。因此，标榜0通电的必然是刷固件刷出来的。</p>
<p>而绿盘大都只有5400RPM，性能比红盘和黑盘相差很多。因此使用专业软件也可以比较出真货与假货的区别。</p>
</li>
<li><p>4</p>
<p>当然，这些只是简单地识别方法。最根本的是不要贪便宜，价格比正品差距很大，那肯定有猫腻。</p>
</li>
<li><p>5</p>
<p>2014.06.15 add</p>
<p>感谢 zxslovers 的经验分享</p>
</li>
</ol>
<p>   我还要补充一点，让造假无所遁形<strong><a href="https://westerndigital.secure.force.com/ind/ID_ProductsRegistered">https://westerndigital.secure.force.com/ind/ID_ProductsRegistered</a></strong>这个是西部数据官网的注册连接，极其难找，一般买家把硬盘买来后只根据硬盘的编号去查询下保修时间，一看保修时间对就认为是正品，这是不对的，因为每个硬盘编号，它对应的还有电路板编号，而这个连接是注册官方保修的连接，只有同时填写硬盘编号和电路板编号才能把硬盘注册的，如果你能注册成功，那么你的硬盘才享受保修服务，是正版的了！</p>
<p>   难点在如何找电路板编号，大家看硬盘后面的电路板，有个非常小的二维码块，从上面读取</p>
<pre><code>电路板序列号为：XSBW821NHF200011801也就是下面划线的部分的字母和数字把硬盘编号S/N后面的一组字母数字如：WMC1T4306300 和这个电路板编号XSBW821NHF200011801一起注册，只有成功了才说明你的硬盘的编号和电路板编号是对的！！这个绝对让假硬盘无所遁形！其他一切皆为浮云</code></pre>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>英国广播公司：《人类星球 第一季》(BBC Human Planet Season 1)【YYeTs人人影视出品】【中英双语字幕】【更新番外篇III】【完结】【BDRip】</title>
    <url>/post/e9b1e83d.html</url>
    <content><![CDATA[<p><a href="http://www.ed2000.com/ShowFile/250303.html">http://www.ed2000.com/ShowFile/250303.html</a> </p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.Human.Planet.S01E01.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|733350684|71ba1fbf1a5ff5d536e33b50310620c6|h=zmfa2fgth6udm4kjckjr6lbzzz7f6uvn|/">人类星球.Human.Planet.S01E01.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>699.38 MB</td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.Human.Planet.S01E02.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|733204896|973e503a87128d16366608ae882bbbfe|/">人类星球.Human.Planet.S01E02.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>699.24 MB</td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.Human.Planet.S01E03.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|733417791|f9decbb04c2cf3204f86d5b6b29b41bd|/">人类星球.Human.Planet.S01E03.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>699.44 MB</td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.Human.Planet.S01E04.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|732792914|9ad5d6528ba68db778dd57e94dfd3160|/">人类星球.Human.Planet.S01E04.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>698.85 MB</td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.Human.Planet.S01E05.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|732790791|aa4271a0d52ab560446f448e9556ac13|/">人类星球.Human.Planet.S01E05.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>698.84 MB</td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.Human.Planet.S01E06.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|732563535|4ccae7973262bcca6e64ab28c1105a32|/">人类星球.Human.Planet.S01E06.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>698.63 MB</td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.Human.Planet.S01E07.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|732735197|5c60d64595b8237bd3cefb9c878c1418|/">人类星球.Human.Planet.S01E07.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>698.79 MB</td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.Human.Planet.S01E08.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|733064183|84778ea88dd75856b8e26932e9811ac4|/">人类星球.Human.Planet.S01E08.Chi_Eng.BDRip.AC3.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>699.10 MB</td>
</tr>
<tr>
<td><a href="http://ed2k//|file|%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83.%E7%95%AA%E5%A4%96%E7%AF%87.Human.Planet.Extra.3.Chi_Eng.WEBRip.1024X576.x264-YYeTs%E4%BA%BA%E4%BA%BA%E5%BD%B1%E8%A7%86(ED2000.COM).mkv|243302285|45fea0c54d42772300a2f5f867511f7d|/">人类星球.番外篇.Human.Planet.Extra.3.Chi_Eng.WEBRip.1024X576.x264-YYeTs人人影视.mkv</a></td>
<td>232.03 MB</td>
</tr>
</tbody></table>
<p> <strong>中文名</strong>: 英国广播公司：人类星球 第一季</p>
<p><strong>英文名</strong>: BBC: Human Planet Season 1</p>
<p><strong>资源格式</strong>: BDRip</p>
<p><strong>版本</strong>: [YYeTs人人影视出品][中英双语字幕][更新番外篇III][完结]</p>
<p><strong>发行时间</strong>: 2011年01月03日</p>
<p><strong>制作发行</strong>: 英国广播公司</p>
<p><strong>地区</strong>: 英国</p>
<p><strong>语言</strong>: 英语</p>
<p><strong>简介</strong>:</p>
<p> <img src="/../images/%E8%8B%B1%E5%9B%BD%E5%B9%BF%E6%92%AD%E5%85%AC%E5%8F%B8%E4%BA%BA%E7%B1%BB%E6%98%9F%E7%90%83%E7%AC%AC%E4%B8%80%E5%AD%A3/thumb.jpg" alt="img"></p>
<p>【类型】: 科教 【影片长度】: 60 Minutes 【集数】: 8集 【字幕】: 无 【服务器】: 随机 【分享时间】: 全天</p>
<blockquote>
<p><strong>多版本下载：</strong><a href="http://yyets.com/showresource-juji-793.html">http://yyets.com/showresource-juji-793.html</a></p>
</blockquote>
<p>【内容介绍】： BBC8集大型电视系列片 - Human Planet （人类星球），探讨人与自然的关系。8集节目分别探讨极地、山区、海洋、丛林、草原、河流、沙漠和城市的人类活动。世界一流的自然与人类专家以及摄影师，从空中、陆地和水下抓拍珍贵镜头。BBC摄制组前往世界80个地方，抓拍了从未在电视屏幕上出现过的罕见精彩的人类活动。 Human Planet is is narrated by John Hurt and also features original music by composer Nitin Sawhney. The series looks at how human beings have been the only animals that have been able to adapt to life in every habitat on Earth. The series looks at man’s ability to survive in the most extreme environments on the planet. </p>
]]></content>
      <categories>
        <category>电影</category>
      </categories>
      <tags>
        <tag>-电影</tag>
      </tags>
  </entry>
  <entry>
    <title>进远景论坛方法</title>
    <url>/post/edb70a23.html</url>
    <content><![CDATA[<p>修改hosts<br>218.93.127.136 pcbeta.com<br>218.93.127.136 uc.pcbeta.com<br>218.93.127.136 m.pcbeta.com<br>218.93.127.136 web.pcbeta.com<br>218.93.127.136 i.pcbeta.com<br>218.93.127.136 bbs.pcbeta.com<br>218.93.127.136 <a href="http://jump.bdimg.com/safecheck/index?url=x+Z5mMbGPAu6psTyi+uBNSwM5kbsgXOExclEQBwqCNr7LAYdITHoVOgaj8AbWjZRMVJWer8MmNrc99WDfAa0fDx0jpvVAOecZVybKVEXRvGgj6bhyjG6iHY9qHh6BM0y">http://www.pcbeta.com</a><br>218.93.127.136 cdn.pcbeta.attachment.inimc.com<br>218.93.127.136 cdn.pcbeta.static.inimc.com<br>218.93.127.136 cdn.pcbeta.css.inimc.com<br>218.93.127.136 static.template.pcbeta.com</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-其他</tag>
      </tags>
  </entry>
  <entry>
    <title>迪优美特rk3128刷机时“测试设备失败”或“低格失败”解决办法</title>
    <url>/post/ee993d94.html</url>
    <content><![CDATA[<p><strong>此解决方法同样适用于芯片为Rk3128的**</strong>其它**<strong>型号的**</strong>机顶**<strong>盒</strong></p>
<p>首先要准备以下三款软件： 1.瑞芯微驱动 2.AndroidTool_Release_v2.33 刷机工具 3.RK3128_固件</p>
<p>先装瑞芯微驱动，然后打开AndroidTool_Release_v2.33，再点“固件”找到准备刷入的RK3128_固件，盒子按住复位键插上usb线，等显示“发现一个LOADER没备”后松开复位键。点<strong>“下载镜像”</strong>再点<strong>低格</strong>，<strong>这时**</strong>低格会停留在**<strong>0%没反应，拔出usb**</strong>插头，然后迅速插入，等重新显示“发现一个LOADER设备”后再点**<strong>就可以正常**</strong>低格了。<strong>低格完成后点击“</strong>升级固件<strong>”回到升级操作界面，先点“</strong>擦除flash<strong>”后再点</strong>升级**，固件便开始刷入<a href="http://www.hdpfans.com/">机顶盒</a>，等校验完成后就成功了。</p>
<p><strong>迪优X16 等盒子刷过带lock固件问题说明：</strong></p>
<p><strong>正常情况下只要是瑞芯微RK3128芯片，刷其它版本的Rk3128固件同样可以随便刷。但是一旦刷过带lock加密底包的固件如 RK3128_DYMT_LOCK2.3_YUNOS2.2.1或RK3128_ZX_android_lock_等等之后 就不能再刷入其它版本固件了。</strong></p>
<p><strong>想要刷其它版本的固件，用以上方法就可以正常刷入了，也无需先刷入原厂固件包擦除flash 后再进行刷机。</strong></p>
<p>AndroidTool_Release_v2.33 刷机工具</p>
<h4 id="本帖隐藏的内容"><a href="#本帖隐藏的内容" class="headerlink" title="本帖隐藏的内容"></a>本帖隐藏的内容</h4><p>链接: <a href="http://pan.baidu.com/s/1o83yfYM">http://pan.baidu.com/s/1o83yfYM</a> 密码: xkwz</p>
<p>安卓Rk3128通用版(沙发桌面)</p>
<h4 id="本帖隐藏的内容-1"><a href="#本帖隐藏的内容-1" class="headerlink" title="本帖隐藏的内容"></a>本帖隐藏的内容</h4><p>链接: <a href="http://pan.baidu.com/s/1bp3eBGN">http://pan.baidu.com/s/1bp3eBGN</a> 密码: fm6c</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>通过广域网(Intelnet)进行远程唤醒[或开机] 图解</title>
    <url>/post/c004a920.html</url>
    <content><![CDATA[<p>WAN远程唤醒与LAN远程唤醒有着诸多不同，WAN远程唤醒首先需要主板、网卡等硬件的支持，需要一条有效的Intelnet连接，与Lan远程唤醒不同的是，WAN远程唤醒需要经过路由器，因此下面我就来详细讲解如何在路由器上进行设置，以支持WAN远程唤醒，前提是，你已经成功进行了LAN远程唤醒。</p>
<p><strong>一、WOL（远程唤醒）工具介绍</strong></p>
<p>实现远程唤醒的软件有很多，原理都是相同的。下面列出几款常用的WOL软件：</p>
<p>■ LanHelper</p>
<p>■ Magic Packet Utility</p>
<p>■ NetWaker for windows</p>
<p>■ WakeOnLanGui（<a href="http://www.depicus.com/">http://www.depicus.com</a>）</p>
<p><strong>二、准备</strong></p>
<p>WAN与LAN在不同在于在广域网上，有许多的路由器等网络设备，这些设备可能会使Magic Packet的包不能到达我们想唤醒的电脑网卡上。因此，要实现通过internet来唤醒，必须得到路由器的支持。下面就以我的TP-Link WR841N无线路由为例来说明配置过程。</p>
<p>首先确保路由器可以正常接入internet，即通过服务商得到一个公网IP（对于家庭来说ADSL、Cable Modem是常见的上网方式），进入路由器WEB配置页面<a href="http://192.168.1.1/">http://192.168.1.1。</a></p>
<p><strong>三、端口映射（虚拟服务器）</strong></p>
<p>依次点击“转发规则”-&gt;“虚拟服务器”，添加一新条目，端口为2301（2301是默认的端口号，也可以是其它端口号，只要不和其它的冲突），IP地址为需要唤醒电脑网卡所使用的IP地址（比如192.168.1.250），协议为UDP，并使之处于“生效”状态。</p>
<p><img src="/../images/%E9%80%9A%E8%BF%87%E5%B9%BF%E5%9F%9F%E7%BD%91(Intelnet" alt="img">进行远程唤醒[或开机] 图解/20150122153904700)</p>
<p>这一步使得当路由器收到发到它2301端口的数据都会转发到IP地址为192.168.1.250的这台电脑上。</p>
<p><strong>四、IP地址与MAC地址之间的绑定</strong></p>
<p>依次点击“IP与MAC绑定”-&gt;“静态ARP绑定设置”，添加一新条目，MAC地址添为网卡（被唤醒电脑上的）MAC，如50-E5-60-CA-1A-4A，IP为上一步设置的IP地址：192.168.1.250。</p>
<p><img src="/../images/%E9%80%9A%E8%BF%87%E5%B9%BF%E5%9F%9F%E7%BD%91(Intelnet" alt="img">进行远程唤醒[或开机] 图解/20150122154246829)</p>
<p>注意：记住要启用路由器的“ARP绑定”功能（图片中的红圈部分），不然此步的设置是不生效的。</p>
<p>当路由器收到从internet发往2301端口的Magic Packet包时，由于设了端口映射，路由器就直接将该Magic Packet包转发到192.168.1.250上。但是由于电脑是处理关机状态，ARP无法通过广播找到192.168.1.250这台电脑，Magic Packet包将被路由器丢弃，因此进行静态的IP-MAC绑定，使数据包可以直接发往MAC地址为50-E5-60-CA-1A-4A的网卡上。</p>
<p>此时，从理论上来说，通过internet的远程唤醒就可以成功了。但是，如果远程主机没有配置静态IP地址，而是通过DHCP方式获取动态IP地址的，那么还有一些工作需要做，以确保万无一失。</p>
<p><strong>五、静态IP地址分配</strong></p>
<p>大家都清楚，DHCP租约协议是有有效期的，TP-Link上的DHCP租约有效期默认是2小时，为了确保远程电脑在启动后可以获得192.168.1.250这个IP地址，需要在DHCP服务器中设置一个静态地址分配，即为MAC地址50-E5-60-CA-1A-4A静态分配192.168.1.250这个IP地址，而且永不过期。</p>
<p><img src="/../images/%E9%80%9A%E8%BF%87%E5%B9%BF%E5%9F%9F%E7%BD%91(Intelnet" alt="img">进行远程唤醒[或开机] 图解/20150122154757301)</p>
<p><strong>六、使用动态DNS功能</strong></p>
<p>在路由器上使用动态DNS功能，这样可以用一个域名来访问而不用查看经常改变的公网IP（ADSL拨号上网的IP是经常变的）。同时，允许路由器可以进行无端WEB管理，以方便当我们在任何地方都可以检查路由器的状态。</p>
<p>说到DDNS，不得不提到大名鼎鼎的花生壳了，TP-LINK路由器默认就内嵌了动态DNS功能，只需要到花生壳的官网注册一个护照，并申请一个免费域名，然后在路由器上登录。登录成功后，会看到域名，这样花生壳就将域名和路由器上的公网IP地址绑定在一起了。</p>
<p><img src="/../images/%E9%80%9A%E8%BF%87%E5%B9%BF%E5%9F%9F%E7%BD%91(Intelnet" alt="img">进行远程唤醒[或开机] 图解/20150122154957702)</p>
<p><strong>七、使用第三方工具进行远程唤醒</strong></p>
<p>访问<a href="http://www.depicus.com/wake-on-lan/woli.aspx%E8%BF%99%E4%B8%AA%E9%A1%B5%E9%9D%A2%EF%BC%8C%E8%BF%99%E6%98%AFdepicus%E6%8F%90%E4%BE%9B%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9C%A8%E7%BA%BF%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%94%A4%E9%86%92%E5%B7%A5%E5%85%B7%E9%A1%B5%E9%9D%A2%EF%BC%8C%E4%BD%BF%E7%94%A8%E8%B5%B7%E6%9D%A5%E5%BE%88%E6%96%B9%E4%BE%BF%E3%80%82%E5%B7%A5%E4%BD%9C%E7%95%8C%E9%9D%A2%E5%A6%82%E4%B8%8B%EF%BC%9A">http://www.depicus.com/wake-on-lan/woli.aspx这个页面，这是depicus提供的一个在线的远程唤醒工具页面，使用起来很方便。工作界面如下：</a></p>
<p><img src="/../images/%E9%80%9A%E8%BF%87%E5%B9%BF%E5%9F%9F%E7%BD%91(Intelnet" alt="img">进行远程唤醒[或开机] 图解/20150122155050140)</p>
<p>下面就进行远程唤醒的四个参数作下说明：</p>
<ul>
<li><strong>Your Network Cards Mac Address：</strong>（内部局域网）远程主机的网卡MAC地址，不是路由器的MAC地址。[一开始我这里搞错了，填的是路由器的MAC地址，怎么也不能远程唤醒]</li>
<li><strong>Any Computers Ip Number or FQDN：</strong>路由器获取到的公网IP地址或使用花生壳DDNS进行绑定的合法域名。这里最好使用DDNS功能绑定一个域名，因为域名是不变的，而你不清楚你的路由器什么时候会重新从ISP服务商那里获取公网IP地址。但如果使用了DDNS，即使路由器的IP地址变了，会自动更新到花生壳服务器上。</li>
<li><strong>Your Subnet Mask：</strong>子网掩码。这个很重要，因为路由器是动态地从ISP服务商那里获取IP地址的，你根本不知道该IP地址所对应的子网掩码，所以索性就填写255.255.255.255，这表示是唯一一个IP地址，而不是一个网段。</li>
<li><strong>Any Port Number：</strong>网络端口，路由器会一直侦听该网络端口，一旦侦测到有数据包发往该端口，就进行转发。</li>
</ul>
<p>经过上述配置，我已经通过Internet成功远程唤醒了我的服务器。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>-技术</tag>
      </tags>
  </entry>
  <entry>
    <title>重做红楼梦的数据分析-判断前80回后40回是否一个人写的</title>
    <url>/post/56293a93.html</url>
    <content><![CDATA[<h1 id="重做红楼梦的数据分析-判断前80回后40回是否一个人写的"><a href="#重做红楼梦的数据分析-判断前80回后40回是否一个人写的" class="headerlink" title="重做红楼梦的数据分析-判断前80回后40回是否一个人写的"></a>重做红楼梦的数据分析-判断前80回后40回是否一个人写的</h1><p>红楼梦的数据分析已经有许多人做过，结论也各不相同。<br>我在知乎上看到两篇帖子：<br>\1. [通过数据挖掘能分析《红楼梦》各回的真伪吗？](<a href="https://www.zhihu.com/question/19768898">https://www.zhihu.com/question/19768898</a> 智慧思特的回答)<br>\2. <a href="https://zhuanlan.zhihu.com/p/21421723">用机器学习判定红楼梦后40回是否曹雪芹所写</a><br>觉得很有意思，于是用自己的方法重做了一次</p>
<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置:"></a>环境配置:</h2><p>我主要使用的编程环境是Jupyter Notebook 4.2.1，因为可以调整每一个代码块，方便<br>纠错什么的。<br>然后我们得用到一个中文分词工具 - Jieba, 是由百度工程师Sun Junyi开发的<br>之后我们还得用到一些做机器学习/数据挖掘的标准包：numpy, matplotlib 和 sklearn</p>
<h2 id="数据准备："><a href="#数据准备：" class="headerlink" title="数据准备："></a>数据准备：</h2><p>用爬虫思想，我去这个网站扒下来红楼梦全集，然后剪掉中间所有的换行符，使得每一回只<br>占文档中的一行。这样的话，方便接下来读取。</p>
<p>直接上代码：<br>一、导入各种需要的包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*-coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="keyword">as</span> bs</span><br><span class="line"></span><br><span class="line">book = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">120</span>):</span><br><span class="line">    print(<span class="string">&quot;处理第&#123;&#125;回...&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> i+<span class="number">1</span>&lt;<span class="number">10</span>:</span><br><span class="line">        url = <span class="string">&quot;http://www.purepen.com/hlm/00&#123;&#125;.htm&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">elif</span> i+<span class="number">1</span> &lt; <span class="number">100</span>:</span><br><span class="line">        url = <span class="string">&quot;http://www.purepen.com/hlm/0&#123;&#125;.htm&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        url = <span class="string">&quot;http://www.purepen.com/hlm/&#123;&#125;.htm&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>)</span><br><span class="line">    request = urllib2.Request(url)</span><br><span class="line">    response = urllib2.urlopen(request)</span><br><span class="line">    bsObj = bs(response.read().decode(<span class="string">&#x27;gb18030&#x27;</span>)) <span class="comment">#注意原网页的codec是哪一种</span></span><br><span class="line">    chapter = bsObj.table.font.contents[<span class="number">0</span>]</span><br><span class="line">    book.append(chapter)<span class="number">123456789101112131415161718192021</span></span><br></pre></td></tr></table></figure>
<p>下面是结果：<br><img src="/../images/%E9%87%8D%E5%81%9A%E7%BA%A2%E6%A5%BC%E6%A2%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%88%A4%E6%96%AD%E5%89%8D80%E5%9B%9E%E5%90%8E40%E5%9B%9E%E6%98%AF%E5%90%A6%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%86%99%E7%9A%84/20160729160447659" alt="这里写图片描述"></p>
<p><img src="/../images/%E9%87%8D%E5%81%9A%E7%BA%A2%E6%A5%BC%E6%A2%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%88%A4%E6%96%AD%E5%89%8D80%E5%9B%9E%E5%90%8E40%E5%9B%9E%E6%98%AF%E5%90%A6%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%86%99%E7%9A%84/20160729160602300" alt="这里写图片描述"></p>
<p>之后把全文存进一个txt文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;红楼梦.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    f.write(codecs.BOM_UTF8)  </span><br><span class="line">    <span class="keyword">for</span> chap <span class="keyword">in</span> book:</span><br><span class="line">        s = chap.encode(<span class="string">&#x27;utf-8&#x27;</span>).strip()</span><br><span class="line">        f.write(<span class="string">&quot;&quot;</span>.join(s.split()))</span><br><span class="line">        f.write(<span class="string">&#x27;\n&#x27;</span>)<span class="number">123456</span></span><br></pre></td></tr></table></figure>
<p>数据ready，可以开始进行处理了</p>
<h2 id="处理"><a href="#处理" class="headerlink" title="处理:"></a>处理:</h2><p>直接上代码：<br><strong>一、导入各种需要的包</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D <span class="comment"># 因为后面会用到3d作图</span></span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="comment"># 下面是机器学习包</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split </span><br><span class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="comment"># Jieba</span></span><br><span class="line"><span class="keyword">import</span> jieba123456789101112</span><br></pre></td></tr></table></figure>
<p><strong>二、读取文件并分词</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;红楼梦.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line"> all_chaps = [chap.decode(<span class="string">&#x27;utf8&#x27;</span>) <span class="keyword">for</span> chap <span class="keyword">in</span> f.readlines()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给整本书分词</span></span><br><span class="line">dictionary = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">120</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;处理第&#123;&#125;回&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>)</span><br><span class="line">    words = <span class="built_in">list</span>(jieba.cut(all_chaps[i]))</span><br><span class="line">    dictionary.append(words)<span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<p><strong>三、Flatten数组</strong> （中文是’摊平’? 哈哈）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tmp = [item <span class="keyword">for</span> sublist <span class="keyword">in</span> dictionary <span class="keyword">for</span> item <span class="keyword">in</span> sublist] <span class="comment"># 摊平</span></span><br><span class="line">dictionary = tmp12</span><br></pre></td></tr></table></figure>
<p><strong>四、 给每一回贴上标签</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给每一回贴上标签</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">120</span>):</span><br><span class="line">    <span class="keyword">if</span> i &lt; <span class="number">80</span>:</span><br><span class="line">        all_chaps[i] = [all_chaps[i],<span class="string">&#x27;1&#x27;</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        all_chaps[i] = [all_chaps[i],<span class="string">&#x27;0&#x27;</span>]</span><br><span class="line"></span><br><span class="line">content = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> all_chaps]</span><br><span class="line">label = [row[<span class="number">1</span>] <span class="keyword">for</span> row <span class="keyword">in</span> all_chaps]<span class="number">123456789</span></span><br></pre></td></tr></table></figure>
<p><strong>五、找出每一回均出现的词</strong><br>之所以要这么做，是因为有一些很常出现的角色名在后四十回因为剧情原因不再出现了。在整个分析中我们注重对于文言虚词和其他连接词的分析，因为这样更能体现出写作者的个人风格。另外，这也是为什么我们没有在Jieba里加入角色名称的字典，因为没有这个必要。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 找出每一回均有出现的词</span></span><br><span class="line"><span class="keyword">from</span> progressbar <span class="keyword">import</span> ProgressBar <span class="comment"># 显示进度</span></span><br><span class="line">pbar =ProgressBar()</span><br><span class="line"></span><br><span class="line">wordineverychap = []</span><br><span class="line">length = <span class="built_in">len</span>(dictionary)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;共有&#123;&#125;个词&quot;</span>.<span class="built_in">format</span>(length)</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> pbar(dictionary):</span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> content:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> text:</span><br><span class="line">            n+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> n==<span class="number">120</span>:</span><br><span class="line">        wordineverychap.append(word)<span class="number">1234567891011121314</span></span><br></pre></td></tr></table></figure>
<p><strong>六、合并虚词，以防虚词被过滤掉</strong><br>这里用的虚词是直接从维基百科上抄下来的，一共20个左右，所以也并不麻烦。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;xuci.txt&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    xuci = [word.decode(<span class="string">&#x27;utf8&#x27;</span>).strip() <span class="keyword">for</span> word <span class="keyword">in</span> f.readlines()]</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> xuci:</span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> wordineverychap:</span><br><span class="line">        wordineverychap.append(word)<span class="number">12345</span></span><br></pre></td></tr></table></figure>
<p><strong>七、过滤重复的词语，并去掉标点符号</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">selected_words = <span class="built_in">list</span>(<span class="built_in">set</span>(wordineverychap))</span><br><span class="line"><span class="comment"># 人工处理, 删除标点符号</span></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> selected_words:</span><br><span class="line">    <span class="built_in">print</span> w1234</span><br></pre></td></tr></table></figure>
<p>计算结果是一共有125个词语</p>
<p><strong>八、给每个词语计数 并 排序</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">wordT = []</span><br><span class="line">countT = []</span><br><span class="line">table = &#123;&#125;</span><br><span class="line"></span><br><span class="line">chapNo = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> chap <span class="keyword">in</span> content:</span><br><span class="line">    sub_table = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> uw:</span><br><span class="line">        sub_table[word.decode(<span class="string">&#x27;utf8&#x27;</span>)] = chap.count(word.decode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">    table[chapNo] = sub_table</span><br><span class="line">    chapNo+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line">table_sorted = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> table:</span><br><span class="line">    sub_table_sorted = <span class="built_in">sorted</span>(table[idx].items(),key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="literal">True</span>)</span><br><span class="line">    table_sorted.append(sub_table_sorted)<span class="number">123456789101112131415161718</span></span><br></pre></td></tr></table></figure>
<p><strong>九、把数据存在csv里，以免不小心关掉程序后不用重新计算</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 任务：把数据存到csv里</span></span><br><span class="line"><span class="keyword">import</span> unicodecsv <span class="keyword">as</span> csv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入第一行和第一列</span></span><br><span class="line">f1 = <span class="built_in">open</span>(<span class="string">&#x27;cipin.csv&#x27;</span>, <span class="string">&#x27;w+&#x27;</span>)</span><br><span class="line">writer = csv.writer(f1, encoding=<span class="string">&#x27;utf8&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">first_row = [<span class="string">&#x27;&#x27;</span>]  <span class="comment"># A1留空</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">120</span>):</span><br><span class="line">    first_row.append(<span class="string">&#x27;第&#123;&#125;回&#x27;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>))</span><br><span class="line">writer.writerow(first_row)   </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> selected_words:</span><br><span class="line">    row = [word]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">120</span>):</span><br><span class="line">        row.append(table[i+<span class="number">1</span>][word.decode(<span class="string">&#x27;utf8&#x27;</span>)])</span><br><span class="line">    writer.writerow(row)</span><br><span class="line"></span><br><span class="line">f1.close()<span class="number">12345678910111213141516171819</span></span><br></pre></td></tr></table></figure>
<p><strong>十、把数据向量化</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 任务：把数据向量化 </span></span><br><span class="line"></span><br><span class="line">all_vectors = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">120</span>):</span><br><span class="line">    chap_vector = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> selected_words:</span><br><span class="line">        chap_vector.append(table[i+<span class="number">1</span>][word.decode(<span class="string">&#x27;utf8&#x27;</span>)])</span><br><span class="line">    all_vectors.append(chap_vector)</span><br><span class="line"><span class="number">12345678910</span></span><br></pre></td></tr></table></figure>
<p><strong>十一、把高维向量压缩为3维向量，方便作图</strong><br>这里我们使用PCA(Principal Component Analysis)，就是一种把高维度向量变成低维度向量的算法。比如我们现在每一回就有125维，无法作图。这个算法，像它的名字一样，会采集最重要的向量，然后压缩成到我们所需要的维数（3维）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#设置PCA的目标维数并创建一个model</span></span><br><span class="line">pca = PCA(n_components=<span class="number">3</span>)</span><br><span class="line"><span class="comment">#Feed我们的向量，进行训练</span></span><br><span class="line">pca.fit(all_vectors)</span><br><span class="line"><span class="comment">#取得目标向量</span></span><br><span class="line">z = pca.fit_transform(all_vectors)</span><br><span class="line"><span class="comment">#取得前八十回的向量</span></span><br><span class="line">xs_a = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[:<span class="number">80</span>]]</span><br><span class="line">ys_a = [row[<span class="number">1</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[:<span class="number">80</span>]]</span><br><span class="line">zs_a = [row[<span class="number">2</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[:<span class="number">80</span>]]</span><br><span class="line"><span class="comment">#取得后四十回的向量</span></span><br><span class="line">xs_b = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[-<span class="number">40</span>:]]</span><br><span class="line">ys_b = [row[<span class="number">1</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[-<span class="number">40</span>:]]</span><br><span class="line">zs_b = [row[<span class="number">2</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[-<span class="number">40</span>:]]</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个新的图表</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"><span class="comment">#绘图</span></span><br><span class="line">ax.scatter(xs_a, ys_a, zs_a, c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax.scatter(xs_b, ys_b, zs_b, c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.show()<span class="number">12345678910111213141516171819202122</span></span><br></pre></td></tr></table></figure>
<p>这就是绘制出来的图表：<br><img src="/../images/%E9%87%8D%E5%81%9A%E7%BA%A2%E6%A5%BC%E6%A2%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%88%A4%E6%96%AD%E5%89%8D80%E5%9B%9E%E5%90%8E40%E5%9B%9E%E6%98%AF%E5%90%A6%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%86%99%E7%9A%84/20160729163738580" alt="这里写图片描述"><br>每一个点表示一回，红色的点表示的是前八十回，蓝色的点表示的是后四十回。从该图我们可以发现，前八十回和后四十回的写作者用词习惯有可观察到的不同，所以由此我们可以大胆的说，前后的写作者是不同的！</p>
<p>为了准确，我们还可以做一组对比试验，这次我们分别画出前四十回 ,中间四十回 和 后四十回：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#前四十回</span></span><br><span class="line">xs_a = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[:<span class="number">40</span>]]</span><br><span class="line">ys_a = [row[<span class="number">1</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[:<span class="number">40</span>]]</span><br><span class="line">zs_a = [row[<span class="number">2</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[:<span class="number">40</span>]]</span><br><span class="line"><span class="comment">#中间四十回</span></span><br><span class="line">xs_b = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[<span class="number">40</span>:<span class="number">80</span>]]</span><br><span class="line">ys_b = [row[<span class="number">1</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[<span class="number">40</span>:<span class="number">80</span>]]</span><br><span class="line">zs_b = [row[<span class="number">2</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[<span class="number">40</span>:<span class="number">80</span>]]</span><br><span class="line"><span class="comment">#最后四十回</span></span><br><span class="line">xs_c = [row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[-<span class="number">40</span>:]]</span><br><span class="line">ys_c = [row[<span class="number">1</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[-<span class="number">40</span>:]]</span><br><span class="line">zs_c = [row[<span class="number">2</span>] <span class="keyword">for</span> row <span class="keyword">in</span> z[-<span class="number">40</span>:]]</span><br><span class="line"></span><br><span class="line">ax.scatter(xs_a, ys_a, zs_a, c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax.scatter(xs_b, ys_b, zs_b, c=<span class="string">&#x27;y&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">ax.scatter(xs_c, ys_c, zs_c, c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.show()<span class="number">1234567891011121314151617</span></span><br></pre></td></tr></table></figure>
<p>画出的图表是这样：<br><img src="/../images/%E9%87%8D%E5%81%9A%E7%BA%A2%E6%A5%BC%E6%A2%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E5%88%A4%E6%96%AD%E5%89%8D80%E5%9B%9E%E5%90%8E40%E5%9B%9E%E6%98%AF%E5%90%A6%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%86%99%E7%9A%84/20160729164814901" alt="这里写图片描述"><br>蓝色的是前四十回，绿色的是中间四十回，红色的是后四十回。在这个图里我们也能看到前四十回和中间四十回重合了很多，而后四十回相对独立。</p>
<p><strong>十三、用机器学习的思路处理</strong><br>简单的说，就是我们把前八十回和后四十回分别做标注，用‘1’表示属于前八十回，‘0’表示属于后四十回。接着我们从前八十回中抽16回，后四十回中抽8回用作训练样本，剩下的用作测试样本。如果训练出来的模型成功从预测样本中预测出是否属于前八十回，就代表我们的想法是对的—–前八十回和后四十回的用词习惯的确不同。</p>
<p>上代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">label = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">120</span>):</span><br><span class="line">    <span class="keyword">if</span> i&lt;<span class="number">80</span>:</span><br><span class="line">        label.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        label.append(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 分出训练和测试样本</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(all_vectors, label, test_size=<span class="number">0.8</span>)</span><br><span class="line"><span class="comment"># 使用GridSearch找到合适的参数</span></span><br><span class="line">params = [&#123;<span class="string">&#x27;C&#x27;</span>:[<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">50</span>,<span class="number">100</span>,<span class="number">250</span>,<span class="number">500</span>]&#125;]</span><br><span class="line">grid = GridSearchCV(SVC(kernel=<span class="string">&#x27;linear&#x27;</span>),params,cv=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 训练！</span></span><br><span class="line">grid.fit(x_train,y_train)</span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred = grid.predict(x_test)</span><br><span class="line"><span class="comment"># 显示预测结果</span></span><br><span class="line">print(classification_report(y_test, y_pred))<span class="number">1234567891011121314151617</span></span><br></pre></td></tr></table></figure>
<p>最后我们的预测结果是这样的：</p>
<table>
<thead>
<tr>
<th>prediction</th>
<th>precision</th>
<th>recall</th>
<th>f1-score</th>
<th>support</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0.85</td>
<td>0.97</td>
<td>0.90</td>
<td>29</td>
</tr>
<tr>
<td>1</td>
<td>0.98</td>
<td>0.93</td>
<td>0.95</td>
<td>67</td>
</tr>
<tr>
<td>avg/total</td>
<td>0.94</td>
<td>0.94</td>
<td>0.94</td>
<td>96</td>
</tr>
</tbody></table>
<p>就结果而言，我们的模型比较准确的预测了测试样本属于哪个分类，说明我们的直观判断，可能是对的。</p>
<p>撒花~</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>-python</tag>
      </tags>
  </entry>
  <entry>
    <title>遗传算法详解（GA）</title>
    <url>/post/7e3b9734.html</url>
    <content><![CDATA[<p><strong>本文是去年课题组周报中的一个专题讲解，详细讲了GA，由于是周报，所以十分详细。很适合初学者入门。文中也简单提及了模拟退火算法。文章综合参考了一些互联网资料。发博客以备忘！</strong></p>
<p><strong>三：遗传算法</strong></p>
<p>​    照例先给出科学定义：</p>
<p>​    遗传算法（Genetic Algorithm, GA）起源于对生物系统所进行的计算机模拟研究。它是模仿自然界生物进化机制发展起来的随机全局搜索和优化方法，借鉴了达尔文的进化论和孟德尔的遗传学说。其本质是一种高效、并行、全局搜索的方法，能在搜索过程中自动获取和积累有关搜索空间的知识，并自适应地控制搜索过程以求得最佳解。</p>
<p>   <strong>再给出相关术语：（各位看看就好，后面都会涉及到，再细说）</strong></p>
<p>基因型(genotype)：性状染色体的内部表现；</p>
<p>表现型(phenotype)：染色体决定的性状的外部表现，或者说，根据基因型形成的个体的外部表现；</p>
<p>进化(evolution)：种群逐渐适应生存环境，品质不断得到改良。生物的进化是以种群的形式进行的。</p>
<p>适应度(fitness)：度量某个物种对于生存环境的适应程度。</p>
<p>选择(selection)：<strong>以一定的概率</strong>从种群中选择若干个个体。一般，选择过程是一种<strong>基于适应度</strong>的优胜劣汰的过程。</p>
<p>复制(reproduction)：细胞分裂时，遗传物质DNA通过复制而转移到新产生的细胞中，新细胞就继承了旧细胞的基因。</p>
<p>交叉(crossover)：两个染色体的某一相同位置处DNA被切断，前后两串分别交叉组合形成两个新的染色体。也称基因重组或杂交；</p>
<p>变异(mutation)：复制时可能（很小的概率）产生某些复制差错，变异产生新的染色体，表现出新的性状。</p>
<p>编码(coding)：DNA中遗传信息在一个长链上按一定的模式排列。遗传编码可看作从表现型到基因型的映射。</p>
<p>解码(decoding)：基因型到表现型的映射。</p>
<p>个体（individual）：指染色体带有特征的实体；</p>
<p>种群（population）：个体的集合，该集合内个体数称为种群的大小。 </p>
<p>​    遗传算法的有趣应用很多，诸如寻路问题，8数码问题，囚犯困境，动作控制，找圆心问题（在一个不规则的多边形中，寻找一个包含在该多边形内的最大圆圈的圆心），TSP问题，生产调度问题，人工生命模拟等。下面我以袋鼠为例子讲讲遗传算法。（因为袋鼠会跳） </p>
<p>   遗传算法中每一条染色体，对应着遗传算法的一个解决方案，一般我们用适应性函数（fitness function）来衡量这个解决方案的优劣。所以从一个基因组到其解的适应度形成一个映射。可以把遗传算法的过程看作是一个在多元函数里面求最优解的过程。 <strong>可以这样想象，这个多维曲面里面有数不清的“山峰”，而这些山峰所对应的就是局部最优解。而其中也会有一个“山峰”的海拔最高的，那么这个就是全局最优解。而遗传算法的任务就是尽量爬到最高峰，而不是陷落在一些小山峰。</strong>（另外，值得注意的是遗传算法不一定要找“最高的山峰”，如果问题的适应度评价越小越好的话，那么全局最优解就是函数的最小值，对应的，遗传算法所要找的就是“最深的谷底”）</p>
<p>​                            <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419105834575" alt="img"></p>
<p><strong>问题的提出与解决方案：</strong></p>
<p>  让我们先来考虑考虑下面这个问题的解决办法。</p>
<p>​      已知一元函数：<img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419105917087" alt="img"></p>
<p>现在要求在既定的区间内找出函数的最大值 </p>
<p>​               <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419105954545" alt="img"></p>
<p><strong>“袋鼠跳”问题</strong></p>
<p>​    既然我们把函数曲线理解成一个一个山峰和山谷组成的山脉。那么我们可以设想所得到的每一个解就是一只袋鼠，我们希望它们不断的向着更高处跳去，直到跳到最高的山峰（尽管袋鼠本身不见得愿意那么做）。所以求最大值的过程就转化成一个“袋鼠跳”的过程。</p>
<p>作为对比下面简单介绍“袋鼠跳”的几种方式。</p>
<p> \1. 爬山法（最速上升爬山法）：</p>
<p>   从搜索空间中随机产生邻近的点，从中选择对应解最优的个体，替换原来的个体，不断重复上述过程。因为爬山法只对“邻近”的点作比较，所以目光比较“短浅”，常常只能收敛到离开初始位置比较近的局部最优解上面。对于存在很多局部最优点的问题，通过一个简单的迭代找出全局最优解的机会非常渺茫。（在爬山法中，袋鼠最有希望到达最靠近它出发点的山顶，但不能保证该山顶是珠穆朗玛峰，或者是一个非常高的山峰。因为一路上它只顾上坡，没有下坡。）</p>
<p>\2. 模拟退火：</p>
<p>   这个方法来自金属热加工过程的启发。在金属热加工过程中，当金属的温度超过它的熔点（Melting Point）时，原子就会激烈地随机运动。与所有的其它的物理系统相类似，原子的这种运动趋向于寻找其能量的极小状态。在这个能量的变迁过程中，开始时，温度非常高， 使得原子具有很高的能量。随着温度不断降低，金属逐渐冷却，金属中的原子的能量就越来越小，最后达到所有可能的最低点。利用模拟退火的时候，让算法从较大的跳跃开始，使到它有足够的“能量”逃离可能“路过”的局部最优解而不至于限制在其中，当它停在全局最优解附近的时候，逐渐的减小跳跃量，以便使其“落脚 ”到全局最优解上。（在模拟退火中，袋鼠喝醉了，而且随机地大跳跃了很长时间。运气好的话，它从一个山峰跳过山谷，到了另外一个更高的山峰上。但最后，它渐渐清醒了并朝着它所在的峰顶跳去。）</p>
<p>\3. 遗传算法：</p>
<p>  模拟物竞天择的生物进化过程，通过维护一个潜在解的群体执行了多方向的搜索，并支持这些方向上的信息构成和交换。是以面为单位的搜索，比以点为单位的搜索，更能发现全局最优解。（在遗传算法中，有很多袋鼠，它们降落到喜玛拉雅山脉的任意地方。<strong>这些袋鼠并不知道它们的任务是寻找珠穆朗玛峰。</strong>但每过几年，就在一些海拔高度较低的地方射杀一些袋鼠，并希望存活下来的袋鼠是多产的，在它们所处的地方生儿育女<em>。</em>）（或者换个说法。从前，有一大群袋鼠，它们被莫名其妙的零散地遗弃于喜马拉雅山脉。于是只好在那里艰苦的生活。海拔低的地方弥漫着一种无色无味的毒气，海拔越高毒气越稀薄。可是可怜的袋鼠们对此<strong>全然不觉</strong>，还是习惯于活蹦乱跳。于是，不断有袋鼠死于海拔较低的地方，而越是在海拔高的袋鼠越是能活得更久，也越有机会生儿育女。就这样经过许多年，这些袋鼠们竟然都不自觉地聚拢到了一个个的山峰上，可是在所有的袋鼠中，只有聚拢到珠穆朗玛峰的袋鼠被带回了美丽的澳洲。）</p>
<p><strong>遗传算法的实现过程</strong></p>
<p>​    遗传算法的实现过程实际上就像自然界的进化过程那样。首先寻找一种对问题潜在解进行“数字化”编码的方案。（建立表现型和基因型的映射关系）然后用随机数初始化一个种群（那么第一批袋鼠就被随意地分散在山脉上），种群里面的个体就是这些数字化的编码。接下来，通过适当的解码过程之后（得到袋鼠的位置坐标），用适应性函数对每一个基因个体作一次适应度评估（袋鼠爬得越高，越是受我们的喜爱，所以适应度相应越高）。用选择函数按照某种规定择优选择（我们要每隔一段时间，在山上射杀一些所在海拔较低的袋鼠，以保证袋鼠总体数目持平。）。让个体基因变异（让袋鼠随机地跳一跳）。然后产生子代（希望存活下来的袋鼠是多产的，并在那里生儿育女）。遗传算法并不保证你能获得问题的最优解，但是使用遗传算法的最大优点在于你不必去了解和操心如何去“找”最优解。（你不必去指导袋鼠向那边跳，跳多远。）而只要简单的“否定”一些表现不好的个体就行了。（*<strong>*把那些总是爱走下坡路的袋鼠射杀，这就是遗传算法的精粹！\</strong>）**</p>
<p> <strong>所以我们总结出遗传算法的一般步骤：</strong></p>
<p>​    开始循环直至找到满意的解。</p>
<p>1.评估每条染色体所对应个体的适应度。</p>
<p>2.遵照适应度越高，选择概率越大的原则，从种群中选择两个个体作为父方和母方。</p>
<p>3.抽取父母双方的染色体，进行交叉，产生子代。</p>
<p>4.对子代的染色体进行变异。</p>
<p>5.重复2，3，4步骤，直到新种群的产生。</p>
<p>结束循环。</p>
<p>​                <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110213089" alt="img"></p>
<p><strong>接下来，我们将详细地剖析遗传算法过程的每一个细节。</strong></p>
<p><strong>编制袋鼠的染色体—-基因的编码方式</strong></p>
<p>   受到人类染色体结构的启发，我们可以设想一下，假设目前只有“0”，“1”两种碱基，我们也用一条链条把他们有序的串连在一起，因为每一个单位都能表现出 1 bit的信息量，所以一条足够长的染色体就能为我们勾勒出一个个体的所有特征。<strong>这就是二进制编码法</strong>，染色体大致如下：</p>
<p><strong>010010011011011110111110</strong></p>
<p>   上面的编码方式虽然简单直观，但明显地，当个体特征比较复杂的时候，需要大量的编码才能精确地描述，相应的解码过程（类似于生物学中的DNA翻译过程，就是把基因型映射到表现型的过程。）将过分繁复，为改善遗传算法的计算复杂性、提高运算效率，提出了浮点数编码。染色体大致如下：</p>
<p><strong>1.2 –3.3 – 2.0 –5.4 – 2.7 – 4.3</strong></p>
<p><strong>（注：还有一种编码方式叫符号编码）</strong></p>
<p>   那么我们如何利用这两种编码方式来为袋鼠的染色体编码呢？因为编码的目的是建立表现型到基因型的映射关系，而表现型一般就被理解为个体的特征。比如人的基因型是46条染色体所描述的却能解码成一个眼，耳，口，鼻等特征各不相同的活生生的人。所以我们要想为“袋鼠”的染色体编码，我们必须先来考虑“袋鼠”的“个体特征”是什么。也许有的人会说，袋鼠的特征很多，比如性别，身长，体重，也许它喜欢吃什么也能算作其中一个特征。但具体在解决这个问题的情况下，我们应该进一步思考：无论这只袋鼠是长短，肥瘦，黑白只要它在低海拔就会被射杀，同时也没有规定身长的袋鼠能跳得远一些，身短的袋鼠跳得近一些。当然它爱吃什么就更不相关了。<strong>我们由始至终都只关心一件事情：袋鼠在哪里。</strong>因为只要我们知道袋鼠在那里，我们就能做两件必须去做的事情：</p>
<p>（1）通过查阅喜玛拉雅山脉的地图来得知袋鼠所在的海拔高度（通过自变量求适应函数的值。）以判断我们有没必要把它射杀。</p>
<p>（2）知道袋鼠跳一跳（交叉和变异）后去到哪个新位置。</p>
<p>   如果我们一时无法准确的判断哪些“个体特征”是必要的，哪些是非必要的，我们常常可以用到这样一种思维方式：比如你认为袋鼠的爱吃什么东西非常必要，那么你就想一想，有两只袋鼠，它们其它的个体特征完全同等的情况下，一只长得黑，另外一只长得不是那么黑。你会马上发现，这不会对它们的命运有丝毫的影响，它们应该有同等的概率被射杀！<strong>只因它们处于同一个地方</strong>。（<strong>值得一提的是</strong>，如果你的基因编码设计中包含了袋鼠黑不黑的信息，这其实不会影响到袋鼠的进化的过程，而那只攀到珠穆朗玛峰的袋鼠黑与白什么的也完全是随机的，但是它所在的位置却是非常确定的。）</p>
<p>  <strong><em>\</em>以上是对遗传算法编码过程中经常经历的思维过程，必须把具体问题抽象成数学模型，突出主要矛盾，舍弃次要矛盾。只有这样才能简洁而有效的解决问题。**</strong></p>
<p>   既然确定了袋鼠的位置作为个体特征，具体来说位置就是横坐标。那么接下来，我们就要建立表现型到基因型的映射关系。就是说如何用编码来表现出袋鼠所在的横坐标。由于横坐标是一个实数，所以说透了我们就是要对这个实数编码。回顾我们上面所介绍的两种编码方式，最先想到的应该就是，对于二进制编码方式来说，编码会比较复杂，而对于浮点数编码方式来说，则会比较简洁。恩，正如你所想的，用浮点数编码，仅仅需要一个浮点数而已。而下面则介绍如何建立二进制编码到一个实数的映射。</p>
<p> 明显地，一定长度的二进制编码序列，只能表示一定精度的浮点数。譬如我们要求解<strong>精确到六位小数</strong>，由于区间长度为2 – (-1) = 3 ,为了保证精度要求，至少把区间[-1,2]分为3 × 106等份。又因为</p>
<p>​      <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110310909" alt="img"></p>
<p>所以编码的二进制串至少需要22位。</p>
<p>​    把一个二进制串（b0,b1,….bn)转化位区间里面对应的实数值通过下面两个步骤。</p>
<p>  （1）将一个二进制串代表的二进制数转化为10进制数：</p>
<p>​         <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110345793" alt="img"></p>
<p>  （2）对应区间内的实数：</p>
<p>​             <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110410684" alt="img"></p>
<p>   （像极了模数转换）</p>
<p>  例如一个二进制串&lt;1000101110110101000111&gt;表示实数值0.637197。</p>
<p>​     <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110442168" alt="img"></p>
<p>（纠正一个错误，这里是-1） </p>
<p>​    二进制串&lt;0000000000000000000000&gt;和&lt;1111111111111111111111&gt;则分别表示区间的两个端点值-1和2。</p>
<p>   好了，目前为止我们把袋鼠的染色体给研究透了，让我们继续跟进袋鼠的进化旅程</p>
<p><strong>物竞天择－－适应性评分与及选择函数。</strong></p>
<p><strong>1.物竞――适应度函数（fitness function）</strong></p>
<p>  自然界生物竞争过程往往包含两个方面：生物相互间的搏斗与及生物与客观环境的搏斗过程。但在我们这个实例里面，你可以想象到，袋鼠相互之间是非常友好的，它们并不需要互相搏斗以争取生存的权利。它们的生死存亡更多是取决于你的判断。因为你要衡量哪只袋鼠该杀，哪只袋鼠不该杀，所以你必须制定一个衡量的标准。而对于这个问题，这个衡量的标准比较容易制定：袋鼠所在的海拔高度。（因为你单纯地希望袋鼠爬得越高越好。）所以我们直接用袋鼠的海拔高度作为它们的适应性评分。即适应度函数直接返回函数值就行了。</p>
<p><strong>2.天择――选择函数（selection）</strong></p>
<p>  自然界中，越适应的个体就越有可能繁殖后代。但是也不能说适应度越高的就肯定后代越多，只能是从概率上来说更多。（毕竟有些所处海拔高度较低的袋鼠很幸运，逃过了你的眼睛。）那么我们怎么来建立这种概率关系呢？下面我们介绍一种常用的选择方法――轮盘赌（Roulette Wheel Selection）选择法。                 </p>
<p>   比如我们有5条染色体，他们所对应的适应度评分分别为：5，7，10，13，15。</p>
<p>​    所以累计总适应度为：</p>
<p>​                 <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110514403" alt="img"></p>
<p>​    所以各个个体被选中的概率分别为：</p>
<p>​         <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110549491" alt="img"></p>
<p> <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110611554" alt="img"></p>
<p>你可以想象一下，我们转动轮盘，轮盘停下来的时候，指针会随机地指向某一个个体所代表的区域，那么非常幸运地，这个个体被选中了。（很明显，适应度评分越高的个体被选中的概率越大。）</p>
<p><strong><em>\</em>注：还有精英选择机制**</strong></p>
<p><strong>遗传变异――基因重组（交叉）与基因突变。</strong></p>
<p> 应该说<strong>这两个步骤就是使得子代不同于父代的根本原因</strong>（<strong>注意，我没有说是子代优于父代，只有经过自然的选择后，才会出现子代优于父代的倾向。</strong>）。对于这两种遗传操作，二进制编码和浮点型编码在处理上有很大的差异，其中二进制编码的遗传操作过程，比较类似于自然界里面的过程，下面将分开讲述。</p>
<p><strong>1.基因重组/交叉(recombination/crossover)</strong></p>
<p>  （1）二进制编码</p>
<p>  二进制编码的基因交换过程非常类似高中生物中所讲的同源染色体的联会过程――随机把其中几个位于同一位置的编码进行交换，产生新的个体。</p>
<p><img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110643602" alt="img"></p>
<p>（2）浮点数编码</p>
<p>   如果一条基因中含有多个浮点数编码，那么也可以用跟上面类似的方法进行基因交叉，不同的是进行交叉的基本单位不是二进制码，而是浮点数。而如果对于单个浮点数的基因交叉，就有其它不同的重组方式了，比如中间重组：随机产生就能得到介于父代基因编码值和母代基因编码值之间的值作为子代基因编码的值。比如5.5和6交叉，产生5.7，5.6。</p>
<p>  考虑到“袋鼠跳”问题的具体情况――袋鼠的个体特征仅仅表现为它所处的位置。可以想象，同一个位置的袋鼠的基因是完全相同的，而两条相同的基因进行交叉后，相当于什么都没有做，所以我们不打算在这个例子里面使用交叉这一个遗传操作步骤。（当然硬要这个操作步骤也不是不行的，你可以把两只异地的袋鼠捉到一起，让它们交配，然后产生子代，再把它们送到它们应该到的地方。）</p>
<p><strong>2.基因突变(Mutation)</strong></p>
<p> （1）二进制编码</p>
<p>   基因突变过程：基因突变是染色体的某一个位点上基因的改变。基因突变使一个基因变成它的等位基因，并且通常会引起一定的表现型变化。正如上面所说，二进制编码的遗传操作过程和生物学中的过程非常相类似，基因串上的“ 0”或“ 1”有一定几率变成与之相反的“ 1”或“ 0”。例如下面这串二进制编码：</p>
<p><strong>101101001011001</strong></p>
<p>经过基因突变后，可能变成以下这串新的编码：</p>
<p><strong>001101011011001</strong></p>
<p>（2）浮点型编码</p>
<p>   浮点型编码的基因突变过程一般是对原来的浮点数增加或者减少一个小随机数。比如原来的浮点数串如下：</p>
<p>1.2,3.4,5.1, 6.0, 4.5</p>
<p>变异后，可能得到如下的浮点数串：</p>
<p>1.3,3.1,4.9, 6.3, 4.4</p>
<p> 当然，<strong>这个小随机数也有大小之分，我们一般管它叫“步长”。</strong>（想想“袋鼠跳”问题，袋鼠跳的长短就是这个步长。）一般来说<strong>步长越大，开始时进化的速度会比较快，但是后来比较难收敛到精确的点上</strong>。而小步长却能较精确的收敛到一个点上。所以<strong>很多时候为了加快遗传算法的进化速度，而又能保证后期能够比较精确地收敛到最优解上面，会采取动态改变步长的方法。</strong>其实这个过程与前面介绍的模拟退火过程比较相类似。</p>
<p> 到此为止，<strong>基因编码，基因适应度评估，基因选择，基因变异都一一实现了</strong>，剩下来的就是把这些遗传过程的“零件”装配起来了。（写成代码）</p>
<p>下面是上例的运行结果：</p>
<p> <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110727716" alt="img"></p>
<p>红点代表真实的最大点，由求导法可求的为f(1.85)=3.85</p>
<p> <img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110801498" alt="img"></p>
<p><img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110917904" alt="img"></p>
<p><img src="/../images/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3%EF%BC%88GA%EF%BC%89/20160419110954715" alt="img"></p>
<p><strong>总结：</strong></p>
<p><strong>编码原则</strong><br>完备性（completeness）：问题空间的所有解都能表示为所设计的基因型；<br>健全性（soundness）：任何一个基因型都对应于一个可能解；<br>非冗余性（non-redundancy）：问题空间和表达空间一一对应。</p>
<p><strong>适应度函数的重要性</strong><br>   适应度函数的选取直接影响遗传算法的收敛速度以及能否找到最优解。一般而言，适应度函数是由目标函数变换而成的。</p>
<p>适应度函数设计不当有可能出现欺骗问题：<br>（1）进化初期，个别超常个体控制选择过程；<br>（2）进化末期，个体差异太小导致陷入局部极值。</p>
<p>欺骗问题举例：</p>
<p>还是袋鼠问题，如果低海拔的地方出现毒雾，会杀死袋鼠，只有爬上珠穆朗玛峰顶端的袋鼠才能生存下来。</p>
<p>因为喜马拉雅山脉有很多山峰，我们以高度作为适应度，case（1）：如果不在珠峰的猴子若比在珠峰半山腰的猴子要高，因为种群大小不变，在珠峰的猴子可能就会被淘汰；case（2）：100只猴子都不在珠峰；</p>
<p>\1. 选择的作用：优胜劣汰，适者生存；</p>
<p>\2. 交叉的作用：保证种群的稳定性，朝着最优解的方向进化；</p>
<p>\3. 变异的作用：保证种群的多样性，避免交叉可能产生的局部收敛。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>-算法</tag>
      </tags>
  </entry>
  <entry>
    <title>香农信息量</title>
    <url>/post/6375c8f0.html</url>
    <content><![CDATA[<p>如果是连续型随机变量的情况，设p为随机变量X的概率分布，即p(x)为随机变量X在X=x处的概率密度函数值，则随机变量X在X=x处的香农信息量定义为：-<br>$$<br>log_2p(x)=log_2\frac{1}{p(x)}<br>$$<br>这时香农信息量的单位为比特。（如果非连续型随机变量，则为某一具体随机事件的概率，其他的同上）</p>
<p>香农信息量用于刻画消除随机变量在处的不确定性所需的信息量的大小。</p>
<p>上面是香农信息量的完整而严谨的表达，基本上读完就只剩下一个问题，为什么是这个式子？为了方便理解我们先看一下香农信息量在数据压缩应用的一般流程。</p>
<p>假设我们有一段数据长下面这样：aaBaaaVaaaaa</p>
<p>可以算出三个字母出现的概率分别为：</p>
<p>$$<br>a:\frac{10}{12}，B:\frac{1}{12}，V:\frac{1}{12}<br>$$<br>香农信息量为：a:0.263，B:3.585，V:3.585</p>
<p>也就是说如果我们要用比特来表述这几个字母，分别需要0.263，3.585，3.585个这样的比特。当然，由于比特是整数的，因此应该向上取整，变为1，4，4个比特。</p>
<p>这个时候我们就可以按照这个指导对字母进行编码，比如把a编码为”00”，把B编码为”10001000”，V编码为”10011001”，然后用编码替换掉字母来完成压缩编码，数据压缩结果为：001000000100100000。</p>
<p>上面例子看起来有点不合理，因为如果我们去搞，我们会编码出不一样的东西，如a编码为”00”，B编码为”1010”，V编码为”1111”，因此可以把数据压缩的更小。那么问题出现在哪呢？</p>
<p>出现在这里的B和V这两个字母只用两个比特进行编码对于他们自身而言并不是充分的。在另外一个压缩的例子中，可以一下子就看出来：abBcdeVfhgim</p>
<p>上面的每一个字母出现的概率都为<br>$$<br>\frac{1}{12}<br>$$<br>，假设我们还是以两个比特去编码B和V，那么就无法完全区分出12个字母。而如果是4个比特，便有16种可能性，可以足够区分这12个字母。</p>
<p>现在回过头来看香农信息量的公式，它正是告诉我们，如果已经知道一个事件出现的概率，至少需要多少的比特数才能完整描绘这个事件（无论外部其他事件的概率怎么变化），其中为底的2就是比特的两种可能性，而因为二分是一个除的关系，因此自变量是概率分之一而不是概率本身。</p>
<p>感性的看，如果我们知道a出现的概率为<br>$$<br>\frac{5}{6}<br>$$<br>，那么用比特中的”0”状态来表述它是完全合理的，因为其他事件的概率总和只有<br>$$<br>\frac{1}{6}<br>$$<br>，但我们给这<br>$$<br>\frac{1}{6}<br>$$<br>空出了比特的”1”这<br>$$<br>\frac{1}{2}<br>$$<br>的空间来表达他们，是完全足够的。</p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
</search>
